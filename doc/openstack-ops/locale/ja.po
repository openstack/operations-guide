# 
# Translators:
# Akihiro Motoki <amotoki@gmail.com>, 2013
# Akira Yoshiyama <akirayoshiyama@gmail.com>, 2013
# Andreas Jaeger <jaegerandi@gmail.com>, 2014
# Ying Chun Guo <daisy.ycguo@gmail.com>, 2013
# doki701 <tokidokidokidoki@gmail.com>, 2013
# yfukuda <fukuda.yuko@jp.fujitsu.com>, 2014
# Masanori Itoh <masanori.itoh@gmail.com>, 2013
# Masanori Itoh <masanori.itoh@gmail.com>, 2013
# Masayuki Igawa <masayuki.igawa@gmail.com>, 2013
# Masayuki Igawa <masayuki.igawa@gmail.com>, 2013
# myamamot <myamamot@redhat.com>, 2014
# *はたらくpokotan* <>, 2013
# Tomoaki Nakajima <>, 2013
# Yuki Shira <shirayuking@gmail.com>, 2013
# Shogo Sato <shogo.sato@gmail.com>, 2014
# tsutomu.takekawa <takekawa@gmail.com>, 2013
# Masanori Itoh <masanori.itoh@gmail.com>, 2013
# Toru Makabe <t.makabe@gmail.com>, 2013
# doki701 <tokidokidokidoki@gmail.com>, 2013
# Tom Fifield <tom@openstack.org>, 2014
# Tomoyuki KATO <tomo@dream.daynight.jp>, 2012-2014
# Toru Makabe <t.makabe@gmail.com>, 2013
# tsutomu.takekawa <takekawa@gmail.com>, 2013
# Ying Chun Guo <daisy.ycguo@gmail.com>, 2013
# ykatabam <ykatabam@redhat.com>, 2014
# Yuki Shira <shirayuking@gmail.com>, 2013
msgid ""
msgstr ""
"Project-Id-Version: OpenStack Manuals\n"
"POT-Creation-Date: 2014-10-30 08:05+0000\n"
"PO-Revision-Date: 2014-10-31 04:50+0000\n"
"Last-Translator: myamamot <myamamot@redhat.com>\n"
"Language-Team: Japanese (http://www.transifex.com/projects/p/openstack-manuals-i18n/language/ja/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: ja\n"
"Plural-Forms: nplurals=1; plural=0;\n"

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/app_roadmaps.xml45(None)
msgid ""
"@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc"
"/openstack-ops/figures/osog_ac01.png'; md5=THIS FILE DOESN'T EXIST"
msgstr "@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/openstack-ops/figures/osog_ac01.png'; md5=THIS FILE DOESN'T EXIST"

#: ./doc/openstack-ops/app_roadmaps.xml10(title)
msgid "Working with Roadmaps"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml12(para)
msgid ""
"The good news: OpenStack has unprecedented transparency when it comes to "
"providing information about what's coming up. The bad news: each release "
"moves very quickly. The purpose of this appendix is to highlight some of the"
" useful pages to track, and take an educated guess at what is coming up in "
"the Icehouse release and perhaps further afield.<indexterm "
"class=\"singular\"><primary>Icehouse</primary><secondary>upcoming release "
"of</secondary></indexterm><indexterm class=\"singular\"><primary>OpenStack "
"community</primary><secondary>working with "
"roadmaps</secondary><tertiary>release cycle</tertiary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml28(para)
msgid ""
"OpenStack follows a six month release cycle, typically releasing in "
"April/May and October/November each year. At the start of each cycle, the "
"community gathers in a single location for a design summit. At the summit, "
"the features for the coming releases are discussed, prioritized, and "
"planned. <xref linkend=\"release-cycle-diagram\"/> shows an example release "
"cycle, with dates showing milestone releases, code freeze, and string freeze"
" dates, along with an example of when the summit occurs. Milestones are "
"interim releases within the cycle that are available as packages for "
"download and testing. Code freeze is putting a stop to adding new features "
"to the release. String freeze is putting a stop to changing any strings "
"within the source code."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml41(title)
msgid "Release cycle diagram"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml51(title)
msgid "Information Available to You"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml53(para)
msgid ""
"There are several good sources of information available that you can use to "
"track your OpenStack development desires.<indexterm "
"class=\"singular\"><primary>OpenStack community</primary><secondary>working "
"with roadmaps</secondary><tertiary>information "
"available</tertiary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml63(para)
msgid ""
"Release notes are maintained on the OpenStack wiki, and also shown here:"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml69(th)
msgid "Series"
msgstr "シリーズ"

#: ./doc/openstack-ops/app_roadmaps.xml71(th)
msgid "Status"
msgstr "状態"

#: ./doc/openstack-ops/app_roadmaps.xml73(th)
msgid "Releases"
msgstr "リリース番号"

#: ./doc/openstack-ops/app_roadmaps.xml75(th)
msgid "Date"
msgstr "リリース日"

#: ./doc/openstack-ops/app_roadmaps.xml81(para)
msgid "Juno"
msgstr "Juno"

#: ./doc/openstack-ops/app_roadmaps.xml83(para)
msgid "Under development"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml87(link)
#: ./doc/openstack-ops/app_roadmaps.xml98(link)
msgid "2014.1"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml89(para)
#: ./doc/openstack-ops/app_roadmaps.xml100(para)
msgid "Apr 17, 2014"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml93(para)
msgid "Icehouse"
msgstr "Icehouse"

#: ./doc/openstack-ops/app_roadmaps.xml95(link)
msgid "Current stable release, security-supported"
msgstr "現在の安定版リリース、セキュリティアップデート対象"

#: ./doc/openstack-ops/app_roadmaps.xml104(para)
#: ./doc/openstack-ops/section_arch_example-nova.xml81(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml57(para)
msgid "Havana"
msgstr "Havana"

#: ./doc/openstack-ops/app_roadmaps.xml106(para)
msgid "Security-supported"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml109(link)
msgid "2013.2"
msgstr "2013.2"

#: ./doc/openstack-ops/app_roadmaps.xml112(para)
#: ./doc/openstack-ops/app_roadmaps.xml131(para)
msgid "Apr 4, 2013"
msgstr "2013年4月4日"

#: ./doc/openstack-ops/app_roadmaps.xml118(link)
msgid "2013.2.1"
msgstr "2013.2.1"

#: ./doc/openstack-ops/app_roadmaps.xml120(para)
msgid "Dec 16, 2013"
msgstr "2013年12月16日"

#: ./doc/openstack-ops/app_roadmaps.xml124(para)
msgid "Grizzly"
msgstr "Grizzly"

#: ./doc/openstack-ops/app_roadmaps.xml126(para)
msgid "EOL"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml128(link)
msgid "2013.1"
msgstr "2013.1"

#: ./doc/openstack-ops/app_roadmaps.xml137(link)
msgid "2013.1.1"
msgstr "2013.1.1"

#: ./doc/openstack-ops/app_roadmaps.xml139(para)
msgid "May 9, 2013"
msgstr "2013年5月9日"

#: ./doc/openstack-ops/app_roadmaps.xml145(link)
msgid "2013.1.2"
msgstr "2013.1.2"

#: ./doc/openstack-ops/app_roadmaps.xml147(para)
msgid "Jun 6, 2013"
msgstr "2013年6月6日"

#: ./doc/openstack-ops/app_roadmaps.xml153(link)
msgid "2013.1.3"
msgstr "2013.1.3"

#: ./doc/openstack-ops/app_roadmaps.xml155(para)
msgid "Aug 8, 2013"
msgstr "2013年8月8日"

#: ./doc/openstack-ops/app_roadmaps.xml161(link)
msgid "2013.1.4"
msgstr "2013.1.4"

#: ./doc/openstack-ops/app_roadmaps.xml163(para)
msgid "Oct 17, 2013"
msgstr "2013年10月17日"

#: ./doc/openstack-ops/app_roadmaps.xml167(para)
msgid "Folsom"
msgstr "Folsom"

#: ./doc/openstack-ops/app_roadmaps.xml169(para)
#: ./doc/openstack-ops/app_roadmaps.xml212(para)
msgid "Community-supported"
msgstr "コミュニティによるサポートが行われている"

#: ./doc/openstack-ops/app_roadmaps.xml171(link)
msgid "2012.2"
msgstr "2012.2"

#: ./doc/openstack-ops/app_roadmaps.xml174(para)
msgid "Sep 27, 2012"
msgstr "2012年9月27日"

#: ./doc/openstack-ops/app_roadmaps.xml180(link)
msgid "2012.2.1"
msgstr "2012.2.1"

#: ./doc/openstack-ops/app_roadmaps.xml182(para)
msgid "Nov 29, 2012"
msgstr "2012年11月29日"

#: ./doc/openstack-ops/app_roadmaps.xml188(link)
msgid "2012.2.2"
msgstr "2012.2.2"

#: ./doc/openstack-ops/app_roadmaps.xml190(para)
msgid "Dec 13, 2012"
msgstr "2012年12月13日"

#: ./doc/openstack-ops/app_roadmaps.xml196(link)
msgid "2012.2.3"
msgstr "2012.2.3"

#: ./doc/openstack-ops/app_roadmaps.xml198(para)
msgid "Jan 31, 2013"
msgstr "2013年1月31日"

#: ./doc/openstack-ops/app_roadmaps.xml204(link)
msgid "2012.2.4"
msgstr "2012.2.4"

#: ./doc/openstack-ops/app_roadmaps.xml206(para)
msgid "Apr 11, 2013"
msgstr "2013年4月11日"

#: ./doc/openstack-ops/app_roadmaps.xml210(para)
msgid "Essex"
msgstr "Essex"

#: ./doc/openstack-ops/app_roadmaps.xml214(link)
msgid "2012.1"
msgstr "2012.1"

#: ./doc/openstack-ops/app_roadmaps.xml217(para)
msgid "Apr 5, 2012"
msgstr "2012年4月5日"

#: ./doc/openstack-ops/app_roadmaps.xml223(link)
msgid "2012.1.1"
msgstr "2012.1.1"

#: ./doc/openstack-ops/app_roadmaps.xml225(para)
msgid "Jun 22, 2012"
msgstr "2012年6月22日"

#: ./doc/openstack-ops/app_roadmaps.xml231(link)
msgid "2012.1.2"
msgstr "2012.1.2"

#: ./doc/openstack-ops/app_roadmaps.xml233(para)
msgid "Aug 10, 2012"
msgstr "2012年8月10日"

#: ./doc/openstack-ops/app_roadmaps.xml239(link)
msgid "2012.1.3"
msgstr "2012.1.3"

#: ./doc/openstack-ops/app_roadmaps.xml241(para)
msgid "Oct 12, 2012"
msgstr "2012年10月12日"

#: ./doc/openstack-ops/app_roadmaps.xml245(para)
msgid "Diablo"
msgstr "Diablo"

#: ./doc/openstack-ops/app_roadmaps.xml247(para)
#: ./doc/openstack-ops/app_roadmaps.xml266(para)
#: ./doc/openstack-ops/app_roadmaps.xml277(para)
#: ./doc/openstack-ops/app_roadmaps.xml288(para)
msgid "Deprecated"
msgstr "非推奨"

#: ./doc/openstack-ops/app_roadmaps.xml249(link)
msgid "2011.3"
msgstr "2011.3"

#: ./doc/openstack-ops/app_roadmaps.xml252(para)
msgid "Sep 22, 2011"
msgstr "2011年9月22日"

#: ./doc/openstack-ops/app_roadmaps.xml258(link)
msgid "2011.3.1"
msgstr "2011.3.1"

#: ./doc/openstack-ops/app_roadmaps.xml260(para)
msgid "Jan 19, 2012"
msgstr "2012年1月19日"

#: ./doc/openstack-ops/app_roadmaps.xml264(para)
msgid "Cactus"
msgstr "Cactus"

#: ./doc/openstack-ops/app_roadmaps.xml268(link)
msgid "2011.2"
msgstr "2011.2"

#: ./doc/openstack-ops/app_roadmaps.xml271(para)
msgid "Apr 15, 2011"
msgstr "2011年4月15日"

#: ./doc/openstack-ops/app_roadmaps.xml275(para)
msgid "Bexar"
msgstr "Bexar"

#: ./doc/openstack-ops/app_roadmaps.xml279(link)
msgid "2011.1"
msgstr "2011.1"

#: ./doc/openstack-ops/app_roadmaps.xml282(para)
msgid "Feb 3, 2011"
msgstr "2011年2月3日"

#: ./doc/openstack-ops/app_roadmaps.xml286(para)
msgid "Austin"
msgstr "Austin"

#: ./doc/openstack-ops/app_roadmaps.xml290(link)
msgid "2010.1"
msgstr "2010.1"

#: ./doc/openstack-ops/app_roadmaps.xml293(para)
msgid "Oct 21, 2010"
msgstr "2010年10月21日"

#: ./doc/openstack-ops/app_roadmaps.xml298(para)
msgid "Here are some other resources:"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml302(link)
msgid ""
"A breakdown of current features under development, with their target "
"milestone"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml308(link)
msgid "A list of all features, including those not yet under development"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml313(link)
msgid "Rough-draft design discussions (\"etherpads\") from the last design summit"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml318(link)
msgid "List of individual code changes under review"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml325(title)
msgid "Influencing the Roadmap"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml327(para)
msgid ""
"OpenStack truly welcomes your ideas (and contributions) and highly values "
"feedback from real-world users of the software. By learning a little about "
"the process that drives feature development, you can participate and perhaps"
" get the additions you desire.<indexterm "
"class=\"singular\"><primary>OpenStack community</primary><secondary>working "
"with roadmaps</secondary><tertiary>influencing</tertiary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml339(para)
msgid ""
"Feature requests typically start their life in Etherpad, a collaborative "
"editing tool, which is used to take coordinating notes at a design summit "
"session specific to the feature. This then leads to the creation of a "
"blueprint on the Launchpad site for the particular project, which is used to"
" describe the feature more formally. Blueprints are then approved by project"
" team members, and development can begin."
msgstr "機能追加リクエストは、通常 Etherpad で始まります。Etherpad は共同編集ツールで、デザインサミットのその機能に関するセッションで議論を整理するのに使われます。続けて、プロジェクトの Launchpad サイトに blueprint が作成され、blueprint を使ってよりきちんとした形で機能が規定されていきます。 この後、blueprint はプロジェクトメンバーによって承認され、開発が始まります。"

#: ./doc/openstack-ops/app_roadmaps.xml346(para)
msgid ""
"Therefore, the fastest way to get your feature request up for consideration "
"is to create an Etherpad with your ideas and propose a session to the design"
" summit. If the design summit has already passed, you may also create a "
"blueprint directly. Read this <link href=\"http://vmartinezdelacruz.com/how-"
"to-work-with-blueprints-without-losing-your-mind/\">blog post about how to "
"work with blueprints</link> the perspective of Victoria Martínez, a "
"developer intern."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml354(para)
msgid ""
"The roadmap for the next release as it is developed can be seen at <link "
"href=\"http://status.openstack.org/release/\">Releases</link>."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml357(para)
msgid ""
"To determine the potential features going in to future releases, or to look "
"at features implemented previously, take a look at the existing blueprints "
"such as <link href=\"https://blueprints.launchpad.net/nova\">OpenStack "
"Compute (nova) Blueprints</link>, <link "
"href=\"https://blueprints.launchpad.net/keystone\">OpenStack Identity "
"(keystone) Blueprints</link>, and release notes."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml364(para)
msgid ""
"Aside from the direct-to-blueprint pathway, there is another very well-"
"regarded mechanism to influence the development roadmap: the user survey. "
"Found at <link href=\"http://openstack.org/user-survey\"/>, it allows you to"
" provide details of your deployments and needs, anonymously by default. Each"
" cycle, the user committee analyzes the results and produces a report, "
"including providing specific information to the technical committee and "
"technical leads of the projects."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml375(title)
msgid "Aspects to Watch"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml377(para)
msgid ""
"You want to keep an eye on the areas improving within OpenStack. The best "
"way to \"watch\" roadmaps for each project is to look at the blueprints that"
" are being approved for work on milestone releases. You can also learn from "
"PTL webinars that follow the OpenStack summits twice a year.<indexterm "
"class=\"startofrange\" xml:id=\"OSaspect\"><primary>OpenStack "
"community</primary><secondary>working with "
"roadmaps</secondary><tertiary>aspects to watch</tertiary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml390(title)
msgid "Driver Quality Improvements"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml392(para)
msgid ""
"A major quality push has occurred across drivers and plug-ins in Block "
"Storage, Compute, and Networking. Particularly, developers of Compute and "
"Networking drivers that require proprietary or hardware products are now "
"required to provide an automated external testing system for use during the "
"development process."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml400(title)
msgid "Easier Upgrades"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml402(para)
msgid ""
"One of the most requested features since OpenStack began (for components "
"other than Object Storage, which tends to \"just work\"): easier upgrades. "
"From Grizzly onward (and significantly improved in Havana), internal "
"messaging communication is versioned, meaning services can theoretically "
"drop back to backward-compatible behavior. This allows you to run later "
"versions of some components, while keeping older versions of others."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml410(para)
msgid ""
"In addition, a lot of focus has been placed on database migrations. These "
"are now better managed, including the use of the Turbo Hipster tool, which "
"tests database migration performance on copies of real-world user databases."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml415(para)
msgid ""
"These changes have facilitated the first proper OpenStack upgrade guide, "
"found in <xref linkend=\"ch_ops_upgrades\"/>, and will continue to improve "
"in Icehouse.<indexterm "
"class=\"singular\"><primary>Icehouse</primary><secondary>upgrades "
"in</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml425(title)
msgid "Deprecation of Nova Network"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml427(para)
msgid ""
"With the introduction of the full software-defined networking stack provided"
" by OpenStack Networking (neutron) in the Folsom release, development effort"
" on the initial networking code that remains part of the Compute component "
"has gradually lessened. While many still use <literal>nova-network</literal>"
" in production, there has been a long-term plan to remove the code in favor "
"of the more flexible and full-featured OpenStack Networking.<indexterm "
"class=\"singular\"><primary>nova</primary><secondary>deprecation "
"of</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml439(para)
msgid ""
"An attempt was made to deprecate <literal>nova-network</literal> during the "
"Havana release, which was aborted due to the lack of equivalent "
"functionality (such as the FlatDHCP multi-host high-availability mode "
"mentioned in this guide), lack of a migration path between versions, "
"insufficient testing, and simplicity when used for the more straightforward "
"use cases <literal>nova-network</literal> traditionally supported. Though "
"significant effort has been made to address these concerns, <literal>nova-"
"network</literal> will not be deprecated in the Icehouse release. In "
"addition, the Program Technical Lead of the Compute project has indicated "
"that, to a limited degree, patches to <literal>nova-network</literal> will "
"now again begin to be accepted.<indexterm "
"class=\"singular\"><primary>Icehouse</primary><secondary>nova network "
"deprecation</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml456(para)
msgid ""
"This leaves you with an important point of decision when designing your "
"cloud. OpenStack Networking is robust enough to use with a small number of "
"limitations (IPv6 support, performance issues in some scenarios) and "
"provides many more features than <literal>nova-network</literal>. However, "
"if you do not have the more complex use cases that can benefit from fuller "
"software-defined networking capabilities, or are uncomfortable with the new "
"concepts introduced, <literal>nova-network</literal> may continue to be a "
"viable option for the next 12 to 18 months."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml466(para)
msgid ""
"Similarly, if you have an existing cloud and are looking to upgrade from "
"<literal>nova-network</literal> to OpenStack Networking, you should have the"
" option to delay the upgrade for this period of time. However, each release "
"of OpenStack brings significant new innovation, and regardless of your use "
"of networking methodology, it is likely best to begin planning for an "
"upgrade within a reasonable timeframe of each release."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml474(para)
msgid ""
"As mentioned, there's currently no way to cleanly migrate from <literal"
">nova-network</literal> to neutron. We recommend that you keep a migration "
"in mind and what that process might involve for when a proper migration path"
" is released. If you must upgrade, please be aware that both service and "
"instance downtime is likely unavoidable."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml483(title)
msgid ""
"Replacement of Open vSwitch Plug-in with <phrase role=\"keep-"
"together\">Modular Layer 2</phrase>"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml486(para)
msgid ""
"The Modular Layer 2 plug-in is a framework allowing OpenStack Networking to "
"simultaneously utilize the variety of layer-2 networking technologies found "
"in complex real-world data centers. It currently works with the existing "
"Open vSwitch, Linux Bridge, and Hyper-V L2 agents and is intended to replace"
" and deprecate the monolithic plug-ins associated with those L2 agents."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml495(title)
msgid "Compute V3 API"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml497(para)
msgid ""
"The third version of the Compute API was broadly discussed and worked on "
"during the Havana and Icehouse release cycles. Current discussions indicate "
"that the V2 API will remain for many releases, but this is a great time to "
"evaluate the Compute API and provide comments while it is being defined. Of "
"particular note is the decision that the V3 API will not support XML "
"messages—being JSON only. This was based on the poor testing of existing XML"
" responses in the V2 API and the lack of effort to continue to develop and "
"maintain an entire second response type. Feedback on this and any such "
"change is welcome by responding to the <link "
"href=\"https://www.openstack.org/user-survey/Login\">user "
"survey</link>.<indexterm "
"class=\"singular\"><primary>Icehouse</primary><secondary>Compute V3 "
"API</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml515(title)
msgid "OpenStack on OpenStack (TripleO)"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml517(para)
msgid ""
"This project continues to improve and you may consider using it for "
"greenfield <phrase role=\"keep-together\">deployments</phrase>."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml522(title)
msgid "Data Processing (Sahara)"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml524(para)
msgid ""
"A much-requested answer to big data problems, a dedicated team has been "
"making solid progress on a Hadoop-as-a-Service project."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml529(title)
msgid "Bare-Metal Deployment (Ironic)"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml531(para)
msgid ""
"Though bare-metal deployment has been widely lauded, and development "
"continues, the project to replace the Compute bare-metal driver will not "
"graduate in Icehouse. A particular blueprint to follow is <link "
"href=\"https://blueprints.launchpad.net/ironic/+spec/migration-from-nova\"> "
"Migration Path from Nova's BM Driver</link>, which tracks the ability to "
"move to the new project from an existing bare-metal deployment.<indexterm "
"class=\"singular\"><primary>Icehouse</primary><secondary>Compute bare-metal "
"deployment</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml544(title)
msgid "Database as a Service (Trove)"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml546(para)
msgid ""
"The OpenStack community has had a database-as-a-service tool in development "
"for some time, and we will finally see the first integrated release of it in"
" Icehouse. Initially, it will only support MySQL, with further options "
"available in Juno onward, but it should be able to deploy database servers "
"out of the box in a highly available way from this release.<indexterm "
"class=\"singular\"><primary>Icehouse</primary><secondary>database-"
"as-a-service tool</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml559(title)
msgid "Messaging as a Service (Marconi)"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml561(para)
msgid ""
"A service to provide queues of messages and notifications has entered "
"“incubation,” meaning if the upcoming development cycles are successful, it "
"will be released in <phrase role=\"keep-together\">Juno</phrase>."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml568(title)
msgid "Scheduler Improvements"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml570(para)
msgid ""
"Both Compute and Block Storage rely on schedulers to determine where to "
"place virtual machines or volumes. In Havana, the Compute scheduler "
"underwent significant improvement, while in Icehouse the scheduler in Block "
"Storage is slated for a boost. Further down the track, an effort started "
"this cycle that aims to create a holistic scheduler covering both will come "
"to fruition.<indexterm "
"class=\"singular\"><primary>Icehouse</primary><secondary>scheduler "
"improvements</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml582(title)
msgid "Block Storage Improvements"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml584(para)
msgid ""
"The team discussed many areas of work at the Icehouse summit, including "
"volume migration support, Ceph integration, and access control for volumes."
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml590(title)
msgid "Toward a Python SDK"
msgstr ""

#: ./doc/openstack-ops/app_roadmaps.xml592(para)
msgid ""
"Though many successfully use the various python-*client code as an effective"
" SDK for interacting with OpenStack, consistency between the projects and "
"documentation availability waxes and wanes. To combat this, an <link "
"href=\"https://wiki.openstack.org/wiki/PythonOpenStackSDK\">effort to "
"improve the experience</link> has started. Cross-project development efforts"
" in OpenStack have a checkered history, such as the <link "
"href=\"https://wiki.openstack.org/wiki/OpenStackClient\"> unified client "
"project</link> having several false starts. However, the early signs for the"
" SDK project are promising, and we expect to see results during the Juno "
"cycle.<indexterm class=\"endofrange\" startref=\"OSaspect\"/>"
msgstr ""

#: ./doc/openstack-ops/bk_ops_guide.xml16(title)
msgid "OpenStack Operations Guide"
msgstr "OpenStack 運用ガイド"

#: ./doc/openstack-ops/bk_ops_guide.xml18(titleabbrev)
msgid "OpenStack Ops Guide"
msgstr "OpenStack 運用ガイド"

#: ./doc/openstack-ops/bk_ops_guide.xml26(orgname)
#: ./doc/openstack-ops/bk_ops_guide.xml32(holder)
msgid "OpenStack Foundation"
msgstr "OpenStack Foundation"

#: ./doc/openstack-ops/bk_ops_guide.xml31(year)
msgid "2014"
msgstr "2014"

#: ./doc/openstack-ops/bk_ops_guide.xml34(productname)
#: ./doc/openstack-ops/ch_ops_resources.xml13(title)
msgid "OpenStack"
msgstr "OpenStack"

#: ./doc/openstack-ops/bk_ops_guide.xml38(remark)
msgid "Copyright details are filled in by the template."
msgstr "Copyright details are filled in by the template."

#: ./doc/openstack-ops/bk_ops_guide.xml43(para)
msgid ""
"This book provides information about designing and operating OpenStack "
"clouds."
msgstr "本書は OpenStack クラウドの設計および運用に関する情報を提供します。"

#: ./doc/openstack-ops/part_operations.xml9(title)
msgid "Operations"
msgstr "運用"

#: ./doc/openstack-ops/part_operations.xml12(para)
msgid ""
"Congratulations! By now, you should have a solid design for your cloud. We "
"now recommend that you turn to the OpenStack Installation Guide (<link "
"href=\"http://docs.openstack.org/havana/install-guide/install/apt/\"/> for "
"Ubuntu, for example), which contains a step-by-step guide on how to manually"
" install the OpenStack packages and dependencies on your cloud."
msgstr ""

#: ./doc/openstack-ops/part_operations.xml18(para)
msgid ""
"While it is important for an operator to be familiar with the steps involved"
" in deploying OpenStack, we also strongly encourage you to evaluate "
"configuration-management tools, such as <glossterm>Puppet</glossterm> or "
"<glossterm>Chef</glossterm>, which can help automate this deployment "
"process.<indexterm "
"class=\"singular\"><primary>Chef</primary></indexterm><indexterm "
"class=\"singular\"><primary>Puppet</primary></indexterm>"
msgstr "オペレータはOpenStackのデプロイに必要な手順に精通している事は重要ですが、一方で、 <glossterm>Puppet</glossterm> や <glossterm>Chef</glossterm>と言った構成管理ツールの検証評価をする事を強くお勧めします。それらは自動構成をする手助けとなります。<indexterm class=\"singular\"><primary>Chef</primary></indexterm><indexterm class=\"singular\"><primary>Puppet</primary></indexterm>"

#: ./doc/openstack-ops/part_operations.xml28(para)
msgid ""
"In the remainder of this guide, we assume that you have successfully "
"deployed an OpenStack cloud and are able to perform basic operations such as"
" adding images, booting instances, and attaching volumes."
msgstr "このガイドの残りの部分では、OpenStackクラウドの構成が無事に成功し、イメージの追加、インスタンスの起動、ボリュームの追加が行えるようになったとします。"

#: ./doc/openstack-ops/part_operations.xml32(para)
msgid ""
"As your focus turns to stable operations, we recommend that you do skim the "
"remainder of this book to get a sense of the content. Some of this content "
"is useful to read in advance so that you can put best practices into effect "
"to simplify your life in the long run. Other content is more useful as a "
"reference that you might turn to when an unexpected event occurs (such as a "
"power failure), or to troubleshoot a particular problem."
msgstr "焦点を安定運用に切り替えるために、この文書の残りの部分をざっくりと読み、感覚をつかむ事をお勧めします。長期運用に向けてのベストプラクティスを実施するためこの文書のいくつかのコンテンツはあらかじめ読んでおくと役に立つでしょう。その他のコンテンツは(電源障害のような)予期しないイベントが発生した場合や特定の問題のトラブルシューティングをする際に役に立つリファレンスとして役に立つでしょう。"

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml88(None)
msgid ""
"@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc"
"/openstack-ops/figures/osog_1201.png'; md5=THIS FILE DOESN'T EXIST"
msgstr ""

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml207(None)
msgid ""
"@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc"
"/openstack-ops/figures/osog_1202.png'; md5=THIS FILE DOESN'T EXIST"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml12(title)
msgid "Network Troubleshooting"
msgstr "ネットワークのトラブルシューティング"

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml14(para)
msgid ""
"Network troubleshooting can unfortunately be a very difficult and confusing "
"procedure. A network issue can cause a problem at several points in the "
"cloud. Using a logical troubleshooting procedure can help mitigate the "
"confusion and more quickly isolate where exactly the network issue is. This "
"chapter aims to give you the information you need to identify any issues for"
" either <literal>nova-network</literal> or OpenStack Networking (neutron) "
"with Linux Bridge or Open vSwitch.<indexterm "
"class=\"singular\"><primary>OpenStack Networking "
"(neutron)</primary><secondary>troubleshooting</secondary></indexterm><indexterm"
" class=\"singular\"><primary>Linux "
"Bridge</primary><secondary>troubleshooting</secondary></indexterm><indexterm"
" class=\"singular\"><primary>network "
"troubleshooting</primary><see>troubleshooting</see></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml35(title)
msgid "Using \"ip a\" to Check Interface States"
msgstr "「ip a」を使ってインタフェース状態をチェックする"

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml37(para)
msgid ""
"On compute nodes and nodes running <literal>nova-network</literal>, use the "
"following command to see information about interfaces, including information"
" about IPs, VLANs, and whether your interfaces are up:<indexterm "
"class=\"singular\"><primary>ip a command</primary></indexterm><indexterm "
"class=\"singular\"><primary>interface states, "
"checking</primary></indexterm><indexterm "
"class=\"singular\"><primary>troubleshooting</primary><secondary>checking "
"interface states</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml52(para)
msgid ""
"If you're encountering any sort of networking difficulty, one good initial "
"sanity check is to make sure that your interfaces are up. For example:"
msgstr "もしあなたがネットワークの問題に直面した場合、まず最初にするとよいのは、インターフェイスがUPになっているかを確認することです。例えば、"

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml66(para)
msgid ""
"You can safely ignore the state of <literal>virbr0</literal>, which is a "
"default bridge created by libvirt and not used by OpenStack."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml71(title)
msgid "Visualizing nova-network Traffic in the Cloud"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml73(para)
msgid ""
"If you are logged in to an instance and ping an external host—for example, "
"Google—the ping packet takes the route shown in <xref "
"linkend=\"traffic-12-1\"/>.<indexterm class=\"singular\"><primary>ping "
"packets</primary></indexterm><indexterm "
"class=\"singular\"><primary>troubleshooting</primary><secondary>nova-network"
" traffic</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml84(title)
msgid "Traffic route for ping packet"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml95(para)
msgid ""
"The instance generates a packet and places it on the virtual Network "
"Interface Card (NIC) inside the instance, such as <literal>eth0</literal>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml101(para)
msgid ""
"The packet transfers to the virtual NIC of the compute host, such as, "
"<literal>vnet1</literal>. You can find out what vnet NIC is being used by "
"looking at the <filename>/etc/libvirt/qemu/instance-xxxxxxxx.xml</filename> "
"file."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml109(para)
msgid ""
"From the vnet NIC, the packet transfers to a bridge on the compute node, "
"such as <code>br100</code>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml112(para)
msgid ""
"If you run FlatDHCPManager, one bridge is on the compute node. If you run "
"VlanManager, one bridge exists for each VLAN."
msgstr "もしFlatDHCPManagerを使っているのであれば、ブリッジはコンピュートノード上に一つです。VlanManagerであれば、VLANごとにブリッジが存在します。"

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml115(para)
msgid ""
"To see which bridge the packet will use, run the command: <placeholder-1/>"
msgstr "下記コマンドを実行することで、パケットがどのブリッジを使うか確認できます。<placeholder-1/>"

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml118(para)
msgid ""
"Look for the vnet NIC. You can also reference <filename>nova.conf</filename>"
" and look for the <code>flat_interface_bridge</code> option."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml124(para)
msgid ""
"The packet transfers to the main NIC of the compute node. You can also see "
"this NIC in the <literal>brctl</literal> output, or you can find it by "
"referencing the <literal>flat_interface</literal> option in "
"<filename>nova.conf</filename>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml131(para)
msgid ""
"After the packet is on this NIC, it transfers to the compute node's default "
"gateway. The packet is now most likely out of your control at this point. "
"The diagram depicts an external gateway. However, in the default "
"configuration with multi-host, the compute host is the gateway."
msgstr "パケットはこのNICに送られた後、コンピュートノードのデフォルトゲートウェイに転送されます。パケットはこの時点で、おそらくあなたの管理範囲外でしょう。図には外部ゲートウェイを描いていますが、マルチホストのデフォルト構成では、コンピュートホストがゲートウェイです。"

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml139(para)
msgid ""
"Reverse the direction to see the path of a ping reply. From this path, you "
"can see that a single packet travels across four different NICs. If a "
"problem occurs with any of these NICs, a network issue occurs."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml145(title)
msgid "Visualizing OpenStack Networking Service Traffic in the Cloud"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml148(para)
msgid ""
"The OpenStack Networking Service, neutron, has many more degrees of freedom "
"than <literal>nova-network</literal> does because of its pluggable backend. "
"It can be configured with open source or vendor proprietary plug-ins that "
"control software defined networking (SDN) hardware or plug-ins that use "
"Linux native facilities on your hosts, such as Open vSwitch or Linux "
"Bridge.<indexterm class=\"startofrange\" "
"xml:id=\"Topen\"><primary>troubleshooting</primary><secondary>OpenStack "
"traffic</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml159(para)
msgid ""
"The networking chapter of the OpenStack <link "
"href=\"http://docs.openstack.org/admin-guide-"
"cloud/content/ch_networking.html\" title=\"Cloud Administrator Guide\">Cloud"
" Administrator Guide</link> shows a variety of networking scenarios and "
"their connection paths. The purpose of this section is to give you the tools"
" to troubleshoot the various components involved however they are plumbed "
"together in your environment."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml167(para)
msgid ""
"For this example, we will use the Open vSwitch (OVS) backend. Other backend "
"plug-ins will have very different flow paths. OVS is the most popularly "
"deployed network driver, according to the October 2013 OpenStack User "
"Survey, with 50 percent more sites using it than the second place Linux "
"Bridge driver. We'll describe each step in turn, with <xref linkend"
"=\"neutron-packet-ping\"/> for reference."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml176(para)
msgid ""
"The instance generates a packet and places it on the virtual NIC inside the "
"instance, such as eth0."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml181(para)
msgid ""
"The packet transfers to a Test Access Point (TAP) device on the compute "
"host, such as tap690466bc-92. You can find out what TAP is being used by "
"looking at the <filename>/etc/libvirt/qemu/instance-xxxxxxxx.xml</filename> "
"file."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml187(para)
msgid ""
"The TAP device name is constructed using the first 11 characters of the port"
" ID (10 hex digits plus an included '-'), so another means of finding the "
"device name is to use the <literal>neutron</literal> command. This returns a"
" pipe-delimited list, the first item of which is the port ID. For example, "
"to get the port ID associated with IP address 10.0.0.10, do this:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml197(para)
msgid ""
"Taking the first 11 characters, we can construct a device name of "
"tapff387e54-9e from this output."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml203(title)
msgid "Neutron network paths"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml214(para)
msgid ""
"The TAP device is connected to the integration bridge, <code>br-int</code>. "
"This bridge connects all the instance TAP devices and any other bridges on "
"the system. In this example, we have <code>int-br-eth1</code> and <code"
">patch-tun</code>. <code>int-br-eth1</code> is one half of a veth pair "
"connecting to the bridge <code>br-eth1</code>, which handles VLAN networks "
"trunked over the physical Ethernet device <code>eth1</code>. <code>patch-"
"tun</code> is an Open vSwitch internal port that connects to the <code>br-"
"tun</code> bridge for GRE networks."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml224(para)
msgid ""
"The TAP devices and veth devices are normal Linux network devices and may be"
" inspected with the usual tools, such as <literal>ip</literal> and "
"<literal>tcpdump</literal>. Open vSwitch internal devices, such as <code"
">patch-tun</code>, are only visible within the Open vSwitch environment. If "
"you try to run <literal>tcpdump -i patch-tun</literal>, it will raise an "
"error, saying that the device does not exist."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml232(para)
msgid ""
"It is possible to watch packets on internal interfaces, but it does take a "
"little bit of networking gymnastics. First you need to create a dummy "
"network device that normal Linux tools can see. Then you need to add it to "
"the bridge containing the internal interface you want to snoop on. Finally, "
"you need to tell Open vSwitch to mirror all traffic to or from the internal "
"port onto this dummy port. After all this, you can then run "
"<literal>tcpdump</literal> on the dummy interface and see the traffic on the"
" internal port."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml242(title)
msgid ""
"To capture packets from the <code>patch-tun</code> internal interface on "
"integration bridge, <code>br-int</code>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml246(para)
msgid "Create and bring up a dummy interface, <code>snooper0</code>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml256(para)
msgid "Add device <code>snooper0</code> to bridge <code>br-int</code>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml264(para)
msgid ""
"Create mirror of <code>patch-tun</code> to <code>snooper0</code> (returns "
"UUID of mirror port):"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml274(para)
msgid ""
"Profit. You can now see traffic on <code>patch-tun</code> by running "
"<literal>tcpdump -i snooper0</literal>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml279(para)
msgid ""
"Clean up by clearing all mirrors on <code>br-int</code> and deleting the "
"dummy interface:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml291(para)
msgid ""
"On the integration bridge, networks are distinguished using internal VLANs "
"regardless of how the networking service defines them. This allows instances"
" on the same host to communicate directly without transiting the rest of the"
" virtual, or physical, network. These internal VLAN IDs are based on the "
"order they are created on the node and may vary between nodes. These IDs are"
" in no way related to the segmentation IDs used in the network definition "
"and on the physical wire."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml300(para)
msgid ""
"VLAN tags are translated between the external tag defined in the network "
"settings, and internal tags in several places. On the <code>br-int</code>, "
"incoming packets from the <code>int-br-eth1</code> are translated from "
"external tags to internal tags. Other translations also happen on the other "
"bridges and will be discussed in those sections."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml310(title)
msgid ""
"To discover which internal VLAN tag is in use for a given external VLAN by "
"using the <literal>ovs-ofctl</literal> command:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml315(para)
msgid ""
"Find the external VLAN tag of the network you're interested in. This is the "
"<code>provider:segmentation_id</code> as returned by the networking service:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml330(para)
msgid ""
"Grep for the <code>provider:segmentation_id</code>, 2113 in this case, in "
"the output of <literal>ovs-ofctl dump-flows br-int</literal>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml340(para)
msgid ""
"Here you can see packets received on port ID 1 with the VLAN tag 2113 are "
"modified to have the internal VLAN tag 7. Digging a little deeper, you can "
"confirm that port 1 is in fact <code>int-br-eth1</code>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml378(para)
msgid ""
"The next step depends on whether the virtual network is configured to use "
"802.1q VLAN tags or GRE:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml383(para)
msgid ""
"VLAN-based networks exit the integration bridge via veth interface <code"
">int-br-eth1</code> and arrive on the bridge <code>br-eth1</code> on the "
"other member of the veth pair <code>phy-br-eth1</code>. Packets on this "
"interface arrive with internal VLAN tags and are translated to external tags"
" in the reverse of the process described above:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml395(para)
msgid ""
"Packets, now tagged with the external VLAN tag, then exit onto the physical "
"network via <code>eth1</code>. The Layer2 switch this interface is connected"
" to must be configured to accept traffic with the VLAN ID used. The next hop"
" for this packet must also be on the same layer-2 network."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml403(para)
msgid ""
"GRE-based networks are passed with <code>patch-tun</code> to the tunnel "
"bridge <code>br-tun</code> on interface <code>patch-int</code>. This bridge "
"also contains one port for each GRE tunnel peer, so one for each compute "
"node and network node in your network. The ports are named sequentially from"
" <code>gre-1</code> onward."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml410(para)
msgid ""
"Matching <code>gre-&lt;n&gt;</code> interfaces to tunnel endpoints is "
"possible by looking at the Open vSwitch state:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml421(para)
msgid ""
"In this case, <code>gre-1</code> is a tunnel from IP 10.10.128.21, which "
"should match a local interface on this node, to IP 10.10.128.16 on the "
"remote side."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml425(para)
msgid ""
"These tunnels use the regular routing tables on the host to route the "
"resulting GRE packet, so there is no requirement that GRE endpoints are all "
"on the same layer-2 network, unlike VLAN encapsulation."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml430(para)
msgid ""
"All interfaces on the <code>br-tun</code> are internal to Open vSwitch. To "
"monitor traffic on them, you need to set up a mirror port as described above"
" for <code>patch-tun</code> in the <code>br-int</code> bridge."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml435(para)
msgid ""
"All translation of GRE tunnels to and from internal VLANs happens on this "
"bridge."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml441(title)
msgid ""
"To discover which internal VLAN tag is in use for a GRE tunnel by using the "
"<literal>ovs-ofctl</literal> command:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml445(para)
msgid ""
"Find the <code>provider:segmentation_id</code> of the network you're "
"interested in. This is the same field used for the VLAN ID in VLAN-based "
"networks:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml460(para)
msgid ""
"Grep for 0x&lt;<code>provider:segmentation_id</code>&gt;, 0x3 in this case, "
"in the output of <literal>ovs-ofctl dump-flows br-tun</literal>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml487(para)
msgid ""
"Here, you see three flows related to this GRE tunnel. The first is the "
"translation from inbound packets with this tunnel ID to internal VLAN ID 1. "
"The second shows a unicast flow to output port 53 for packets destined for "
"MAC address fa:16:3e:a6:48:24. The third shows the translation from the "
"internal VLAN representation to the GRE tunnel ID flooded to all output "
"ports. For further details of the flow descriptions, see the man page for "
"<literal>ovs-ofctl</literal>. As in the previous VLAN example, numeric port "
"IDs can be matched with their named representations by examining the output "
"of <literal>ovs-ofctl show br-tun</literal>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml503(para)
msgid ""
"The packet is then received on the network node. Note that any traffic to "
"the l3-agent or dhcp-agent will be visible only within their network "
"namespace. Watching any interfaces outside those namespaces, even those that"
" carry the network traffic, will only show broadcast packets like Address "
"Resolution Protocols (ARPs), but unicast traffic to the router or DHCP "
"address will not be seen. See <link href=\"http://docs.openstack.org"
"/openstack-"
"ops/content/network_troubleshooting.html#dealing_with_netns\">Dealing with "
"Network Namespaces</link> for detail on how to run commands within these "
"namespaces."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml514(para)
msgid ""
"Alternatively, it is possible to configure VLAN-based networks to use "
"external routers rather than the l3-agent shown here, so long as the "
"external router is on the same VLAN:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml520(para)
msgid ""
"VLAN-based networks are received as tagged packets on a physical network "
"interface, <code>eth1</code> in this example. Just as on the compute node, "
"this interface is a member of the <code>br-eth1</code> bridge."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml527(para)
msgid ""
"GRE-based networks will be passed to the tunnel bridge <code>br-tun</code>, "
"which behaves just like the GRE interfaces on the compute node."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml535(para)
msgid ""
"Next, the packets from either input go through the integration bridge, again"
" just as on the compute node."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml540(para)
msgid ""
"The packet then makes it to the l3-agent. This is actually another TAP "
"device within the router's network namespace. Router namespaces are named in"
" the form <code>qrouter-&lt;router-uuid&gt;</code>. Running <literal>ip "
"a</literal> within the namespace will show the TAP device name, qr-"
"e6256f7d-31 in this example:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml557(para)
msgid ""
"The <code>qg-&lt;n&gt;</code> interface in the l3-agent router namespace "
"sends the packet on to its next hop through device <code>eth2</code> on the "
"external bridge <code>br-ex</code>. This bridge is constructed similarly to "
"<code>br-eth1</code> and may be inspected in the same way."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml565(para)
msgid ""
"This external bridge also includes a physical network interface, "
"<code>eth2</code> in this example, which finally lands the packet on the "
"external network destined for an external router or destination."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml572(para)
msgid ""
"DHCP agents running on OpenStack networks run in namespaces similar to the "
"l3-agents. DHCP namespaces are named <code>qdhcp-&lt;uuid&gt;</code> and "
"have a TAP device on the integration bridge. Debugging of DHCP issues "
"usually involves working inside this network namespace.<indexterm "
"class=\"endofrange\" startref=\"Topen\"/>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml583(title)
msgid "Finding a Failure in the Path"
msgstr "経路上の障害を見つける"

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml585(para)
msgid ""
"Use ping to quickly find where a failure exists in the network path. In an "
"instance, first see whether you can ping an external host, such as "
"google.com. If you can, then there shouldn't be a network problem at all."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml590(para)
msgid ""
"If you can't, try pinging the IP address of the compute node where the "
"instance is hosted. If you can ping this IP, then the problem is somewhere "
"between the compute node and that compute node's gateway."
msgstr "もしそれができないのであれば、インスタンスがホストされているコンピュートノードのIPアドレスへpingを試行してください。もしそのIPにpingできるのであれば、そのコンピュートノードと、ゲートウェイ間のどこかに問題があります。"

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml594(para)
msgid ""
"If you can't ping the IP address of the compute node, the problem is between"
" the instance and the compute node. This includes the bridge connecting the "
"compute node's main NIC with the vnet NIC of the instance."
msgstr "もしコンピュートノードのIPアドレスにpingできないのであれば、問題はインスタンスとコンピュートノード間にあります。これはコンピュートノードの物理NICとインスタンス vnet NIC間のブリッジ接続を含みます。"

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml599(para)
msgid ""
"One last test is to launch a second instance and see whether the two "
"instances can ping each other. If they can, the issue might be related to "
"the firewall on the compute node.<indexterm class=\"singular\"><primary>path"
" failures</primary></indexterm><indexterm "
"class=\"singular\"><primary>troubleshooting</primary><secondary>detecting "
"path failures</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml611(title)
#: ./doc/openstack-ops/ch_ops_resources.xml76(code)
msgid "tcpdump"
msgstr "tcpdump"

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml613(para)
msgid ""
"One great, although very in-depth, way of troubleshooting network issues is "
"to use <literal>tcpdump</literal>. We recommended using "
"<literal>tcpdump</literal> at several points along the network path to "
"correlate where a problem might be. If you prefer working with a GUI, either"
" live or by using a <literal>tcpdump</literal> capture, do also check out "
"<link href=\"http://www.wireshark.org/\" "
"title=\"Wireshark\">Wireshark</link>.<indexterm "
"class=\"singular\"><primary>tcpdump</primary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml623(para)
msgid "For example, run the following command:"
msgstr "例えば、以下のコマンドを実行します。"

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml628(para)
msgid "Run this on the command line of the following areas:"
msgstr "このコマンドは以下の場所で実行します。"

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml632(para)
msgid "An external server outside of the cloud"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml636(para)
msgid "A compute node"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml640(para)
msgid "An instance running on that compute node"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml644(para)
msgid "In this example, these locations have the following IP addresses:"
msgstr "例では、この環境には以下のIPアドレスが存在します"

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml656(para)
msgid ""
"Next, open a new shell to the instance and then ping the external host where"
" <literal>tcpdump</literal> is running. If the network path to the external "
"server and back is fully functional, you see something like the following:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml661(para)
msgid "On the external server:"
msgstr "外部サーバー上"

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml671(para)
msgid "On the compute node:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml692(para)
msgid "On the instance:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml698(para)
msgid ""
"Here, the external server received the ping request and sent a ping reply. "
"On the compute node, you can see that both the ping and ping reply "
"successfully passed through. You might also see duplicate packets on the "
"compute node, as seen above, because <literal>tcpdump</literal> captured the"
" packet on both the bridge and outgoing interface."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml706(title)
msgid "iptables"
msgstr "iptables"

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml708(para)
msgid ""
"Through <literal>nova-network</literal>, OpenStack Compute automatically "
"manages iptables, including forwarding packets to and from instances on a "
"compute node, forwarding floating IP traffic, and managing security group "
"rules.<indexterm "
"class=\"singular\"><primary>iptables</primary></indexterm><indexterm "
"class=\"singular\"><primary>troubleshooting</primary><secondary>iptables</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml719(para)
msgid "Run the following command to view the current iptables configuration:"
msgstr "iptablesの現在の構成を見るには、以下のコマンドを実行します。"

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml725(para)
msgid ""
"If you modify the configuration, it reverts the next time you restart "
"<literal>nova-network</literal>. You must use OpenStack to manage iptables."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml732(title)
msgid "Network Configuration in the Database for nova-network"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml734(para)
msgid ""
"With <literal>nova-network</literal>, the nova database table contains a few"
" tables with networking information:<indexterm "
"class=\"singular\"><primary>databases</primary><secondary>nova-network "
"troubleshooting</secondary></indexterm><indexterm "
"class=\"singular\"><primary>troubleshooting</primary><secondary>nova-network"
" database</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml748(literal)
msgid "fixed_ips"
msgstr "fixed_ips"

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml751(para)
msgid ""
"Contains each possible IP address for the subnet(s) added to Compute. This "
"table is related to the <literal>instances</literal> table by way of the "
"<literal>fixed_ips.instance_uuid</literal> column."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml759(literal)
msgid "floating_ips"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml762(para)
msgid ""
"Contains each floating IP address that was added to Compute. This table is "
"related to the <literal>fixed_ips</literal> table by way of the "
"<literal>floating_ips.fixed_ip_id</literal> column."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml770(literal)
#: ./doc/openstack-ops/ch_ops_projects_users.xml300(systemitem)
msgid "instances"
msgstr "instances"

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml773(para)
msgid ""
"Not entirely network specific, but it contains information about the "
"instance that is utilizing the <literal>fixed_ip</literal> and optional "
"<literal>floating_ip</literal>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml780(para)
msgid ""
"From these tables, you can see that a floating IP is technically never "
"directly related to an instance; it must always go through a fixed IP."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml785(title)
msgid "Manually Deassociating a Floating IP"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml787(para)
msgid ""
"Sometimes an instance is terminated but the floating IP was not correctly "
"de-associated from that instance. Because the database is in an inconsistent"
" state, the usual tools to deassociate the IP no longer work. To fix this, "
"you must manually update the database.<indexterm "
"class=\"singular\"><primary>IP "
"addresses</primary><secondary>floating</secondary></indexterm><indexterm "
"class=\"singular\"><primary>floating IP address</primary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml799(para)
msgid "First, find the UUID of the instance in question:"
msgstr "まず、インスタンスのUUIDを確認します。"

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml803(para)
msgid "Next, find the fixed IP entry for that UUID:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml807(para)
msgid "You can now get the related floating IP entry:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml811(para)
msgid "And finally, you can deassociate the floating IP:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml816(para)
msgid "You can optionally also deallocate the IP from the user's pool:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml825(title)
msgid "Debugging DHCP Issues with nova-network"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml827(para)
msgid ""
"One common networking problem is that an instance boots successfully but is "
"not reachable because it failed to obtain an IP address from dnsmasq, which "
"is the DHCP server that is launched by the <literal>nova-network</literal> "
"service.<indexterm class=\"singular\"><primary>DHCP (Dynamic Host "
"Configuration "
"Protocol)</primary><secondary>debugging</secondary></indexterm><indexterm "
"class=\"singular\"><primary>troubleshooting</primary><secondary>nova-network"
" DHCP</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml840(para)
msgid ""
"The simplest way to identify that this is the problem with your instance is "
"to look at the console output of your instance. If DHCP failed, you can "
"retrieve the console log by doing:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml846(para)
msgid ""
"If your instance failed to obtain an IP through DHCP, some messages should "
"appear in the console. For example, for the Cirros image, you see output "
"that looks like the following:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml860(para)
msgid ""
"After you establish that the instance booted properly, the task is to figure"
" out where the failure is."
msgstr "インスタンスが正しく起動した後、この手順でどこが問題かを切り分けることができます。"

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml863(para)
msgid ""
"A DHCP problem might be caused by a misbehaving dnsmasq process. First, "
"debug by checking logs and then restart the dnsmasq processes only for that "
"project (tenant). In VLAN mode, there is a dnsmasq process for each tenant. "
"Once you have restarted targeted dnsmasq processes, the simplest way to rule"
" out dnsmasq causes is to kill all of the dnsmasq processes on the machine "
"and restart <literal>nova-network</literal>. As a last resort, do this as "
"root:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml875(para)
msgid ""
"Use <literal>openstack-nova-network</literal> on RHEL/CentOS/Fedora but "
"<literal>nova-network</literal> on Ubuntu/Debian."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml880(para)
msgid ""
"Several minutes after <literal>nova-network</literal> is restarted, you "
"should see new dnsmasq processes running:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml904(para)
msgid ""
"If your instances are still not able to obtain IP addresses, the next thing "
"to check is whether dnsmasq is seeing the DHCP requests from the instance. "
"On the machine that is running the dnsmasq process, which is the compute "
"host if running in multi-host mode, look at "
"<literal>/var/log/syslog</literal> to see the dnsmasq output. If dnsmasq is "
"seeing the request properly and handing out an IP, the output looks like "
"this:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml920(para)
msgid ""
"If you do not see the <literal>DHCPDISCOVER</literal>, a problem exists with"
" the packet getting from the instance to the machine running dnsmasq. If you"
" see all of the preceding output and your instances are still not able to "
"obtain IP addresses, then the packet is able to get from the instance to the"
" host running dnsmasq, but it is not able to make the return trip."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml927(para)
msgid "You might also see a message such as this:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml932(para)
msgid ""
"This may be a dnsmasq and/or <literal>nova-network</literal> related issue. "
"(For the preceding example, the problem happened to be that dnsmasq did not "
"have any more IP addresses to give away because there were no more fixed IPs"
" available in the OpenStack Compute database.)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml937(para)
msgid ""
"If there's a suspicious-looking dnsmasq log message, take a look at the "
"command-line arguments to the dnsmasq processes to see if they look correct:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml943(para)
msgid "The output looks something like the following:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml972(para)
msgid ""
"The output shows three different dnsmasq processes. The dnsmasq process that"
" has the DHCP subnet range of 192.168.122.0 belongs to libvirt and can be "
"ignored. The other two dnsmasq processes belong to <literal>nova-"
"network</literal>. The two processes are actually related—one is simply the "
"parent process of the other. The arguments of the dnsmasq processes should "
"correspond to the details you configured <literal>nova-network</literal> "
"with."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml980(para)
msgid ""
"If the problem does not seem to be related to dnsmasq itself, at this point "
"use <code>tcpdump</code> on the interfaces to determine where the packets "
"are getting lost."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml984(para)
msgid ""
"DHCP traffic uses UDP. The client sends from port 68 to port 67 on the "
"server. Try to boot a new instance and then systematically listen on the "
"NICs until you identify the one that isn't seeing the traffic. To use "
"<code>tcpdump</code> to listen to ports 67 and 68 on br100, you would do:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml992(para)
msgid ""
"You should be doing sanity checks on the interfaces using command such as "
"<code>ip a</code> and <code>brctl show</code> to ensure that the interfaces "
"are actually up and configured the way that you think that they are."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml999(title)
msgid "Debugging DNS Issues"
msgstr "DNS の問題をデバッグする"

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml1001(para)
msgid ""
"If you are able to use SSH to log into an instance, but it takes a very long"
" time (on the order of a minute) to get a prompt, then you might have a DNS "
"issue. The reason a DNS issue can cause this problem is that the SSH server "
"does a reverse DNS lookup on the IP address that you are connecting from. If"
" DNS lookup isn't working on your instances, then you must wait for the DNS "
"reverse lookup timeout to occur for the SSH login process to "
"complete.<indexterm class=\"singular\"><primary>DNS (Domain Name Server, "
"Service or "
"System)</primary><secondary>debugging</secondary></indexterm><indexterm "
"class=\"singular\"><primary>troubleshooting</primary><secondary>DNS "
"issues</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml1017(para)
msgid ""
"When debugging DNS issues, start by making sure that the host where the "
"dnsmasq process for that instance runs is able to correctly resolve. If the "
"host cannot resolve, then the instances won't be able to either."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml1022(para)
msgid ""
"A quick way to check whether DNS is working is to resolve a hostname inside "
"your instance by using the <code>host</code> command. If DNS is working, you"
" should see:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml1031(para)
msgid ""
"If you're running the Cirros image, it doesn't have the \"host\" program "
"installed, in which case you can use ping to try to access a machine by "
"hostname to see whether it resolves. If DNS is working, the first line of "
"ping would be:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml1039(para)
msgid ""
"If the instance fails to resolve the hostname, you have a DNS problem. For "
"example:"
msgstr "もしインスタンスがホスト名の解決に失敗するのであれば、DNSに問題があります。例えば、"

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml1045(para)
msgid ""
"In an OpenStack cloud, the dnsmasq process acts as the DNS server for the "
"instances in addition to acting as the DHCP server. A misbehaving dnsmasq "
"process may be the source of DNS-related issues inside the instance. As "
"mentioned in the previous section, the simplest way to rule out a "
"misbehaving dnsmasq process is to kill all the dnsmasq processes on the "
"machine and restart <literal>nova-network</literal>. However, be aware that "
"this command affects everyone running instances on this node, including "
"tenants that have not seen the issue. As a last resort, as root:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml1058(para)
msgid "After the dnsmasq processes start again, check whether DNS is working."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml1061(para)
msgid ""
"If restarting the dnsmasq process doesn't fix the issue, you might need to "
"use <code>tcpdump</code> to look at the packets to trace where the failure "
"is. The DNS server listens on UDP port 53. You should see the DNS request on"
" the bridge (such as, br100) of your compute node. Let's say you start "
"listening with <code>tcpdump</code> on the compute node:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml1071(para)
msgid ""
"Then, if you use SSH to log into your instance and try <code>ping "
"openstack.org</code>, you should see something like:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml1084(title)
msgid "Troubleshooting Open vSwitch"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml1086(para)
msgid ""
"Open vSwitch as used in the previous OpenStack Networking Service examples "
"is a full-featured multilayer virtual switch licensed under the open source "
"Apache 2.0 license. Full documentation can be found at <link "
"href=\"http://openvswitch.org/\">the project's website</link>. In practice, "
"given the preceding configuration, the most common issues are being sure "
"that the required bridges (<code>br-int</code>, <code>br-tun</code>, <code"
">br-ex</code>, etc.) exist and have the proper ports connected to "
"them.<indexterm class=\"singular\"><primary>Open "
"vSwitch</primary><secondary>troubleshooting</secondary></indexterm><indexterm"
" class=\"singular\"><primary>troubleshooting</primary><secondary>Open "
"vSwitch</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml1103(para)
msgid ""
"The Open vSwitch driver should and usually does manage this automatically, "
"but it is useful to know how to do this by hand with the <literal>ovs-"
"vsctl</literal> command. This command has many more subcommands than we will"
" use here; see the man page or use <literal>ovs-vsctl --help</literal> for "
"the full listing."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml1109(para)
msgid ""
"To list the bridges on a system, use <literal>ovs-vsctl list-br</literal>. "
"This example shows a compute node that has an internal bridge and a tunnel "
"bridge. VLAN networks are trunked through the <code>eth1</code> network "
"interface:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml1120(para)
msgid ""
"Working from the physical interface inwards, we can see the chain of ports "
"and bridges. First, the bridge <code>eth1-br</code>, which contains the "
"physical network interface <literal>eth1</literal> and the virtual interface"
" <code>phy-eth1-br</code>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml1130(para)
msgid ""
"Next, the internal bridge, <code>br-int</code>, contains <code>int-"
"eth1-br</code>, which pairs with <code>phy-eth1-br</code> to connect to the "
"physical network shown in the previous bridge, <code>patch-tun</code>, which"
" is used to connect to the GRE tunnel bridge and the TAP devices that "
"connect to the instances currently running on the system:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml1145(para)
msgid ""
"The tunnel bridge, <code>br-tun</code>, contains the <code>patch-int</code> "
"interface and <code>gre-&lt;N&gt;</code> interfaces for each peer it "
"connects to via GRE, one for each compute and network node in your cluster:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml1159(para)
msgid ""
"If any of these links is missing or incorrect, it suggests a configuration "
"error. Bridges can be added with <literal>ovs-vsctl add-br</literal>, and "
"ports can be added to bridges with <literal>ovs-vsctl add-port</literal>. "
"While running these by hand can be useful debugging, it is imperative that "
"manual changes that you intend to keep be reflected back into your "
"configuration files."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml1168(title)
msgid "Dealing with Network Namespaces"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml1170(para)
msgid ""
"Linux network namespaces are a kernel feature the networking service uses to"
" support multiple isolated layer-2 networks with overlapping IP address "
"ranges. The support may be disabled, but it is on by default. If it is "
"enabled in your environment, your network nodes will run their dhcp-agents "
"and l3-agents in isolated namespaces. Network interfaces and traffic on "
"those interfaces will not be visible in the default namespace.<indexterm "
"class=\"singular\"><primary>network namespaces, "
"troubleshooting</primary></indexterm><indexterm "
"class=\"singular\"><primary>namespaces, "
"troubleshooting</primary></indexterm><indexterm "
"class=\"singular\"><primary>troubleshooting</primary><secondary>network "
"namespaces</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml1186(para)
msgid ""
"To see whether you are using namespaces, run <literal>ip netns</literal>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml1197(para)
msgid ""
"L3-agent router namespaces are named "
"<literal>qrouter-<replaceable>&lt;router_uuid&gt;</replaceable></literal>, "
"and dhcp-agent name spaces are named "
"<literal>qdhcp-</literal><literal><replaceable>&lt;net_uuid&gt;</replaceable></literal>."
" This output shows a network node with four networks running dhcp-agents, "
"one of which is also running an l3-agent router. It's important to know "
"which network you need to be working in. A list of existing networks and "
"their UUIDs can be obtained by running <literal>neutron net-list</literal> "
"with administrative credentials."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml1207(para)
msgid ""
"Once you've determined which namespace you need to work in, you can use any "
"of the debugging tools mention earlier by prefixing the command with "
"<literal>ip netns exec &lt;namespace&gt;</literal>. For example, to see what"
" network interfaces exist in the first qdhcp namespace returned above, do "
"this:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml1227(para)
msgid ""
"From this you see that the DHCP server on that network is using the "
"tape6256f7d-31 device and has an IP address of 10.0.1.100. Seeing the "
"address 169.254.169.254, you can also see that the dhcp-agent is running a "
"metadata-proxy service. Any of the commands mentioned previously in this "
"chapter can be run in the same way. It is also possible to run a shell, such"
" as <literal>bash</literal>, and have an interactive session within the "
"namespace. In the latter case, exiting the shell returns you to the top-"
"level default namespace."
msgstr ""

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml1238(title)
#: ./doc/openstack-ops/ch_ops_projects_users.xml1097(title)
#: ./doc/openstack-ops/ch_ops_lay_of_land.xml823(title)
#: ./doc/openstack-ops/ch_ops_backup_recovery.xml281(title)
#: ./doc/openstack-ops/ch_ops_log_monitor.xml997(title)
msgid "Summary"
msgstr "概要"

#: ./doc/openstack-ops/ch_ops_network_troubleshooting.xml1240(para)
msgid ""
"The authors have spent too much time looking at packet dumps in order to "
"distill this information for you. We trust that, following the methods "
"outlined in this chapter, you will have an easier time! Aside from working "
"with the tools and steps above, don't forget that sometimes an extra pair of"
" eyes goes a long way to assist."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml10(title)
msgid "Tales From the Cryp^H^H^H^H Cloud"
msgstr "ハリウッド^H^H^H^H^Hクラウドナイトメア"

#: ./doc/openstack-ops/app_crypt.xml12(para)
msgid ""
"Herein lies a selection of tales from OpenStack cloud operators. Read, and "
"learn from their wisdom."
msgstr "ここにあるのは、OpenStack クラウドオペレータ達の苦闘の抜粋である。これを読み、彼らの叡智を学ぶが良い。"

#: ./doc/openstack-ops/app_crypt.xml16(title)
msgid "Double VLAN"
msgstr "ダブル VLAN"

#: ./doc/openstack-ops/app_crypt.xml17(para)
msgid ""
"I was on-site in Kelowna, British Columbia, Canada setting up a new "
"OpenStack cloud. The deployment was fully automated: Cobbler deployed the OS"
" on the bare metal, bootstrapped it, and Puppet took over from there. I had "
"run the deployment scenario so many times in practice and took for granted "
"that everything was working."
msgstr "私は、新しい OpenStack クラウドのセットアップをするため、カナダのブリティッシュコロンビア州ケロウナの現地にいた。デプロイ作業は完全に自動化されていた。Cobbler が物理マシンに OS をデプロイし、それを起動し、その後は Puppet が引き継いだ。私は練習で幾度もデプロイシナリオを実行してきたし、もちろん全て正常であった。"

#: ./doc/openstack-ops/app_crypt.xml23(para)
msgid ""
"On my last day in Kelowna, I was in a conference call from my hotel. In the "
"background, I was fooling around on the new cloud. I launched an instance "
"and logged in. Everything looked fine. Out of boredom, I ran "
"<placeholder-1/> and all of the sudden the instance locked up."
msgstr "ケロウナの最終日、私はホテルから電話会議に参加していた。その裏で、私は新しいクラウドをいじっていた。私はインスタンスを１つ起動し、ログインした。全ては正常に思えた。退屈しのぎに、私は <placeholder-1/> を実行したところ、突然そのインスタンスがロックアップしてしまった。"

#: ./doc/openstack-ops/app_crypt.xml29(para)
msgid ""
"Thinking it was just a one-off issue, I terminated the instance and launched"
" a new one. By then, the conference call ended and I was off to the data "
"center."
msgstr "これは単なる１回限りの問題と思ったので、私はインスタンスを削除して、新しいインスタンスを起動した。その後電話会議は終了し、私はデータセンターを離れた。"

#: ./doc/openstack-ops/app_crypt.xml32(para)
msgid ""
"At the data center, I was finishing up some tasks and remembered the lock-"
"up. I logged into the new instance and ran <placeholder-1/> again. It "
"worked. Phew. I decided to run it one more time. It locked up. WTF."
msgstr "データセンターで、私はいくつかの仕事を済ませると、ロックアップのことを思い出した。私は新しいインスタンスにログインし、再度 <placeholder-1/> を実行した。コマンドは機能した。ふぅ。私はもう一度試してみることにした。今度はロックアップした。何だこれは？"

#: ./doc/openstack-ops/app_crypt.xml36(para)
msgid ""
"After reproducing the problem several times, I came to the unfortunate "
"conclusion that this cloud did indeed have a problem. Even worse, my time "
"was up in Kelowna and I had to return back to Calgary."
msgstr "何度か問題が再現した後、私はこのクラウドが実は問題を抱えているという不幸な結論に至った。更に悪いことに、私がケロウナから出発する時間になっており、カルガリーに戻らなければならなかった。"

#: ./doc/openstack-ops/app_crypt.xml40(para)
msgid ""
"Where do you even begin troubleshooting something like this? An instance "
"just randomly locks when a command is issued. Is it the image? Nopeit "
"happens on all images. Is it the compute node? Nopeall nodes. Is the "
"instance locked up? No! New SSH connections work just fine!"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml45(para)
msgid ""
"We reached out for help. A networking engineer suggested it was an MTU "
"issue. Great! MTU! Something to go on! What's MTU and why would it cause a "
"problem?"
msgstr "我々は助けを求めた。ネットワークエンジニアは、これは MTU の問題ではないかというのだ。素晴らしい！MTU! 事態は動き始めた! MTU とは何で、何故それが問題になるのだろうか？"

#: ./doc/openstack-ops/app_crypt.xml48(para)
msgid ""
"MTU is maximum transmission unit. It specifies the maximum number of bytes "
"that the interface accepts for each packet. If two interfaces have two "
"different MTUs, bytes might get chopped off and weird things happensuch as "
"random session lockups."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml54(para)
msgid ""
"Not all packets have a size of 1500. Running the <placeholder-1/> command "
"over SSH might only create a single packets less than 1500 bytes. However, "
"running a command with heavy output, such as <placeholder-2/> requires "
"several packets of 1500 bytes."
msgstr "すべてのパケットサイズが 1500 に収まるわけではない。SSH 経由の <placeholder-1/> コマンド実行は 1500 バイト未満のサイズのパケット１つで収まるかもしれない。しかし、 <placeholder-2/> のように多大な出力を行うコマンドを実行する場合、1500 バイトのパケットが複数必要とある。"

#: ./doc/openstack-ops/app_crypt.xml60(para)
msgid ""
"OK, so where is the MTU issue coming from? Why haven't we seen this in any "
"other deployment? What's new in this situation? Well, new data center, new "
"uplink, new switches, new model of switches, new servers, first time using "
"this model of servers… so, basically everything was new. Wonderful. We toyed"
" around with raising the MTU at various areas: the switches, the NICs on the"
" compute nodes, the virtual NICs in the instances, we even had the data "
"center raise the MTU for our uplink interface. Some changes worked, some "
"didn't. This line of troubleshooting didn't feel right, though. We shouldn't"
" have to be changing the MTU in these areas."
msgstr "OK。では MTU の問題はどこから来るのか？なぜ我々は他のデプロイでこの問題に遭遇しなかったのか？この状況は何が新しいのか？えっと、新しいデータセンター、新しい上位リンク、新しいスイッチ、スイッチの新機種、新しいサーバー、サーバーの新機種…つまり、基本的に全てが新しいものだった。素晴らしい。我々は様々な領域で MTU の増加を試してみた。スイッチ、コンピュータのNIC、インスタンスの仮想NIC、データセンターの上位リンク用のインターフェースのMTUまでいじってみた。いくつかの変更ではうまくいったが、他はダメだった。やはり、この線の障害対策はうまくいってないようだった。我々はこれらの領域のMTUは変更すべきではないようだ。"

#: ./doc/openstack-ops/app_crypt.xml72(para)
msgid ""
"As a last resort, our network admin (Alvaro) and myself sat down with four "
"terminal windows, a pencil, and a piece of paper. In one window, we ran "
"ping. In the second window, we ran <placeholder-1/> on the cloud controller."
" In the third, <placeholder-2/> on the compute node. And the forth had "
"<placeholder-3/> on the instance. For background, this cloud was a multi-"
"node, non-multi-host setup."
msgstr "結局、我々のネットワーク管理者（Alvao）と私自身は４つのターミナルウィンドウ、１本の鉛筆と紙切れを持って座った。１つのウインドウで我々は ping を実行した。２つ目のウインドウではクラウドコントローラー上の <placeholder-1/>、３つ目ではコンピュートノード上の <placeholder-2/>、４つ目ではインスタンス上の <placeholder-3/> を実行した。前提として、このクラウドはマルチノード、非マルチホスト構成である。"

#: ./doc/openstack-ops/app_crypt.xml80(para)
msgid ""
"One cloud controller acted as a gateway to all compute nodes. VlanManager "
"was used for the network config. This means that the cloud controller and "
"all compute nodes had a different VLAN for each OpenStack project. We used "
"the -s option of <placeholder-1/> to change the packet size. We watched as "
"sometimes packets would fully return, sometimes they'd only make it out and "
"never back in, and sometimes the packets would stop at a random point. We "
"changed <placeholder-2/> to start displaying the hex dump of the packet. We "
"pinged between every combination of outside, controller, compute, and "
"instance."
msgstr "１つのクラウドコントローラーが全コンピュートノードのゲートウェイの役割を果たしていた。ネットワーク設定には VlanManager が使われていた。これは、クラウドコントローラーと全コンピュートノードで、各 OpenStack プロジェクトが異なる VLAN を持つことを意味する。パケットサイズ変更のため、<placeholder-1/> の -s オプションを使用していた。パケットが全て戻ってくる時もあれば、パケットが出ていったきり全く戻って来ない時もあれば、パケットはランダムな場所で止まってしまう時もある、という状況だった。<placeholder-2/> を変更し、パケットの16進ダンプを表示するようにした。外部、コントローラー、コンピュート、インスタンスのあらゆる組み合わせの間で ping を実行した。"

#: ./doc/openstack-ops/app_crypt.xml92(para)
msgid ""
"Finally, Alvaro noticed something. When a packet from the outside hits the "
"cloud controller, it should not be configured with a VLAN. We verified this "
"as true. When the packet went from the cloud controller to the compute node,"
" it should only have a VLAN if it was destined for an instance. This was "
"still true. When the ping reply was sent from the instance, it should be in "
"a VLAN. True. When it came back to the cloud controller and on its way out "
"to the public internet, it should no longer have a VLAN. False. Uh oh. It "
"looked as though the VLAN part of the packet was not being removed."
msgstr "遂に、Alvaro が何かを掴んだ。外部からのパケットがクラウドコントローラーを叩いた際、パケットは VLAN で設定されるべきではない。我々はこれが正しいことを検証した。パケットがクラウドコントローラーからコンピュートノードに行く際、パケットはインスタンス宛の場合にのみ VLAN を持つべきである。これもまた正しかった。ping のレスポンスがインスタンスから送られる際、パケットは VLAN 中にいるべきである。ＯＫ。クラウドコントローラーからパブリックインターネットにパケットが戻る際、パケットには VLAN を持つべきではない。ＮＧ。うぉっ。まるで パケットの VLAN 部分が削除されていないように見える。"

#: ./doc/openstack-ops/app_crypt.xml103(para)
msgid "That made no sense."
msgstr "これでは意味が無かった。"

#: ./doc/openstack-ops/app_crypt.xml104(para)
msgid ""
"While bouncing this idea around in our heads, I was randomly typing commands"
" on the compute node: <placeholder-1/>"
msgstr "このアイデアが我々の頭を駆け巡る間、私はコンピュートノード上でコマンドをランダムに叩いていた。 <placeholder-1/>"

#: ./doc/openstack-ops/app_crypt.xml111(para)
msgid "\"Hey Alvaro, can you run a VLAN on top of a VLAN?\""
msgstr "「Alvaro、VLAN 上に VLAN って作れるのかい？」"

#: ./doc/openstack-ops/app_crypt.xml113(para)
msgid "\"If you did, you'd add an extra 4 bytes to the packet\""
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml115(para)
msgid "Then it all made sense… <placeholder-1/>"
msgstr "やっと事の全容が判明した… <placeholder-1/>"

#: ./doc/openstack-ops/app_crypt.xml119(para)
msgid ""
"In <filename>nova.conf</filename>, <code>vlan_interface</code> specifies "
"what interface OpenStack should attach all VLANs to. The correct setting "
"should have been: <placeholder-1/>."
msgstr "<filename>nova.conf</filename> 中で、<code>vlan_interface</code> は OpenStack が全ての VLAN をアタッチすべきインターフェースがどれかを指定する。正しい設定はこうだった: <placeholder-1/>"

#: ./doc/openstack-ops/app_crypt.xml123(para)
msgid "As this would be the server's bonded NIC."
msgstr "これはサーバーの冗長化された（bonded）NIC であるべきだからだ。"

#: ./doc/openstack-ops/app_crypt.xml124(para)
msgid ""
"vlan20 is the VLAN that the data center gave us for outgoing public internet"
" access. It's a correct VLAN and is also attached to bond0."
msgstr "vlan20 はデータセンターが外向けのパブリックなインターネットアクセス用に我々に付与した VLAN である。これは正しい VLAN で bond0 にアタッチされている。"

#: ./doc/openstack-ops/app_crypt.xml127(para)
msgid ""
"By mistake, I configured OpenStack to attach all tenant VLANs to vlan20 "
"instead of bond0 thereby stacking one VLAN on top of another which then "
"added an extra 4 bytes to each packet which cause a packet of 1504 bytes to "
"be sent out which would cause problems when it arrived at an interface that "
"only accepted 1500!"
msgstr "ミスにより、私は全てのテナント VLAN を bond0 の代わりに vlan20 にアタッチするよう OpenStack を設定した。それによって１つの VLAN が別の VLAN の上に積み重なり、各パケットに余分に４バイトが追加され、送信されるパケットサイズが 1504 バイトになる原因となった。これがパケットサイズ 1500 のみ許容するインターフェースに到達した際、問題の原因となったのだった！"

#: ./doc/openstack-ops/app_crypt.xml133(para)
msgid "As soon as this setting was fixed, everything worked."
msgstr "全力でこの問題を修正した結果、全てが正常に動作するようになった。"

#: ./doc/openstack-ops/app_crypt.xml137(title)
msgid "\"The Issue\""
msgstr "「あの問題」"

#: ./doc/openstack-ops/app_crypt.xml138(para)
msgid ""
"At the end of August 2012, a post-secondary school in Alberta, Canada "
"migrated its infrastructure to an OpenStack cloud. As luck would have it, "
"within the first day or two of it running, one of their servers just "
"disappeared from the network. Blip. Gone."
msgstr "2012年8月の終わり、カナダ アルバータ州のある大学はそのインフラを OpenStack クラウドに移行した。幸か不幸か、サービスインから1～2日間に、彼らのサーバーの1台がネットワークから消失した。ビッ。いなくなった。"

#: ./doc/openstack-ops/app_crypt.xml143(para)
msgid ""
"After restarting the instance, everything was back up and running. We "
"reviewed the logs and saw that at some point, network communication stopped "
"and then everything went idle. We chalked this up to a random occurrence."
msgstr "インスタンスの再起動後、全ては元通りに動くようになった。我々はログを見直し、問題の箇所（ネットワーク通信が止まり、全ては待機状態になった）を見た。我々はランダムな事象の原因はこのインスタンスだと判断した。"

#: ./doc/openstack-ops/app_crypt.xml148(para)
msgid "A few nights later, it happened again."
msgstr "数日後、それは再び起こった。"

#: ./doc/openstack-ops/app_crypt.xml149(para)
msgid ""
"We reviewed both sets of logs. The one thing that stood out the most was "
"DHCP. At the time, OpenStack, by default, set DHCP leases for one minute "
"(it's now two minutes). This means that every instance contacts the cloud "
"controller (DHCP server) to renew its fixed IP. For some reason, this "
"instance could not renew its IP. We correlated the instance's logs with the "
"logs on the cloud controller and put together a conversation:"
msgstr "我々はログのセットを両方見直した。頻発したログの１つは DHCP だった。当時、OpenStack はデフォルトでは DHCP リース期間を 1分に設定していた (現在は 2分)。これは、各インスタンスが固定 IP アドレスを更新するためにクラウドコントローラー（DHCP サーバー）に接続することを意味する。幾つかの理由で、このインスタンスはその IP アドレスを更新できなかった。インスタンスのログとクラウドコントローラー上のログを突き合わせ、並べてやりとりにしてみた。"

#: ./doc/openstack-ops/app_crypt.xml160(para)
msgid "Instance tries to renew IP."
msgstr "インスタンスはIPアドレスを更新しようとする。"

#: ./doc/openstack-ops/app_crypt.xml163(para)
msgid "Cloud controller receives the renewal request and sends a response."
msgstr "クラウドコントローラーは更新リクエストを受信し、レスポンスを返す。"

#: ./doc/openstack-ops/app_crypt.xml167(para)
msgid "Instance \"ignores\" the response and re-sends the renewal request."
msgstr "インスタンスはそのレスポンスを「無視」して、更新リクエストを再送する。"

#: ./doc/openstack-ops/app_crypt.xml171(para)
msgid "Cloud controller receives the second request and sends a new response."
msgstr "クラウドコントローラーは２度めのリクエストを受信し、新しいレスポンスを返す。"

#: ./doc/openstack-ops/app_crypt.xml175(para)
msgid ""
"Instance begins sending a renewal request to <code>255.255.255.255</code> "
"since it hasn't heard back from the cloud controller."
msgstr "インスタンスはクラウドコントローラーからのレスポンスを受信しなかったため、更新リクエストを<code>255.255.255.255</code>に送信し始める。"

#: ./doc/openstack-ops/app_crypt.xml180(para)
msgid ""
"The cloud controller receives the <code>255.255.255.255</code> request and "
"sends a third response."
msgstr "クラウドコントローラーは <code>255.255.255.255</code> 宛のリクエストを受信し、３番めのレスポンスを返す。"

#: ./doc/openstack-ops/app_crypt.xml185(para)
msgid "The instance finally gives up."
msgstr "最終的に、インスタンスはIPアドレス取得を諦める。"

#: ./doc/openstack-ops/app_crypt.xml188(para)
msgid ""
"With this information in hand, we were sure that the problem had to do with "
"DHCP. We thought that for some reason, the instance wasn't getting a new IP "
"address and with no IP, it shut itself off from the network."
msgstr "この情報により、我々は問題が DHCP 実行に起因するものと確信した。何らかの理由でインスタンスが新しいIPアドレスを取得できず、その結果IPアドレスがなくなり、インスタンスは自分自身をネットワークから切り離した、と考えた。"

#: ./doc/openstack-ops/app_crypt.xml192(para)
msgid ""
"A quick Google search turned up this: <link "
"href=\"https://lists.launchpad.net/openstack/msg11696.html\">DHCP lease "
"errors in VLAN mode</link> "
"(https://lists.launchpad.net/openstack/msg11696.html) which further "
"supported our DHCP theory."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml197(para)
msgid ""
"An initial idea was to just increase the lease time. If the instance only "
"renewed once every week, the chances of this problem happening would be "
"tremendously smaller than every minute. This didn't solve the problem, "
"though. It was just covering the problem up."
msgstr "最初のアイデアは、単にリース時間を増やすことだった。もしインスタンスが毎週１回だけIPアドレスを更新するのであれば、毎分更新する場合よりこの問題が起こる可能性は極端に低くなるだろう。これはこの問題を解決しないが、問題を単に取り繕うことはできる。"

#: ./doc/openstack-ops/app_crypt.xml202(para)
msgid ""
"We decided to have <placeholder-1/> run on this instance and see if we could"
" catch it in action again. Sure enough, we did."
msgstr "我々は、このインスタンス上で <placeholder-1/> を実行して、操作で再びこの現象に遭遇するか見てみることにした。実際、我々はやってみた。"

#: ./doc/openstack-ops/app_crypt.xml205(para)
msgid ""
"The <placeholder-1/> looked very, very weird. In short, it looked as though "
"network communication stopped before the instance tried to renew its IP. "
"Since there is so much DHCP chatter from a one minute lease, it's very hard "
"to confirm it, but even with only milliseconds difference between packets, "
"if one packet arrives first, it arrived first, and if that packet reported "
"network issues, then it had to have happened before DHCP."
msgstr "<placeholder-1/> の結果は非常に奇妙だった。一言で言えば、インスタンスが IP アドレスを更新しようとする前に、まるでネットワーク通信が停止しているように見えた。１分間のリース期間で大量の DHCP ネゴシエーションがあるため、確認作業は困難を極めた。しかし、パケット間のたった数ミリ秒の違いであれ、あるパケットが最初に到着する際、そのパケットが最初に到着し、そのパケットがネットワーク障害を報告した場合、DHCP より前にネットワーク障害が発生していることになる。"

#: ./doc/openstack-ops/app_crypt.xml213(para)
msgid ""
"Additionally, this instance in question was responsible for a very, very "
"large backup job each night. While \"The Issue\" (as we were now calling it)"
" didn't happen exactly when the backup happened, it was close enough (a few "
"hours) that we couldn't ignore it."
msgstr "加えて、問題のインスタンスは毎晩非常に長いバックアップジョブを担っていた。「あの問題」（今では我々はこの障害をこう呼んでいる）はバックアップが行われている最中には起こらなかったが、（数時間たっていて）「あの問題」が起こるまであと少しのところだった。"

#: ./doc/openstack-ops/app_crypt.xml218(para)
msgid ""
"Further days go by and we catch The Issue in action more and more. We find "
"that dhclient is not running after The Issue happens. Now we're back to "
"thinking it's a DHCP issue. Running "
"<filename>/etc/init.d/networking</filename> restart brings everything back "
"up and running."
msgstr "それから何日か過ぎ、我々は「あの問題」に度々遭遇した。我々は「あの問題」の発生後、dhclient が実行されていないことを発見した。今、我々は、それが DHCP の問題であるという考えに立ち戻った。<filename>/etc/init.d/networking</filename> restart を実行すると、全ては元通りに実行されるようになった。"

#: ./doc/openstack-ops/app_crypt.xml223(para)
msgid ""
"Ever have one of those days where all of the sudden you get the Google "
"results you were looking for? Well, that's what happened here. I was looking"
" for information on dhclient and why it dies when it can't renew its lease "
"and all of the sudden I found a bunch of OpenStack and dnsmasq discussions "
"that were identical to the problem we were seeing!"
msgstr "探し続けてきた Google の検索結果が突然得られたという事態をお分かりだろうか？えっと、それがここで起こったことだ。私は dhclient の情報と、何故 dhclient がそのリースを更新できない場合に死ぬのかを探していて、我々が遭遇したのと同じ問題についての OpenStack と dnsmasq の議論の束を突然発見した。"

#: ./doc/openstack-ops/app_crypt.xml230(para)
msgid ""
"<link href=\"http://www.gossamer-"
"threads.com/lists/openstack/operators/18197\">Problem with Heavy Network IO "
"and Dnsmasq</link> (http://www.gossamer-"
"threads.com/lists/openstack/operators/18197)"
msgstr "<link href=\"http://www.gossamer-threads.com/lists/openstack/operators/18197\">高負荷ネットワークIOとdnsmasqの問題</link> (http://www.gossamer-threads.com/lists/openstack/operators/18197)"

#: ./doc/openstack-ops/app_crypt.xml236(para)
msgid ""
"<link href=\"http://www.gossamer-"
"threads.com/lists/openstack/dev/14696\">instances losing IP address while "
"running, due to No DHCPOFFER</link> (http://www.gossamer-"
"threads.com/lists/openstack/dev/14696)"
msgstr "<link href=\"http://www.gossamer-threads.com/lists/openstack/dev/14696\">DHCPOFFERが送信されない事による、起動中のインスタンスのIPアドレスの消失</link> (http://www.gossamer-threads.com/lists/openstack/dev/14696)"

#: ./doc/openstack-ops/app_crypt.xml242(para)
msgid "Seriously, Google."
msgstr "マジ？Google。"

#: ./doc/openstack-ops/app_crypt.xml243(para)
msgid ""
"This bug report was the key to everything: <link "
"href=\"https://bugs.launchpad.net/ubuntu/+source/qemu-kvm/+bug/997978\"> KVM"
" images lose connectivity with bridged network</link> "
"(https://bugs.launchpad.net/ubuntu/+source/qemu-kvm/+bug/997978)"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml249(para)
msgid ""
"It was funny to read the report. It was full of people who had some strange "
"network problem but didn't quite explain it in the same way."
msgstr "レポートを読むのは楽しかった。同じ奇妙なネットワーク問題にあった人々であふれていたが、全く同じ説明はなかった。"

#: ./doc/openstack-ops/app_crypt.xml252(para)
msgid "So it was a qemu/kvm bug."
msgstr "つまり、これは qemu/kvm のバグである。"

#: ./doc/openstack-ops/app_crypt.xml253(para)
msgid ""
"At the same time of finding the bug report, a co-worker was able to "
"successfully reproduce The Issue! How? He used <placeholder-1/> to spew a "
"ton of bandwidth at an instance. Within 30 minutes, the instance just "
"disappeared from the network."
msgstr "バグ報告を発見すると同時に、同僚が「あの問題」を再現することに成功した！どうやって？彼は <placeholder-1/> を使用して、インスタンス上で膨大なネットワーク負荷をかけた。30分後、インスタンスはネットワークから姿を消した。"

#: ./doc/openstack-ops/app_crypt.xml258(para)
msgid ""
"Armed with a patched qemu and a way to reproduce, we set out to see if we've"
" finally solved The Issue. After 48 hours straight of hammering the instance"
" with bandwidth, we were confident. The rest is history. You can search the "
"bug report for \"joe\" to find my comments and actual tests."
msgstr "パッチを当てた qemu と再現方法を携えて、我々は「あの問題」を最終的に解決したかを確認する作業に着手した。インスタンスにネットワーク負荷をかけてから丸48時間後、我々は確信していた。その後のことは知っての通りだ。あなたは、joe へのバグ報告を検索し、私のコメントと実際のテストを見つけることができる。"

#: ./doc/openstack-ops/app_crypt.xml266(title)
msgid "Disappearing Images"
msgstr "イメージの消失"

#: ./doc/openstack-ops/app_crypt.xml267(para)
msgid ""
"At the end of 2012, Cybera (a nonprofit with a mandate to oversee the "
"development of cyberinfrastructure in Alberta, Canada) deployed an updated "
"OpenStack cloud for their <link title=\"DAIR project\" "
"href=\"http://www.canarie.ca/en/dair-program/about\">DAIR project</link> "
"(http://www.canarie.ca/en/dair-program/about). A few days into production, a"
" compute node locks up. Upon rebooting the node, I checked to see what "
"instances were hosted on that node so I could boot them on behalf of the "
"customer. Luckily, only one instance."
msgstr "2012年の終わり、Cybera （カナダ アルバータ州にある、サイバーインフラのデプロイを監督する権限を持つ非営利団体）が、彼らの <link title=\"DAIR project\" href=\"http://www.canarie.ca/en/dair-program/about\">DAIR プロジェクト</link> (http://www.canarie.ca/en/dair-program/about) 用に新しい OpenStack クラウドをデプロイした。サービスインから数日後、あるコンピュートノードがロックアップした。問題のノードの再起動にあたり、私は顧客の権限でインスタンスを起動するため、そのノード上で何のインスタンスがホスティングされていたかを確認した。幸運にも、インスタンスは１つだけだった。"

#: ./doc/openstack-ops/app_crypt.xml278(para)
msgid ""
"The <placeholder-1/> command wasn't working, so I used <placeholder-2/>, but"
" it immediately came back with an error saying it was unable to find the "
"backing disk. In this case, the backing disk is the Glance image that is "
"copied to <filename>/var/lib/nova/instances/_base</filename> when the image "
"is used for the first time. Why couldn't it find it? I checked the directory"
" and sure enough it was gone."
msgstr "<placeholder-1/> コマンドは機能しなかったので、<placeholder-2/> を使用したが、すぐに仮想ディスクが見つからないとのエラーが返ってきた。この場合、仮想ディスクは Glance イメージで、イメージが最初に使用する際に <filename>/var/lib/nova/instances/_base</filename> にコピーされていた。何故イメージが見つからないのか？私はそのディレクトリをチェックし、イメージがないことを知った。"

#: ./doc/openstack-ops/app_crypt.xml287(para)
msgid ""
"I reviewed the <code>nova</code> database and saw the instance's entry in "
"the <code>nova.instances</code> table. The image that the instance was using"
" matched what virsh was reporting, so no inconsistency there."
msgstr "私は <code>nova</code> データベースを見直し、<code>nova.instances</code> テーブル中の当該インスタンスのレコードを見た。インスタンスが使用しているイメージは virsh が報告したものと一致した。よって、ここでは矛盾は発見されなかった。"

#: ./doc/openstack-ops/app_crypt.xml291(para)
msgid ""
"I checked Glance and noticed that this image was a snapshot that the user "
"created. At least that was good newsthis user would have been the only user "
"affected."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml295(para)
msgid ""
"Finally, I checked StackTach and reviewed the user's events. They had "
"created and deleted several snapshotsmost likely experimenting. Although the"
" timestamps didn't match up, my conclusion was that they launched their "
"instance and then deleted the snapshot and it was somehow removed from "
"/var/lib/nova/instances/_base. None of that made sense, but it was the best "
"I could come up with."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml302(para)
msgid ""
"It turns out the reason that this compute node locked up was a hardware "
"issue. We removed it from the DAIR cloud and called Dell to have it "
"serviced. Dell arrived and began working. Somehow or another (or a fat "
"finger), a different compute node was bumped and rebooted. Great."
msgstr "コンピュートノードがロックアップした原因はハードウェアの問題だったことが判明した。我々はそのハードウェアを DAIR クラウドから取り外し、修理するよう Dell に依頼した。Dell が到着して作業を開始した。何とかかんとか（あるいはタイプミス）で、異なるコンピュートノードを落としてしまい、再起動した。素晴らしい。"

#: ./doc/openstack-ops/app_crypt.xml308(para)
msgid ""
"When this node fully booted, I ran through the same scenario of seeing what "
"instances were running so I could turn them back on. There were a total of "
"four. Three booted and one gave an error. It was the same error as before: "
"unable to find the backing disk. Seriously, what?"
msgstr "そのノードが完全に起動した際、インスタンスが起動した時に何が起こるのかを見るため、私は同じシナリオを実行して、インスタンスを復旧した。インスタンスは全部で４つあった。３つは起動し、１つはエラーになった。このエラーは以前のエラーと同じだった。「unable to find the backing disk.」マジ、何で？"

#: ./doc/openstack-ops/app_crypt.xml314(para)
msgid ""
"Again, it turns out that the image was a snapshot. The three other instances"
" that successfully started were standard cloud images. Was it a problem with"
" snapshots? That didn't make sense."
msgstr "再度、イメージがスナップショットであることが判明した。無事に起動した他の３インスタンスは標準のクラウドイメージであった。これはスナップショットの問題か？それは意味が無かった。"

#: ./doc/openstack-ops/app_crypt.xml318(para)
msgid ""
"A note about DAIR's architecture: "
"<filename>/var/lib/nova/instances</filename> is a shared NFS mount. This "
"means that all compute nodes have access to it, which includes the "
"<code>_base</code> directory. Another centralized area is "
"<filename>/var/log/rsyslog</filename> on the cloud controller. This "
"directory collects all OpenStack logs from all compute nodes. I wondered if "
"there were any entries for the file that <placeholder-1/> is reporting: "
"<placeholder-2/>"
msgstr "DAIR のアーキテクチャは <filename>/var/lib/nova/instances</filename> が共有 NFS マウントであることに注意したい。これは、全てのコンピュートノードがそのディレクトリにアクセスし、その中に <code>_base</code> ディレクトリが含まれることを意味していた。その他の集約化エリアはクラウドコントローラーの <filename>/var/log/rsyslog</filename> だ。このディレクトリは全コンピュートノードの全ての OpenStack ログが収集されていた。私は、<placeholder-1/> が報告したファイルに関するエントリがあるのだろうかと思った。 <placeholder-2/>"

#: ./doc/openstack-ops/app_crypt.xml333(para)
msgid "Ah-hah! So OpenStack was deleting it. But why?"
msgstr "あっはっは！じゃぁ、OpenStack が削除したのか。でも何故？"

#: ./doc/openstack-ops/app_crypt.xml334(para)
msgid ""
"A feature was introduced in Essex to periodically check and see if there "
"were any <code>_base</code> files not in use. If there were, Nova would "
"delete them. This idea sounds innocent enough and has some good qualities to"
" it. But how did this feature end up turned on? It was disabled by default "
"in Essex. As it should be. It was <link "
"href=\"https://bugs.launchpad.net/nova/+bug/1029674\">decided to be turned "
"on in Folsom</link> (https://bugs.launchpad.net/nova/+bug/1029674). I cannot"
" emphasize enough that:"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml346(emphasis)
msgid "Actions which delete things should not be enabled by default."
msgstr "何かを削除する操作はデフォルトで有効化されるべきではない。"

#: ./doc/openstack-ops/app_crypt.xml349(para)
msgid "Disk space is cheap these days. Data recovery is not."
msgstr "今日、ディスクスペースは安価である。データの復元はそうではない。"

#: ./doc/openstack-ops/app_crypt.xml351(para)
msgid ""
"Secondly, DAIR's shared <filename>/var/lib/nova/instances</filename> "
"directory contributed to the problem. Since all compute nodes have access to"
" this directory, all compute nodes periodically review the _base directory. "
"If there is only one instance using an image, and the node that the instance"
" is on is down for a few minutes, it won't be able to mark the image as "
"still in use. Therefore, the image seems like it's not in use and is "
"deleted. When the compute node comes back online, the instance hosted on "
"that node is unable to start."
msgstr "次に、DAIR の共有された <filename>/var/lib/nova/instances</filename> が問題を助長した。全コンピュートノードがこのディレクトリにアクセスするため、全てのコンピュートノードは定期的に _base ディレクトリを見直していた。あるイメージを使用しているインスタンスが１つだけあり、そのインスタンスが存在するノードが数分間ダウンした場合、そのイメージが使用中であるという印を付けられなくなる。それゆえ、イメージは使用中に見えず、削除されてしまったのだ。そのコンピュートノードが復帰した際、そのノード上でホスティングされていたインスタンスは起動できない。"

#: ./doc/openstack-ops/app_crypt.xml364(title)
msgid "The Valentine's Day Compute Node Massacre"
msgstr "バレンタインデーのコンピュートノード大虐殺"

#: ./doc/openstack-ops/app_crypt.xml365(para)
msgid ""
"Although the title of this story is much more dramatic than the actual "
"event, I don't think, or hope, that I'll have the opportunity to use "
"\"Valentine's Day Massacre\" again in a title."
msgstr "この物語のタイトルは実際の事件よりかなりドラマティックだが、私はタイトル中に「バレンタインデーの大虐殺」を使用する機会が再びあるとは思わない（し望まない）。"

#: ./doc/openstack-ops/app_crypt.xml369(para)
msgid ""
"This past Valentine's Day, I received an alert that a compute node was no "
"longer available in the cloudmeaning, showed this particular node with a "
"status of XXX."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml374(para)
msgid ""
"I logged into the cloud controller and was able to both <placeholder-1/> and"
" SSH into the problematic compute node which seemed very odd. Usually if I "
"receive this type of alert, the compute node has totally locked up and would"
" be inaccessible."
msgstr "実に奇妙なことだが、私はクラウドコントローラーにログインし、問題のコンピュートノードに <placeholder-1/> と SSH の両方を実行できた。通常、この種の警告を受け取ると、コンピュートノードは完全にロックしていてアクセス不可になる。"

#: ./doc/openstack-ops/app_crypt.xml379(para)
msgid "After a few minutes of troubleshooting, I saw the following details:"
msgstr "数分間のトラブル調査の後、以下の詳細が判明した。"

#: ./doc/openstack-ops/app_crypt.xml383(para)
msgid "A user recently tried launching a CentOS instance on that node"
msgstr "最近、あるユーザがそのノード上で CentOS のインスタンスを起動しようとした。"

#: ./doc/openstack-ops/app_crypt.xml387(para)
msgid "This user was the only user on the node (new node)"
msgstr "このユーザはそのノード（新しいノード）上の唯一のユーザだった。"

#: ./doc/openstack-ops/app_crypt.xml391(para)
msgid "The load shot up to 8 right before I received the alert"
msgstr "私が警告を受け取る直前、負荷率は８に急増した。"

#: ./doc/openstack-ops/app_crypt.xml395(para)
msgid "The bonded 10gb network device (bond0) was in a DOWN state"
msgstr "冗長化された 10Gb ネットワークデバイス(bond0）は DOWN 状態だった。"

#: ./doc/openstack-ops/app_crypt.xml399(para)
msgid "The 1gb NIC was still alive and active"
msgstr "1Gb NICはまだ生きていて、有効だった。"

#: ./doc/openstack-ops/app_crypt.xml402(para)
msgid ""
"I looked at the status of both NICs in the bonded pair and saw that neither "
"was able to communicate with the switch port. Seeing as how each NIC in the "
"bond is connected to a separate switch, I thought that the chance of a "
"switch port dying on each switch at the same time was quite improbable. I "
"concluded that the 10gb dual port NIC had died and needed replaced. I "
"created a ticket for the hardware support department at the data center "
"where the node was hosted. I felt lucky that this was a new node and no one "
"else was hosted on it yet."
msgstr "私は bonding ペアの両方の NIC の状態を確認し、両方ともスイッチポートへの通信ができないことを知った。bond 中の各 NIC が異なるスイッチに接続されていることを知り、私は、各スイッチのスイッチポートが同時に死ぬ可能性はまずないと思った。私は 10Gb デュアルポート NIC が死んで、交換が必要だと結論づけた。私は、そのノードがホスティングされているデータセンターのハードウェアサポート部門に宛てたチケットを作成した。私は、それが新しいノードで、他のインスタンスがまだそのノード上でホスティングされていないことを幸運に思った。"

#: ./doc/openstack-ops/app_crypt.xml412(para)
msgid ""
"An hour later I received the same alert, but for another compute node. Crap."
" OK, now there's definitely a problem going on. Just like the original node,"
" I was able to log in by SSH. The bond0 NIC was DOWN but the 1gb NIC was "
"active."
msgstr "１時間後、私は同じ警告を受信したが、別のコンピュートノードだった。拍手。OK、問題は間違いなく現在進行中だ。元のノードと全く同様に、私は SSH でログインすることが出来た。bond0 NIC は DOWN だったが、1Gb NIC は有効だった。"

#: ./doc/openstack-ops/app_crypt.xml417(para)
msgid ""
"And the best part: the same user had just tried creating a CentOS instance. "
"What?"
msgstr "そして、最も重要なこと。同じユーザが CentOS インスタンスを作成しようとしたばかりだった。何だと？"

#: ./doc/openstack-ops/app_crypt.xml419(para)
msgid ""
"I was totally confused at this point, so I texted our network admin to see "
"if he was available to help. He logged in to both switches and immediately "
"saw the problem: the switches detected spanning tree packets coming from the"
" two compute nodes and immediately shut the ports down to prevent spanning "
"tree loops: <placeholder-1/>"
msgstr "私はこの時点で完全に混乱した。よって、私はネットワーク管理者に対して、私を助けられるか聞いてみるためメールした。彼は両方のスイッチにログインし、すぐに問題を発見した。そのスイッチは２つのコンピュートノードから来たスパニングツリーパケットを検出し、スパニングツリーループを回避するため、即時にそれらのポートをダウンさせたのだ。<placeholder-1/>"

#: ./doc/openstack-ops/app_crypt.xml432(para)
msgid ""
"He re-enabled the switch ports and the two compute nodes immediately came "
"back to life."
msgstr "彼はスイッチポートを再度有効にしたところ、２つのコンピュートノードは即時に復活した。"

#: ./doc/openstack-ops/app_crypt.xml434(para)
msgid ""
"Unfortunately, this story has an open ending... we're still looking into why"
" the CentOS image was sending out spanning tree packets. Further, we're "
"researching a proper way on how to mitigate this from happening. It's a "
"bigger issue than one might think. While it's extremely important for "
"switches to prevent spanning tree loops, it's very problematic to have an "
"entire compute node be cut from the network when this happens. If a compute "
"node is hosting 100 instances and one of them sends a spanning tree packet, "
"that instance has effectively DDOS'd the other 99 instances."
msgstr "不幸にも、この話にはエンディングがない…我々は、なぜ CentOS イメージがスパニングツリーパケットを送信し始める原因をいまだ探している。更に、我々は障害時にスパニングツリーを軽減する正しい方法を調査している。これは誰かが思うより大きな問題だ。スパニングツリーループを防ぐことはスイッチにとって非常に重要であるが、スパニングツリーが起こった際に、コンピュートノード全体がネットワークから切り離されることも大きな問題である。コンピュートノードが 100 インスタンスをホスティングしていて、そのうち１つがスパニングツリーパケットを送信した場合、そのインスタンスは事実上他の 99 インスタンスを DDoS（サービス不能攻撃）したことになる。"

#: ./doc/openstack-ops/app_crypt.xml445(para)
msgid ""
"This is an ongoing and hot topic in networking circles especially with the "
"raise of virtualization and virtual switches."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml450(title)
msgid "Down the Rabbit Hole"
msgstr "ウサギの穴に落ちて"

#: ./doc/openstack-ops/app_crypt.xml451(para)
msgid ""
"Users being able to retrieve console logs from running instances is a boon "
"for supportmany times they can figure out what's going on inside their "
"instance and fix what's going on without bothering you. Unfortunately, "
"sometimes overzealous logging of failures can cause problems of its own."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml457(para)
msgid ""
"A report came in: VMs were launching slowly, or not at all. Cue the standard"
" checksnothing on the nagios, but there was a spike in network towards the "
"current master of our RabbitMQ cluster. Investigation started, but soon the "
"other parts of the queue cluster were leaking memory like a sieve. Then the "
"alert came inthe master rabbit server went down. Connections failed over to "
"the slave."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml464(para)
msgid ""
"At that time, our control services were hosted by another team and we didn't"
" have much debugging information to determine what was going on with the "
"master, and couldn't reboot it. That team noted that it failed without "
"alert, but managed to reboot it. After an hour, the cluster had returned to "
"its normal state and we went home for the day."
msgstr "この時、我々のコントロールサービスは別のチームによりホスティングされており、我々には現用系サーバー上で何が起こっているのかを調査するための大したデバッグ情報がなく、再起動もできなかった。このチームは警報なしで障害が起こったと連絡してきたが、そのサーバーの再起動を管理していた。１時間後、クラスタは通常状態に復帰し、我々はその日は帰宅した。"

#: ./doc/openstack-ops/app_crypt.xml471(para)
msgid ""
"Continuing the diagnosis the next morning was kick started by another "
"identical failure. We quickly got the message queue running again, and tried"
" to work out why Rabbit was suffering from so much network traffic. Enabling"
" debug logging on <systemitem class=\"service\">nova-api</systemitem> "
"quickly brought understanding. A <placeholder-1/> was scrolling by faster "
"than we'd ever seen before. CTRL+C on that and we could plainly see the "
"contents of a system log spewing failures over and over again - a system log"
" from one of our users' instances."
msgstr "翌朝の継続調査は別の同様の障害でいきなり始まった。我々は急いで RabbitMQ サーバーを再起動し、何故 RabbitMQ がそのような過剰なネットワーク負荷に直面しているのかを調べようとした。<systemitem class=\"service\">nova-api</systemitem> のデバッグログを出力することにより、理由はすぐに判明した。<placeholder-1/> は我々が見たこともない速さでスクロールしていた。CTRL+C でコマンドを止め、障害を吐き出していたシステムログの内容をはっきり目にすることが出来た。－我々のユーザの１人のインスタンスからのシステムログだった。"

#: ./doc/openstack-ops/app_crypt.xml483(para)
msgid ""
"After finding the instance ID we headed over to "
"<filename>/var/lib/nova/instances</filename> to find the "
"<filename>console.log</filename>: <placeholder-1/>"
msgstr "インスタンスIDの発見後、<filename>console.log</filename> を探すため <filename>/var/lib/nova/instances</filename> にアクセスした。<placeholder-1/>"

#: ./doc/openstack-ops/app_crypt.xml491(para)
msgid ""
"Sure enough, the user had been periodically refreshing the console log page "
"on the dashboard and the 5G file was traversing the rabbit cluster to get to"
" the dashboard."
msgstr "思った通り、ユーザはダッシュボード上のコンソールログページを定期的に更新しており、ダッシュボードに向けて5GB のファイルが RabbitMQ クラスタを通過していた。"

#: ./doc/openstack-ops/app_crypt.xml495(para)
msgid ""
"We called them and asked them to stop for a while, and they were happy to "
"abandon the horribly broken VM. After that, we started monitoring the size "
"of console logs."
msgstr "我々はユーザを呼び、しばらくダッシュボードの更新を止めるよう申し入れた。すると、恐ろしい VM の破壊は止み、彼らは大いに喜んだ。その後、我々はコンソールログのサイズを監視するようになった。"

#: ./doc/openstack-ops/app_crypt.xml499(para)
msgid ""
"To this day, <link href=\"https://bugs.launchpad.net/nova/+bug/832507\">the "
"issue</link> (https://bugs.launchpad.net/nova/+bug/832507) doesn't have a "
"permanent resolution, but we look forward to the discussion at the next "
"summit."
msgstr "今日に至るまで、<link href=\"https://bugs.launchpad.net/nova/+bug/832507\">この問題</link> (https://bugs.launchpad.net/nova/+bug/832507) には完全な解決策がないが、我々は次回のサミットの議論に期待している。"

#: ./doc/openstack-ops/app_crypt.xml507(title)
msgid "Havana Haunted by the Dead"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml508(para)
msgid ""
"Felix Lee of Academia Sinica Grid Computing Centre in Taiwan contributed "
"this story."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml510(para)
msgid ""
"I just upgraded OpenStack from Grizzly to Havana 2013.2-2 using the RDO "
"repository and everything was running pretty wellexcept the EC2 API."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml513(para)
msgid ""
"I noticed that the API would suffer from a heavy load and respond slowly to "
"particular EC2 requests such as <literal>RunInstances</literal>."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml516(para)
msgid "Output from <filename>/var/log/nova/nova-api.log</filename> on Havana:"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml525(para)
msgid ""
"This request took over two minutes to process, but executed quickly on "
"another co-existing Grizzly deployment using the same hardware and system "
"configuration."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml528(para)
msgid ""
"Output from <filename>/var/log/nova/nova-api.log</filename> on Grizzly:"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml537(para)
msgid ""
"While monitoring system resources, I noticed a significant increase in "
"memory consumption while the EC2 API processed this request. I thought it "
"wasn't handling memory properlypossibly not releasing memory. If the API "
"received several of these requests, memory consumption quickly grew until "
"the system ran out of RAM and began using swap. Each node has 48 GB of RAM "
"and the \"nova-api\" process would consume all of it within minutes. Once "
"this happened, the entire system would become unusably slow until I "
"restarted the nova-api service."
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml547(para)
msgid ""
"So, I found myself wondering what changed in the EC2 API on Havana that "
"might cause this to happen. Was it a bug or a normal behavior that I now "
"need to work around?"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml550(para)
msgid ""
"After digging into the Nova code, I noticed two areas in "
"<filename>api/ec2/cloud.py</filename> potentially impacting my system:"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml562(para)
msgid ""
"Since my database contained many recordsover 1 million metadata records and "
"over 300,000 instance records in \"deleted\" or \"errored\" stateseach "
"search took ages. I decided to clean up the database by first archiving a "
"copy for backup and then performing some deletions using the MySQL client. "
"For example, I ran the following SQL command to remove rows of instances "
"deleted for over a year:"
msgstr ""

#: ./doc/openstack-ops/app_crypt.xml570(para)
msgid ""
"Performance increased greatly after deleting the old records and my new "
"deployment continues to behave well."
msgstr ""

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/section_arch_example-nova.xml411(None)
msgid ""
"@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc"
"/openstack-ops/figures/osog_01in01.png'; md5=THIS FILE DOESN'T EXIST"
msgstr "@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/openstack-ops/figures/osog_01in01.png'; md5=THIS FILE DOESN'T EXIST"

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/section_arch_example-nova.xml450(None)
msgid ""
"@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc"
"/openstack-ops/figures/osog_01in02.png'; md5=THIS FILE DOESN'T EXIST"
msgstr "@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/openstack-ops/figures/osog_01in02.png'; md5=THIS FILE DOESN'T EXIST"

#: ./doc/openstack-ops/section_arch_example-nova.xml12(title)
msgid "Example Architecture—Legacy Networking (nova)"
msgstr "アーキテクチャ例: レガシーネットワーク (nova)"

#: ./doc/openstack-ops/section_arch_example-nova.xml14(para)
msgid ""
"This particular example architecture has been upgraded from Grizzly to "
"Havana and tested in production environments where many public IP addresses "
"are available for assignment to multiple instances. You can find a second "
"example architecture that uses OpenStack Networking (neutron) after this "
"section. Each example offers high availability, meaning that if a particular"
" node goes down, another node with the same configuration can take over the "
"tasks so that service continues to be available.<indexterm "
"class=\"singular\"><primary>Havana</primary></indexterm><indexterm "
"class=\"singular\"><primary>Grizzly</primary></indexterm>"
msgstr "この特定のアーキテクチャ例は、Grizzly から Havana にアップグレードされており、複数のインスタンスに割り当てるためのパブリック IP アドレスが多数利用可能な本番環境でテスト済みです。このセクションの次には、OpenStack Networking (neutron) を使用する第 2 のアーキテクチャ例を紹介しています。各例では高可用性を提供しています。これは、特定のノードが停止した場合には同じ設定の別のノードがタスクを引き継いでサービスを引き続き提供できることを意味します。<indexterm class=\"singular\"><primary>Havana</primary></indexterm><indexterm class=\"singular\"><primary>Grizzly</primary></indexterm>"

#: ./doc/openstack-ops/section_arch_example-nova.xml27(title)
#: ./doc/openstack-ops/section_arch_example-neutron.xml23(title)
msgid "Overview"
msgstr "概要"

#: ./doc/openstack-ops/section_arch_example-nova.xml29(para)
msgid ""
"The simplest architecture you can build upon for Compute has a single cloud "
"controller and multiple compute nodes. The simplest architecture for Object "
"Storage has five nodes: one for identifying users and proxying requests to "
"the API, then four for storage itself to provide enough replication for "
"eventual consistency. This example architecture does not dictate a "
"particular number of nodes, but shows the thinking <phrase role=\"keep-"
"together\">and considerations</phrase> that went into choosing this "
"architecture including the features <phrase role=\"keep-"
"together\">offered</phrase>.<indexterm "
"class=\"singular\"><primary>CentOS</primary></indexterm><indexterm "
"class=\"singular\"><primary>RDO (Red Hat Distributed "
"OpenStack)</primary></indexterm><indexterm "
"class=\"singular\"><primary>Ubuntu</primary></indexterm><indexterm "
"class=\"singular\"><primary>legacy networking "
"(nova)</primary><secondary>component "
"overview</secondary></indexterm><indexterm "
"class=\"singular\"><primary>example architectures</primary><see>legacy "
"networking; OpenStack networking</see></indexterm><indexterm "
"class=\"singular\"><primary>Object Storage</primary><secondary>simplest "
"architecture for</secondary></indexterm><indexterm "
"class=\"singular\"><primary>Compute</primary><secondary>simplest "
"architecture for</secondary></indexterm>"
msgstr "Compute 用の基盤となる最もシンプルなアーキテクチャは、単一のクラウドコントローラーと複数のコンピュートノードで構成されます。Object Storage 用の最もシンプルなアーキテクチャは、ユーザーを識別して API への要求をプロキシするノード 1 つと、最終的な一貫性を確保するのに十分なレプリケーションを提供する、ストレージ自体のためのノード 4つを合わせた 5 つのノードで構成されます。このアーキテクチャの例では、特定のノード数は決まっていませんが、このアーキテクチャを選択するにあたって考慮 <phrase role=\"keep-together\">および検討した点</phrase> (どのような機能を<phrase role=\"keep-together\">提供するか</phrase>など) をお分かりいただけます。<indexterm class=\"singular\"><primary>CentOS</primary></indexterm><indexterm class=\"singular\"><primary>RDO (Red Hat Distributed OpenStack)</primary></indexterm><indexterm class=\"singular\"><primary>Ubuntu</primary></indexterm><indexterm class=\"singular\"><primary>レガシーネットワーク (nova)</primary><secondary>コンポーネントの概要</secondary></indexterm><indexterm class=\"singular\"><primary>アーキテクチャ例</primary><see>レガシーネットワーク; OpenStack Networking</see></indexterm><indexterm class=\"singular\"><primary>Object Storage</primary><secondary>最もシンプルなアーキテクチャ</secondary></indexterm><indexterm class=\"singular\"><primary>Compute</primary><secondary>最もシンプルなアーキテクチャ</secondary></indexterm>"

#: ./doc/openstack-ops/section_arch_example-nova.xml62(title)
#: ./doc/openstack-ops/section_arch_example-neutron.xml38(title)
msgid "Components"
msgstr "コンポーネント"

#: ./doc/openstack-ops/section_arch_example-nova.xml71(th)
#: ./doc/openstack-ops/section_arch_example-neutron.xml47(th)
msgid "Component"
msgstr "コンポーネント"

#: ./doc/openstack-ops/section_arch_example-nova.xml73(th)
#: ./doc/openstack-ops/section_arch_example-neutron.xml49(th)
msgid "Details"
msgstr "詳細"

#: ./doc/openstack-ops/section_arch_example-nova.xml79(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml55(para)
msgid "OpenStack release"
msgstr "OpenStack リリース"

#: ./doc/openstack-ops/section_arch_example-nova.xml85(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml61(para)
msgid "Host operating system"
msgstr "ホストのオペレーティングシステム"

#: ./doc/openstack-ops/section_arch_example-nova.xml87(para)
msgid ""
"Ubuntu 12.04 LTS or Red Hat Enterprise Linux 6.5, including derivatives such"
" as CentOS and Scientific Linux"
msgstr "Ubuntu 12.04 LTS または Red Hat Enterprise Linux 6.5 (CentOS および Scientific Linux などの派生物を含む)"

#: ./doc/openstack-ops/section_arch_example-nova.xml93(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml67(para)
msgid "OpenStack package repository"
msgstr "OpenStack パッケージリポジトリ"

#: ./doc/openstack-ops/section_arch_example-nova.xml95(para)
msgid ""
"<link href=\"https://wiki.ubuntu.com/ServerTeam/CloudArchive\">Ubuntu Cloud "
"Archive</link> or <link "
"href=\"http://openstack.redhat.com/Frequently_Asked_Questions\">RDO</link>*"
msgstr "<link href=\"https://wiki.ubuntu.com/ServerTeam/CloudArchive\">Ubuntu Cloud Archive</link> または <link href=\"http://openstack.redhat.com/Frequently_Asked_Questions\">RDO</link>*"

#: ./doc/openstack-ops/section_arch_example-nova.xml101(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml74(para)
msgid "Hypervisor"
msgstr "ハイパーバイザー"

#: ./doc/openstack-ops/section_arch_example-nova.xml103(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml76(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml166(term)
#: ./doc/openstack-ops/ch_arch_compute_nodes.xml124(link)
msgid "KVM"
msgstr "KVM"

#: ./doc/openstack-ops/section_arch_example-nova.xml107(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml80(para)
#: ./doc/openstack-ops/ch_arch_cloud_controller.xml368(title)
msgid "Database"
msgstr "データベース"

#: ./doc/openstack-ops/section_arch_example-nova.xml109(para)
msgid "MySQL*"
msgstr "MySQL*"

#: ./doc/openstack-ops/section_arch_example-nova.xml113(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml86(para)
msgid "Message queue"
msgstr "メッセージキュー"

#: ./doc/openstack-ops/section_arch_example-nova.xml115(para)
msgid "RabbitMQ for Ubuntu; Qpid for Red Hat Enterprise Linux and derivatives"
msgstr "Ubuntu には RabbitMQ、Red Hat Enterprise Linux には Qpid、 および派生物"

#: ./doc/openstack-ops/section_arch_example-nova.xml120(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml92(para)
msgid "Networking service"
msgstr "ネットワークサービス"

#: ./doc/openstack-ops/section_arch_example-nova.xml122(literal)
msgid "nova-network"
msgstr "nova-network"

#: ./doc/openstack-ops/section_arch_example-nova.xml126(para)
msgid "Network manager"
msgstr "ネットワークマネージャー"

#: ./doc/openstack-ops/section_arch_example-nova.xml128(para)
#: ./doc/openstack-ops/ch_arch_network_design.xml332(para)
msgid "FlatDHCP"
msgstr "FlatDHCP"

#: ./doc/openstack-ops/section_arch_example-nova.xml132(para)
msgid "Single <literal>nova-network</literal> or multi-host?"
msgstr "単一の <literal>nova-network</literal> またはマルチホスト?"

#: ./doc/openstack-ops/section_arch_example-nova.xml135(para)
msgid "multi-host*"
msgstr "マルチホスト*"

#: ./doc/openstack-ops/section_arch_example-nova.xml139(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml104(para)
msgid "Image Service (glance) backend"
msgstr "Image Service (glance) バックエンド"

#: ./doc/openstack-ops/section_arch_example-nova.xml141(para)
msgid "file"
msgstr "file"

#: ./doc/openstack-ops/section_arch_example-nova.xml145(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml110(para)
msgid "Identity Service (keystone) driver"
msgstr "Identity Service (keystone) のドライバー"

#: ./doc/openstack-ops/section_arch_example-nova.xml147(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml112(para)
msgid "SQL"
msgstr "SQL"

#: ./doc/openstack-ops/section_arch_example-nova.xml151(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml116(para)
msgid "Block Storage Service (cinder) backend"
msgstr "Block Storage Service (cinder) バックエンド"

#: ./doc/openstack-ops/section_arch_example-nova.xml153(para)
msgid "LVM/iSCSI"
msgstr "LVM/iSCSI"

#: ./doc/openstack-ops/section_arch_example-nova.xml157(para)
msgid "Live Migration backend"
msgstr "ライブマイグレーションバックエンド"

#: ./doc/openstack-ops/section_arch_example-nova.xml159(para)
msgid "Shared storage using NFS*"
msgstr "NFS を使用する共有ストレージ* "

#: ./doc/openstack-ops/section_arch_example-nova.xml163(para)
#: ./doc/openstack-ops/ch_arch_storage.xml241(th)
msgid "Object storage"
msgstr "オブジェクトストレージ"

#: ./doc/openstack-ops/section_arch_example-nova.xml165(para)
#: ./doc/openstack-ops/ch_arch_storage.xml285(para)
#: ./doc/openstack-ops/ch_arch_storage.xml625(term)
msgid "OpenStack Object Storage (swift)"
msgstr "OpenStack Object Storage (swift)"

#: ./doc/openstack-ops/section_arch_example-nova.xml170(para)
msgid ""
"An asterisk (*) indicates when the example architecture deviates from the "
"settings of a default installation. We'll offer explanations for those "
"deviations next.<indexterm "
"class=\"singular\"><primary>objects</primary><secondary>object "
"storage</secondary></indexterm><indexterm "
"class=\"singular\"><primary>storage</primary><secondary>object "
"storage</secondary></indexterm><indexterm "
"class=\"singular\"><primary>migration</primary></indexterm><indexterm "
"class=\"singular\"><primary>live migration</primary></indexterm><indexterm "
"class=\"singular\"><primary>IP "
"addresses</primary><secondary>floating</secondary></indexterm><indexterm "
"class=\"singular\"><primary>floating IP "
"address</primary></indexterm><indexterm "
"class=\"singular\"><primary>storage</primary><secondary>block "
"storage</secondary></indexterm><indexterm class=\"singular\"><primary>block "
"storage</primary></indexterm><indexterm "
"class=\"singular\"><primary>dashboard</primary></indexterm><indexterm "
"class=\"singular\"><primary>legacy networking "
"(nova)</primary><secondary>features supported by</secondary></indexterm>"
msgstr "アスタリスク (*) は、アーキテクチャの例がデフォルトインストールの設定から逸脱している箇所を示しています。この逸脱については、次のセクションで説明します。<indexterm class=\"singular\"><primary>オブジェクト</primary><secondary>Object Storage</secondary></indexterm><indexterm class=\"singular\"><primary>ストレージ</primary><secondary>Object Storage</secondary></indexterm><indexterm class=\"singular\"><primary>マイグレーション</primary></indexterm><indexterm class=\"singular\"><primary>ライブマイグレーション</primary></indexterm><indexterm class=\"singular\"><primary>IP アドレス</primary><secondary>floating</secondary></indexterm><indexterm class=\"singular\"><primary>floating IP address</primary></indexterm><indexterm class=\"singular\"><primary>ストレージ</primary><secondary>ブロックストレージ</secondary></indexterm><indexterm class=\"singular\"><primary>ブロックストレージ</primary></indexterm><indexterm class=\"singular\"><primary>ダッシュボード</primary></indexterm><indexterm class=\"singular\"><primary>レガシーネットワーク (nova)</primary><secondary>サポート対象機能</secondary></indexterm>"

#: ./doc/openstack-ops/section_arch_example-nova.xml209(para)
msgid ""
"<glossterm>Dashboard</glossterm>: You probably want to offer a dashboard, "
"but your users may be more interested in API access only."
msgstr "<glossterm>ダッシュボード</glossterm>: ダッシュボードの提供を考慮されているかもしれませんが、ユーザーは API アクセスのみの方に対する関心の方が高い可能性があります。"

#: ./doc/openstack-ops/section_arch_example-nova.xml215(para)
msgid ""
"<glossterm>Block storage</glossterm>: You don't have to offer users block "
"storage if their use case only needs ephemeral storage on compute nodes, for"
" example."
msgstr "<glossterm>ブロックストレージ</glossterm>: ユーザーのユースケースでコンピュートノード上などの一時的なストレージのみが必要とされる場合は、ブロックストレージを提供する必要はありません。"

#: ./doc/openstack-ops/section_arch_example-nova.xml221(para)
msgid ""
"<glossterm>Floating IP address</glossterm>: Floating IP addresses are public"
" IP addresses that you allocate from a predefined pool to assign to virtual "
"machines at launch. Floating IP address ensure that the public IP address is"
" available whenever an instance is booted. Not every organization can offer "
"thousands of public floating IP addresses for thousands of instances, so "
"this feature is considered optional."
msgstr "<glossterm>Floating IP アドレス</glossterm>: Floating IP アドレスとは、仮想マシンの起動時に事前定義されたプールから確保されるパブリック IP アドレスです。Floating IP アドレスにより、インスタンスの起動時には常にパブリック IP アドレスが利用できます。すべての組織が何千ものインスタンスに何千ものパブリック Floating IP アドレスを提供できるとは限らないので、この機能はオプションと考えられます。"

#: ./doc/openstack-ops/section_arch_example-nova.xml232(para)
msgid ""
"<glossterm>Live migration</glossterm>: If you need to move running virtual "
"machine instances from one host to another with little or no service "
"interruption, you would enable live migration, but it is considered "
"optional."
msgstr "<glossterm>ライブマイグレーション</glossterm>: サービスをほとんどまたは全く停止せずに実行中の仮想マシンをホスト間で移動する必要がある場合には、ライブマイグレーションを有効化することになりますが、この機能はオプションと考えられます。"

#: ./doc/openstack-ops/section_arch_example-nova.xml239(para)
msgid ""
"<glossterm>Object storage</glossterm>: You may choose to store machine "
"images on a file system rather than in object storage if you do not have the"
" extra hardware for the required replication and redundancy that OpenStack "
"Object Storage offers."
msgstr "<glossterm>Object Storage</glossterm>: OpenStack Object Storage が提供するレプリケーションと冗長化に必要な追加のハードウェアがない場合には、マシンイメージをファイルシステムに保存するように選択することが可能です。"

#: ./doc/openstack-ops/section_arch_example-nova.xml205(para)
msgid ""
"The following features of OpenStack are supported by the example "
"architecture documented in this guide, but are optional:<placeholder-1/>"
msgstr "以下にあげる OpenStack の機能は、本ガイドに記載のアーキテクチャではサポートされていますが、必須項目ではありません。<placeholder-1/>"

#: ./doc/openstack-ops/section_arch_example-nova.xml250(title)
#: ./doc/openstack-ops/section_arch_example-neutron.xml125(title)
msgid "Rationale"
msgstr "設定指針"

#: ./doc/openstack-ops/section_arch_example-nova.xml252(para)
msgid ""
"This example architecture has been selected based on the current default "
"feature set of OpenStack <glossterm>Havana</glossterm>, with an emphasis on "
"stability. We believe that many clouds that currently run OpenStack in "
"production have made similar choices.<indexterm "
"class=\"singular\"><primary>legacy networking "
"(nova)</primary><secondary>rationale for choice of</secondary></indexterm>"
msgstr "このアーキテクチャの例は、OpenStack <glossterm>Havana</glossterm> の現在のデフォルト機能セットをベースに、安定性に重点を置いて選択しています。現在 OpenStack を本番環境で実行しているクラウドの多くは、同様の選択をしているものと推定されます。<indexterm class=\"singular\"><primary>レガシーネットワーク (nova)</primary><secondary>選択の理由</secondary></indexterm>"

#: ./doc/openstack-ops/section_arch_example-nova.xml262(para)
msgid ""
"You must first choose the operating system that runs on all of the physical "
"nodes. While OpenStack is supported on several distributions of Linux, we "
"used <emphasis>Ubuntu 12.04 LTS (Long Term Support)</emphasis>, which is "
"used by the majority of the development community, has feature completeness "
"compared with other distributions and has clear future support plans."
msgstr "まず最初に、物理ノード上で実行するオペレーティングシステムを選択する必要があります。OpenStack は複数の Linux ディストリビューションでサポートされていますが、開発コミュニティの大半で使用されている <emphasis>Ubuntu 12.04 LTS (Long Term Support)</emphasis> を使用しました。このディストリビューションは、他のディストリビューションと比較した場合、機能の完全性が高く、将来のサポートプランが明確に立てられています。"

#: ./doc/openstack-ops/section_arch_example-nova.xml269(para)
msgid ""
"We recommend that you do not use the default Ubuntu OpenStack install "
"packages and instead use the <link "
"href=\"https://wiki.ubuntu.com/ServerTeam/CloudArchive\">Ubuntu Cloud "
"Archive</link>. The Cloud Archive is a package repository supported by "
"Canonical that allows you to upgrade to future OpenStack releases while "
"remaining on Ubuntu 12.04."
msgstr "デフォルトの Ubuntu OpenStack インストールパッケージは使用せずに、<link href=\"https://wiki.ubuntu.com/ServerTeam/CloudArchive\">Ubuntu Cloud Archive</link> を使用することをお勧めします。Cloud Archive は、Canonical がサポートするパッケージリポジトリです。これにより、Ubuntu 12.04 を維持した状態で将来の OpenStack リリースにアップグレードすることができます。"

#: ./doc/openstack-ops/section_arch_example-nova.xml276(para)
msgid ""
"<emphasis>KVM</emphasis> as a <glossterm>hypervisor</glossterm> complements "
"the choice of Ubuntu—being a matched pair in terms of support, and also "
"because of the significant degree of attention it garners from the OpenStack"
" development community (including the authors, who mostly use KVM). It is "
"also feature complete, free from licensing charges and "
"restrictions.<indexterm class=\"singular\"><primary>kernel-based VM (KVM) "
"hypervisor</primary></indexterm><indexterm "
"class=\"singular\"><primary>hypervisors</primary><secondary>KVM</secondary></indexterm>"
msgstr "<emphasis>KVM</emphasis> は <glossterm>ハイパーバイザー</glossterm> として Ubuntu の選択を補完します。これらはサポート面で対応する一対であり、OpenStack 開発コミュニティ (主に KVM を使用する作成者) から集まる注目度が高いのも理由です。また、機能が完全で、ライセンスの料金や制限がありません。<indexterm class=\"singular\"><primary>kernel-based VM (KVM) ハイパーバイザー</primary></indexterm><indexterm class=\"singular\"><primary>ハイパーバイザー</primary><secondary>KVM</secondary></indexterm>"

#: ./doc/openstack-ops/section_arch_example-nova.xml289(para)
msgid ""
"<emphasis>MySQL</emphasis> follows a similar trend. Despite its recent "
"change of ownership, this database is the most tested for use with OpenStack"
" and is heavily documented. We deviate from the default database, "
"<emphasis>SQLite</emphasis>, because SQLite is not an appropriate database "
"for production usage."
msgstr "<emphasis>MySQL</emphasis> も同様の傾向に沿っています。最近所有権が移転したにも関わらず、このデータベースは OpenStack での使用では最も検証されており、十分に文書化されています。<emphasis>SQLite</emphasis> は本番環境での使用には適してないため、デフォルトのデータベースでは対象外とします。"

#: ./doc/openstack-ops/section_arch_example-nova.xml295(para)
msgid ""
"The choice of <emphasis>RabbitMQ</emphasis> over other AMQP compatible "
"options that are gaining support in OpenStack, such as ZeroMQ and Qpid, is "
"due to its ease of use and significant testing in production. It also is the"
" only option that supports features such as Compute cells. We recommend "
"clustering with RabbitMQ, as it is an integral component of the system and "
"fairly simple to implement due to its inbuilt nature.<indexterm "
"class=\"singular\"><primary>Advanced Message Queuing Protocol "
"(AMQP)</primary></indexterm>"
msgstr "OpenStack では AMQP 互換の選択肢として ZeroMQ や Qpid などのサポートが進んでいますが、<emphasis>RabbitMQ</emphasis> を選んだのは、その使いやすさと本番環境で十分にテストされているのが理由です。また、RabbitMQ は Compute Cell といった機能でサポートされている唯一の選択肢です。メッセージキューは OpenStack システムで不可欠のコンポーネントで、RabbitMQ 自体で元々サポートされているため、極めて簡単に実装できます。このため、RabbitMQ は クラスター構成にすることを推奨します。<indexterm class=\"singular\"><primary>Advanced Message Queuing Protocol (AMQP)</primary></indexterm>"

#: ./doc/openstack-ops/section_arch_example-nova.xml305(para)
msgid ""
"As discussed in previous chapters, there are several options for networking "
"in OpenStack Compute. We recommend <emphasis>FlatDHCP</emphasis> and to use "
"<emphasis>Multi-Host</emphasis> networking mode for high availability, "
"running one <code>nova-network</code> daemon per OpenStack compute host. "
"This provides a robust mechanism for ensuring network interruptions are "
"isolated to individual compute hosts, and allows for the direct use of "
"hardware network gateways."
msgstr "前章で述べたように、OpenStack Compute のネットワークにはいくつかの選択肢がありますが、高可用性には <emphasis>FlatDHCP</emphasis> で <emphasis>マルチホスト</emphasis> ネットワークモードを使用して、OpenStack Compute ホスト毎に <code>nova-network</code>  デーモンを 1 つ実行することを推奨します。これにより、ネットワーク障害が確実に各コンピュートホスト内に隔離される堅牢性の高いメカニズムが提供され、各ホストはハードウェアのネットワークゲートウェイと直接通信することが可能となります。"

#: ./doc/openstack-ops/section_arch_example-nova.xml314(para)
msgid ""
"<emphasis>Live Migration</emphasis> is supported by way of shared storage, "
"with <emphasis>NFS</emphasis> as the distributed file system."
msgstr "<emphasis>ライブマイグレーション</emphasis> は、共有ストレージを使用することによってサポートされます。分散ファイルシステムには <emphasis>NFS</emphasis> を使用します。"

#: ./doc/openstack-ops/section_arch_example-nova.xml318(para)
msgid ""
"Acknowledging that many small-scale deployments see running Object Storage "
"just for the storage of virtual machine images as too costly, we opted for "
"the file backend in the OpenStack Image Service (Glance). If your cloud will"
" include Object Storage, you can easily add it as a backend."
msgstr "多くの小規模なデプロイメントでは、 Object Storage を仮想マシンイメージのストレージのみに使用するとコストがかかり過ぎることが分かっているため、OpenStack Image Service (Glance) 内のファイルバックエンドを選択しました。設計対象のクラウド環境に Object Storage が含まれる場合には、バックエンドとして容易に追加できます。"

#: ./doc/openstack-ops/section_arch_example-nova.xml324(para)
msgid ""
"We chose the <emphasis>SQL backend for Identity Service "
"(keystone)</emphasis> over others, such as LDAP. This backend is simple to "
"install and is robust. The authors acknowledge that many installations want "
"to bind with existing directory services and caution careful understanding "
"of the <link href=\"http://docs.openstack.org/havana/config-"
"reference/content/ch_configuring-openstack-identity.html#configuring-"
"keystone-for-ldap-backend\" title=\"LDAP config options\">array of options "
"available</link>."
msgstr "<emphasis>Identity Service (keystone) には SQL バックエンド</emphasis> を他のバックエンド (例: LDAP など) よりも優先して選択しました。このバックエンドは、インストールが簡単な上、頑強です。本ガイドの執筆者は、多くのインストールで既存のディレクトリサービスをバインディングする必要があることを認識しており、<link href=\"http://docs.openstack.org/havana/config-reference/content/ch_configuring-openstack-identity.html#configuring-keystone-for-ldap-backend\" title=\"LDAP config options\">利用可能な数々の選択肢</link> に記載の内容を慎重に理解するように警告しています。"

#: ./doc/openstack-ops/section_arch_example-nova.xml332(para)
msgid ""
"Block Storage (cinder) is installed natively on external storage nodes and "
"uses the <emphasis>LVM/iSCSI plug-in</emphasis>. Most Block Storage Service "
"plug-ins are tied to particular vendor products and implementations limiting"
" their use to consumers of those hardware platforms, but LVM/iSCSI is robust"
" and stable on commodity hardware."
msgstr "Block Storage (cinder) は、外部ストレージノードにネイティブでインストールされ、<emphasis>LVM/iSCSI plug-in</emphasis> を使用します。大半の Block Storage Service プラグインは、特定のベンダーの製品や実装と関連付けられており、使用はそれらのハードウェアプラットフォームのユーザーに制限されていますが、LVM/iSCSI はコモディティハードウェア上で堅牢性および安定性があります。"

#: ./doc/openstack-ops/section_arch_example-nova.xml341(para)
msgid ""
"While the cloud can be run without the <emphasis>OpenStack "
"Dashboard</emphasis>, we consider it to be indispensable, not just for user "
"interaction with the cloud, but also as a tool for operators. Additionally, "
"the dashboard's use of Django makes it a flexible framework for <phrase role"
"=\"keep-together\">extension</phrase>."
msgstr "クラウドは <emphasis>OpenStack Dashboard</emphasis> がなくても稼働させることは可能ですが、クラウドとの対話だけでなく運用担当者のツールとしても不可欠な要素と判断しました。また、ダッシュボードに採用されている Django により、<phrase role=\"keep-together\">拡張機能</phrase> のための柔軟なフレームワークとなります。"

#: ./doc/openstack-ops/section_arch_example-nova.xml349(title)
msgid "Why not use the OpenStack Network Service (neutron)?"
msgstr "OpenStack Network Service (neutron) を使用しない理由"

#: ./doc/openstack-ops/section_arch_example-nova.xml351(para)
msgid ""
"This example architecture does not use the OpenStack Network Service "
"(neutron), because it does not yet support multi-host networking and our "
"organizations (university, government) have access to a large range of "
"publicly-accessible IPv4 addresses.<indexterm "
"class=\"singular\"><primary>legacy networking (nova)</primary><secondary>vs."
" OpenStack Network Service (neutron)</secondary></indexterm>"
msgstr "このアーキテクチャ例では、OpenStack Networking Service (neutron)  は使用していません。neutron はマルチホストネットワークをまだサポートしておらず、また対象となる組織 (大学/政府機関) ではパブリックでアクセス可能な IPv4 アドレスを広範囲で利用できるのが理由です。<indexterm class=\"singular\"><primary>レガシーネットワーク (nova)</primary><secondary>vs. OpenStack Network Service (neutron)</secondary></indexterm>"

#: ./doc/openstack-ops/section_arch_example-nova.xml362(title)
msgid "Why use multi-host networking?"
msgstr "マルチホストネットワークを使用する理由"

#: ./doc/openstack-ops/section_arch_example-nova.xml364(para)
msgid ""
"In a default OpenStack deployment, there is a single <code>nova-"
"network</code> service that runs within the cloud (usually on the cloud "
"controller) that provides services such as network address translation "
"(NAT), DHCP, and DNS to the guest instances. If the single node that runs "
"the <code>nova-network</code> service goes down, you cannot access your "
"instances, and the instances cannot access the Internet. The single node "
"that runs the <literal>nova-network</literal> service can become a "
"bottleneck if excessive network traffic comes in and goes out of the "
"cloud.<indexterm class=\"singular\"><primary>networks</primary><secondary"
">multi-host</secondary></indexterm><indexterm class=\"singular\"><primary"
">multi-host networking</primary></indexterm><indexterm "
"class=\"singular\"><primary>legacy networking "
"(nova)</primary><secondary>benefits of multi-host "
"networking</secondary></indexterm>"
msgstr "デフォルトの OpenStack デプロイメントでは、単一の <code>nova-network</code> サービスがクラウド内 (通常はクラウドコントローラー) で実行され、ネットワークアドレス変換 (NAT)、DHCP、DNS などのサービスをゲストインスタンスにd提供します。<code>nova-network</code> サービスを実行する単一のノードが停止した場合には、インスタンスにアクセスできなくなり、またインスタンスはインターネットにアクセスできません。クラウドでネットワークトラフィックが過剰に送受信されると、<literal>nova-network</literal> サービスを実行する単一ノードがボトルネックとなる可能性があります。<indexterm class=\"singular\"><primary>ネットワーク</primary><secondary>マルチホスト</secondary></indexterm><indexterm class=\"singular\"><primary>マルチホストネットワーク</primary></indexterm><indexterm class=\"singular\"><primary>レガシーネットワーク(nova)</primary><secondary>マルチホストネットワークの利点</secondary></indexterm>"

#: ./doc/openstack-ops/section_arch_example-nova.xml385(para)
msgid ""
"<link href=\"http://docs.openstack.org/havana/install-"
"guide/install/apt/content/nova-network.html\">Multi-host</link> is a high-"
"availability option for the network configuration, where the <literal>nova-"
"network</literal> service is run on every compute node instead of running on"
" only a single node."
msgstr "<link href=\"http://docs.openstack.org/havana/install-guide/install/apt/content/nova-network.html\">マルチホスト</link> とは、ネットワーク設定の高可用性オプションです。このオプションでは、<literal>nova-network</literal> サービスが単一のノードだけではなく、各コンピュートノードで実行されます。"

#: ./doc/openstack-ops/section_arch_example-nova.xml394(title)
#: ./doc/openstack-ops/section_arch_example-neutron.xml232(title)
msgid "Detailed Description"
msgstr "詳細な説明"

#: ./doc/openstack-ops/section_arch_example-nova.xml396(para)
msgid ""
"The reference architecture consists of multiple compute nodes, a cloud "
"controller, an external NFS storage server for instance storage, and an "
"OpenStack Block Storage server for <glossterm>volume</glossterm> "
"storage.<indexterm class=\"singular\"><primary>legacy networking "
"(nova)</primary><secondary>detailed description</secondary></indexterm> A "
"network time service (Network Time Protocol, or NTP) synchronizes time on "
"all the nodes. FlatDHCPManager in multi-host mode is used for the "
"networking. A logical diagram for this example architecture shows which "
"services are running on each node:"
msgstr "この参照アーキテクチャは、複数のコンピュートノード、クラウドコントローラー 1 台、インスタンスストレージ用の外部 NFS ストレージサーバー 1 台、<glossterm>volume</glossterm> ストレージ用の OpenStack Block Storage サーバー 1 台で構成されます。<indexterm class=\"singular\"><primary>レガシーネットワーク (nova)</primary><secondary>詳しい説明</secondary></indexterm> ネットワークタイムサービス (Network Time Protocol / NTP) は全ノードの時刻を同期します。ネットワークには、マルチホストモードの FlatDHCPManager を使用しています。このアーキテクチャ例の論理図には、各ノードで実行されているサービスが示されています。"

#: ./doc/openstack-ops/section_arch_example-nova.xml416(para)
msgid ""
"The cloud controller runs the dashboard, the API services, the database "
"(MySQL), a message queue server (RabbitMQ), the scheduler for choosing "
"compute resources (<literal>nova-scheduler</literal>), Identity services "
"(keystone, <code>nova-consoleauth</code>), Image services (<code>glance-"
"api</code>, <code>glance-registry</code>), services for console access of "
"guests, and Block Storage services, including the scheduler for storage "
"resources (<code>cinder-api</code> and <code>cinder-"
"scheduler</code>).<indexterm class=\"singular\"><primary>cloud "
"controllers</primary><secondary>duties of</secondary></indexterm>"
msgstr "クラウドコントローラーは、ダッシュボード、API サービス、データベース (MySQL)、メッセージキューサーバー (RabbitMQ)、コンピュートリソースを選択するスケジューラー (<literal>nova-scheduler</literal>)、Identity Service (keystone、<code>nova-consoleauth</code>)、Image Service (<code>glance-api</code>、 <code>glance-registry</code>)、ゲストのコンソールアクセスのためのサービス、ストレージリソースのスケジューラーを含む Block Storage Service (<code>cinder-api</code> および <code>cinder-scheduler</code>) を実行します。<indexterm class=\"singular\"><primary>クラウドコントローラー</primary><secondary>役割</secondary></indexterm>"

#: ./doc/openstack-ops/section_arch_example-nova.xml429(para)
msgid ""
"Compute nodes are where the computing resources are held, and in our example"
" architecture, they run the hypervisor (KVM), libvirt (the driver for the "
"hypervisor, which enables live migration from node to node), <code>nova-"
"compute</code>, <code>nova-api-metadata</code> (generally only used when "
"running in multi-host mode, it retrieves instance-specific metadata), <code"
">nova-vncproxy</code>, and <code>nova-network</code>."
msgstr "コンピュートノードには、コンピューティングリソースが保持されます。このアーキテクチャ例では、コンピュートノードで、ハイパーバイザー (KVM)、libvirt (ノード間でのライブマイグレーションを可能にするハイパーバイザー用ドライバー)、<code>nova-compute</code>、 <code>nova-api-metadata</code> (通常はマルチホストモードの場合のみ使用され、インスタンス固有のメタデータを取得する)、nova-vncproxy、<code>nova-network</code> を実行します。"

#: ./doc/openstack-ops/section_arch_example-nova.xml437(para)
msgid ""
"The network consists of two switches, one for the management or private "
"traffic, and one that covers public access, including floating IPs. To "
"support this, the cloud controller and the compute nodes have two network "
"cards. The OpenStack Block Storage and NFS storage servers only need to "
"access the private network and therefore only need one network card, but "
"multiple cards run in a bonded configuration are recommended if possible. "
"Floating IP access is direct to the Internet, whereas Flat IP access goes "
"through a NAT. To envision the network traffic, use this diagram:"
msgstr "ネットワークは、2 つのスイッチで構成され、1 つは管理/プライベートトラフィック用、もう 1 つは Floating IP を含むパブリックアクセスが対象です。この構成に対応するために、クラウドコントローラーおよびコンピュートノードで NIC を 2 枚を装備します。OpenStack Block Storage および NFS ストレージサーバーは、プライベートネットワークにのみアクセスする必要があるので、必要な NIC は 1 枚ですが、可能な場合には複数の NIC をボンディング構成で動作させることを推奨します。Floating IP のアクセスは、インターネットに直結ですが、Flat IP のアクセスは NAT 経由となります。ネットワークトラフィックの構想には、以下の図を利用してください。"

#: ./doc/openstack-ops/section_arch_example-nova.xml457(title)
msgid "Optional Extensions"
msgstr "さらなる拡張"

#: ./doc/openstack-ops/section_arch_example-nova.xml459(para)
msgid ""
"You can extend this reference architecture as<indexterm "
"class=\"singular\"><primary>legacy networking "
"(nova)</primary><secondary>optional extensions</secondary></indexterm> "
"follows:"
msgstr "この参照アーキテクチャは、<indexterm class=\"singular\"><primary>レガシーネットワーク (nova)</primary><secondary>オプションの拡張機能</secondary></indexterm>以下のように拡張することが可能です:"

#: ./doc/openstack-ops/section_arch_example-nova.xml468(para)
msgid "Add additional cloud controllers (see <xref linkend=\"maintenance\"/>)."
msgstr "追加でクラウドコントローラーを増やす (<xref linkend=\"maintenance\"/> を参照)。"

#: ./doc/openstack-ops/section_arch_example-nova.xml473(para)
msgid ""
"Add an OpenStack Storage service (see the Object Storage chapter in the "
"<emphasis>OpenStack Installation Guide</emphasis> for your distribution)."
msgstr "OpenStack Storage Service を追加する (お使いのディストリビューション向けの <emphasis>OpenStack インストールガイド</emphasis> で Object Storage の章を参照してください)"

#: ./doc/openstack-ops/section_arch_example-nova.xml479(para)
msgid ""
"Add additional OpenStack Block Storage hosts (see <xref "
"linkend=\"maintenance\"/>)."
msgstr "追加で OpenStack Block Storage ホストを増やす (see <xref linkend=\"maintenance\"/> 参照)。"

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/section_arch_example-neutron.xml490(None)
msgid ""
"@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc"
"/openstack-ops/figures/osog_0101.png'; md5=THIS FILE DOESN'T EXIST"
msgstr "@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/openstack-ops/figures/osog_0101.png'; md5=THIS FILE DOESN'T EXIST"

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/section_arch_example-neutron.xml514(None)
msgid ""
"@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc"
"/openstack-ops/figures/osog_0102.png'; md5=THIS FILE DOESN'T EXIST"
msgstr "@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/openstack-ops/figures/osog_0102.png'; md5=THIS FILE DOESN'T EXIST"

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/section_arch_example-neutron.xml536(None)
msgid ""
"@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc"
"/openstack-ops/figures/osog_0103.png'; md5=THIS FILE DOESN'T EXIST"
msgstr "@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/openstack-ops/figures/osog_0103.png'; md5=THIS FILE DOESN'T EXIST"

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/section_arch_example-neutron.xml546(None)
msgid ""
"@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc"
"/openstack-ops/figures/osog_0104.png'; md5=THIS FILE DOESN'T EXIST"
msgstr "@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/openstack-ops/figures/osog_0104.png'; md5=THIS FILE DOESN'T EXIST"

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/section_arch_example-neutron.xml556(None)
msgid ""
"@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc"
"/openstack-ops/figures/osog_0105.png'; md5=THIS FILE DOESN'T EXIST"
msgstr "@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/openstack-ops/figures/osog_0105.png'; md5=THIS FILE DOESN'T EXIST"

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/section_arch_example-neutron.xml566(None)
msgid ""
"@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc"
"/openstack-ops/figures/osog_0106.png'; md5=THIS FILE DOESN'T EXIST"
msgstr "@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/openstack-ops/figures/osog_0106.png'; md5=THIS FILE DOESN'T EXIST"

#: ./doc/openstack-ops/section_arch_example-neutron.xml16(title)
msgid "Example Architecture—OpenStack Networking"
msgstr "アーキテクチャの例: OpenStack Networking"

#: ./doc/openstack-ops/section_arch_example-neutron.xml18(para)
msgid ""
"This chapter provides an example architecture using OpenStack Networking, "
"also known as the Neutron project, in a highly available environment."
msgstr "本章には、OpenStack Networking (別称: Neutron プロジェクト) を高可用性環境で使用するアーキテクチャの例を記載します。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml25(para)
msgid ""
"A highly-available environment can be put into place if you require an "
"environment that can scale horizontally, or want your cloud to continue to "
"be operational in case of node failure. This example architecture has been "
"written based on the current default feature set of OpenStack Havana, with "
"an emphasis on high availability.<indexterm class=\"singular\"><primary>RDO "
"(Red Hat Distributed OpenStack)</primary></indexterm><indexterm "
"class=\"singular\"><primary>OpenStack Networking "
"(neutron)</primary><secondary>component overview</secondary></indexterm>"
msgstr "高可用性環境は、水平スケールが可能な環境が必要な場合や、ノードに障害が発生した場合にもクラウドの稼働を継続させたい場合に設置することができます。以下のアーキテクチャ例では、 OpenStack Havana の現在のデフォルト機能セットをベースとし、高可用性に重点を置いて記載しました。<indexterm class=\"singular\"><primary>RDO (Red Hat Distributed OpenStack)</primary></indexterm><indexterm class=\"singular\"><primary>OpenStack Networking (neutron)</primary><secondary>コンポーネント概要</secondary></indexterm>"

#: ./doc/openstack-ops/section_arch_example-neutron.xml63(para)
msgid "Red Hat Enterprise Linux 6.5"
msgstr "Red Hat Enterprise Linux 6.5"

#: ./doc/openstack-ops/section_arch_example-neutron.xml69(link)
msgid "Red Hat Distributed OpenStack (RDO)"
msgstr "Red Hat Distributed OpenStack (RDO)"

#: ./doc/openstack-ops/section_arch_example-neutron.xml82(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml176(term)
msgid "MySQL"
msgstr "MySQL"

#: ./doc/openstack-ops/section_arch_example-neutron.xml88(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml188(term)
msgid "Qpid"
msgstr "Qpid"

#: ./doc/openstack-ops/section_arch_example-neutron.xml94(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml198(term)
msgid "OpenStack Networking"
msgstr "OpenStack Networking"

#: ./doc/openstack-ops/section_arch_example-neutron.xml98(para)
msgid "Tenant Network Separation"
msgstr "テナントネットワークの分離"

#: ./doc/openstack-ops/section_arch_example-neutron.xml100(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml208(term)
msgid "VLAN"
msgstr "VLAN"

#: ./doc/openstack-ops/section_arch_example-neutron.xml106(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml118(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml218(term)
#: ./doc/openstack-ops/ch_arch_compute_nodes.xml476(para)
msgid "GlusterFS"
msgstr "GlusterFS"

#: ./doc/openstack-ops/section_arch_example-neutron.xml127(para)
msgid ""
"This example architecture has been selected based on the current default "
"feature set of OpenStack Havana, with an emphasis on high availability. This"
" architecture is currently being deployed in an internal Red Hat OpenStack "
"cloud and used to run hosted and shared services, which by their nature must"
" be highly available.<indexterm class=\"singular\"><primary>OpenStack "
"Networking (neutron)</primary><secondary>rationale for choice "
"of</secondary></indexterm>"
msgstr "このアーキテクチャ例は、OpenStack Havana の現在のデフォルト機能セットをベースに、高可用性に重点を置いて選択しています。このアーキテクチャは、現在 Red Hat の 企業内 OpenStack クラウドでデプロイされており、ホステッド共有サービスの運用に使用されています。ホステッド共有サービスは、その性質上、高可用性が要求されます。<indexterm class=\"singular\"><primary>OpenStack Networking (neutron)</primary><secondary>設定指針</secondary></indexterm>"

#: ./doc/openstack-ops/section_arch_example-neutron.xml138(para)
msgid ""
"This architecture's components have been selected for the following reasons:"
msgstr "このアーキテクチャコンポーネントは、以下のような理由で選択されています。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml143(term)
msgid "Red Hat Enterprise Linux"
msgstr "Red Hat Enterprise Linux"

#: ./doc/openstack-ops/section_arch_example-neutron.xml146(para)
msgid ""
"You must choose an operating system that can run on all of the physical "
"nodes. This example architecture is based on Red Hat Enterprise Linux, which"
" offers reliability, long-term support, certified testing, and is hardened. "
"Enterprise customers, now moving into OpenStack usage, typically require "
"these advantages."
msgstr "全物理ノードで実行可能なオペレーティングシステムを選択する必要があります。このアーキテクチャ例は、信頼性、長期的なサポート、認定テストが提供され、セキュリティ強化されている Red Hat Enterprise Linux をベースにしています。現在、OpenStack の採用に向けて移行中の企業顧客には、通常このような利点が要求されます。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml156(term)
msgid "RDO"
msgstr "RDO"

#: ./doc/openstack-ops/section_arch_example-neutron.xml159(para)
msgid ""
"The Red Hat Distributed OpenStack package offers an easy way to download the"
" most current OpenStack release that is built for the Red Hat Enterprise "
"Linux platform."
msgstr "Red Hat Distributed OpenStack パッケージは、Red Hat Enterprise Linux プラットフォーム用に構築された最新の OpenStack リリースを容易にダウンロードする方法を提供します。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml169(para)
msgid ""
"KVM is the supported hypervisor of choice for Red Hat Enterprise Linux (and "
"included in distribution). It is feature complete and free from licensing "
"charges and restrictions."
msgstr "KVM は、Red Hat Enterprise Linux に最適なサポート対象ハイパーバイザーです (また、ディストリビューションにも含まれます)。機能が完成されており、ライセンスの料金や制限は課せられません。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml179(para)
msgid ""
"MySQL is used as the database backend for all databases in the OpenStack "
"environment. MySQL is the supported database of choice for Red Hat "
"Enterprise Linux (and included in distribution); the database is open "
"source, scalable, and handles memory well."
msgstr "MySQL は、OpenStack 環境の全データベースのデータベースバックエンドとして使用されます。MySQL は、Red Hat Enterprise Linux に最適なサポート対象データベースです (また、ディストリビューションにも同梱されています)。このデータベースは、オープンソースで、拡張が可能な上、メモリーの処理を効率的に行います。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml191(para)
msgid ""
"Apache Qpid offers 100 percent compatibility with the Advanced Message "
"Queuing Protocol Standard, and its broker is available for both C++ and "
"Java."
msgstr "Apache Qpid は、Advanced Message Queuing Protocol の標準との 100% の互換性を提供し、ブローカーは C++ と Java の両方で利用可能です。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml201(para)
msgid ""
"OpenStack Networking offers sophisticated networking functionality, "
"including Layer 2 (L2) network segregation and provider networks."
msgstr "OpenStack Networking は、レイヤー 2 (L2) ネットワークの分離やプロバイダーネットワークを含む高度なネットワーク機能を提供します。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml211(para)
msgid ""
"Using a virtual local area network offers broadcast control, security, and "
"physical layer transparency. If needed, use VXLAN to extend your address "
"space."
msgstr "仮想ローカルエリアネットワークを使用してブロードキャスト制御、セキュリティ、物理レイヤーの透過性を提供します。必要な場合には、VXLAN を使用してアドレス空間を拡張します。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml221(para)
msgid ""
"GlusterFS offers scalable storage. As your environment grows, you can "
"continue to add more storage nodes (instead of being restricted, for "
"example, by an expensive storage array)."
msgstr "GlusterFS は拡張可能なストレージを提供します。環境の拡大に応じて、 (高額なストレージアレイなどによる制約を受けずに) ストレージノードを継続的に追加することが可能です。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml235(title)
#: ./doc/openstack-ops/section_arch_example-neutron.xml248(caption)
msgid "Node types"
msgstr "ノードのタイプ"

#: ./doc/openstack-ops/section_arch_example-neutron.xml237(para)
msgid ""
"This section gives you a breakdown of the different nodes that make up the "
"OpenStack environment. A node is a physical machine that is provisioned with"
" an operating system, and running a defined software stack on top of it. "
"<xref linkend=\"node-types-table\"/> provides node descriptions and "
"specifications.<indexterm class=\"singular\"><primary>OpenStack Networking "
"(neutron)</primary><secondary>detailed description "
"of</secondary></indexterm>"
msgstr "本セクションでは、OpenStack 環境を構成する異なるノードの内訳を記載します。 ノードとは、オペレーティングシステムがプロビジョニングされた物理マシンで、その上に定義済みソフトウェアスタックを実行します。 <xref linkend=\"node-types-table\"/> には、ノードの説明と仕様を記載しています。<indexterm class=\"singular\"><primary>OpenStack Networking (neutron)</primary><secondary>詳細</secondary></indexterm>"

#: ./doc/openstack-ops/section_arch_example-neutron.xml258(th)
msgid "Type"
msgstr "種別"

#: ./doc/openstack-ops/section_arch_example-neutron.xml260(th)
#: ./doc/openstack-ops/ch_ops_user_facing.xml273(emphasis)
#: ./doc/openstack-ops/ch_ops_projects_users.xml241(th)
#: ./doc/openstack-ops/ch_ops_projects_users.xml613(th)
msgid "Description"
msgstr "説明"

#: ./doc/openstack-ops/section_arch_example-neutron.xml262(th)
msgid "Example hardware"
msgstr "ハードウェアの例"

#: ./doc/openstack-ops/section_arch_example-neutron.xml268(td)
msgid "Controller"
msgstr "コントローラー"

#: ./doc/openstack-ops/section_arch_example-neutron.xml270(para)
msgid ""
"Controller nodes are responsible for running the management software "
"services needed for the OpenStack environment to function. These nodes:"
msgstr "コントローラーノードは、 OpenStack 環境が機能するために必要な管理ソフトウェアサービスを実行します。これらのノードは、以下のような役割を果たします。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml276(para)
msgid ""
"Provide the front door that people access as well as the API services that "
"all other components in the environment talk to."
msgstr "ユーザーがアクセスするフロントドアに加えて、環境内その他すべてのコンポーネントが通信する API サービスを提供します。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml282(para)
msgid ""
"Run a number of services in a highly available fashion, utilizing Pacemaker "
"and HAProxy to provide a virtual IP and load-balancing functions so all "
"controller nodes are being used."
msgstr "全コントローラーノードが使用されるように Pacemaker と HAProxy を利用して仮想 IP および負荷分散機能を提供して、多数のサービスを高可用性で実行します。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml289(para)
msgid ""
"Supply highly available \"infrastructure\" services, such as MySQL and Qpid,"
" that underpin all the services."
msgstr "高可用性の「インフラストラクチャ」サービス (全サービスの基盤となる MySQL や Qpid など) を提供します。 "

#: ./doc/openstack-ops/section_arch_example-neutron.xml295(para)
msgid ""
"Provide what is known as \"persistent storage\" through services run on the "
"host as well. This persistent storage is backed onto the storage nodes for "
"reliability."
msgstr "ホストでも実行されるサービスを介して、いわゆる「永続ストレージ」を提供します。この永続ストレージは、信頼性のためにストレージノードにバッキングされます。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml302(para)
msgid "See <xref linkend=\"node_controller-diagram\"/>."
msgstr "<xref linkend=\"node_controller-diagram\"/> を参照してください。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml303(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml327(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml369(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml384(para)
msgid "Model: Dell R620"
msgstr "モデル: Dell R620"

#: ./doc/openstack-ops/section_arch_example-neutron.xml303(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml341(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml384(para)
msgid "CPU: 2x Intel® Xeon® CPU E5-2620 0 @ 2.00 GHz"
msgstr "CPU: 2x Intel® Xeon® CPU E5-2620 0 @ 2.00 GHz"

#: ./doc/openstack-ops/section_arch_example-neutron.xml304(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml370(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml385(para)
msgid "Memory: 32 GB"
msgstr "メモリー: 32 GB"

#: ./doc/openstack-ops/section_arch_example-neutron.xml304(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml370(para)
msgid "Disk: two 300 GB 10000 RPM SAS Disks"
msgstr "ディスク: 300 GB 10000 RPM SAS ディスク x 2"

#: ./doc/openstack-ops/section_arch_example-neutron.xml305(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml345(para)
#: ./doc/openstack-ops/section_arch_example-neutron.xml386(para)
msgid "Network: two 10G network ports"
msgstr "ネットワーク: 10G のネットワークポート x 2"

#: ./doc/openstack-ops/section_arch_example-neutron.xml309(td)
#: ./doc/openstack-ops/ch_ops_backup_recovery.xml128(title)
msgid "Compute"
msgstr "コンピュート"

#: ./doc/openstack-ops/section_arch_example-neutron.xml310(para)
msgid "Compute nodes run the virtual machine instances in OpenStack. They:"
msgstr "コンピュートノードは、OpenStack 内の仮想マシンインスタンスを実行します。コンピュートノードは、以下のような役割を果たします。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml315(para)
msgid "Run the bare minimum of services needed to facilitate these instances."
msgstr "それらのインスタンスを円滑に稼働するために必要な最低限のサービスを実行します。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml319(para)
msgid ""
"Use local storage on the node for the virtual machines so that no VM "
"migration or instance recovery at node failure is possible."
msgstr "ノードの障害発生時に仮想マシンの移行やインスタンスのリカバリができないように、仮想マシンにノード上のローカルストレージを使用します。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml324(phrase)
msgid "See <xref linkend=\"node_compute-diagram\"/>."
msgstr "<xref linkend=\"node_compute-diagram\"/> を参照してください。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml327(para)
msgid "CPU: 2x Intel® Xeon® CPU E5-2650 0 @ 2.00 GHz"
msgstr "CPU: 2x Intel® Xeon® CPU E5-2650 0 @ 2.00 GHz"

#: ./doc/openstack-ops/section_arch_example-neutron.xml328(para)
msgid "Memory: 128 GB"
msgstr "メモリー: 128 GB"

#: ./doc/openstack-ops/section_arch_example-neutron.xml329(para)
msgid "Disk: two 600 GB 10000 RPM SAS Disks"
msgstr "ディスク: 600 GB 10000 RPM SAS ディスク x 2"

#: ./doc/openstack-ops/section_arch_example-neutron.xml329(para)
msgid "Network: four 10G network ports (For future proofing expansion)"
msgstr "ネットワーク: 10G ネットワークポート x 4 (将来を保証する拡張性のため)"

#: ./doc/openstack-ops/section_arch_example-neutron.xml333(td)
msgid "Storage"
msgstr "ストレージ"

#: ./doc/openstack-ops/section_arch_example-neutron.xml334(para)
msgid ""
"Storage nodes store all the data required for the environment, including "
"disk images in the Image Service library, and the persistent storage volumes"
" created by the Block Storage service. Storage nodes use GlusterFS "
"technology to keep the data highly available and scalable."
msgstr "ストレージノードは、環境に必要な全データを保管します。これには、Image Service ライブラリ内のディスクイメージや、Block Storage Service によって作成された永続ストレージボリュームが含まれます。ストレージノードは GlusterFS テクノロジーを使用してデータの高可用性とスケーラビリティを確保します。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml339(para)
msgid "See <xref linkend=\"node_storage-diagram\"/>."
msgstr "<xref linkend=\"node_storage-diagram\"/> を参照してください。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml341(para)
msgid "Model: Dell R720xd"
msgstr "モデル: Dell R720xd"

#: ./doc/openstack-ops/section_arch_example-neutron.xml342(para)
msgid "Memory: 64 GB"
msgstr "メモリー: 64 GB"

#: ./doc/openstack-ops/section_arch_example-neutron.xml343(para)
msgid ""
"Disk: two 500 GB 7200 RPM SAS Disks and twenty-four 600 GB 10000 RPM SAS "
"Disks"
msgstr "ディスク: 500 GB 7200 RPM SAS ディスク x 2 および 600 GB 10000 RPM SAS ディスク x 24"

#: ./doc/openstack-ops/section_arch_example-neutron.xml344(para)
msgid "Raid Controller: PERC H710P Integrated RAID Controller, 1 GB NV Cache"
msgstr "RAID コントローラー: PERC H710P Integrated RAID Controller、1 GB NV キャッシュ"

#: ./doc/openstack-ops/section_arch_example-neutron.xml349(td)
msgid "Network"
msgstr "ネットワーク"

#: ./doc/openstack-ops/section_arch_example-neutron.xml350(para)
msgid ""
"Network nodes are responsible for doing all the virtual networking needed "
"for people to create public or private networks and uplink their virtual "
"machines into external networks. Network nodes:"
msgstr "ネットワークノードは、ユーザーがパブリックまたはプライベートネットワークを作成し、仮想マシンを外部ネットワークにアップリンクするために必要なすべての仮想ネットワーキングを実行する役割を果たします。ネットワークノードは以下のような操作を実行します。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml357(para)
msgid ""
"Form the only ingress and egress point for instances running on top of "
"OpenStack."
msgstr "OpenStack 上で実行されているインスタンス用の唯一の送受信ポイントを形成します。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml361(para)
msgid ""
"Run all of the environment's networking services, with the exception of the "
"networking API service (which runs on the controller node)."
msgstr "環境の全ネットワークサービスを実行します。ただし、ネットワーク API サービス (コントローラーノードで実行される) を除きます。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml367(para)
msgid "See <xref linkend=\"node_network-diagram\"/>."
msgstr "<xref linkend=\"node_network-diagram\"/> を参照してください。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml369(para)
msgid "CPU: 1x Intel® Xeon® CPU E5-2620 0 @ 2.00 GHz"
msgstr "CPU: 1x Intel® Xeon® CPU E5-2620 0 @ 2.00 GHz"

#: ./doc/openstack-ops/section_arch_example-neutron.xml371(para)
msgid "Network: five 10G network ports"
msgstr "ネットワーク: 10G ネットワークポート x 5"

#: ./doc/openstack-ops/section_arch_example-neutron.xml375(td)
msgid "Utility"
msgstr "ユーティリティ"

#: ./doc/openstack-ops/section_arch_example-neutron.xml376(para)
msgid ""
"Utility nodes are used by internal administration staff only to provide a "
"number of basic system administration functions needed to get the "
"environment up and running and to maintain the hardware, OS, and software on"
" which it runs."
msgstr "ユーティリティノードは、環境を稼働させ、その環境を実行しているハードウェア/OS/ソフトウェアを維持管理するのに必要な多数の基本的なシステム管理機能を提供するために、内部管理スタッフのみが使用します。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml379(para)
msgid ""
"These nodes run services such as provisioning, configuration management, "
"monitoring, or GlusterFS management software. They are not required to "
"scale, although these machines are usually backed up."
msgstr "これらのノードは、プロビジョニング、設定管理、モニタリング、GlusterFS 管理ソフトウェアなどのサービスを実行します。拡張の必要はありませんが、これらのマシンは通常バックアップされます。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml385(para)
msgid "Disk: two 500 GB 7200 RPM SAS Disks"
msgstr "ディスク: 500 GB 7200 RPM SAS ディスク x 2"

#: ./doc/openstack-ops/section_arch_example-neutron.xml394(title)
msgid "Networking layout"
msgstr "ネットワークのレイアウト"

#: ./doc/openstack-ops/section_arch_example-neutron.xml396(para)
msgid ""
"The network contains all the management devices for all hardware in the "
"environment (for example, by including Dell iDrac7 devices for the hardware "
"nodes, and management interfaces for network switches). The network is "
"accessed by internal staff only when diagnosing or recovering a hardware "
"issue."
msgstr "ネットワークには、環境内の全ハードウェア用の管理デバイスがすべて含まれます (例: ハードウェアノード用の Dell iDrac7 デバイスやネットワークスイッチ用の管理インターフェースの追加による) 。ネットワークは、ハードウェア問題の診断またはリカバリを実行する場合にのみ内部スタッフがアクセスします。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml403(title)
msgid "OpenStack internal network"
msgstr "OpenStack 内部ネットワーク"

#: ./doc/openstack-ops/section_arch_example-neutron.xml405(para)
msgid ""
"This network is used for OpenStack management functions and traffic, "
"including services needed for the provisioning of physical nodes "
"(<literal>pxe</literal>, <literal>tftp</literal>, "
"<literal>kickstart</literal>), traffic between various OpenStack node types "
"using OpenStack APIs and messages (for example, <literal>nova-"
"compute</literal> talking to <literal>keystone</literal> or <literal>cinder-"
"volume</literal> talking to <literal>nova-api</literal>), and all traffic "
"for storage data to the storage layer underneath by the Gluster protocol. "
"All physical nodes have at least one network interface (typically "
"<literal>eth0</literal>) in this network. This network is only accessible "
"from other VLANs on port 22 (for <literal>ssh</literal> access to manage "
"machines)."
msgstr "このネットワークは、OpenStack の管理機能およびトラフィックに使用されます。これには、物理ノードのプロビジョニングに必要なサービス (<literal>pxe</literal>、<literal>tftp</literal>、<literal>kickstart</literal>)、OpenStack API およびメッセージを使用する様々な OpenStack ノードタイプの間のトラフィック (例: <literal>nova-compute</literal> から <literal>keystone</literal> への通信や　<literal>cinder-volume</literal> から <literal>nova-api</literal> への通信など)、 Gluster プロトコルによる配下のストレージ層へのストレージデータの全トラフィックなどが含まれます。全物理ノードで、少なくとも 1 つのネットワークインターフェース  (通常は <literal>eth0</literal>) がこのネットワークに設定されます。他の VLAN からのこのネットワークへのアクセスは、ポート 22 でのみで可能です  (マシンを管理するための <literal>ssh</literal> アクセス)。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml423(title)
msgid "Public Network"
msgstr "パブリックネットワーク"

#: ./doc/openstack-ops/section_arch_example-neutron.xml427(para)
msgid ""
"IP addresses for public-facing interfaces on the controller nodes (which end"
" users will access the OpenStack services)"
msgstr "コントローラーノード上のパブリックインターフェースの IP アドレス (エンドユーザーが OpenStack サービスにアクセスするのに使用)"

#: ./doc/openstack-ops/section_arch_example-neutron.xml433(para)
msgid ""
"A range of publicly routable, IPv4 network addresses to be used by OpenStack"
" Networking for floating IPs. You may be restricted in your access to IPv4 "
"addresses; a large range of IPv4 addresses is not necessary."
msgstr "OpenStack Networking が Floating IP に使用する、パブリックにルーティング可能な IPv4 ネットワークアドレスの範囲。IPv4 アドレスへのアクセスは制限される可能性があります。IPv4 アドレスの範囲を大きくする必要はありません。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml440(para)
msgid "Routers for private networks created within OpenStack."
msgstr "OpenStack 内に作成されるプライベートネットワーク用のルーター"

#: ./doc/openstack-ops/section_arch_example-neutron.xml425(para)
msgid "This network is a combination of: <placeholder-1/>"
msgstr "このネットワークは、以下の要素の組み合わせです: <placeholder-1/>"

#: ./doc/openstack-ops/section_arch_example-neutron.xml445(para)
msgid ""
"This network is connected to the controller nodes so users can access the "
"OpenStack interfaces, and connected to the network nodes to provide VMs with"
" publicly routable traffic functionality. The network is also connected to "
"the utility machines so that any utility services that need to be made "
"public (such as system monitoring) can be accessed."
msgstr "このネットワークは、ユーザーが OpenStack インターフェースにアクセスできるようするためにコントローラーノードに接続され、パブリックでルーティング可能なトラフィックの機能を仮想マシンに提供するためにネットワークノードに接続されます。また、このネットワークは、公開する必要のある任意のユーティリティサービス (システムの監視など) にアクセスできるようにするために、ユーティリティマシンにも接続されます。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml454(title)
msgid "VM traffic network"
msgstr "仮想マシントラフィックネットワーク"

#: ./doc/openstack-ops/section_arch_example-neutron.xml456(para)
msgid ""
"This is a closed network that is not publicly routable and is simply used as"
" a private, internal network for traffic between virtual machines in "
"OpenStack, and between the virtual machines and the network nodes that "
"provide l3 routes out to the public network (and floating IPs for "
"connections back in to the VMs). Because this is a closed network, we are "
"using a different address space to the others to clearly define the "
"separation. Only Compute and OpenStack Networking nodes need to be connected"
" to this network."
msgstr "これは、パブリックにはルーティングできない閉じたネットワークで、単に OpenStack 内の仮想マシン間のトラフィックや、パブリックネットワークへの外向きの L3 ルート (および仮想マシンに戻る接続のための Floating IP) を提供するネットワークノードと仮想マシンと間 のトラフィックのためのプライベートの内部ネットワークに使用されます。このネットワークは閉じているため、他とは異なるアドレス空間を使用して、その区別を明確に定義しています。このネットワークに接続する必要があるのは、Compute ノードと OpenStack Networking ノードのみです。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml468(title)
msgid "Node connectivity"
msgstr "ノードの接続性"

#: ./doc/openstack-ops/section_arch_example-neutron.xml470(para)
msgid ""
"The following section details how the nodes are connected to the different "
"networks (see <xref linkend=\"networking_layout\"/>) and what other "
"considerations need to take place (for example, bonding) when connecting "
"nodes to the networks."
msgstr "以下のセクションでは、ノードを異なるネットワークに接続する方法 ( <xref linkend=\"networking_layout\"/> を参照) と、ノードをネットワークに接続する際に他に考慮すべき点 (例: ボンディング) について説明します。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml476(title)
msgid "Initial deployment"
msgstr "初期デプロイメント"

#: ./doc/openstack-ops/section_arch_example-neutron.xml478(para)
msgid ""
"Initially, the connection setup should revolve around keeping the "
"connectivity simple and straightforward in order to minimize deployment "
"complexity and time to deploy. The deployment shown in <xref "
"linkend=\"fig1-1\"/> aims to have 1 10G connectivity available to all "
"compute nodes, while still leveraging bonding on appropriate nodes for "
"maximum performance."
msgstr "デプロイメントの複雑度と所要時間を最小限に抑えるためには、初めに、接続性を単純かつ簡潔に保つことを中心に接続の設定を展開する必要があります。<xref linkend=\"fig1-1\"/> に示したデプロイメントでは、全コンピュートノードに 10G の接続を 1 つずつ提供する一方で、適切なノードにはボンディングを活用してパフォーマンスを最大化することを目的としています。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml486(title)
msgid "Basic node deployment"
msgstr "基本ノードデプロイメント"

#: ./doc/openstack-ops/section_arch_example-neutron.xml497(title)
msgid "Connectivity for maximum performance"
msgstr "パフォーマンスを最大化するための接続性"

#: ./doc/openstack-ops/section_arch_example-neutron.xml499(para)
msgid ""
"If the networking performance of the basic layout is not enough, you can "
"move to <xref linkend=\"fig1-2\"/>, which provides 2 10G network links to "
"all instances in the environment as well as providing more network bandwidth"
" to the storage layer. bandwidth obtaining maximum performance"
msgstr "基本レイアウトのネットワークパフォーマンスが十分でない場合には、<xref linkend=\"fig1-2\"/> に移行することができます。このレイアウトでは、環境内の全インスタンスに 10G のネットワークリンクを2 つ提供するだけでなく、ストレージ層にさらなるネットワーク帯域幅を提供し、パフォーマンスを最大化します。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml510(title)
msgid "Performance node deployment"
msgstr "パフォーマンスノードのデプロイメント"

#: ./doc/openstack-ops/section_arch_example-neutron.xml522(title)
msgid "Node diagrams"
msgstr "ノードの図"

#: ./doc/openstack-ops/section_arch_example-neutron.xml524(para)
msgid ""
"The following diagrams (<xref linkend=\"node_controller-diagram\"/> through "
"<xref linkend=\"node_storage-diagram\"/>) include logical information about "
"the different types of nodes, indicating what services will be running on "
"top of them and how they interact with each other. The diagrams also "
"illustrate how the availability and scalability of services are achieved."
msgstr "以下の図 (<xref linkend=\"node_controller-diagram\"/> through <xref linkend=\"node_storage-diagram\"/>) には、異なるタイプのノードについての論理的情報が含まれます。この図には、実行されるサービスやそれらがどのように相互に対話するかが示されています。また、サービスの可用性とスケーラビリティがどのように実現されるかについても図示しています。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml532(title)
msgid "Controller node"
msgstr "コントローラーノード"

#: ./doc/openstack-ops/section_arch_example-neutron.xml542(title)
msgid "Compute node"
msgstr "コンピュートノード"

#: ./doc/openstack-ops/section_arch_example-neutron.xml552(title)
msgid "Network node"
msgstr "ネットワークノード"

#: ./doc/openstack-ops/section_arch_example-neutron.xml562(title)
msgid "Storage node"
msgstr "ストレージノード"

#: ./doc/openstack-ops/section_arch_example-neutron.xml574(title)
msgid "Example Component Configuration"
msgstr "コンポーネントの設定例"

#: ./doc/openstack-ops/section_arch_example-neutron.xml695(para)
msgid ""
"Because Pacemaker is cluster software, the software itself handles its own "
"availability, leveraging <literal>corosync</literal> and "
"<literal>cman</literal> underneath."
msgstr "Pacemaker は、クラスタリングソフトウェアであるため、基盤となる <literal>corosync</literal> および <literal>cman</literal> を活用して、ソフトウェア自体が自らの可用性を処理します。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml702(para)
msgid ""
"If you use the GlusterFS native client, no virtual IP is needed, since the "
"client knows all about nodes after initial connection and automatically "
"routes around failures on the client side."
msgstr "GlusterFS ネイティブクライアントを使用する場合には、そのクライアントは初回接続後にノードに関する全情報を認識し、クライアント側の障害を迂回するように自動的にルーティングするため、仮想 IP は必要ありません。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml709(para)
msgid ""
"If you use the NFS or SMB adaptor, you will need a virtual IP on which to "
"mount the GlusterFS volumes."
msgstr "NFS または SMB のアダプターを使用する場合には、GlusterFS ボリュームをマウントする仮想 IP が必要となります。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml691(para)
msgid ""
"Pacemaker is the clustering software used to ensure the availability of "
"services running on the controller and network nodes: <placeholder-1/>"
msgstr "Pacemaker とは、コントローラーノードおよびネットワークノードで実行されているサービスの可用性を確保するために使用するクラスタリングソフトウェアです: <placeholder-1/>"

#: ./doc/openstack-ops/section_arch_example-neutron.xml825(para)
msgid ""
"Configured to use Qpid, <phrase role=\"keep-"
"together\"><literal>qpid_heartbeat = </literal><phrase role=\"keep-"
"together\"><literal>10</literal>,</phrase></phrase><phrase role=\"keep-"
"together\"> configured to use</phrase> Memcached for caching, configured to "
"use <phrase role=\"keep-together\"><literal>libvirt</literal>,</phrase> "
"configured to use <phrase role=\"keep-"
"together\"><literal>neutron</literal>.</phrase>"
msgstr "Qpid を使用するように設定、<phrase role=\"keep-together\"><literal>qpid_heartbeat = </literal><phrase role=\"keep-together\"><literal>10</literal>、</phrase></phrase><phrase role=\"keep-together\"> </phrase> Memcached をキャッシュに使用するように設定、 <phrase role=\"keep-together\"><literal>libvirt</literal> を使用するように設定、</phrase>  <phrase role=\"keep-together\"><literal>neutron</literal> を使用するように設定</phrase>"

#: ./doc/openstack-ops/section_arch_example-neutron.xml833(para)
msgid ""
"Configured <literal>nova-consoleauth</literal> to use Memcached for session "
"management (so that it can have multiple copies and run in a load balancer)."
msgstr "<literal>nova-consoleauth</literal> がセッション管理に Memcached を使用するように設定 (複数のコピーが存在可能で、ロードバランサーで実行できる)。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml837(para)
msgid ""
"The nova API, scheduler, objectstore, cert, consoleauth, conductor, and "
"vncproxy services are run on all controller nodes, ensuring at least one "
"instance will be available in case of node failure. Compute is also behind "
"HAProxy, which detects when the software fails and routes requests around "
"the failing instance."
msgstr "nova API、scheduler、objectstore、cert、consoleauth、conductor、および vncproxy のサービスは、全コントローラーノードで実行され、ノードに障害が発生した場合には少なくとも 1  インスタンスが利用可能となるようにします。Compute は、ソフトウェアの障害を検出して、障害の発生したインスタンスを迂回するように要求をルーティングする HAProxy の背後に配置されます。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml842(para)
msgid ""
"Compute's compute and conductor services, which run on the compute nodes, "
"are only needed to run services on that node, so availability of those "
"services is coupled tightly to the nodes that are available. As long as a "
"compute node is up, it will have the needed services running on top of it."
msgstr "コンピュートノード上で実行される Compute のコンピュートサービスおよびコンダクターサービスは、そのノード上でのみサービスを実行する必要があるので、これらのサービスの可用性はそのノードの稼働状態と密接に連結しています。コンピュートノードが稼働している限りは、そのノード上で必要なサービスが実行されます。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml895(para)
msgid ""
"The OpenStack Networking service is run on all controller nodes, ensuring at"
" least one instance will be available in case of node failure. It also sits "
"behind HAProxy, which detects if the software fails and routes requests "
"around the failing instance."
msgstr "OpenStack Networking Service は、全コントローラーノード上で実行され、ノードの障害が発生した場合に少なくとも 1  インスタンスが利用可能となるようにします。また、このサービスは、ソフトウェアの障害を検出して、障害の発生したインスタンスを迂回するように要求をルーティングする HAProxy の背後に配置されます。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml899(para)
msgid ""
"OpenStack Networking's <literal>ovs-agent</literal>, "
"<literal>l3-agent</literal>, <literal>dhcp-agent</literal>, and <literal"
">metadata-agent</literal> services run on the network nodes, as "
"<literal>lsb</literal> resources inside of Pacemaker. This means that in the"
" case of network node failure, services are kept running on another node. "
"Finally, the <literal>ovs-agent</literal> service is also run on all compute"
" nodes, and in case of compute node failure, the other nodes will continue "
"to function using the copy of the service running on them."
msgstr "OpenStack Networking の <literal>ovs-agent</literal>、<literal>l3-agent</literal>、<literal>dhcp-agent</literal>、および <literal>metadata-agent</literal> のサービスは、ネットワークノード上で Pacemaker 内の <literal>lsb</literal> リソースとして稼働します。これは、ネットワークノードに障害が発生した場合にサービスが別のノードで稼働し続けることを意味します。最後に <literal>ovs-agent</literal> サービスも全コンピュートノードで稼働し、コンピュートノードに障害が発生した場合に、その他のノードが、そこで実行されているサービスのコピーを使用して機能し続けます。"

#: ./doc/openstack-ops/section_arch_example-neutron.xml576(para)
msgid ""
"<xref linkend=\"thirdparty-table\"/> and <xref linkend=\"openstack-config-"
"table\"/> include example configuration and considerations for both third-"
"party and OpenStack<indexterm class=\"singular\"><primary>OpenStack "
"Networking (neutron)</primary><secondary>third-party component "
"configuration</secondary></indexterm> components: <table rules=\"all\" "
"xml:id=\"thirdparty-table\"><caption>Third-party component "
"configuration</caption><col width=\"10%\"/><col width=\"30%\"/><col "
"width=\"30%\"/><col "
"width=\"30%\"/><thead><tr><th>Component</th><th>Tuning</th><th>Availability</th><th>Scalability</th></tr></thead><tbody><tr><td>MySQL</td><td><literal"
">binlog-format = row</literal></td><td>Master/master replication. However, "
"both nodes are not used at the same time. Replication keeps all nodes as "
"close to being up to date as possible (although the asynchronous nature of "
"the replication means a fully consistent state is not possible). Connections"
" to the database only happen through a Pacemaker virtual IP, ensuring that "
"most problems that occur with master-master replication can be "
"avoided.</td><td>Not heavily considered. Once load on the MySQL server "
"increases enough that scalability needs to be considered, multiple masters "
"or a master/slave setup can be used.</td></tr><tr><td>Qpid</td><td><literal"
">max-connections=1000</literal><literal>worker-threads=20</literal><literal"
">connection-backlog=10</literal>, sasl security enabled with SASL-BASIC "
"authentication</td><td>Qpid is added as a resource to the Pacemaker software"
" that runs on Controller nodes where Qpid is situated. This ensures only one"
" Qpid instance is running at one time, and the node with the Pacemaker "
"virtual IP will always be the node running Qpid.</td><td>Not heavily "
"considered. However, Qpid can be changed to run on all controller nodes for "
"scalability and availability purposes, and removed from "
"Pacemaker.</td></tr><tr><td>HAProxy</td><td><literal>maxconn "
"3000</literal></td><td>HAProxy is a software layer-7 load balancer used to "
"front door all clustered OpenStack API components and do SSL termination. "
"HAProxy can be added as a resource to the Pacemaker software that runs on "
"the Controller nodes where HAProxy is situated. This ensures that only one "
"HAProxy instance is running at one time, and the node with the Pacemaker "
"virtual IP will always be the node running HAProxy.</td><td>Not considered. "
"HAProxy has small enough performance overheads that a single instance should"
" scale enough for this level of workload. If extra scalability is needed, "
"<literal>keepalived</literal> or other Layer-4 load balancing can be "
"introduced to be placed in front of multiple copies of "
"HAProxy.</td></tr><tr><td>Memcached</td><td><literal>MAXCONN=\"8192\" "
"CACHESIZE=\"30457\"</literal></td><td>Memcached is a fast in-memory key-"
"value cache software that is used by OpenStack components for caching data "
"and increasing performance. Memcached runs on all controller nodes, ensuring"
" that should one go down, another instance of Memcached is "
"available.</td><td>Not considered. A single instance of Memcached should be "
"able to scale to the desired workloads. If scalability is desired, HAProxy "
"can be placed in front of Memcached (in raw <literal>tcp</literal> mode) to "
"utilize multiple Memcached instances for scalability. However, this might "
"cause cache consistency "
"issues.</td></tr><tr><td>Pacemaker</td><td>Configured to use <phrase role"
"=\"keep-together\"><literal>corosync</literal> "
"and</phrase><literal>cman</literal> as a cluster communication stack/quorum "
"manager, and as a two-node cluster.</td><placeholder-1/><td>If more nodes "
"need to be made cluster aware, Pacemaker can scale to 64 "
"nodes.</td></tr><tr><td>GlusterFS</td><td><literal>glusterfs</literal> "
"performance profile \"virt\" enabled on all volumes. Volumes are setup in "
"two-node replication.</td><td>Glusterfs is a clustered file system that is "
"run on the storage nodes to provide persistent scalable data storage in the "
"environment. Because all connections to gluster use the "
"<literal>gluster</literal> native mount points, the "
"<literal>gluster</literal> instances themselves provide availability and "
"failover functionality.</td><td>The scalability of GlusterFS storage can be "
"achieved by adding in more storage volumes.</td></tr></tbody></table><table "
"rules=\"all\" xml:id=\"openstack-config-table\"><caption>OpenStack component"
" configuration</caption><col width=\"8%\"/><col width=\"8%\"/><col "
"width=\"25%\"/><col width=\"29%\"/><col "
"width=\"30%\"/><thead><tr><th>Component</th><th>Node "
"type</th><th>Tuning</th><th>Availability</th><th>Scalability</th></tr></thead><tbody><tr><td>Dashboard"
" (horizon)</td><td>Controller</td><td>Configured to use Memcached as a "
"session store, <literal>neutron</literal> support is enabled, "
"<literal>can_set_mount_point = False</literal></td><td>The dashboard is run "
"on all controller nodes, ensuring at least one instance will be available in"
" case of node failure. It also sits behind HAProxy, which detects when the "
"software fails and routes requests around the failing instance.</td><td>The "
"dashboard is run on all controller nodes, so scalability can be achieved "
"with additional controller nodes. HAProxy allows scalability for the "
"dashboard as more nodes are added.</td></tr><tr><td>Identity "
"(keystone)</td><td>Controller</td><td>Configured to use Memcached for "
"caching and PKI for tokens.</td><td>Identity is run on all controller nodes,"
" ensuring at least one instance will be available in case of node failure. "
"Identity also sits behind HAProxy, which detects when the software fails and"
" routes requests around the failing instance.</td><td>Identity is run on all"
" controller nodes, so scalability can be achieved with additional controller"
" nodes. HAProxy allows scalability for Identity as more nodes are "
"added.</td></tr><tr><td>Image Service "
"(glance)</td><td>Controller</td><td><literal>/var/lib/glance/images</literal>"
" is a GlusterFS native mount to a Gluster volume off the storage "
"layer.</td><td>The Image Service is run on all controller nodes, ensuring at"
" least one instance will be available in case of node failure. It also sits "
"behind HAProxy, which detects when the software fails and routes requests "
"around the failing instance.</td><td>The Image Service is run on all "
"controller nodes, so scalability can be achieved with additional controller "
"nodes. HAProxy allows scalability for the Image Service as more nodes are "
"added.</td></tr><tr><td>Compute (nova)</td><td>Controller, "
"Compute</td><placeholder-2/><placeholder-3/><td>The nova API, scheduler, "
"objectstore, cert, consoleauth, conductor, and vncproxy services are run on "
"all controller nodes, so scalability can be achieved with additional "
"controller nodes. HAProxy allows scalability for Compute as more nodes are "
"added. The scalability of services running on the compute nodes (compute, "
"conductor) is achieved linearly by adding in more compute "
"nodes.</td></tr><tr><td>Block Storage "
"(cinder)</td><td>Controller</td><td>Configured to use Qpid, <phrase role"
"=\"keep-together\"><literal>qpid_heartbeat = </literal><phrase role=\"keep-"
"together\"><literal>10</literal>,</phrase></phrase><phrase role=\"keep-"
"together\"> configured to use a Gluster</phrase> volume from the storage "
"layer as the backend for Block Storage, using the Gluster native "
"client.</td><td>Block Storage API, scheduler, and volume services are run on"
" all controller nodes, ensuring at least one instance will be available in "
"case of node failure. Block Storage also sits behind HAProxy, which detects "
"if the software fails and routes requests around the failing "
"instance.</td><td>Block Storage API, scheduler and volume services are run "
"on all controller nodes, so scalability can be achieved with additional "
"controller nodes. HAProxy allows scalability for Block Storage as more nodes"
" are added.</td></tr><tr><td>OpenStack Networking "
"(neutron)</td><td>Controller, Compute, Network</td><td>Configured to use "
"QPID, <phrase role=\"keep-together\"><literal>qpid_heartbeat = "
"10</literal></phrase>, kernel namespace support enabled, "
"<literal>tenant_network_type = vlan</literal>, "
"<literal>allow_overlapping_ips = true</literal>, "
"<literal>tenant_network_type = vlan</literal>, <literal>bridge_uplinks = br-"
"ex:em2</literal>, <literal>bridge_mappings = physnet1:br-"
"ex</literal></td><placeholder-4/><td>The OpenStack Networking server service"
" is run on all controller nodes, so scalability can be achieved with "
"additional controller nodes. HAProxy allows scalability for OpenStack "
"Networking as more nodes are added. Scalability of services running on the "
"network nodes is not currently supported by OpenStack Networking, so they "
"are not be considered. One copy of the services should be sufficient to "
"handle the workload. Scalability of the <literal>ovs-agent</literal> running"
" on compute nodes is achieved by adding in more compute nodes as "
"necessary.</td></tr></tbody></table>"
msgstr "<xref linkend=\"thirdparty-table\"/> および <xref linkend=\"openstack-config-table\"/> には、サードパーティーおよび OpenStack の両方のコンポーネントの設定例および考慮事項を記載しています<indexterm class=\"singular\"><primary>OpenStack Networking (neutron)</primary><secondary>サードパーティーコンポーネントの設定</secondary></indexterm>: <table rules=\"all\" xml:id=\"thirdparty-table\"><caption>Third-party component configuration</caption><col width=\"10%\"/><col width=\"30%\"/><col width=\"30%\"/><col width=\"30%\"/><thead><tr><th>コンポーネント</th><th>チューニング</th><th>可用性</th><th>拡張性</th></tr></thead><tbody><tr><td>MySQL</td><td><literal>binlog-format = row</literal></td><td>マスター/マスターレプリケーション。ただし、両ノードは同時には使用されません。レプリケーションにより、全ノードは可能な限り最新に近い状態で維持されます (ただし、非同期レプリケーションの性質により、完全な一貫性を確保することは不可能です)。データベースへの接続は、Pacemaker の仮想 IP を使用してのみ行い、マスター/マスターレプリケーションで発生する大半の問題を回避することができるようにします。</td><td>大きくは考慮されません。MySQL サーバーの負荷が十分に高くなったら、拡張性を検討する必要があり、マスターを複数またはマスター/スレーブ設定を 1 つ使用することができます。</td></tr><tr><td>Qpid</td><td><literal>max-connections=1000</literal><literal>worker-threads=20</literal><literal>connection-backlog=10</literal>、SASL-BASIC 認証で sasl セキュリティを有効化</td><td>Qpid は、配置先のコントローラーノードで実行されるPacemaker ソフトウェアにリソースとして追加されます。これにより、1 回に実行される Qpid インスタンスは 1 つのみとなり、Pacemaker の仮想 IP が割り当てられているノードが、常に Qpid を実行するノードとなります。</td><td>大きくは考慮されません。ただし、拡張性と可用性を目的として、Qpid を全コントローラーノードで実行するように変更し、Pacemaker から削除することが可能です。</td></tr><tr><td>HAProxy</td><td><literal>maxconn 3000</literal></td><td>HAProxy は、クラスター化されたすべての OpenStack API コンポーネントのフロントドアに使用して、すべての SSL 終了を実行するソフトウェア L7 ロードバランサーです。HAProxy は、配置先のコントローラーノードで実行される Pacemaker ソフトウェアにリソースとして追加することができます。これにより、1 回に実行されるHAProxy インスタンスは 1 つのみとなり、Pacemaker の仮想 IP が割り当てられているノードが、常に HAProxy  を実行するノードとなります。</td><td>考慮されません。HAProxy はパフォーマンスオーバーヘッドが十分小さいので、1 つのインスタンスで。このレベルのワークロードには十分に拡張できるはずです。さらなる拡張性が要求される場合には、<literal>keepalived</literal> またはその他の L4 ロードバランシングを HAProxy の複数コピーの前に配置することができます。</td></tr><tr><td>Memcached</td><td><literal>MAXCONN=\"8192\" CACHESIZE=\"30457\"</literal></td><td>Memcached は、OpenStack コンポーネントがデータのキャッシュとパフォーマンス向上のために使用する高速のインメモリーキー値キャッシュソフトウェアです。Memcached は、全コントローラーノード上で実行して、いずれかが停止した場合には、別の Memcached インスタンスが利用できるようにします。</td><td>考慮されません。単一の Memcached インスタンスで必要なワークロードに拡張可能なはずです。拡張性が要求される場合には、HAProxy を Memcached の前に (raw <literal>tcp</literal> モードで) 配置して、複数の Memcached インスタンスを活用することで拡張性を実現することができます。ただし、これにより、キャッシュの一貫性に問題が生じる可能性があります。</td></tr><tr><td>Pacemaker</td><td><phrase role=\"keep-together\"><literal>corosync</literal> および </phrase><literal>cman</literal> をクラスター通信スタック/クォーラムマネージャーおよび 2 ノード構成のクラスターとして使用するように設定。</td><placeholder-1/><td>それよりも多い数のノードをクラスターに認識させる必要がある場合には、Pacemaker は 64 ノードまで拡張が可能です。</td></tr><tr><td>GlusterFS</td><td><literal>glusterfs</literal> パフォーマンスプロファイル \"virt\" を全ボリュームで有効化。ボリュームは 2 ノードレプリケーションに設定。</td><td>Glusterfs は、環境内で永続的な拡張性のあるデータストレージを提供するためにストレージノード上で実行するクラスター化したファイルシステムです。gluster への接続にはすべて <literal>gluster</literal> ネイティブのマウントポイントを使用するので、<literal>gluster</literal> インスタンス自体が可用性とフェイルオーバー機能を提供します。</td><td>GlusterFS ストレージの拡張性は、ストレージボリュームを追加することによって実現することができます。</td></tr></tbody></table><table rules=\"all\" xml:id=\"openstack-config-table\"><caption>OpenStack コンポーネントの設定</caption><col width=\"8%\"/><col width=\"8%\"/><col width=\"25%\"/><col width=\"29%\"/><col width=\"30%\"/><thead><tr><th>コンポーネント</th><th>ノードタイプ</th><th>チューニング</th><th>可用性</th><th>拡張性</th></tr></thead><tbody><tr><td>Dashboard (horizon)</td><td>コントローラー</td><td>セッションストアとして Memcached を使用するように設定、 <literal>neutron</literal> サポートの有効化、 <literal>can_set_mount_point = False</literal></td><td>ダッシュボードは、全コントローラーノード上で実行され、ノードに障害が発生した場合には、少なくとも 1 インスタンスが利用可能な状態となるようにします。また、ソフトウェアの障害発生時に検出し、障害が発生したインスタンスを迂回してルーティングする HAProxy の背後に配置されます。</td><td>ダッシュボードは全コントローラー上で実行されるため、追加のコントローラーノードで拡張性を実現することができます。HAProxy は、ノードの追加に伴うダッシュボードの拡張性を可能にします。</td></tr><tr><td>Identity (keystone)</td><td>コントローラー</td><td>キャッシングとトークン用の PKI に Memcached を使用するように設定。</td><td>Identity は全ノードで実行され、ノードに障害が発生した場合には少なくとも 1 インスタンスが利用可能な状態となるようにします。Identity も、ソフトウェアの障害発生時に検出し、障害が発生したインスタンスを迂回してルーティングする HAProxy の背後に配置されます。</td><td>Identity は全コントローラーノード上で実行されるため、追加のコントローラーノードで拡張性を実現することができます。HAProxy は、ノードの追加に伴う Identity の拡張性を可能にします。</td></tr><tr><td>Image Service (glance)</td><td>Controller</td><td><literal>/var/lib/glance/images</literal> は ストレージレイヤー外のGluster ボリュームへの GlusterFS ネイティブマウントです。</td><td>Image Service は、全コントローラーノードで実行され、ノードの障害が発生した場合には少なくとも 1 インスタンスが利用できるようにします。これも、ソフトウェアの障害発生時に検出し、障害が発生したインスタンスを迂回してルーティングする HAProxy の背後に配置されます。</td><td>Image Service は全コントローラーノードで実行されるため、追加のコントローラーノードで拡張性を実現することができます。HAProxy は、ノードの追加に伴う Image Service の拡張性を可能にします。</td></tr><tr><td>Compute (nova)</td><td>コントローラー、コンピュート</td><placeholder-2/><placeholder-3/><td>nova API、scheduler、objectstore、cert,、consoleauth、conductor および  vncproxy サービスは、全コントローラーノードで実行されるため、追加のコントラーノードで拡張性を実現することができます。HAProxy は、ノードの追加に伴う Compute の拡張性を可能にします。コンピュートノードで実行されるサービス (compute、conductor) の拡張性は、コンピュートノードをさらに追加することによって直線的に実現されます。</td></tr><tr><td>Block Storage (cinder)</td><td>コントローラー</td><td>Qpid を使用するように設定<phrase role=\"keep-together\"><literal>qpid_heartbeat = </literal><phrase role=\"keep-together\"><literal>10</literal>、</phrase></phrase>Gluster ネイティブクライアントを使用して、ストレージ層から Block Storage のバックエンドとして<phrase role=\"keep-together\"> Gluster ボリュームを使用するように設定</phrase></td><td>Block Storage API、scheduler、および volume サービスは、全コントローラーノードで実行され、ノードに障害が発生した場合には、少なくとも 1 インスタンスが利用可能な状態となるようにします。Block Storage も、ソフトウェアの障害発生時に検出して、障害が発生したインスタンスを迂回してルーティングする HAProxy の背後に配置されます。.</td><td>Block Storage API、scheduler、および  volume サービスは、全コントローラーノードで実行されるため、追加のコントローラーノードで拡張性を実現することができます。HAProxy は、ノードの追加に伴う Block Storage の拡張性を可能にします。</td></tr><tr><td>OpenStack Networking (neutron)</td><td>Controller、Compute、Network</td><td>QPID を使用するように設定<phrase role=\"keep-together\"><literal>qpid_heartbeat = 10</literal></phrase>、カーネル名前空間のサポートの有効化、<literal>tenant_network_type = vlan</literal>、<literal>allow_overlapping_ips = true</literal>、<literal>tenant_network_type = vlan</literal>、<literal>bridge_uplinks = br-ex:em2</literal>、<literal>bridge_mappings = physnet1:br-ex</literal></td><placeholder-4/><td>OpenStack Networking サーバーサービスは、全コントローラーノードで実行されるため、追加のコントローラーノードで拡張性を実現することができます。HAProxy は、ノードの追加に伴う OpenStack Networking の拡張性を可能にします。OpenStack Networking では、ネットワークノード上で実行されるサービスの拡張性は現在サポートされていないため、考慮されていません。各サービスのコピーを 1 つでワークロードの処理に十分なはずです。コンピュートノードで実行される <literal>ovs-agent</literal> の拡張性は、必要に応じてコンピュートノードをさらに追加することによって実現されます。</td></tr></tbody></table>"

#: ./doc/openstack-ops/app_usecases.xml10(title)
msgid "Use Cases"
msgstr "事例"

#: ./doc/openstack-ops/app_usecases.xml12(para)
msgid ""
"This appendix contains a small selection of use cases from the community, "
"with more technical detail than usual. Further examples can be found on the "
"<link href=\"https://www.openstack.org/user-stories/\" title=\"OpenStack "
"User Stories Website\">OpenStack website</link>."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml19(title)
msgid "NeCTAR"
msgstr "NeCTAR"

#: ./doc/openstack-ops/app_usecases.xml21(para)
msgid ""
"Who uses it: researchers from the Australian publicly funded research "
"sector. Use is across a wide variety of disciplines, with the purpose of "
"instances ranging from running simple web servers to using hundreds of cores"
" for high-throughput computing.<indexterm class=\"singular\"><primary>NeCTAR"
" Research Cloud</primary></indexterm><indexterm "
"class=\"singular\"><primary>use "
"cases</primary><secondary>NeCTAR</secondary></indexterm><indexterm "
"class=\"singular\"><primary>OpenStack community</primary><secondary>use "
"cases</secondary><tertiary>NeCTAR</tertiary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml40(title)
#: ./doc/openstack-ops/app_usecases.xml114(title)
#: ./doc/openstack-ops/app_usecases.xml206(title)
#: ./doc/openstack-ops/app_usecases.xml262(title)
msgid "Deployment"
msgstr "デプロイ"

#: ./doc/openstack-ops/app_usecases.xml42(para)
msgid ""
"Using OpenStack Compute cells, the NeCTAR Research Cloud spans eight sites "
"with approximately 4,000 cores per site."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml45(para)
msgid ""
"Each site runs a different configuration, as resource "
"<glossterm>cell</glossterm>s in an OpenStack Compute cells setup. Some sites"
" span multiple data centers, some use off compute node storage with a shared"
" file system, and some use on compute node storage with a nonshared file "
"system. Each site deploys the Image Service with an Object Storage backend. "
"A central Identity Service, dashboard, and Compute API service are used. A "
"login to the dashboard triggers a SAML login with Shibboleth, which creates "
"an <glossterm>account</glossterm> in the Identity Service with an SQL "
"backend."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml55(para)
msgid ""
"Compute nodes have 24 to 48 cores, with at least 4 GB of RAM per core and "
"approximately 40 GB of ephemeral storage per core."
msgstr "コンピュートノードは 24～48コアがあり、１コアあたり 4GB 以上の RAM があり、１コアあたり約 40GB 以上の一時ストレージがあります。"

#: ./doc/openstack-ops/app_usecases.xml58(para)
msgid ""
"All sites are based on Ubuntu 12.04, with KVM as the hypervisor. The "
"OpenStack version in use is typically the current stable version, with 5 to "
"10 percent back-ported code from trunk and modifications. Migration to "
"Ubuntu 14.04 is planned as part of the Havana to Icehouse upgrade.<indexterm"
" class=\"singular\"><primary>Icehouse</primary><secondary>migration to "
"Ubuntu</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml70(title)
#: ./doc/openstack-ops/app_usecases.xml170(title)
#: ./doc/openstack-ops/app_usecases.xml231(title)
#: ./doc/openstack-ops/app_usecases.xml285(title)
#: ./doc/openstack-ops/ch_ops_resources.xml11(title)
msgid "Resources"
msgstr "情報源"

#: ./doc/openstack-ops/app_usecases.xml74(link)
msgid "OpenStack.org case study"
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml79(link)
msgid "NeCTAR-RC GitHub"
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml84(link)
msgid "NeCTAR website"
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml92(title)
msgid "MIT CSAIL"
msgstr "MIT CSAIL"

#: ./doc/openstack-ops/app_usecases.xml94(para)
msgid ""
"Who uses it: researchers from the MIT Computer Science and Artificial "
"Intelligence Lab.<indexterm class=\"singular\"><primary>CSAIL (Computer "
"Science and Artificial Intelligence Lab)</primary></indexterm><indexterm "
"class=\"singular\"><primary>MIT CSAIL (Computer Science and Artificial "
"Intelligence Lab)</primary></indexterm><indexterm "
"class=\"singular\"><primary>use cases</primary><secondary>MIT "
"CSAIL</secondary></indexterm><indexterm "
"class=\"singular\"><primary>OpenStack community</primary><secondary>use "
"cases</secondary><tertiary>MIT CSAIL</tertiary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml116(para)
msgid ""
"The CSAIL cloud is currently 64 physical nodes with a total of 768 physical "
"cores and 3,456 GB of RAM. Persistent data storage is largely outside the "
"cloud on NFS, with cloud resources focused on compute resources. There are "
"more than 130 users in more than 40 projects, typically running 2,000–2,500 "
"vCPUs in 300 to 400 instances."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml122(para)
msgid ""
"We initially deployed on Ubuntu 12.04 with the Essex release of OpenStack "
"using FlatDHCP multi-host networking."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml125(para)
msgid ""
"The software stack is still Ubuntu 12.04 LTS, but now with OpenStack Havana "
"from the Ubuntu Cloud Archive. KVM is the hypervisor, deployed using <link "
"href=\"http://fai-project.org/\">FAI</link> and Puppet for configuration "
"management. The FAI and Puppet combination is used lab-wide, not only for "
"OpenStack. There is a single cloud controller node, which also acts as "
"network controller, with the remainder of the server hardware dedicated to "
"compute nodes."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml133(para)
msgid ""
"Host aggregates and instance-type extra specs are used to provide two "
"different resource allocation ratios. The default resource allocation ratios"
" we use are 4:1 CPU and 1.5:1 RAM. Compute-intensive workloads use instance "
"types that require non-oversubscribed hosts where "
"<literal>cpu_ratio</literal> and <literal>ram_ratio</literal> are both set "
"to 1.0. Since we have hyperthreading enabled on our compute nodes, this "
"provides one vCPU per CPU thread, or two vCPUs per physical core."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml142(para)
msgid ""
"With our upgrade to Grizzly in August 2013, we moved to OpenStack Networking"
" Service, neutron (quantum at the time). Compute nodes have two-gigabit "
"network interfaces and a separate management card for IPMI management. One "
"network interface is used for node-to-node communications. The other is used"
" as a trunk port for OpenStack managed VLANs. The controller node uses two "
"bonded 10g network interfaces for its public IP communications. Big pipes "
"are used here because images are served over this port, and it is also used "
"to connect to iSCSI storage, backending the image storage and database. The "
"controller node also has a gigabit interface that is used in trunk mode for "
"OpenStack managed VLAN traffic. This port handles traffic to the dhcp-agent "
"and metadata-proxy."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml155(para)
msgid ""
"We approximate the older <literal>nova-network</literal> multi-host HA setup"
" by using \"provider vlan networks\" that connect instances directly to "
"existing publicly addressable networks and use existing physical routers as "
"their default gateway. This means that if our network controller goes down, "
"running instances still have their network available, and no single Linux "
"host becomes a traffic bottleneck. We are able to do this because we have a "
"sufficient supply of IPv4 addresses to cover all of our instances and thus "
"don't need NAT and don't use floating IP addresses. We provide a single "
"generic public network to all projects and additional existing VLANs on a "
"project-by-project basis as needed. Individual projects are also allowed to "
"create their own private GRE based networks."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml174(link)
msgid "CSAIL homepage"
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml182(title)
msgid "DAIR"
msgstr "DAIR"

#: ./doc/openstack-ops/app_usecases.xml184(para)
msgid ""
"Who uses it: DAIR is an integrated virtual environment that leverages the "
"CANARIE network to develop and test new information communication technology"
" (ICT) and other digital technologies. It combines such digital "
"infrastructure as advanced networking and cloud computing and storage to "
"create an environment for developing and testing innovative ICT "
"applications, protocols, and services; performing at-scale experimentation "
"for deployment; and facilitating a faster time to market.<indexterm "
"class=\"singular\"><primary>DAIR</primary></indexterm><indexterm "
"class=\"singular\"><primary>use "
"cases</primary><secondary>DAIR</secondary></indexterm><indexterm "
"class=\"singular\"><primary>OpenStack community</primary><secondary>use "
"cases</secondary><tertiary>DAIR</tertiary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml208(para)
msgid ""
"DAIR is hosted at two different data centers across Canada: one in Alberta "
"and the other in Quebec. It consists of a cloud controller at each location,"
" although, one is designated the \"master\" controller that is in charge of "
"central authentication and quotas. This is done through custom scripts and "
"light modifications to OpenStack. DAIR is currently running Grizzly."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml215(para)
msgid "For Object Storage, each region has a swift environment."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml217(para)
msgid ""
"A NetApp appliance is used in each region for both block storage and "
"instance storage. There are future plans to move the instances off the "
"NetApp appliance and onto a distributed file system such as "
"<glossterm>Ceph</glossterm> or GlusterFS."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml222(para)
msgid ""
"VlanManager is used extensively for network management. All servers have two"
" bonded 10GbE NICs that are connected to two redundant switches. DAIR is set"
" up to use single-node networking where the cloud controller is the gateway "
"for all instances on all compute nodes. Internal OpenStack traffic (for "
"example, storage traffic) does not go through the cloud controller."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml235(link)
msgid "DAIR homepage"
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml243(title)
msgid "CERN"
msgstr "CERN"

#: ./doc/openstack-ops/app_usecases.xml245(para)
msgid ""
"Who uses it: researchers at CERN (European Organization for Nuclear "
"Research) conducting high-energy physics research.<indexterm "
"class=\"singular\"><primary>CERN (European Organization for Nuclear "
"Research)</primary></indexterm><indexterm class=\"singular\"><primary>use "
"cases</primary><secondary>CERN</secondary></indexterm><indexterm "
"class=\"singular\"><primary>OpenStack community</primary><secondary>use "
"cases</secondary><tertiary>CERN</tertiary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml264(para)
msgid ""
"The environment is largely based on Scientific Linux 6, which is Red Hat "
"compatible. We use KVM as our primary hypervisor, although tests are ongoing"
" with Hyper-V on Windows Server 2008."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml268(para)
msgid ""
"We use the Puppet Labs OpenStack modules to configure Compute, Image "
"Service, Identity, and dashboard. Puppet is used widely for instance "
"configuration, and Foreman is used as a GUI for reporting and instance "
"provisioning."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml273(para)
msgid ""
"Users and groups are managed through Active Directory and imported into the "
"Identity Service using LDAP. CLIs are available for nova and Euca2ools to do"
" this."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml277(para)
msgid ""
"There are three clouds currently running at CERN, totaling about 3,400 "
"compute nodes, with approximately 60,000 cores. The CERN IT cloud aims to "
"expand to 300,000 cores by 2015."
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml289(link)
msgid "“OpenStack in Production: A tale of 3 OpenStack Clouds”"
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml294(link)
msgid "“Review of CERN Data Centre Infrastructure”"
msgstr ""

#: ./doc/openstack-ops/app_usecases.xml299(link)
msgid "“CERN Cloud Infrastructure User Guide”"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml12(title)
msgid "Customization"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml14(para)
msgid ""
"OpenStack might not do everything you need it to do out of the box. To add a"
" new feature, you can follow different paths.<indexterm "
"class=\"singular\"><primary>customization</primary><secondary>paths "
"available</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml22(para)
msgid ""
"To take the first path, you can modify the OpenStack code directly. Learn "
"<link href=\"https://wiki.openstack.org/wiki/How_To_Contribute\">how to "
"contribute</link>, follow the <link "
"href=\"https://wiki.openstack.org/wiki/GerritWorkflow\">code review "
"workflow</link>, make your changes, and contribute them back to the upstream"
" OpenStack project. This path is recommended if the feature you need "
"requires deep integration with an existing project. The community is always "
"open to contributions and welcomes new functionality that follows the "
"feature-development guidelines. This path still requires you to use DevStack"
" for testing your feature additions, so this chapter walks you through the "
"DevStack environment.<indexterm class=\"singular\"><primary>OpenStack "
"community</primary><secondary>customization and</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml37(para)
msgid ""
"For the second path, you can write new features and plug them in using "
"changes to a configuration file. If the project where your feature would "
"need to reside uses the Python Paste framework, you can create middleware "
"for it and plug it in through configuration. There may also be specific ways"
" of customizing a project, such as creating a new scheduler driver for "
"Compute or a custom tab for the dashboard."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml44(para)
msgid ""
"This chapter focuses on the second path for customizing OpenStack by "
"providing two examples for writing new features. The first example shows how"
" to modify Object Storage (swift) middleware to add a new feature, and the "
"second example provides a new scheduler feature for OpenStack Compute "
"(nova). To customize OpenStack this way you need a development environment. "
"The best way to get an environment up and running quickly is to run DevStack"
" within your cloud."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml53(title)
msgid "Create an OpenStack Development Environment"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml55(para)
msgid ""
"To create a development environment, you can use DevStack. DevStack is "
"essentially a collection of shell scripts and configuration files that "
"builds an OpenStack development environment for you. You use it to create "
"such an environment for developing a new feature.<indexterm "
"class=\"singular\"><primary>customization</primary><secondary>development "
"environment creation for</secondary></indexterm><indexterm "
"class=\"singular\"><primary>development environments, "
"creating</primary></indexterm><indexterm "
"class=\"singular\"><primary>DevStack</primary><secondary>development "
"environment creation</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml71(para)
msgid ""
"You can find all of the documentation at the <link "
"href=\"http://devstack.org/\">DevStack</link> website."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml75(title)
msgid ""
"To run DevStack for the stable Havana branch on an instance in your "
"OpenStack cloud:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml79(para)
msgid ""
"Boot an instance from the dashboard or the nova command-line interface (CLI)"
" with the following parameters:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml84(para)
msgid "Name: devstack-havana"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml88(para)
msgid "Image: Ubuntu 12.04 LTS"
msgstr "イメージ: Ubuntu 12.04 LTS"

#: ./doc/openstack-ops/ch_ops_customize.xml92(para)
msgid "Memory Size: 4 GB RAM"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml96(para)
msgid "Disk Size: minimum 5 GB"
msgstr "ディスクサイズ: 最低 5 GB"

#: ./doc/openstack-ops/ch_ops_customize.xml100(para)
msgid ""
"If you are using the <code>nova</code> client, specify <code>--flavor "
"3</code> for the <code>nova boot</code> command to get adequate memory and "
"disk sizes."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml106(para)
msgid ""
"Log in and set up DevStack. Here's an example of the commands you can use to"
" set up DevStack on a virtual machine:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml113(replaceable)
msgid "username"
msgstr "ユーザー名"

#: ./doc/openstack-ops/ch_ops_customize.xml113(replaceable)
msgid "my.instance.ip.address"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml111(para)
msgid "Log in to the instance: <placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml117(para)
msgid "Update the virtual machine's operating system: <placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml123(para)
msgid "Install git: <placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml129(para)
msgid ""
"Clone the stable/havana branch of the <literal>devstack</literal> "
"repository: <placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml137(para)
msgid "Change to the <literal>devstack</literal> repository: <placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml145(para)
msgid ""
"(Optional) If you've logged in to your instance as the root user, you must "
"create a \"stack\" user; otherwise you'll run into permission issues. If "
"you've logged in as a user other than root, you can skip these steps:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml152(para)
msgid "Run the DevStack script to create the stack user:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml158(para)
msgid ""
"Give ownership of the <literal>devstack</literal> directory to the stack "
"user:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml165(para)
msgid "Set some permissions you can use to view the DevStack screen later:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml172(para)
msgid "Switch to the stack user:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml180(para)
msgid ""
"Edit the <filename>localrc</filename> configuration file that controls what "
"DevStack will deploy. Copy the example <filename>localrc</filename> file at "
"the end of this section (<xref linkend=\"localrc\"/>):"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml189(para)
msgid "Run the stack script that will install OpenStack: <placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml195(para)
msgid ""
"When the stack script is done, you can open the screen session it started to"
" view all of the running OpenStack services: <placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml202(para)
msgid ""
"Press <keycombo><keycap>Ctrl</keycap><keycap>A</keycap></keycombo> followed "
"by 0 to go to the first <literal>screen</literal> window."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml214(para)
msgid ""
"The <code>stack.sh</code> script takes a while to run. Perhaps you can take "
"this opportunity to <link href=\"https://www.openstack.org/join/\">join the "
"OpenStack Foundation</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml221(para)
msgid ""
"<literal>Screen</literal> is a useful program for viewing many related "
"services at once. For more information, see the <link "
"href=\"http://aperiodic.net/screen/quick_reference\">GNU screen quick "
"reference</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml229(para)
msgid ""
"Now that you have an OpenStack development environment, you're free to hack "
"around without worrying about damaging your production deployment. <xref "
"linkend=\"localrc\"/> provides a working environment for running OpenStack "
"Identity, Compute, Block Storage, Image Service, the OpenStack dashboard, "
"and Object Storage with the stable/havana branches as the starting point."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml237(title)
msgid "localrc"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml282(title)
msgid "Customizing Object Storage (Swift) Middleware"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml284(para)
msgid ""
"OpenStack Object Storage, known as swift when reading the code, is based on "
"the Python <link href=\"http://pythonpaste.org/\">Paste</link> framework. "
"The best introduction to its architecture is <link "
"href=\"http://pythonpaste.org/do-it-yourself-framework.html\">A Do-It-"
"Yourself Framework</link>. Because of the swift project's use of this "
"framework, you are able to add features to a project by placing some custom "
"code in a project's pipeline without having to change any of the core "
"code.<indexterm class=\"singular\"><primary>Paste "
"framework</primary></indexterm><indexterm "
"class=\"singular\"><primary>Python</primary></indexterm><indexterm "
"class=\"singular\"><primary>swift</primary><secondary>swift "
"middleware</secondary></indexterm><indexterm "
"class=\"singular\"><primary>Object Storage</primary><secondary>customization"
" of</secondary></indexterm><indexterm "
"class=\"singular\"><primary>customization</primary><secondary>Object "
"Storage</secondary></indexterm><indexterm "
"class=\"singular\"><primary>DevStack</primary><secondary>customizing Object "
"Storage (swift)</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml313(para)
msgid ""
"Imagine a scenario where you have public access to one of your containers, "
"but what you really want is to restrict access to that to a set of IPs based"
" on a whitelist. In this example, we'll create a piece of middleware for "
"swift that allows access to a container from only a set of IP addresses, as "
"determined by the container's metadata items. Only those IP addresses that "
"you explicitly whitelist using the container's metadata will be able to "
"access the container."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml322(para)
msgid ""
"This example is for illustrative purposes only. It should not be used as a "
"container IP whitelist solution without further development and extensive "
"security testing.<indexterm class=\"singular\"><primary>security "
"issues</primary><secondary>middleware example</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml331(para)
msgid ""
"When you join the screen session that <code>stack.sh</code> starts with "
"<code>screen -r stack</code>, you see a screen for each service running, "
"which can be a few or several, depending on how many services you configured"
" DevStack to run."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml336(para)
msgid ""
"The asterisk * indicates which screen window you are viewing. This example "
"shows we are viewing the key (for keystone) screen window:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml341(para)
msgid "The purpose of the screen windows are as follows:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml345(code)
#: ./doc/openstack-ops/ch_ops_customize.xml824(code)
msgid "shell"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml348(para)
#: ./doc/openstack-ops/ch_ops_customize.xml827(para)
msgid "A shell where you can get some work done"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml353(code)
msgid "key*"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml356(para)
#: ./doc/openstack-ops/ch_ops_customize.xml835(para)
msgid "The keystone service"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml361(code)
#: ./doc/openstack-ops/ch_ops_customize.xml840(code)
#: ./doc/openstack-ops/ch_ops_log_monitor.xml95(para)
msgid "horizon"
msgstr "horizon"

#: ./doc/openstack-ops/ch_ops_customize.xml364(para)
#: ./doc/openstack-ops/ch_ops_customize.xml843(para)
msgid "The horizon dashboard web application"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml369(code)
msgid "s-{name}"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml372(para)
msgid "The swift services"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml378(title)
msgid "To create the middleware and plug it in through Paste configuration:"
msgstr "ミドルウェアを作成して Paste の環境設定を通して組み込むためには："

#: ./doc/openstack-ops/ch_ops_customize.xml381(para)
msgid ""
"All of the code for OpenStack lives in <code>/opt/stack</code>. Go to the "
"swift directory in the <code>shell</code> screen and edit your middleware "
"module."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml386(para)
msgid "Change to the directory where Object Storage is installed:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml393(para)
msgid "Create the <literal>ip_whitelist.py</literal> Python source code file:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml400(para)
msgid ""
"Copy the code in <xref linkend=\"ip_whitelist\"/> into "
"<filename>ip_whitelist.py</filename>. The following code is a middleware "
"example that restricts access to a container based on IP address as "
"explained at the beginning of the section. Middleware passes the request on "
"to another application. This example uses the swift \"swob\" library to wrap"
" Web Server Gateway Interface (WSGI) requests and responses into objects for"
" swift to interact with. When you're done, save and close the file."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml410(title)
msgid "ip_whitelist.py"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml507(para)
msgid ""
"There is a lot of useful information in <code>env</code> and "
"<code>conf</code> that you can use to decide what to do with the request. To"
" find out more about what properties are available, you can insert the "
"following log statement into the <code>__init__</code> method:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml515(para)
msgid "and the following log statement into the <code>__call__</code> method:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml522(para)
msgid ""
"To plug this middleware into the swift Paste pipeline, you edit one "
"configuration file, <filename>/etc/swift/proxy-server.conf</filename>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml530(para)
msgid ""
"Find the <code>[filter:ratelimit]</code> section in <filename>/etc/swift"
"/proxy-server.conf</filename>, and copy in the following configuration "
"section after it:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml546(para)
msgid ""
"Find the <code>[pipeline:main]</code> section in <filename>/etc/swift/proxy-"
"server.conf</filename>, and add <code>ip_whitelist</code> after ratelimit to"
" the list like so. When you're done, save and close the file:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml556(para)
msgid ""
"Restart the <literal>swift proxy</literal> service to make swift use your "
"middleware. Start by switching to the <literal>swift-proxy</literal> screen:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml562(para)
msgid ""
"Press <keycombo><keycap>Ctrl</keycap><keycap>A</keycap></keycombo> followed "
"by <keycap>3</keycap>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml570(para)
#: ./doc/openstack-ops/ch_ops_customize.xml1069(para)
msgid ""
"Press <keycombo><keycap>Ctrl</keycap><keycap>C</keycap></keycombo> to kill "
"the service."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml578(para)
#: ./doc/openstack-ops/ch_ops_customize.xml1077(para)
msgid "Press Up Arrow to bring up the last command."
msgstr "上矢印キーを押し、最後のコマンドを表示させます。"

#: ./doc/openstack-ops/ch_ops_customize.xml582(para)
#: ./doc/openstack-ops/ch_ops_customize.xml1081(para)
msgid "Press Enter to run it."
msgstr "Enter キーを押し、実行します。"

#: ./doc/openstack-ops/ch_ops_customize.xml588(para)
msgid ""
"Test your middleware with the <code>swift</code> CLI. Start by switching to "
"the shell screen and finish by switching back to the <code>swift-"
"proxy</code> screen to check the log output:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml594(para)
msgid ""
"Press <keycombo><keycap>Ctrl</keycap><keycap>A</keycap></keycombo> followed "
"by 0."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml602(para)
msgid "Make sure you're in the <literal>devstack</literal> directory:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml609(para)
msgid "Source openrc to set up your environment variables for the CLI:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml616(para)
msgid "Create a container called <literal>middleware-test</literal>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml623(para)
msgid ""
"Press <keycombo><keycap>Ctrl</keycap><keycap>A</keycap></keycombo> followed "
"by <keycap>3</keycap> to check the log output."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml634(para)
msgid "Among the log statements you'll see the lines:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml639(para)
msgid ""
"These two statements are produced by our middleware and show that the "
"request was sent from our DevStack instance and was allowed."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml645(para)
msgid ""
"Test the middleware from outside DevStack on a remote machine that has "
"access to your DevStack instance:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml650(para)
msgid ""
"Install the <code>keystone</code> and <code>swift</code> clients on your "
"local machine:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml657(para)
msgid ""
"Attempt to list the objects in the <literal>middleware-test</literal> "
"container:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml670(para)
msgid ""
"Press <keycombo><keycap>Ctrl</keycap><keycap>A</keycap></keycombo> followed "
"by <keycap>3</keycap> to check the log output. Look at the swift log "
"statements again, and among the log statements, you'll see the lines:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml685(para)
msgid ""
"Here we can see that the request was denied because the remote IP address "
"wasn't in the set of allowed IPs."
msgstr "ここで、リモートIPアドレスが、許可されたIPアドレスの中になかったため、リクエストが拒否されていることがわかります。"

#: ./doc/openstack-ops/ch_ops_customize.xml690(para)
msgid ""
"Back in your DevStack instance on the shell screen, add some metadata to "
"your container to allow the request from the remote machine:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml696(para)
msgid ""
"Press <keycombo><keycap>Ctrl</keycap><keycap>A</keycap></keycombo> followed "
"by <keycap>0</keycap>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml704(para)
msgid "Add metadata to the container to allow the IP:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml710(para)
msgid ""
"Now try the command from Step 10 again and it succeeds. There are no objects"
" in the container, so there is nothing to list; however, there is also no "
"error to report."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml719(para)
msgid ""
"Functional testing like this is not a replacement for proper unit and "
"integration testing, but it serves to get you started.<indexterm "
"class=\"singular\"><primary>testing</primary><secondary>functional "
"testing</secondary></indexterm><indexterm "
"class=\"singular\"><primary>functional testing</primary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml730(para)
msgid ""
"You can follow a similar pattern in other projects that use the Python Paste"
" framework. Simply create a middleware module and plug it in through "
"configuration. The middleware runs in sequence as part of that project's "
"pipeline and can call out to other services as necessary. No project core "
"code is touched. Look for a <code>pipeline</code> value in the project's "
"<code>conf</code> or <code>ini</code> configuration files in "
"<code>/etc/&lt;project&gt;</code> to identify projects that use Paste."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml739(para)
msgid ""
"When your middleware is done, we encourage you to open source it and let the"
" community know on the OpenStack mailing list. Perhaps others need the same "
"functionality. They can use your code, provide feedback, and possibly "
"contribute. If enough support exists for it, perhaps you can propose that it"
" be added to the official swift <link "
"href=\"https://github.com/openstack/swift/tree/master/swift/common/middleware\">middleware</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml748(title)
msgid "Customizing the OpenStack Compute (nova) Scheduler"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml750(para)
msgid ""
"Many OpenStack projects allow for customization of specific features using a"
" driver architecture. You can write a driver that conforms to a particular "
"interface and plug it in through configuration. For example, you can easily "
"plug in a new scheduler for Compute. The existing schedulers for Compute are"
" feature full and well documented at <link "
"href=\"http://docs.openstack.org/trunk/config-reference/content"
"/section_compute-scheduler.html\">Scheduling</link>. However, depending on "
"your user's use cases, the existing schedulers might not meet your "
"requirements. You might need to create a new scheduler.<indexterm "
"class=\"singular\"><primary>customization</primary><secondary>OpenStack "
"Compute (nova) Scheduler</secondary></indexterm><indexterm "
"class=\"singular\"><primary>schedulers</primary><secondary>customization "
"of</secondary></indexterm><indexterm "
"class=\"singular\"><primary>DevStack</primary><secondary>customizing "
"OpenStack Compute (nova) scheduler</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml772(para)
msgid ""
"To create a scheduler, you must inherit from the class "
"<code>nova.scheduler.driver.Scheduler</code>. Of the five methods that you "
"can override, you <emphasis>must</emphasis> override the two methods marked "
"with an asterisk (*) below:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml779(code)
msgid "update_service_capabilities"
msgstr "update_service_capabilities"

#: ./doc/openstack-ops/ch_ops_customize.xml783(code)
msgid "hosts_up"
msgstr "hosts_up"

#: ./doc/openstack-ops/ch_ops_customize.xml787(code)
msgid "group_hosts"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml791(para)
msgid "* <code>schedule_run_instance</code>"
msgstr "* <code>schedule_run_instance</code>"

#: ./doc/openstack-ops/ch_ops_customize.xml795(para)
msgid "* <code>select_destinations</code>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml799(para)
msgid ""
"To demonstrate customizing OpenStack, we'll create an example of a Compute "
"scheduler that randomly places an instance on a subset of hosts, depending "
"on the originating IP address of the request and the prefix of the hostname."
" Such an example could be useful when you have a group of users on a subnet "
"and you want all of their instances to start within some subset of your "
"hosts."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml807(para)
msgid ""
"This example is for illustrative purposes only. It should not be used as a "
"scheduler for Compute without further development and <phrase role=\"keep-"
"together\">testing</phrase>.<indexterm class=\"singular\"><primary>security "
"issues</primary><secondary>scheduler example</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml816(para)
msgid ""
"When you join the screen session that <code>stack.sh</code> starts with "
"<code>screen -r stack</code>, you are greeted with many screen windows:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml832(code)
#: ./doc/openstack-ops/ch_ops_projects_users.xml396(replaceable)
msgid "key"
msgstr "key"

#: ./doc/openstack-ops/ch_ops_customize.xml848(code)
msgid "n-{name}"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml851(para)
msgid "The nova services"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml856(code)
msgid "n-sch"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml859(para)
msgid "The nova scheduler service"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml865(title)
msgid "To create the scheduler and plug it in through configuration:"
msgstr "スケジューラーを作成して、設定を通して組み込むためには："

#: ./doc/openstack-ops/ch_ops_customize.xml869(para)
msgid ""
"The code for OpenStack lives in <code>/opt/stack</code>, so go to the "
"<literal>nova</literal> directory and edit your scheduler module. Change to "
"the directory where <literal>nova</literal> is installed:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml878(para)
msgid ""
"Create the <filename>ip_scheduler.py</filename> Python source code file:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml885(para)
msgid ""
"The code in <xref linkend=\"ip_scheduler\"/> is a driver that will schedule "
"servers to hosts based on IP address as explained at the beginning of the "
"section. Copy the code into <filename>ip_scheduler.py</filename>. When "
"you're done, save and close the file."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml892(title)
msgid "ip_scheduler.py"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml1020(para)
msgid ""
"There is a lot of useful information in <code>context</code>, "
"<code>request_spec</code>, and <code>filter_properties</code> that you can "
"use to decide where to schedule the instance. To find out more about what "
"properties are available, you can insert the following log statements into "
"the <code>schedule_run_instance</code> method of the scheduler above:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml1033(para)
msgid ""
"To plug this scheduler into nova, edit one configuration file, "
"<filename>/etc/nova/nova.conf</filename>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml1040(para)
msgid "Find the <code>scheduler_driver</code> config and change it like so:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml1047(para)
msgid ""
"Restart the nova scheduler service to make nova use your scheduler. Start by"
" switching to the <code>n-sch</code> screen:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml1052(para)
msgid ""
"Press <keycombo><keycap>Ctrl</keycap><keycap>A</keycap></keycombo> followed "
"by <keycap>9</keycap>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml1060(para)
msgid ""
"Press <keycombo><keycap>Ctrl</keycap><keycap>A</keycap></keycombo> followed "
"by <keycap>N</keycap> until you reach the <code>n-sch</code> screen."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml1087(para)
msgid ""
"Test your scheduler with the nova CLI. Start by switching to the "
"<code>shell</code> screen and finish by switching back to the "
"<code>n-sch</code> screen to check the log output:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml1093(para)
msgid ""
"Press <keycombo><keycap>Ctrl</keycap><keycap>A</keycap></keycombo> followed "
"by <keycap>0</keycap>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml1101(para)
msgid "Make sure you're in the <filename>devstack</filename> directory:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml1108(para)
msgid ""
"Source <filename>openrc</filename> to set up your environment variables for "
"the CLI:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml1115(para)
msgid ""
"Put the image ID for the only installed image into an environment variable:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml1122(para)
msgid "Boot a test server:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml1130(para)
msgid ""
"Switch back to the <code>n-sch</code> screen. Among the log statements, "
"you'll see the line:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml1141(para)
msgid ""
"Functional testing like this is not a replacement for proper unit and "
"integration testing, but it serves to get you started."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml1145(para)
msgid ""
"A similar pattern can be followed in other projects that use the driver "
"architecture. Simply create a module and class that conform to the driver "
"interface and plug it in through configuration. Your code runs when that "
"feature is used and can call out to other services as necessary. No project "
"core code is touched. Look for a \"driver\" value in the project's "
"<filename>.conf</filename> configuration files in "
"<code>/etc/&lt;project&gt;</code> to identify projects that use a driver "
"architecture."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml1154(para)
msgid ""
"When your scheduler is done, we encourage you to open source it and let the "
"community know on the OpenStack mailing list. Perhaps others need the same "
"functionality. They can use your code, provide feedback, and possibly "
"contribute. If enough support exists for it, perhaps you can propose that it"
" be added to the official Compute <link "
"href=\"https://github.com/openstack/nova/tree/master/nova/scheduler\">schedulers</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml1163(title)
msgid "Customizing the Dashboard (Horizon)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml1165(para)
msgid ""
"The dashboard is based on the Python <link "
"href=\"https://www.djangoproject.com/\">Django</link> web application "
"framework. The best guide to customizing it has already been written and can"
" be found at <link "
"href=\"http://docs.openstack.org/developer/horizon/topics/tutorial.html\">Building"
" on Horizon</link>.<indexterm "
"class=\"singular\"><primary>Django</primary></indexterm><indexterm "
"class=\"singular\"><primary>Python</primary></indexterm><indexterm "
"class=\"singular\"><primary>dashboard</primary></indexterm><indexterm "
"class=\"singular\"><primary>DevStack</primary><secondary>customizing "
"dashboard</secondary></indexterm><indexterm "
"class=\"singular\"><primary>customization</primary><secondary>dashboard</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_customize.xml1187(title)
#: ./doc/openstack-ops/ch_arch_storage.xml774(title)
#: ./doc/openstack-ops/ch_arch_compute_nodes.xml610(title)
#: ./doc/openstack-ops/ch_arch_network_design.xml526(title)
#: ./doc/openstack-ops/ch_arch_provision.xml368(title)
msgid "Conclusion"
msgstr "まとめ"

#: ./doc/openstack-ops/ch_ops_customize.xml1189(para)
msgid ""
"When operating an OpenStack cloud, you may discover that your users can be "
"quite demanding. If OpenStack doesn't do what your users need, it may be up "
"to you to fulfill those requirements. This chapter provided you with some "
"options for customization and gave you the tools you need to get started."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml12(title)
msgid "Upstream OpenStack"
msgstr "OpenStack コミュニティ"

#: ./doc/openstack-ops/ch_ops_upstream.xml14(para)
msgid ""
"OpenStack is founded on a thriving community that is a source of help and "
"welcomes your contributions. This chapter details some of the ways you can "
"interact with the others involved."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml19(title)
msgid "Getting Help"
msgstr "助けを得る"

#: ./doc/openstack-ops/ch_ops_upstream.xml21(para)
msgid ""
"There are several avenues available for seeking assistance. The quickest way"
" is to help the community help you. Search the Q&amp;A sites, mailing list "
"archives, and bug lists for issues similar to yours. If you can't find "
"anything, follow the directions for reporting bugs or use one of the "
"channels for support, which are listed below.<indexterm "
"class=\"singular\"><primary>mailing lists</primary></indexterm><indexterm "
"class=\"singular\"><primary>OpenStack</primary><secondary>documentation</secondary></indexterm><indexterm"
" class=\"singular\"><primary>help, resources "
"for</primary></indexterm><indexterm "
"class=\"singular\"><primary>troubleshooting</primary><secondary>getting "
"help</secondary></indexterm><indexterm class=\"singular\"><primary>OpenStack"
" community</primary><secondary>getting help from</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml44(para)
msgid ""
"Your first port of call should be the official OpenStack documentation, "
"found on <link href=\"http://docs.openstack.org\"/>. You can get questions "
"answered on <link href=\"http://ask.openstack.org\"/>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml49(para)
msgid ""
"<link href=\"https://wiki.openstack.org/wiki/Mailing_Lists\">Mailing "
"lists</link> are also a great place to get help. The wiki page has more "
"information about the various lists. As an operator, the main lists you "
"should be aware of are:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml56(link)
msgid "General list"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml60(para)
msgid ""
"<emphasis>openstack@lists.openstack.org</emphasis>. The scope of this list "
"is the current state of OpenStack. This is a very high-traffic mailing list,"
" with many, many emails per day."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml67(link)
msgid "Operators list"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml71(para)
msgid ""
"<emphasis>openstack-operators@lists.openstack.org.</emphasis> This list is "
"intended for discussion among existing OpenStack cloud operators, such as "
"yourself. Currently, this list is relatively low traffic, on the order of "
"one email a day."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml79(link)
msgid "Development list"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml83(para)
msgid ""
"<emphasis>openstack-dev@lists.openstack.org</emphasis>. The scope of this "
"list is the future state of OpenStack. This is a high-traffic mailing list, "
"with multiple emails per day."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml90(para)
msgid ""
"We recommend that you subscribe to the general list and the operator list, "
"although you must set up filters to manage the volume for the general list. "
"You'll also find links to the mailing list archives on the mailing list wiki"
" page, where you can search through the discussions."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml96(para)
msgid ""
"<link href=\"https://wiki.openstack.org/wiki/IRC\">Multiple IRC "
"channels</link> are available for general questions and developer "
"discussions. The general discussion channel is #openstack on "
"<emphasis>irc.freenode.net</emphasis>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml103(title)
msgid "Reporting Bugs"
msgstr "バグ報告"

#: ./doc/openstack-ops/ch_ops_upstream.xml105(para)
msgid ""
"As an operator, you are in a very good position to report unexpected "
"behavior with your cloud. Since OpenStack is flexible, you may be the only "
"individual to report a particular issue. Every issue is important to fix, so"
" it is essential to learn how to easily submit a bug report.<indexterm "
"class=\"singular\"><primary>maintenance/debugging</primary><secondary>reporting"
" bugs</secondary></indexterm><indexterm class=\"singular\"><primary>bugs, "
"reporting</primary></indexterm><indexterm "
"class=\"singular\"><primary>OpenStack "
"community</primary><secondary>reporting bugs</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml121(para)
msgid ""
"All OpenStack projects use <link "
"href=\"https://launchpad.net/\">Launchpad</link> for bug tracking. You'll "
"need to create an account on Launchpad before you can submit a bug report."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml126(para)
msgid ""
"Once you have a Launchpad account, reporting a bug is as simple as "
"identifying the project or projects that are causing the issue. Sometimes "
"this is more difficult than expected, but those working on the bug triage "
"are happy to help relocate issues if they are not in the right place "
"initially:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml134(para)
msgid ""
"Report a bug in <link "
"href=\"https://bugs.launchpad.net/nova/+filebug/+login\">nova</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml139(para)
msgid ""
"Report a bug in <link href=\"https://bugs.launchpad.net/python-"
"novaclient/+filebug/+login\">python-novaclient</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml144(para)
msgid ""
"Report a bug in <link "
"href=\"https://bugs.launchpad.net/swift/+filebug/+login\">swift</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml149(para)
msgid ""
"Report a bug in <link href=\"https://bugs.launchpad.net/python-"
"swiftclient/+filebug/+login\">python-swiftclient</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml154(para)
msgid ""
"Report a bug in <link "
"href=\"https://bugs.launchpad.net/glance/+filebug/+login\">glance</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml159(para)
msgid ""
"Report a bug in <link href=\"https://bugs.launchpad.net/python-"
"glanceclient/+filebug/+login\">python-glanceclient</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml164(para)
msgid ""
"Report a bug in <link "
"href=\"https://bugs.launchpad.net/keystone/+filebug/+login\">keystone</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml169(para)
msgid ""
"Report a bug in <link href=\"https://bugs.launchpad.net/python-"
"keystoneclient/+filebug/+login\">python-keystoneclient</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml174(para)
msgid ""
"Report a bug in <link "
"href=\"https://bugs.launchpad.net/neutron/+filebug/+login\">neutron</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml179(para)
msgid ""
"Report a bug in <link href=\"https://bugs.launchpad.net/python-"
"neutronclient/+filebug/+login\">python-neutronclient</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml184(para)
msgid ""
"Report a bug in <link "
"href=\"https://bugs.launchpad.net/cinder/+filebug/+login\">cinder</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml189(para)
msgid ""
"Report a bug in <link href=\"https://bugs.launchpad.net/python-"
"cinderclient/+filebug/+login\">python-cinderclient</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml194(para)
msgid ""
"Report a bug in <link "
"href=\"https://bugs.launchpad.net/horizon/+filebug/+login\">horizon</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml199(para)
msgid ""
"Report a bug with the <link href=\"https://bugs.launchpad.net/openstack-"
"manuals/+filebug/+login\">documentation</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml204(para)
msgid ""
"Report a bug with the <link href=\"https://bugs.launchpad.net/openstack-api-"
"site/+filebug/+login\">API documentation</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml209(para)
msgid ""
"To write a good bug report, the following process is essential. First, "
"search for the bug to make sure there is no bug already filed for the same "
"issue. If you find one, be sure to click on \"This bug affects X people. "
"Does this bug affect you?\" If you can't find the issue, then enter the "
"details of your report. It should at least include:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml217(para)
msgid ""
"The release, or milestone, or commit ID corresponding to the software that "
"you are running"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml222(para)
msgid "The operating system and version where you've identified the bug"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml227(para)
msgid "Steps to reproduce the bug, including what went wrong"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml231(para)
msgid "Description of the expected results instead of what you saw"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml236(para)
msgid "Portions of your log files so that you include only relevant excerpts"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml241(para)
msgid "When you do this, the bug is created with:"
msgstr "バグ報告をすると、バグは次のステータスで作成されます。"

#: ./doc/openstack-ops/ch_ops_upstream.xml245(para)
msgid "Status: <emphasis>New</emphasis>"
msgstr "Status: <emphasis>New</emphasis>"

#: ./doc/openstack-ops/ch_ops_upstream.xml249(para)
msgid ""
"In the bug comments, you can contribute instructions on how to fix a given "
"bug, and set it to <emphasis>Triaged</emphasis>. Or you can directly fix it:"
" assign the bug to yourself, set it to <emphasis>In progress</emphasis>, "
"branch the code, implement the fix, and propose your change for merging. But"
" let's not get ahead of ourselves; there are bug triaging tasks as well."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml257(title)
msgid "Confirming and Prioritizing"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml259(para)
msgid ""
"This stage is about checking that a bug is real and assessing its impact. "
"Some of these steps require bug supervisor rights (usually limited to core "
"teams). If the bug lacks information to properly reproduce or assess the "
"importance of the bug, the bug is set to:"
msgstr "このステップでは、バグが実際に起こるかのチェックやその重要度の判定が行われます。これらのステップを行うには、バグ管理者権限が必要なものがあります (通常、バグ管理者権限はコア開発者チームだけが持っています)。バグ報告に、バグを再現したり、バグの重要度を判定したりするのに必要な情報が不足している場合、バグは"

#: ./doc/openstack-ops/ch_ops_upstream.xml266(para)
msgid "Status: <emphasis>Incomplete</emphasis>"
msgstr "Status: <emphasis>Incomplete</emphasis>"

#: ./doc/openstack-ops/ch_ops_upstream.xml270(para)
msgid ""
"Once you have reproduced the issue (or are 100 percent confident that this "
"is indeed a valid bug) and have permissions to do so, set:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml276(para)
msgid "Status: <emphasis>Confirmed</emphasis>"
msgstr "Status: <emphasis>Confirmed</emphasis>"

#: ./doc/openstack-ops/ch_ops_upstream.xml280(para)
msgid "Core developers also prioritize the bug, based on its impact:"
msgstr "にセットして下さい。"

#: ./doc/openstack-ops/ch_ops_upstream.xml285(para)
msgid "Importance: &lt;Bug impact&gt;"
msgstr "Importance: &lt;バグ影響度&gt;"

#: ./doc/openstack-ops/ch_ops_upstream.xml289(para)
msgid "The bug impacts are categorized as follows:"
msgstr "バグ影響度は以下のカテゴリに分かれています。"

#: ./doc/openstack-ops/ch_ops_upstream.xml295(para)
msgid ""
"<emphasis>Critical</emphasis> if the bug prevents a key feature from working"
" properly (regression) for all users (or without a simple workaround) or "
"results in data loss"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml301(para)
msgid ""
"<emphasis>High</emphasis> if the bug prevents a key feature from working "
"properly for some users (or with a workaround)"
msgstr "<emphasis>High</emphasis> このバグにより、目玉となる機能が何人かユーザで正常に動作しない場合 (または簡単なワークアラウンドで動作する場合)"

#: ./doc/openstack-ops/ch_ops_upstream.xml306(para)
msgid ""
"<emphasis>Medium</emphasis> if the bug prevents a secondary feature from "
"working properly"
msgstr "<emphasis>Medium</emphasis> このバグにより、ある程度重要な機能が正常に動作しない場合"

#: ./doc/openstack-ops/ch_ops_upstream.xml311(para)
msgid "<emphasis>Low</emphasis> if the bug is mostly cosmetic"
msgstr "<emphasis>Low</emphasis> このバグが多くの場合で軽微な場合"

#: ./doc/openstack-ops/ch_ops_upstream.xml315(para)
msgid ""
"<emphasis>Wishlist</emphasis> if the bug is not really a bug but rather a "
"welcome change in behavior"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml320(para)
msgid ""
"If the bug contains the solution, or a patch, set the bug status to "
"<emphasis>Triaged</emphasis>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml325(title)
msgid "Bug Fixing"
msgstr "バグ修正"

#: ./doc/openstack-ops/ch_ops_upstream.xml327(para)
msgid ""
"At this stage, a developer works on a fix. During that time, to avoid "
"duplicating the work, the developer should set:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml332(para)
msgid "Status: <emphasis>In Progress</emphasis>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml336(para)
msgid "Assignee: &lt;yourself&gt;"
msgstr "Assignee: &lt;あなた自身&gt;"

#: ./doc/openstack-ops/ch_ops_upstream.xml340(para)
msgid ""
"When the fix is ready, the developer proposes a change and gets the change "
"reviewed."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml345(title)
msgid "After the Change Is Accepted"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml347(para)
msgid ""
"After the change is reviewed, accepted, and lands in master, it "
"automatically moves to:"
msgstr "変更がレビューされ、受理されて、マスターブランチにマージされると、バグの状態は自動的に以下のようになります。"

#: ./doc/openstack-ops/ch_ops_upstream.xml352(para)
msgid "Status: <emphasis>Fix Committed</emphasis>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml356(para)
msgid ""
"When the fix makes it into a milestone or release branch, it automatically "
"moves to:"
msgstr "修正がマイルストーンやリリースブランチに取り込まれると、バグの状態は自動的に以下のようになります。"

#: ./doc/openstack-ops/ch_ops_upstream.xml361(para)
msgid "Milestone: Milestone the bug was fixed in"
msgstr "Milestone: このバグの修正が入ったマイルストーン"

#: ./doc/openstack-ops/ch_ops_upstream.xml365(para)
msgid "Status: <emphasis>Fix Released</emphasis>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml372(title)
msgid "Join the OpenStack Community"
msgstr "OpenStack コミュニティに参加する"

#: ./doc/openstack-ops/ch_ops_upstream.xml374(para)
msgid ""
"Since you've made it this far in the book, you should consider becoming an "
"official individual member of the community and <link "
"href=\"https://www.openstack.org/join/\">join the OpenStack "
"Foundation</link>. The OpenStack Foundation is an independent body providing"
" shared resources to help achieve the OpenStack mission by protecting, "
"empowering, and promoting OpenStack software and the community around it, "
"including users, developers, and the entire ecosystem. We all share the "
"responsibility to make this community the best it can possibly be, and "
"signing up to be a member is the first step to participating. Like the "
"software, individual membership within the OpenStack Foundation is free and "
"accessible to anyone.<indexterm class=\"singular\"><primary>OpenStack "
"community</primary><secondary>joining</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml392(title)
msgid "How to Contribute to the Documentation"
msgstr "ドキュメント作成への貢献の仕方"

#: ./doc/openstack-ops/ch_ops_upstream.xml394(para)
msgid ""
"OpenStack documentation efforts encompass operator and administrator docs, "
"API docs, and user docs.<indexterm class=\"singular\"><primary>OpenStack "
"community</primary><secondary>contributing to</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml401(para)
msgid ""
"The genesis of this book was an in-person event, but now that the book is in"
" your hands, we want you to contribute to it. OpenStack documentation "
"follows the coding principles of iterative work, with bug logging, "
"investigating, and fixing."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml406(para)
msgid ""
"Just like the code, <link href=\"http://docs.openstack.org\"/> is updated "
"constantly using the Gerrit review system, with source stored in GitHub in "
"the <link href=\"https://github.com/openstack/openstack-manuals"
"/\">openstack-manuals repository</link> and the <link "
"href=\"https://github.com/openstack/api-site/\">api-site repository</link>, "
"in DocBook format."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml413(para)
msgid ""
"To review the documentation before it's published, go to the OpenStack "
"Gerrit server at <link href=\"http://review.openstack.org\"/> and search for"
" <link href=\"https://review.openstack.org/#/q/status:open+project:openstack"
"/openstack-manuals,n,z\">project:openstack/openstack-manuals</link> or <link"
" href=\"https://review.openstack.org/#/q/status:open+project:openstack/api-"
"site,n,z\">project:openstack/api-site</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml420(para)
msgid ""
"See the <link href=\"https://wiki.openstack.org/wiki/How_To_Contribute\">How"
" To Contribute page on the wiki</link> for more information on the steps you"
" need to take to submit your first documentation review or change."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml426(title)
msgid "Security Information"
msgstr "セキュリティ情報"

#: ./doc/openstack-ops/ch_ops_upstream.xml428(para)
msgid ""
"As a community, we take security very seriously and follow a specific "
"process for reporting potential issues. We vigilantly pursue fixes and "
"regularly eliminate exposures. You can report security issues you discover "
"through this specific process. The OpenStack Vulnerability Management Team "
"is a very small group of experts in vulnerability management drawn from the "
"OpenStack community. The team's job is facilitating the reporting of "
"vulnerabilities, coordinating security fixes and handling progressive "
"disclosure of the vulnerability information. Specifically, the team is "
"responsible for the following functions:<indexterm "
"class=\"singular\"><primary>vulnerability "
"tracking/management</primary></indexterm><indexterm "
"class=\"singular\"><primary>security "
"issues</primary><secondary>reporting/fixing "
"vulnerabilities</secondary></indexterm><indexterm "
"class=\"singular\"><primary>OpenStack community</primary><secondary>security"
" information</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml451(term)
msgid "Vulnerability management"
msgstr "脆弱性管理"

#: ./doc/openstack-ops/ch_ops_upstream.xml454(para)
msgid ""
"All vulnerabilities discovered by community members (or users) can be "
"reported to the team."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml460(term)
msgid "Vulnerability tracking"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml463(para)
msgid ""
"The team will curate a set of vulnerability related issues in the issue "
"tracker. Some of these issues are private to the team and the affected "
"product leads, but once remediation is in place, all vulnerabilities are "
"public."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml471(term)
msgid "Responsible disclosure"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml474(para)
msgid ""
"As part of our commitment to work with the security community, the team "
"ensures that proper credit is given to security researchers who responsibly "
"report issues in OpenStack."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml481(para)
msgid ""
"We provide two ways to report issues to the OpenStack Vulnerability "
"Management Team, depending on how sensitive the issue is:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml486(para)
msgid ""
"Open a bug in Launchpad and mark it as a \"security bug.\" This makes the "
"bug private and accessible to only the Vulnerability Management Team."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml492(para)
msgid ""
"If the issue is extremely sensitive, send an encrypted email to one of the "
"team's members. Find their GPG keys at <link "
"href=\"http://www.openstack.org/projects/openstack-security/\">OpenStack "
"Security</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml499(para)
msgid ""
"You can find the full list of security-oriented teams you can join at <link "
"href=\"https://wiki.openstack.org/wiki/SecurityTeams\">Security "
"Teams</link>. The vulnerability management process is fully documented at "
"<link "
"href=\"https://wiki.openstack.org/wiki/VulnerabilityManagement\">Vulnerability"
" Management</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upstream.xml507(title)
msgid "Finding Additional Information"
msgstr "さらに情報を見つける"

#: ./doc/openstack-ops/ch_ops_upstream.xml509(para)
msgid ""
"In addition to this book, there are many other sources of information about "
"OpenStack. The <link href=\"http://www.openstack.org/\">OpenStack "
"website</link> is a good starting point, with <link "
"href=\"http://docs.openstack.org/\">OpenStack Docs</link> and <link "
"href=\"http://developer.openstack.org/\">OpenStack API Docs</link> providing"
" technical documentation about OpenStack. The <link "
"href=\"https://wiki.openstack.org/wiki/Main_Page\">OpenStack wiki</link> "
"contains a lot of general information that cuts across the OpenStack "
"projects, including a list of <link "
"href=\"https://wiki.openstack.org/wiki/OperationsTools\">recommended "
"tools</link>. Finally, there are a number of blogs aggregated at <link "
"href=\"http://planet.openstack.org/\">Planet OpenStack</link>.<indexterm "
"class=\"singular\"><primary>OpenStack "
"community</primary><secondary>additional information</secondary></indexterm>"
msgstr ""

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/part_architecture.xml82(None)
msgid ""
"@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc"
"/openstack-ops/figures/osog_0001.png'; md5=THIS FILE DOESN'T EXIST"
msgstr "@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/openstack-ops/figures/osog_0001.png'; md5=THIS FILE DOESN'T EXIST"

#: ./doc/openstack-ops/part_architecture.xml10(title)
msgid "Architecture"
msgstr "アーキテクチャ"

#: ./doc/openstack-ops/part_architecture.xml13(para)
msgid ""
"Designing an OpenStack cloud is a great achievement. It requires a robust "
"understanding of the requirements and needs of the cloud's users to "
"determine the best possible configuration to meet them. OpenStack provides a"
" great deal of flexibility to achieve your needs, and this part of the book "
"aims to shine light on many of the decisions you need to make during the "
"process."
msgstr "OpenStack クラウドの設計は重要な作業です。クラウドのユーザーの要件とニーズを確実に理解して、それらに対応するために可能な限り最良の構成を決定する必要があります。OpenStack は、ユーザーのニーズを満たすための優れた柔軟性を提供します。本セクションでは、このようなプロセスで行う必要のある数多くの決定事項を明確に説明することを目的としています。"

#: ./doc/openstack-ops/part_architecture.xml20(para)
msgid ""
"To design, deploy, and configure OpenStack, administrators must understand "
"the logical architecture. A diagram can help you envision all the integrated"
" services within OpenStack and how they interact with each other.<indexterm "
"class=\"singular\"><primary>modules, types "
"of</primary></indexterm><indexterm "
"class=\"singular\"><primary>OpenStack</primary><secondary>module types "
"in</secondary></indexterm>"
msgstr "OpenStack の設計、デプロイ、および構成を行うにあたって、管理者は論理アーキテクチャを理解するが必要があります。OpenStack 内で統合される全サービスおよびそれらがどのように相互作用するかについての構想を立てるには、図が役立ちます。<indexterm class=\"singular\"><primary>モジュール、タイプ</primary></indexterm><indexterm class=\"singular\"><primary>OpenStack</primary><secondary>モジュールタイプ</secondary></indexterm>"

#: ./doc/openstack-ops/part_architecture.xml31(para)
msgid "OpenStack modules are one of the following types:"
msgstr "OpenStack のモジュールは、以下の種別のいずれかです。"

#: ./doc/openstack-ops/part_architecture.xml35(term)
msgid "Daemon"
msgstr "デーモン"

#: ./doc/openstack-ops/part_architecture.xml38(para)
msgid ""
"Runs as a background process. On Linux platforms, a daemon is usually "
"installed as a service.<indexterm "
"class=\"singular\"><primary>daemons</primary><secondary>basics "
"of</secondary></indexterm>"
msgstr "バックグラウンドプロセスとして実行されます。Linux プラットフォームでは、デーモンは通常サービスとしてインストールされます。<indexterm class=\"singular\"><primary>デーモン</primary><secondary>基本</secondary></indexterm>"

#: ./doc/openstack-ops/part_architecture.xml48(term)
msgid "Script"
msgstr "スクリプト"

#: ./doc/openstack-ops/part_architecture.xml51(para)
msgid ""
"Installs a virtual environment and runs tests.<indexterm "
"class=\"singular\"><primary>script modules</primary></indexterm>"
msgstr "仮想環境をインストールし、テストを実行します。<indexterm class=\"singular\"><primary>スクリプトモジュール</primary></indexterm>"

#: ./doc/openstack-ops/part_architecture.xml59(term)
msgid "Command-line interface (CLI)"
msgstr "コマンドラインインターフェース (CLI)"

#: ./doc/openstack-ops/part_architecture.xml62(para)
msgid ""
"Enables users to submit API calls to OpenStack services through "
"commands.<indexterm class=\"singular\"><primary>Command-line interface "
"(CLI)</primary></indexterm>"
msgstr "ユーザーはコマンドを使用して API コールを OpenStack サービスに送信できます。<indexterm class=\"singular\"><primary>コマンドラインインターフェース (CLI)</primary></indexterm>"

#: ./doc/openstack-ops/part_architecture.xml70(para)
msgid ""
"As shown, end users can interact through the dashboard, CLIs, and APIs. All "
"services authenticate through a common Identity Service, and individual "
"services interact with each other through public APIs, except where "
"privileged administrator commands are necessary. <xref linkend=\"openstack-"
"diagram\"/> shows the most common, but not the only logical architecture for"
" an OpenStack cloud."
msgstr "下図に示したように、エンドユーザーはダッシュボード、CLI、および API を使用して対話することができます。サービスはすべて、共通の Identity Service を介して認証を行い、またサービス相互間の対話は、特権のある管理者がコマンドを実行する必要がある場合を除いてパブリック API を使用して行われます。<xref linkend=\"openstack-diagram\"/> には、OpenStack の最も一般的な論理アーキテクチャを示しています。ただし、これは唯一のアーキテクチャではありません。"

#: ./doc/openstack-ops/part_architecture.xml77(title)
msgid ""
"OpenStack Logical Architecture (<link href=\"http://docs.openstack.org"
"/openstack-ops/content/figures/2/figures/osog_0001.png\"/>)"
msgstr "OpenStack の論理アーキテクチャ (<link href=\"http://docs.openstack.org/openstack-ops/content/figures/2/figures/osog_0001.png\"/>)"

#: ./doc/openstack-ops/ch_ops_resources.xml17(link)
#: ./doc/openstack-ops/preface_ops.xml171(link)
msgid "Installation Guide for Debian 7.0"
msgstr "インストールガイド Debian 7.0 版"

#: ./doc/openstack-ops/ch_ops_resources.xml20(link)
#: ./doc/openstack-ops/preface_ops.xml176(link)
msgid "Installation Guide for openSUSE and SUSE Linux Enterprise Server"
msgstr "インストールガイド openSUSE、SUSE Linux Enterprise Server 版"

#: ./doc/openstack-ops/ch_ops_resources.xml25(link)
#: ./doc/openstack-ops/preface_ops.xml182(link)
msgid "Installation Guide for Red Hat Enterprise Linux, CentOS, and Fedora"
msgstr "インストールガイド Red Hat Enterprise Linux、CentOS、Fedora 版"

#: ./doc/openstack-ops/ch_ops_resources.xml31(link)
#: ./doc/openstack-ops/preface_ops.xml188(link)
msgid "Installation Guide for Ubuntu 12.04/14.04 (LTS) Server"
msgstr "インストールガイド Ubuntu 12.04/14.04 (LTS) Server 版"

#: ./doc/openstack-ops/ch_ops_resources.xml35(link)
#: ./doc/openstack-ops/preface_ops.xml207(link)
msgid "OpenStack Cloud Administrator Guide"
msgstr "OpenStack クラウド管理者ガイド"

#: ./doc/openstack-ops/ch_ops_resources.xml39(emphasis)
msgid "OpenStack Cloud Computing Cookbook"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml39(link)
msgid "<placeholder-1/> (Packt Publishing)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml45(title)
msgid "Cloud (General)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml48(link)
msgid "“The NIST Definition of Cloud Computing”"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml54(title)
msgid "Python"
msgstr "Python"

#: ./doc/openstack-ops/ch_ops_resources.xml57(emphasis)
msgid "Dive Into Python"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml57(link)
#: ./doc/openstack-ops/ch_ops_resources.xml107(link)
msgid "<placeholder-1/> (Apress)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml63(title)
#: ./doc/openstack-ops/ch_arch_compute_nodes.xml599(title)
msgid "Networking"
msgstr "ネットワーク"

#: ./doc/openstack-ops/ch_ops_resources.xml66(emphasis)
msgid "TCP/IP Illustrated, Volume 1: The Protocols, 2/E"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml66(link)
msgid "<placeholder-1/> (Pearson)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml71(emphasis)
msgid "The TCP/IP Guide"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml71(link)
#: ./doc/openstack-ops/ch_ops_resources.xml94(link)
msgid "<placeholder-1/> (No Starch Press)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml75(link)
msgid "“A <placeholder-1/> Tutorial and Primer”"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml81(title)
msgid "Systems Administration"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml84(emphasis)
msgid "UNIX and Linux Systems Administration Handbook"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml84(link)
msgid "<placeholder-1/> (Prentice Hall)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml91(title)
msgid "Virtualization"
msgstr "仮想化"

#: ./doc/openstack-ops/ch_ops_resources.xml94(emphasis)
msgid "The Book of Xen"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml100(title)
#: ./doc/openstack-ops/ch_ops_maintenance.xml859(title)
msgid "Configuration Management"
msgstr "構成管理"

#: ./doc/openstack-ops/ch_ops_resources.xml103(link)
msgid "Puppet Labs Documentation"
msgstr ""

#: ./doc/openstack-ops/ch_ops_resources.xml107(emphasis)
msgid "Pro Puppet"
msgstr ""

#: ./doc/openstack-ops/ch_arch_examples.xml12(title)
msgid "Example Architectures"
msgstr "アーキテクチャの例"

#: ./doc/openstack-ops/ch_arch_examples.xml14(para)
msgid ""
"To understand the possibilities OpenStack offers, it's best to start with "
"basic architectures that are tried-and-true and have been tested in "
"production environments. We offer two such examples with basic pivots on the"
" base operating system (Ubuntu and Red Hat Enterprise Linux) and the "
"networking architectures. There are other differences between these two "
"examples, but you should find the considerations made for the choices in "
"each as well as a rationale for why it worked well in a given environment."
msgstr "OpenStack が提供する可能性を理解するには、確実に信頼できる、本番環境での検証済みの基本アーキテクチャから開始するのが最善の方法です。本ガイドでは、ベースオペレーティングシステム  (Ubuntu および Red Hat Enterprise Linux) 上に基本ピボットとネットワークアーキテクチャを備えた基本アーキテクチャの例を 2 つ紹介しています。これらの 2 つの例では、他にも相違点がありますが、各例で選択にあたって考慮した点と、それらのアーキテクチャが特定の環境で適切に機能するための設定指針をご理解いただけるはずです。"

#: ./doc/openstack-ops/ch_arch_examples.xml23(para)
msgid ""
"Because OpenStack is highly configurable, with many different backends and "
"network configuration options, it is difficult to write documentation that "
"covers all possible OpenStack deployments. Therefore, this guide defines "
"example architectures to simplify the task of documenting, as well as to "
"provide the scope for this guide. Both of the offered architecture examples "
"are currently running in production and serving users."
msgstr "OpenStack は、多数の異なるバックエンドおよびネットワーク設定オプションを利用して高度に設定することが可能です。可能な OpenStack デプロイメントをすべて網羅するドキュメントを執筆するのは難しいため、本ガイドではアーキテクチャの例を定義することによって文書化の作業を簡素化すると共に、本書のスコープを規定します。以下に紹介するアーキテクチャの例はいずれも本番環境で現在実行中であり、ユーザーにサービスを提供しています。"

#: ./doc/openstack-ops/ch_arch_examples.xml31(para)
msgid ""
"As always, refer to the <xref linkend=\"openstack_glossary\"/> if you are "
"unclear about any of the terminology mentioned in these architectures."
msgstr "これらのアーキテクチャで言及されている用語が明確に理解できない場合には、通常通り <xref linkend=\"openstack_glossary\"/> を参照してください。"

#: ./doc/openstack-ops/ch_arch_examples.xml41(title)
msgid "Parting Thoughts on Architectures"
msgstr "アーキテクチャについての章の結び"

#: ./doc/openstack-ops/ch_arch_examples.xml43(para)
msgid ""
"With so many considerations and options available, our hope is to provide a "
"few clearly-marked and tested paths for your OpenStack exploration. If "
"you're looking for additional ideas, check out <xref linkend=\"use-"
"cases\"/>, the <link href=\"http://docs.openstack.org/\">OpenStack "
"Installation Guides</link>, or the <link href=\"http://www.openstack.org"
"/user-stories/\">OpenStack User Stories page</link>."
msgstr "数多くの考慮事項およびオプションがあるため、本セクションでは、OpenStack をお試しいただくための明確に記載した検証済みの方法を提供するように構成しています。本セクションに記載した以外の情報をお探しの場合には、<xref linkend=\"use-cases\"/>、<link href=\"http://docs.openstack.org/\">OpenStack Installation Guides</link>、または <link href=\"http://www.openstack.org/user-stories/\">OpenStack User Stories page</link> をご確認ください。"

#: ./doc/openstack-ops/ch_ops_user_facing.xml10(title)
msgid "User-Facing Operations"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml12(para)
msgid ""
"This guide is for OpenStack operators and does not seek to be an exhaustive "
"reference for users, but as an operator, you should have a basic "
"understanding of how to use the cloud facilities. This chapter looks at "
"OpenStack from a basic user perspective, which helps you understand your "
"users' needs and determine, when you get a trouble ticket, whether it is a "
"user issue or a service issue. The main concepts covered are images, "
"flavors, security groups, block storage, and instances."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml21(title)
#: ./doc/openstack-ops/ch_ops_user_facing.xml1165(para)
#: ./doc/openstack-ops/ch_arch_cloud_controller.xml585(title)
msgid "Images"
msgstr "イメージ"

#: ./doc/openstack-ops/ch_ops_user_facing.xml25(para)
msgid ""
"OpenStack images can often be thought of as \"virtual machine templates.\" "
"Images can also be standard installation media such as ISO images. "
"Essentially, they contain bootable file systems that are used to launch "
"instances.<indexterm class=\"singular\"><primary>user "
"training</primary><secondary>images</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml35(title)
msgid "Adding Images"
msgstr "イメージの追加"

#: ./doc/openstack-ops/ch_ops_user_facing.xml37(para)
msgid ""
"Several premade images exist and can easily be imported into the Image "
"Service. A common image to add is the CirrOS image, which is very small and "
"used for testing purposes.<indexterm "
"class=\"singular\"><primary>images</primary><secondary>adding</secondary></indexterm>"
" To add this image, simply do:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml49(para)
msgid ""
"The <code>glance image-create</code> command provides a large set of options"
" for working with your image. For example, the <code>min-disk</code> option "
"is useful for images that require root disks of a certain size (for example,"
" large Windows images). To view these options, do:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml57(para)
msgid ""
"The <code>location</code> option is important to note. It does not copy the "
"entire image into the Image Service, but references an original location "
"where the image can be found. Upon launching an instance of that image, the "
"Image Service accesses the image from the location specified."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml63(para)
msgid ""
"The <code>copy-from</code> option copies the image from the location "
"specified into the <code>/var/lib/glance/images</code> directory. The same "
"thing is done when using the STDIN redirection with &lt;, as shown in the "
"example."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml68(para)
msgid "Run the following command to view the properties of existing images:"
msgstr "既存のイメージのプロパティを表示するために、以下のコマンドを実行します。"

#: ./doc/openstack-ops/ch_ops_user_facing.xml75(title)
msgid "Sharing Images Between Projects"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml77(para)
msgid ""
"In a multitenant cloud environment, users sometimes want to share their "
"personal images or snapshots with other projects.<indexterm "
"class=\"singular\"><primary>projects</primary><secondary>sharing images "
"between</secondary></indexterm><indexterm "
"class=\"singular\"><primary>images</primary><secondary>sharing between "
"projects</secondary></indexterm> This can be done on the command line with "
"the <literal>glance</literal> tool by the owner of the image."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml90(para)
msgid "To share an image or snapshot with another project, do the following:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml95(para)
msgid "Obtain the UUID of the image:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml101(para)
msgid ""
"Obtain the UUID of the project with which you want to share your image. "
"Unfortunately, nonadmin users are unable to use the "
"<literal>keystone</literal> command to do this. The easiest solution is to "
"obtain the UUID either from an administrator of the cloud or from a user "
"located in the project."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml109(para)
msgid ""
"Once you have both pieces of information, run the <literal>glance</literal> "
"command:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml114(para)
#: ./doc/openstack-ops/ch_ops_projects_users.xml372(para)
#: ./doc/openstack-ops/ch_ops_projects_users.xml398(para)
#: ./doc/openstack-ops/ch_ops_projects_users.xml422(para)
#: ./doc/openstack-ops/ch_ops_projects_users.xml458(para)
#: ./doc/openstack-ops/ch_ops_projects_users.xml660(para)
#: ./doc/openstack-ops/ch_ops_projects_users.xml687(para)
msgid "For example:"
msgstr "例えば"

#: ./doc/openstack-ops/ch_ops_user_facing.xml119(para)
msgid ""
"Project 771ed149ef7e4b2b88665cc1c98f77ca will now have access to image "
"733d1c44-a2ea-414b-aca7-69decf20d810."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml126(title)
msgid "Deleting Images"
msgstr "イメージの削除"

#: ./doc/openstack-ops/ch_ops_user_facing.xml128(para)
msgid ""
"To delete an image,<indexterm "
"class=\"singular\"><primary>images</primary><secondary>deleting</secondary></indexterm>"
" just execute:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml137(para)
msgid ""
"Deleting an image does not affect instances or snapshots that were based on "
"the image."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml143(title)
msgid "Other CLI Options"
msgstr "他の CLI オプション"

#: ./doc/openstack-ops/ch_ops_user_facing.xml145(para)
msgid ""
"A full set of options can be found using:<indexterm "
"class=\"singular\"><primary>images</primary><secondary>CLI options "
"for</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml154(para)
msgid ""
"or the <link href=\"http://docs.openstack.org/cli-"
"reference/content/glanceclient_commands.html\">Command-Line Interface "
"Reference </link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml159(title)
msgid "The Image Service and the Database"
msgstr "イメージサービスおよびデータベース"

#: ./doc/openstack-ops/ch_ops_user_facing.xml161(para)
msgid ""
"The only thing that the Image Service does not store in a database is the "
"image itself. The Image Service database has two main tables:<indexterm "
"class=\"singular\"><primary>databases</primary><secondary>Image "
"Service</secondary></indexterm><indexterm class=\"singular\"><primary>Image "
"Service</primary><secondary>database tables</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml175(literal)
msgid "images"
msgstr "images"

#: ./doc/openstack-ops/ch_ops_user_facing.xml179(literal)
msgid "image_properties"
msgstr "image_properties"

#: ./doc/openstack-ops/ch_ops_user_facing.xml183(para)
msgid ""
"Working directly with the database and SQL queries can provide you with "
"custom lists and reports of images. Technically, you can update properties "
"about images through the database, although this is not generally "
"recommended."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml190(title)
msgid "Example Image Service Database Queries"
msgstr "イメージサービスのデータベースクエリーの例"

#: ./doc/openstack-ops/ch_ops_user_facing.xml192(para)
msgid ""
"One interesting example is modifying the table of images and the owner of "
"that image. This can be easily done if you simply display the unique ID of "
"the owner. <indexterm class=\"singular\"><primary>Image "
"Service</primary><secondary>database queries</secondary></indexterm>This "
"example goes one step further and displays the readable name of the owner:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml206(para)
msgid "Another example is displaying all properties for a certain image:"
msgstr "もう一つの例は、特定のイメージに関するすべてのプロパティを表示することです。"

#: ./doc/openstack-ops/ch_ops_user_facing.xml215(title)
msgid "Flavors"
msgstr "フレーバー"

#: ./doc/openstack-ops/ch_ops_user_facing.xml217(para)
msgid ""
"Virtual hardware templates are called \"flavors\" in OpenStack, defining "
"sizes for RAM, disk, number of cores, and so on. The default install "
"provides five flavors."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml221(para)
msgid ""
"These are configurable by admin users (the rights may also be delegated to "
"other users by redefining the access controls for "
"<code>compute_extension:flavormanage</code> in "
"<code>/etc/nova/policy.json</code> on the <code>nova-api</code> server). To "
"get the list of available flavors on your system, run:<indexterm "
"class=\"singular\"><primary>DAC (discretionary access "
"control)</primary></indexterm><indexterm "
"class=\"singular\"><primary>flavor</primary></indexterm><indexterm "
"class=\"singular\"><primary>user "
"training</primary><secondary>flavors</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml247(para)
msgid ""
"The <code>nova flavor-create</code> command allows authorized users to "
"create new flavors. Additional flavor manipulation commands can be shown "
"with the command: <placeholder-1/>"
msgstr "<code>nova flavor-create</code> コマンドにより、権限のあるユーザーが新しいフレーバーを作成できます。さらなるフレーバーの操作コマンドは次のコマンドを用いて表示できます: <placeholder-1/>"

#: ./doc/openstack-ops/ch_ops_user_facing.xml251(para)
msgid ""
"Flavors define a number of parameters, resulting in the user having a choice"
" of what type of virtual machine to run—just like they would have if they "
"were purchasing a physical server. <xref linkend=\"table-flavor-params\"/> "
"lists the elements that can be set. Note in particular <phrase role=\"keep-"
"together\"><literal>extra_specs</literal>,</phrase> which can be used to "
"define free-form characteristics, giving a lot of flexibility beyond just "
"the size of RAM, CPU, and Disk.<indexterm class=\"singular\"><primary>base "
"image</primary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml263(caption)
msgid "Flavor parameters"
msgstr "フレーバーのパラメーター"

#: ./doc/openstack-ops/ch_ops_user_facing.xml271(emphasis)
msgid "Column"
msgstr "項目"

#: ./doc/openstack-ops/ch_ops_user_facing.xml279(para)
msgid "ID"
msgstr "ID"

#: ./doc/openstack-ops/ch_ops_user_facing.xml281(para)
msgid "A unique numeric ID."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml285(para)
#: ./doc/openstack-ops/ch_ops_user_facing.xml1187(th)
#: ./doc/openstack-ops/ch_arch_scaling.xml78(th)
msgid "Name"
msgstr "名前"

#: ./doc/openstack-ops/ch_ops_user_facing.xml287(para)
msgid ""
"A descriptive name, such as xx.size_name, is conventional but not required, "
"though some third-party tools may rely on it."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml293(para)
msgid "Memory_MB"
msgstr "Memory_MB"

#: ./doc/openstack-ops/ch_ops_user_facing.xml295(para)
msgid "Virtual machine memory in megabytes."
msgstr "メガバイト単位の仮想マシンメモリー。"

#: ./doc/openstack-ops/ch_ops_user_facing.xml299(para)
#: ./doc/openstack-ops/ch_arch_scaling.xml84(th)
msgid "Disk"
msgstr "ディスク"

#: ./doc/openstack-ops/ch_ops_user_facing.xml301(para)
msgid ""
"Virtual root disk size in gigabytes. This is an ephemeral disk the base "
"image is copied into. You don't use it when you boot from a persistent "
"volume. The \"0\" size is a special case that uses the native base image "
"size as the size of the ephemeral root volume."
msgstr "ギガバイト単位の仮想ルートディスク容量。これはベースイメージがコピーされる一時ディスクです。永続的なボリュームからブートするとき、これは使用されません。「0」という容量は特別な値で、一時ルートボリュームの容量としてベースイメージのネイティブ容量をそのまま使用することを意味します。"

#: ./doc/openstack-ops/ch_ops_user_facing.xml309(para)
#: ./doc/openstack-ops/ch_arch_scaling.xml86(th)
msgid "Ephemeral"
msgstr "エフェメラル"

#: ./doc/openstack-ops/ch_ops_user_facing.xml311(para)
msgid ""
"Specifies the size of a secondary ephemeral data disk. This is an empty, "
"unformatted disk and exists only for the life of the instance."
msgstr "二次的な一時データディスクの容量を指定します。これは空の、フォーマットされていないディスクです。インスタンスの生存期間だけ存在します。"

#: ./doc/openstack-ops/ch_ops_user_facing.xml317(para)
msgid "Swap"
msgstr "スワップ"

#: ./doc/openstack-ops/ch_ops_user_facing.xml319(para)
msgid "Optional swap space allocation for the instance."
msgstr "インスタンスに割り当てられるスワップ空間。これはオプションです。"

#: ./doc/openstack-ops/ch_ops_user_facing.xml324(para)
#: ./doc/openstack-ops/ch_ops_projects_users.xml347(para)
msgid "VCPUs"
msgstr "仮想 CPU"

#: ./doc/openstack-ops/ch_ops_user_facing.xml326(para)
msgid "Number of virtual CPUs presented to the instance."
msgstr "インスタンスに存在する仮想 CPU 数。"

#: ./doc/openstack-ops/ch_ops_user_facing.xml331(para)
msgid "RXTX_Factor"
msgstr "RXTX_Factor"

#: ./doc/openstack-ops/ch_ops_user_facing.xml333(para)
msgid ""
"Optional property that allows created servers to have a different "
"bandwidth<indexterm "
"class=\"singular\"><primary>bandwidth</primary><secondary>capping</secondary></indexterm>"
" cap from that defined in the network they are attached to. This factor is "
"multiplied by the rxtx_base property of the network. Default value is 1.0 "
"(that is, the same as the attached network)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml345(para)
msgid "Is_Public"
msgstr "Is_Public"

#: ./doc/openstack-ops/ch_ops_user_facing.xml347(para)
msgid ""
"Boolean value that indicates whether the flavor is available to all users or"
" private. Private flavors do not get the current tenant assigned to them. "
"Defaults to <literal>True</literal>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml354(para)
msgid "extra_specs"
msgstr "extra_specs"

#: ./doc/openstack-ops/ch_ops_user_facing.xml356(para)
msgid ""
"Additional optional restrictions on which compute nodes the flavor can run "
"on. This is implemented as key-value pairs that must match against the "
"corresponding key-value pairs on compute nodes. Can be used to implement "
"things like special resources (such as flavors that can run only on compute "
"nodes with GPU hardware)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml367(title)
msgid "Private Flavors"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml369(para)
msgid ""
"A user might need a custom flavor that is uniquely tuned for a project she "
"is working on. For example, the user might require 128 GB of memory. If you "
"create a new flavor as described above, the user would have access to the "
"custom flavor, but so would all other tenants in your cloud. Sometimes this "
"sharing isn't desirable. In this scenario, allowing all users to have access"
" to a flavor with 128 GB of memory might cause your cloud to reach full "
"capacity very quickly. To prevent this, you can restrict access to the "
"custom flavor using the <literal>nova</literal> command:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml381(para)
msgid "To view a flavor's access list, do the following:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml386(title)
msgid "Best Practices"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml388(para)
msgid ""
"Once access to a flavor has been restricted, no other projects besides the "
"ones granted explicit access will be able to see the flavor. This includes "
"the admin project. Make sure to add the admin project in addition to the "
"original project."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml393(para)
msgid ""
"It's also helpful to allocate a specific numeric range for custom and "
"private flavors. On UNIX-based systems, nonsystem accounts usually have a "
"UID starting at 500. A similar approach can be taken with custom flavors. "
"This helps you easily identify which flavors are custom, private, and public"
" for the entire cloud."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml402(title)
msgid "How Do I Modify an Existing Flavor?"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml404(para)
msgid ""
"The OpenStack dashboard simulates the ability to modify a flavor by deleting"
" an existing flavor and creating a new one with the same name."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml413(title)
msgid "Security Groups"
msgstr "セキュリティグループ"

#: ./doc/openstack-ops/ch_ops_user_facing.xml415(para)
msgid ""
"A common new-user issue with OpenStack is failing to set an appropriate "
"security group when launching an instance. As a result, the user is unable "
"to contact the instance on the network.<indexterm "
"class=\"singular\"><primary>security groups</primary></indexterm><indexterm "
"class=\"singular\"><primary>user training</primary><secondary>security "
"groups</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml426(para)
msgid ""
"Security groups are sets of IP filter rules that are applied to an "
"instance's networking. They are project specific, and project members can "
"edit the default rules for their group and add new rules sets. All projects "
"have a \"default\" security group, which is applied to instances that have "
"no other security group defined. Unless changed, this security group denies "
"all incoming traffic."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml434(title)
msgid "General Security Groups Configuration"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml436(para)
msgid ""
"The <code>nova.conf</code> option <code>allow_same_net_traffic</code> (which"
" defaults to <literal>true</literal>) globally controls whether the rules "
"apply to hosts that share a network. When set to <literal>true</literal>, "
"hosts on the same subnet are not filtered and are allowed to pass all types "
"of traffic between them. On a flat network, this allows all instances from "
"all projects unfiltered communication. With VLAN networking, this allows "
"access between instances within the same project. If "
"<code>allow_same_net_traffic</code> is set to <literal>false</literal>, "
"security groups are enforced for all connections. In this case, it is "
"possible for projects to simulate <code>allow_same_net_traffic</code> by "
"configuring their default security group to allow all traffic from their "
"subnet."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml451(para)
msgid ""
"As noted in the previous chapter, the number of rules per security group is "
"controlled by the <code>quota_security_group_rules</code>, and the number of"
" allowed security groups per project is controlled by the "
"<code>quota_security_groups</code> quota."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml460(title)
msgid "End-User Configuration of Security Groups"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml462(para)
msgid ""
"Security groups for the current project can be found on the OpenStack "
"dashboard under <guilabel>Access &amp; Security</guilabel>. To see details "
"of an existing group, select the <guilabel>edit</guilabel> action for that "
"security group. Obviously, modifying existing groups can be done from this "
"<guilabel>edit</guilabel> interface. There is a <guibutton>Create Security "
"Group</guibutton> button on the main <guilabel>Access &amp; "
"Security</guilabel> page for creating new groups. We discuss the terms used "
"in these fields when we explain the command-line equivalents."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml472(para)
msgid ""
"From the command line, you can get a list of security groups for the project"
" you're acting in using the <literal>nova</literal> command:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml486(para)
msgid "To view the details of the \"open\" security group:"
msgstr "「open」セキュリティグループの詳細を表示する方法:"

#: ./doc/openstack-ops/ch_ops_user_facing.xml497(para)
msgid ""
"These rules are all \"allow\" type rules, as the default is deny. The first "
"column is the IP protocol (one of icmp, tcp, or udp), and the second and "
"third columns specify the affected port range. The fourth column specifies "
"the IP range in CIDR format. This example shows the full port range for all "
"protocols allowed from all IPs."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml503(para)
msgid ""
"When adding a new security group, you should pick a descriptive but brief "
"name. This name shows up in brief descriptions of the instances that use it "
"where the longer description field often does not. Seeing that an instance "
"is using security group <literal>http</literal> is much easier to understand"
" than <literal>bobs_group</literal> or <literal>secgrp1</literal>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml510(para)
msgid ""
"As an example, let's create a security group that allows web traffic "
"anywhere on the Internet. We'll call this group "
"<literal>global_http</literal>, which is clear and reasonably concise, "
"encapsulating what is allowed and from where. From the command line, do:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml524(para)
msgid ""
"This creates the empty security group. To make it do what we want, we need "
"to add some rules:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml535(para)
msgid ""
"Note that the arguments are positional, and the <literal>from-port</literal>"
" and <literal>to-port</literal> arguments specify the allowed local port "
"range connections. These arguments are not indicating source and destination"
" ports of the connection. More complex rule sets can be built up through "
"multiple invocations of <literal>nova secgroup-add-rule</literal>. For "
"example, if you want to pass both http and https traffic, do this:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml550(para)
msgid ""
"Despite only outputting the newly added rule, this operation is additive:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml561(para)
msgid ""
"The inverse operation is called <literal>secgroup-delete-rule</literal>, "
"using the same format. Whole security groups can be removed with <literal"
">secgroup-delete</literal>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml566(para)
msgid ""
"To create security group rules for a cluster of instances, you want to use "
"<phrase role=\"keep-together\">SourceGroups</phrase>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml569(para)
msgid ""
"SourceGroups are a special dynamic way of defining the CIDR of allowed "
"sources. The user specifies a SourceGroup (security group name) and then all"
" the users' other instances using the specified SourceGroup are selected "
"dynamically. This dynamic selection alleviates the need for individual rules"
" to allow each new member of the <phrase role=\"keep-"
"together\">cluster</phrase>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml576(para)
msgid ""
"The code is structured like this: <code>nova secgroup-add-group-rule "
"&lt;secgroup&gt; &lt;source-group&gt; &lt;ip-proto&gt; &lt;from-port&gt; &lt"
";to-port&gt;</code>. An example usage is shown here:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml583(para)
msgid ""
"The \"cluster\" rule allows SSH access from any other instance that uses the"
" <literal>global-http</literal> group."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml591(title)
#: ./doc/openstack-ops/ch_arch_storage.xml178(title)
#: ./doc/openstack-ops/ch_ops_backup_recovery.xml196(title)
msgid "Block Storage"
msgstr "ブロックストレージ"

#: ./doc/openstack-ops/ch_ops_user_facing.xml593(para)
msgid ""
"OpenStack volumes are persistent block-storage devices that may be attached "
"and detached from instances, but they can be attached to only one instance "
"at a time. Similar to an external hard drive, they do not provide shared "
"storage in the way a network file system or object store does. It is left to"
" the operating system in the instance to put a file system on the block "
"device and mount it, or not.<indexterm class=\"singular\"><primary>block "
"storage</primary></indexterm><indexterm "
"class=\"singular\"><primary>storage</primary><secondary>block "
"storage</secondary></indexterm><indexterm class=\"singular\"><primary>user "
"training</primary><secondary>block storage</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml610(para)
msgid ""
"As with other removable disk technology, it is important that the operating "
"system is not trying to make use of the disk before removing it. On Linux "
"instances, this typically involves unmounting any file systems mounted from "
"the volume. The OpenStack volume service cannot tell whether it is safe to "
"remove volumes from an instance, so it does what it is told. If a user tells"
" the volume service to detach a volume from an instance while it is being "
"written to, you can expect some level of file system corruption as well as "
"faults from whatever process within the instance was using the device."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml620(para)
msgid ""
"There is nothing OpenStack-specific in being aware of the steps needed to "
"access block devices from within the instance operating system, potentially "
"formatting them for first use and being cautious when removing them. What is"
" specific is how to create new volumes and attach and detach them from "
"instances. These operations can all be done from the "
"<guilabel>Volumes</guilabel> page of the dashboard or by using the "
"<literal>cinder</literal> command-line client."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml628(para)
msgid ""
"To add new volumes, you need only a name and a volume size in gigabytes. "
"Either put these into the <guilabel>create volume</guilabel> web form or use"
" the command line:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml634(para)
msgid ""
"This creates a 10 GB volume named <literal>test-volume</literal>. To list "
"existing volumes and the instances they are connected to, if any:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml645(para)
msgid ""
"OpenStack Block Storage also allows for creating snapshots of volumes. "
"Remember that this is a block-level snapshot that is crash consistent, so it"
" is best if the volume is not connected to an instance when the snapshot is "
"taken and second best if the volume is not in use on the instance it is "
"attached to. If the volume is under heavy use, the snapshot may have an "
"inconsistent file system. In fact, by default, the volume service does not "
"take a snapshot of a volume that is attached to an image, though it can be "
"forced to. To take a volume snapshot, either select <guilabel>Create "
"Snapshot</guilabel> from the actions column next to the volume name on the "
"dashboard volume page, or run this from the command line:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml671(para)
msgid ""
"For more information about updating Block Storage volumes (for example, "
"resizing or transferring), see the <link href=\"http://docs.openstack.org"
"/user-guide/content/\">OpenStack End User Guide</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml675(title)
msgid "Block Storage Creation Failures"
msgstr "ブロックストレージの作成エラー"

#: ./doc/openstack-ops/ch_ops_user_facing.xml677(para)
msgid ""
"If a user tries to create a volume and the volume immediately goes into an "
"error state, the best way to troubleshoot is to grep the cinder log files "
"for the volume's UUID. First try the log files on the cloud controller, and "
"then try the storage node where the volume was attempted to be created:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml690(title)
#: ./doc/openstack-ops/ch_ops_projects_users.xml296(para)
#: ./doc/openstack-ops/ch_ops_maintenance.xml267(title)
msgid "Instances"
msgstr "インスタンス"

#: ./doc/openstack-ops/ch_ops_user_facing.xml692(para)
msgid ""
"Instances are the running virtual machines within an OpenStack cloud. This "
"section deals with how to work with them and their underlying images, their "
"network properties, and how they are represented in the database.<indexterm "
"class=\"singular\"><primary>user "
"training</primary><secondary>instances</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml702(title)
msgid "Starting Instances"
msgstr "インスタンスの起動"

#: ./doc/openstack-ops/ch_ops_user_facing.xml704(para)
msgid ""
"To launch an instance, you need to select an image, a flavor, and a name. "
"The name needn't be unique, but your life will be simpler if it is because "
"many tools will use the name in place of the UUID so long as the name is "
"unique. You can start an instance from the dashboard from the "
"<guibutton>Launch Instance</guibutton> button on the "
"<guilabel>Instances</guilabel> page or by selecting the "
"<guilabel>Launch</guilabel> action next to an image or snapshot on the "
"<guilabel>Images &amp; Snapshots</guilabel> page.<indexterm "
"class=\"singular\"><primary>instances</primary><secondary>starting</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml718(para)
msgid "On the command line, do this:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml722(para)
msgid ""
"There are a number of optional items that can be specified. You should read "
"the rest of this section before trying to start an instance, but this is the"
" base command that later details are layered upon."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml726(para)
msgid ""
"To delete instances from the dashboard, select the <guilabel>Terminate "
"instance</guilabel> action next to the instance on the "
"<guilabel>Instances</guilabel> page. From the command line, do this:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml733(para)
msgid ""
"It is important to note that powering off an instance does not terminate it "
"in the OpenStack sense."
msgstr "注意すべき大事な点は、インスタンスの電源オフは、OpenStack 的な意味でのインスタンスの終了ではないということです。"

#: ./doc/openstack-ops/ch_ops_user_facing.xml738(title)
msgid "Instance Boot Failures"
msgstr "インスタンスの起動失敗"

#: ./doc/openstack-ops/ch_ops_user_facing.xml740(para)
msgid ""
"If an instance fails to start and immediately moves to an error state, there"
" are a few different ways to track down what has gone wrong. Some of these "
"can be done with normal user access, while others require access to your log"
" server or compute nodes.<indexterm "
"class=\"singular\"><primary>instances</primary><secondary>boot "
"failures</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml749(para)
msgid ""
"The simplest reasons for nodes to fail to launch are quota violations or the"
" scheduler being unable to find a suitable compute node on which to run the "
"instance. In these cases, the error is apparent when you run a <code>nova "
"show</code> on the faulted instance:<indexterm "
"class=\"singular\"><primary>config drive</primary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml787(para)
msgid ""
"In this case, looking at the <literal>fault</literal> message shows "
"<literal>NoValidHost</literal>, indicating that the scheduler was unable to "
"match the instance requirements."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml791(para)
msgid ""
"If <code>nova show</code> does not sufficiently explain the failure, "
"searching for the instance UUID in the <code>nova-compute.log</code> on the "
"compute node it was scheduled on or the <code>nova-scheduler.log</code> on "
"your scheduler hosts is a good place to start looking for lower-level "
"problems."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml797(para)
msgid ""
"Using <code>nova show</code> as an admin user will show the compute node the"
" instance was scheduled on as <code>hostId</code>. If the instance failed "
"during scheduling, this field is blank."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml803(title)
msgid "Using Instance-Specific Data"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml805(para)
msgid ""
"There are two main types of instance-specific data: metadata and user "
"data.<indexterm "
"class=\"singular\"><primary>metadata</primary><secondary>instance "
"metadata</secondary></indexterm><indexterm "
"class=\"singular\"><primary>instances</primary><secondary>instance-specific "
"data</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml817(title)
msgid "Instance metadata"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml819(para)
msgid ""
"For Compute, instance metadata is a collection of key-value pairs associated"
" with an instance. Compute reads and writes to these key-value pairs any "
"time during the instance lifetime, from inside and outside the instance, "
"when the end user uses the Compute API to do so. However, you cannot query "
"the instance-associated key-value pairs with the metadata service that is "
"compatible with the Amazon EC2 metadata service."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml827(para)
msgid ""
"For an example of instance metadata, users can generate and register SSH "
"keys using the <literal>nova</literal> command:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml832(para)
msgid ""
"This creates a key named <placeholder-1/>, which you can associate with "
"instances. The file <filename>mykey.pem</filename> is the private key, which"
" should be saved to a secure location because it allows root access to "
"instances the <placeholder-2/> key is associated with."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml838(para)
msgid "Use this command to register an existing key with OpenStack:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml844(para)
msgid ""
"You must have the matching private key to access instances associated with "
"this key."
msgstr "この鍵と関連付けられたインスタンスにアクセスするために、対応する秘密鍵を持つ必要があります。"

#: ./doc/openstack-ops/ch_ops_user_facing.xml848(para)
msgid ""
"To associate a key with an instance on boot, add <code>--key_name "
"mykey</code> to your command line. For example:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml854(para)
msgid ""
"When booting a server, you can also add arbitrary metadata so that you can "
"more easily identify it among other running instances. Use the "
"<code>--meta</code> option with a key-value pair, where you can make up the "
"string for both the key and the value. For example, you could add a "
"description and also the creator of the server:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml863(para)
msgid ""
"When viewing the server information, you can see the metadata included on "
"the <phrase role=\"keep-together\">metadata</phrase> line:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml899(title)
msgid "Instance user data"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml901(para)
msgid ""
"The <code>user-data</code> key is a special key in the metadata service that"
" holds a file that cloud-aware applications within the guest instance can "
"access. For example, <link "
"href=\"https://help.ubuntu.com/community/CloudInit\" title=\"OpenStack Image"
" Service\">cloudinit</link> is an open source package from Ubuntu, but "
"available in most distributions, that handles early initialization of a "
"cloud instance that makes use of this user data.<indexterm "
"class=\"singular\"><primary>user data</primary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml912(para)
msgid ""
"This user data can be put in a file on your local system and then passed in "
"at instance creation with the flag <code>--user-data &lt;user-data-"
"file&gt;</code>. For example:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml918(para)
msgid ""
"To understand the difference between user data and metadata, realize that "
"user data is created before an instance is started. User data is accessible "
"from within the instance when it is running. User data can be used to store "
"configuration, a script, or anything the tenant wants."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml926(title)
msgid "File injection"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml928(para)
msgid ""
"Arbitrary local files can also be placed into the instance file system at "
"creation time by using the <code>--file &lt;dst-path=src-path&gt;</code> "
"option. You may store up to five files.<indexterm "
"class=\"singular\"><primary>file injection</primary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml935(para)
msgid ""
"For example, let's say you have a special "
"<filename>authorized_keys</filename> file named special_authorized_keysfile "
"that for some reason you want to put on the instance instead of using the "
"regular SSH key injection. In this case, you can use the following command:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml948(title)
msgid "Associating Security Groups"
msgstr "セキュリティグループの割り当て"

#: ./doc/openstack-ops/ch_ops_user_facing.xml950(para)
msgid ""
"Security groups, as discussed earlier, are typically required to allow "
"network traffic to an instance, unless the default security group for a "
"project has been modified to be more permissive.<indexterm "
"class=\"singular\"><primary>security groups</primary></indexterm><indexterm "
"class=\"singular\"><primary>user training</primary><secondary>security "
"groups</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml961(para)
msgid ""
"Adding security groups is typically done on instance boot. When launching "
"from the dashboard, you do this on the <guilabel>Access &amp; "
"Security</guilabel> tab of the <guilabel>Launch Instance</guilabel> dialog. "
"When launching from the command line, append <code>--security-groups</code> "
"with a comma-separated list of security groups."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml968(para)
msgid ""
"It is also possible to add and remove security groups when an instance is "
"running. Currently this is only available through the command-line tools. "
"Here is an example:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml978(title)
#: ./doc/openstack-ops/ch_ops_projects_users.xml259(para)
msgid "Floating IPs"
msgstr "Floating IP"

#: ./doc/openstack-ops/ch_ops_user_facing.xml980(para)
msgid ""
"Where floating IPs are configured in a deployment, each project will have a "
"limited number of floating IPs controlled by a quota. However, these need to"
" be allocated to the project from the central pool prior to their "
"use—usually by the administrator of the project. To allocate a floating IP "
"to a project, use the <guibutton>Allocate IP to Project</guibutton> button "
"on the <guilabel>Access &amp; Security</guilabel> page of the dashboard. The"
" command line can also be used:<indexterm "
"class=\"singular\"><primary>address pool</primary></indexterm><indexterm "
"class=\"singular\"><primary>IP "
"addresses</primary><secondary>floating</secondary></indexterm><indexterm "
"class=\"singular\"><primary>user training</primary><secondary>floating "
"IPs</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1001(para)
msgid ""
"Once allocated, a floating IP can be assigned to running instances from the "
"dashboard either by selecting <guibutton>Associate Floating IP</guibutton> "
"from the actions drop-down next to the IP on the <guilabel>Access &amp; "
"Security</guilabel> page or by making this selection next to the instance "
"you want to associate it with on the <guilabel>Instances</guilabel> page. "
"The inverse action, <guibutton>Dissociate Floating IP</guibutton>, is "
"available only from the <guilabel>Access &amp; Security</guilabel> page and "
"not from the <guilabel>Instances</guilabel> page."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1011(para)
msgid ""
"To associate or disassociate a floating IP with a server from the command "
"line, use the following commands:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1020(title)
msgid "Attaching Block Storage"
msgstr "ブロックストレージの接続"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1022(para)
msgid ""
"You can attach block storage to instances from the dashboard on the "
"<guilabel>Volumes</guilabel> page. Click the <guibutton>Edit "
"Attachments</guibutton> action next to the volume you want to "
"attach.<indexterm "
"class=\"singular\"><primary>storage</primary><secondary>block "
"storage</secondary></indexterm><indexterm class=\"singular\"><primary>block "
"storage</primary></indexterm><indexterm class=\"singular\"><primary>user "
"training</primary><secondary>block storage</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1037(para)
msgid "To perform this action from command line, run the following command:"
msgstr "このアクションをコマンドラインから実行するには、以下のコマンドを実行します"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1042(para)
msgid ""
"You can also specify block device<indexterm "
"class=\"singular\"><primary>block device</primary></indexterm> mapping at "
"instance boot time through the nova command-line client with this option "
"set:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1050(code)
msgid "&lt;dev-name&gt;=&lt;id&gt;:&lt;type&gt;:&lt;size(GB)&gt;:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1049(phrase)
msgid "The block device mapping format is <placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1051(code)
msgid "&lt;delete-on-terminate&gt;"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1051(phrase)
msgid "<placeholder-1/>, where:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1056(term)
msgid "dev-name"
msgstr "dev-name"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1059(para)
msgid ""
"A device name where the volume is attached in the system at "
"<code>/dev/<replaceable>dev_name</replaceable></code>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1065(term)
msgid "id"
msgstr "id"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1068(para)
msgid ""
"The ID of the volume to boot from, as shown in the output of <literal>nova "
"volume-list</literal>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1074(term)
msgid "type"
msgstr "type"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1077(para)
msgid ""
"Either <literal>snap</literal>, which means that the volume was created from"
" a snapshot, or anything other than <literal>snap</literal> (a blank string "
"is valid). In the preceding example, the volume was not created from a "
"snapshot, so we leave this field blank in our following example."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1086(term)
msgid "size (GB)"
msgstr "size (GB)"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1089(para)
msgid ""
"The size of the volume in gigabytes. It is safe to leave this blank and have"
" the Compute Service infer the size."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1095(term)
msgid "delete-on-terminate"
msgstr "delete-on-terminate"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1098(para)
msgid ""
"A boolean to indicate whether the volume should be deleted when the instance"
" is terminated. True can be specified as <literal>True</literal> or "
"<literal>1</literal>. False can be specified as <literal>False</literal> or "
"<literal>0</literal>."
msgstr "インスタンスが終了したときに、ボリュームが削除されるかどうかを指示する論理値です。真は <literal>True</literal> または <literal>1</literal> として指定できます。偽は <literal>False</literal> または <literal>0</literal> として指定できます。"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1107(para)
msgid ""
"The following command will boot a new instance and attach a volume at the "
"same time. The volume of ID 13 will be attached as <code>/dev/vdc</code>. It"
" is not a snapshot, does not specify a size, and will not be deleted when "
"the instance is terminated:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1116(para)
msgid ""
"If you have previously prepared block storage with a bootable file system "
"image, it is even possible to boot from persistent block storage. The "
"following command boots an image from the specified volume. It is similar to"
" the previous command, but the image is omitted and the volume is now "
"attached as <code>/dev/vda</code>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1125(para)
msgid ""
"Read more detailed instructions for launching an instance from a bootable "
"volume in the <link href=\"http://docs.openstack.org/user-"
"guide/content/boot_from_volume.html\">OpenStack End User Guide</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1130(para)
msgid ""
"To boot normally from an image and attach block storage, map to a device "
"other than vda. You can find instructions for launching an instance and "
"attaching a volume to the instance and for copying the image to the attached"
" volume in the <link href=\"http://docs.openstack.org/user-"
"guide/content/dashboard_launch_instances_from_image.html\">OpenStack End "
"User Guide</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1141(title)
msgid "Taking Snapshots"
msgstr "スナップショットの取得"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1143(para)
msgid ""
"The OpenStack snapshot mechanism allows you to create new images from "
"running instances. This is very convenient for upgrading base images or for "
"taking a published image and customizing it for local use. To snapshot a "
"running instance to an image using the CLI, do this:<indexterm "
"class=\"singular\"><primary>base image</primary></indexterm><indexterm "
"class=\"singular\"><primary>snapshot</primary></indexterm><indexterm "
"class=\"singular\"><primary>user "
"training</primary><secondary>snapshots</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1159(para)
msgid ""
"The dashboard interface for snapshots can be confusing because the "
"<guilabel>Images &amp; Snapshots</guilabel> page splits content up into "
"several areas:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1169(para)
msgid "Instance snapshots"
msgstr "インスタンスのスナップショット"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1173(para)
msgid "Volume snapshots"
msgstr "ボリュームのスナップショット"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1177(para)
msgid ""
"However, an instance snapshot <emphasis>is</emphasis> an image. The only "
"difference between an image that you upload directly to the Image Service "
"and an image that you create by snapshot is that an image created by "
"snapshot has additional properties in the glance database. These properties "
"are found in the <literal>image_properties</literal> table and include:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1189(th)
msgid "Value"
msgstr "値"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1195(literal)
msgid "image_type"
msgstr "image_type"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1197(para)
#: ./doc/openstack-ops/ch_ops_user_facing.xml1216(para)
msgid "snapshot"
msgstr "スナップショット"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1201(literal)
msgid "instance_uuid"
msgstr "instance_uuid"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1203(para)
msgid "&lt;uuid of instance that was snapshotted&gt;"
msgstr "&lt;スナップショットされたインスタンスの UUID&gt;"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1207(literal)
msgid "base_image_ref"
msgstr "base_image_ref"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1209(para)
msgid "&lt;uuid of original image of instance that was snapshotted&gt;"
msgstr "&lt;スナップショットされたインスタンスの元イメージの UUID&gt;"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1214(literal)
msgid "image_location"
msgstr "image_location"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1222(title)
msgid "Live Snapshots"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1224(para)
msgid ""
"Live snapshots is a feature that allows users to snapshot the running "
"virtual machines without pausing them. These snapshots are simply disk-only "
"snapshots. Snapshotting an instance can now be performed with no downtime "
"(assuming QEMU 1.3+ and libvirt 1.0+ are used).<indexterm "
"class=\"singular\"><primary>live snapshots</primary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1233(title)
msgid "Ensuring Snapshots Are Consistent"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1235(para)
msgid ""
"The following section is from Sébastien Han's <link href=\"http://www"
".sebastien-han.fr/blog/2012/12/10/openstack-perform-consistent-snapshots/\" "
"title=\"OpenStack Image Service\">“OpenStack: Perform Consistent Snapshots” "
"blog entry</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1240(para)
msgid ""
"A snapshot captures the state of the file system, but not the state of the "
"memory. Therefore, to ensure your snapshot contains the data that you want, "
"before your snapshot you need to ensure that:"
msgstr "スナップショットは、ファイルシステムの状態をキャプチャーしますが、メモリーの状態をキャプチャーしません。そのため、スナップショットに期待するデータが含まれることを確実にするために、次のことを確実にする必要があります。"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1247(para)
msgid "Running programs have written their contents to disk"
msgstr "実行中のプログラムがコンテンツをディスクに書き込んだこと"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1251(para)
msgid ""
"The file system does not have any \"dirty\" buffers: where programs have "
"issued the command to write to disk, but the operating system has not yet "
"done the write"
msgstr "ファイルシステムが「ダーティー」バッファーを持たないこと: 「ダーティー」バッファーがあるとは、プログラムがディスクに書き込むためにコマンドを発行しましたが、オペレーティングシステムがまだ書き込みを完了していないことです。"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1257(para)
msgid ""
"To ensure that important services have written their contents to disk (such "
"as databases), we recommend that you read the documentation for those "
"applications to determine what commands to issue to have them sync their "
"contents to disk. If you are unsure how to do this, the safest approach is "
"to simply stop these running services normally."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1264(para)
msgid ""
"To deal with the \"dirty\" buffer issue, we recommend using the sync command"
" before snapshotting:"
msgstr "「ダーティー」バッファーの問題を解決するために、スナップショットの前に sync コマンドを使用することを推奨します。"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1269(para)
msgid ""
"Running <code>sync</code> writes dirty buffers (buffered blocks that have "
"been modified but not written yet to the disk block) to disk."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1273(para)
msgid ""
"Just running <code>sync</code> is not enough to ensure that the file system "
"is consistent. We recommend that you use the <code>fsfreeze</code> tool, "
"which halts new access to the file system, and create a stable image on disk"
" that is suitable for snapshotting. The <code>fsfreeze</code> tool supports "
"several file systems, including ext3, ext4, and XFS. If your virtual machine"
" instance is running on Ubuntu, install the util-linux package to get "
"<literal>fsfreeze</literal>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1284(para)
msgid ""
"If your operating system doesn't have a version of "
"<literal>fsfreeze</literal> available, you can use "
"<literal>xfs_freeze</literal> instead, which is available on Ubuntu in the "
"xfsprogs package. Despite the \"xfs\" in the name, xfs_freeze also works on "
"ext3 and ext4 if you are using a Linux kernel version 2.6.29 or greater, "
"since it works at the virtual file system (VFS) level starting at 2.6.29. "
"The xfs_freeze version supports the same command-line arguments as "
"<literal>fsfreeze</literal>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1293(para)
msgid ""
"Consider the example where you want to take a snapshot of a persistent block"
" storage volume, detected by the guest operating system as "
"<literal>/dev/vdb</literal> and mounted on <literal>/mnt</literal>. The "
"fsfreeze command accepts two arguments:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1301(term)
msgid "-f"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1304(para)
msgid "Freeze the system"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1309(term)
msgid "-u"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1312(para)
msgid "Thaw (unfreeze) the system"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1317(para)
msgid ""
"To freeze the volume in preparation for snapshotting, you would do the "
"following, as root, inside the instance:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1322(para)
msgid ""
"You <emphasis>must mount the file system</emphasis> before you run the "
"<literal>fsfreeze</literal> command."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1325(para)
msgid ""
"When the <literal>fsfreeze -f</literal> command is issued, all ongoing "
"transactions in the file system are allowed to complete, new write system "
"calls are halted, and other calls that modify the file system are halted. "
"Most importantly, all dirty data, metadata, and log information are written "
"to disk."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1331(para)
msgid ""
"Once the volume has been frozen, do not attempt to read from or write to the"
" volume, as these operations hang. The operating system stops every I/O "
"operation and any I/O attempts are delayed until the file system has been "
"unfrozen."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1336(para)
msgid ""
"Once you have issued the <literal>fsfreeze</literal> command, it is safe to "
"perform the snapshot. For example, if your instance was named <literal>mon-"
"instance</literal> and you wanted to snapshot it to an image named <literal"
">mon-snapshot</literal>, you could now run the following:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1344(para)
msgid ""
"When the snapshot is done, you can thaw the file system with the following "
"command, as root, inside of the instance:"
msgstr "スナップショットの作成が終わったら、インスタンスの中で root として以下のコマンドを用いて、ファイルシステムをフリーズ解除できます。"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1349(para)
msgid ""
"If you want to back up the root file system, you can't simply run the "
"preceding command because it will freeze the prompt. Instead, run the "
"following one-liner, as root, inside the instance:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1361(title)
msgid "Instances in the Database"
msgstr "データベースにあるインスタンス"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1363(para)
msgid ""
"While instance information is stored in a number of database tables, the "
"table you most likely need to look at in relation to user instances is the "
"instances table.<indexterm "
"class=\"singular\"><primary>instances</primary><secondary>database "
"information</secondary></indexterm><indexterm "
"class=\"singular\"><primary>databases</primary><secondary>instance "
"information in</secondary></indexterm><indexterm "
"class=\"singular\"><primary>user "
"training</primary><secondary>instances</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1379(para)
msgid ""
"The instances table carries most of the information related to both running "
"and deleted instances. It has a bewildering array of fields; for an "
"exhaustive list, look at the database. These are the most useful fields for "
"operators looking to form queries:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1386(para)
msgid ""
"The <literal>deleted</literal> field is set to <literal>1</literal> if the "
"instance has been deleted and <literal>NULL</literal> if it has not been "
"deleted. This field is important for excluding deleted instances from your "
"queries."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1393(para)
msgid ""
"The <literal>uuid</literal> field is the UUID of the instance and is used "
"throughout other tables in the database as a foreign key. This ID is also "
"reported in logs, the dashboard, and command-line tools to uniquely identify"
" an instance."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1400(para)
msgid ""
"A collection of foreign keys are available to find relations to the "
"instance. The most useful of these—<literal>user_id</literal> and "
"<literal>project_id</literal>—are the UUIDs of the user who launched the "
"instance and the project it was launched in."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1407(para)
msgid ""
"The <literal>host</literal> field tells which compute node is hosting the "
"instance."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1412(para)
msgid ""
"The <literal>hostname</literal> field holds the name of the instance when it"
" is launched. The display-name is initially the same as hostname but can be "
"reset using the nova rename command."
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1418(para)
msgid ""
"A number of time-related fields are useful for tracking when state changes "
"happened on an instance:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1423(literal)
msgid "created_at"
msgstr "created_at"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1427(literal)
msgid "updated_at"
msgstr "updated_at"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1431(literal)
msgid "deleted_at"
msgstr "deleted_at"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1435(literal)
msgid "scheduled_at"
msgstr "scheduled_at"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1439(literal)
msgid "launched_at"
msgstr "launched_at"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1443(literal)
msgid "terminated_at"
msgstr "terminated_at"

#: ./doc/openstack-ops/ch_ops_user_facing.xml1449(title)
msgid "Good Luck!"
msgstr ""

#: ./doc/openstack-ops/ch_ops_user_facing.xml1451(para)
msgid ""
"This section was intended as a brief introduction to some of the most useful"
" of many OpenStack commands. For an exhaustive list, please refer to the "
"<link href=\"http://docs.openstack.org/user-guide-admin/content/\">Admin "
"User Guide</link>, and for additional hints and tips, see the <link "
"href=\"http://docs.openstack.org/admin-guide-cloud/content/\">Cloud Admin "
"Guide</link>. We hope your users remain happy and recognize your hard work! "
"(For more hard work, turn the page to the next chapter, where we discuss the"
" system-facing operations: maintenance, failures and debugging.)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml10(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml160(title)
msgid "Upgrades"
msgstr "アップグレード"

#: ./doc/openstack-ops/ch_ops_upgrades.xml12(para)
msgid ""
"With the exception of Object Storage, upgrading from one version of "
"OpenStack to another can take a great deal of effort. Until the situation "
"improves, this chapter provides some guidance on the operational aspects "
"that you should consider for performing an upgrade based on detailed steps "
"for a basic architecture."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml20(title)
msgid "Pre-Upgrade Testing Environment"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml22(para)
msgid ""
"The most important step is the pre-upgrade testing. If you are upgrading "
"immediately after release of a new version, undiscovered bugs might hinder "
"your progress. Some deployers prefer to wait until the first point release "
"is announced. However, if you have a significant deployment, you might "
"follow the development and testing of the release to ensure that bugs for "
"your use cases are fixed.<indexterm "
"class=\"singular\"><primary>upgrading</primary><secondary>pre-upgrade "
"testing</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml33(para)
msgid ""
"Even if you have what seems to be a near-identical architecture as the one "
"described in this guide, each OpenStack cloud is different. As a result, you"
" must still test upgrades between versions in your environment. For this, "
"you need an approximate clone of your environment."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml39(para)
msgid ""
"However, that is not to say that it needs to be the same size or use "
"identical hardware as the production environment—few of us have that luxury."
" It is important to consider the hardware and scale of the cloud that you "
"are upgrading, but these tips can help you avoid that incredible "
"cost:<indexterm "
"class=\"singular\"><primary>upgrading</primary><secondary>controlling cost "
"of</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml51(term)
msgid "Use your own cloud"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml54(para)
msgid ""
"The simplest place to start testing the next version of OpenStack is by "
"setting up a new environment inside your own cloud. This might seem "
"odd—especially the double virtualization used in running compute nodes—but "
"it's a sure way to very quickly test your configuration."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml63(term)
msgid "Use a public cloud"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml66(para)
msgid ""
"Especially because your own cloud is unlikely to have sufficient space to "
"scale test to the level of the entire cloud, consider using a public cloud "
"to test the scalability limits of your cloud controller configuration. Most "
"public clouds bill by the hour, which means it can be inexpensive to perform"
" even a test with many nodes.<indexterm class=\"singular\"><primary>cloud "
"controllers</primary><secondary>scalability and</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml80(term)
msgid "Make another storage endpoint on the same system"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml83(para)
msgid ""
"If you use an external storage plug-in or shared file system with your "
"cloud, in many cases, you can test whether it works by creating a second "
"share or endpoint. This action enables you to test the system before "
"entrusting the new version onto your storage."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml92(term)
msgid "Watch the network"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml95(para)
msgid ""
"Even at smaller-scale testing, look for excess network packets to determine "
"whether something is going horribly wrong in inter-component communication."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml102(para)
msgid "To set up the test environment, you can use one of several methods:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml109(para)
msgid ""
"Do a full manual install by using the <link "
"href=\"http://docs.openstack.org/\"><citetitle>OpenStack Installation "
"Guide</citetitle></link> for your platform. Review the final configuration "
"files and installed packages."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml116(para)
msgid ""
"Create a clone of your automated configuration infrastructure with changed "
"package repository URLs."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml118(para)
msgid "Alter the configuration until it works."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml121(para)
msgid ""
"Either approach is valid. Use the approach that matches your experience."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml123(para)
msgid ""
"An upgrade pre-testing system is excellent for getting the configuration to "
"work; however, it is important to note that the historical use of the system"
" and differences in user interaction can affect the success of upgrades, "
"too. We've seen experiences where database migrations encountered a bug "
"(later fixed!) because of slight table differences between fresh Grizzly "
"installs and those that migrated from Folsom to Grizzly."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml131(para)
msgid ""
"Artificial scale testing can go only so far. After your cloud is upgraded, "
"you must pay careful attention to the performance aspects of your cloud."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml137(title)
msgid "Preparing for a Rollback"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml139(para)
msgid ""
"Like all major system upgrades, your upgrade could fail for one or more "
"difficult-to-determine reasons. You should prepare for this situation by "
"leaving the ability to roll back your environment to the previous release, "
"including databases, configuration files, and packages. We provide an "
"example process for rolling back your environment in <xref linkend"
"=\"ops_upgrades-roll-back\"/>.<indexterm "
"class=\"singular\"><primary>upgrading</primary><secondary>process "
"overview</secondary></indexterm><indexterm "
"class=\"singular\"><primary>rollbacks</primary><secondary>preparing "
"for</secondary></indexterm><indexterm "
"class=\"singular\"><primary>upgrading</primary><secondary>preparation "
"for</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml162(para)
msgid "The upgrade process generally follows these steps:"
msgstr "一般的に、アップグレード作業は以下の手順で行います。"

#: ./doc/openstack-ops/ch_ops_upgrades.xml166(para)
msgid ""
"Perform some \"cleaning\" of the environment prior to starting the upgrade "
"process to ensure a consistent state. For example, instances not fully "
"purged from the system after deletion might cause indeterminate behavior."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml173(para)
msgid "Read the release notes and documentation."
msgstr "リリースノートとドキュメントを読みます。"

#: ./doc/openstack-ops/ch_ops_upgrades.xml177(para)
msgid "Find incompatibilities between your versions."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml181(para)
msgid ""
"Develop an upgrade procedure and assess it thoroughly by using a test "
"environment similar to your production environment."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml187(para)
msgid "Run the upgrade procedure on the production environment."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml192(para)
msgid ""
"You can perform an upgrade with operational instances, but this strategy can"
" be dangerous. You might consider using live migration to temporarily "
"relocate instances to other compute nodes while performing upgrades. "
"However, you must ensure database consistency throughout the process; "
"otherwise your environment might become unstable. Also, don't forget to "
"provide sufficient notice to your users, including giving them plenty of "
"time to perform their own backups."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml201(para)
msgid "The following order for service upgrades seems the most successful:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml206(para)
msgid "Upgrade the OpenStack Identity Service (keystone)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml211(para)
msgid "Upgrade the OpenStack Image Service (glance)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml215(para)
msgid "Upgrade OpenStack Compute (nova), including networking components."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml220(para)
msgid "Upgrade OpenStack Block Storage (cinder)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml224(para)
msgid "Upgrade the OpenStack dashboard."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml228(para)
msgid "The general upgrade process includes the following steps:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml233(para)
msgid "Create a backup of configuration files and databases."
msgstr "設定ファイルとデータベースのバックアップを作成します。"

#: ./doc/openstack-ops/ch_ops_upgrades.xml238(para)
msgid "Update the configuration files according to the release notes."
msgstr "リリースノートに従って設定ファイルを更新します。"

#: ./doc/openstack-ops/ch_ops_upgrades.xml243(para)
msgid "Upgrade the packages by using your distribution's package manager."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml248(para)
msgid "Stop services, update database schemas, and restart services."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml253(para)
msgid "Verify proper operation of your environment."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml259(title)
msgid "Upgrade Levels"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml260(para)
msgid ""
"Upgrade levels are a feature added to OpenStack Compute in the Grizzly "
"release to provide version locking on the RPC (Message Queue) communications"
" between the various Compute services."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml264(para)
msgid ""
"This functionality is an important piece of the puzzle when it comes to live"
" upgrades and is conceptually similar to the existing API versioning that "
"allows OpenStack services of different versions to communicate without "
"issue, for example Grizzly Compute can still make Grizzly Identity API calls"
" even if Identity is running Icehouse."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml270(para)
msgid ""
"Without upgrade levels, an X+1 version Compute service can receive and "
"understand X version RPC messages, but it can only send out X+1 version RPC "
"messages. For example, if a <systemitem class=\"service\">nova-"
"conductor</systemitem> process has been upgraded to Icehouse, then the "
"conductor service will be able to understand messages from Havana "
"<systemitem class=\"service\">nova-compute</systemitem> processes, but those"
" compute services will not be able to understand messages sent by the "
"conductor service."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml279(para)
msgid ""
"During an upgrade, operators can add configuration options to "
"<filename>nova.conf</filename> which lock the version of RPC messages and "
"allow live upgrading of the services without interruption caused by version "
"mismatch. The configuration options allow the specification of RPC version "
"numbers if desired, but release name alias are also supported. For example:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml289(para)
msgid ""
"will keep the RPC version locked across the specified services to the RPC "
"version used in Havana. As all instances of a particular service are "
"upgraded to the newer version, the corresponding line can be removed from "
"<filename>nova.conf</filename>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml293(para)
msgid ""
"Using this functionality, ideally one would lock the RPC version to the "
"OpenStack version being upgraded from on <systemitem class=\"service\">nova-"
"compute</systemitem> nodes, to ensure that, for example Havana <systemitem "
"class=\"service\">nova-compute</systemitem> processes will continue to work "
"with Grizzly <systemitem class=\"service\">nova-conductor</systemitem> "
"processes while the upgrade completes. Once the upgrade of <systemitem "
"class=\"service\">nova-compute</systemitem> processes is complete, the "
"operator can move onto upgrading <systemitem class=\"service\">nova-"
"conductor</systemitem> and remove the version locking for <systemitem "
"class=\"service\">nova-compute</systemitem> in "
"<filename>nova.conf</filename>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml311(title)
msgid "How to Perform an Upgrade from Grizzly to Havana—Ubuntu"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml316(para)
msgid ""
"For this section, we assume that you are starting with the architecture "
"provided in the OpenStack <link href=\"http://docs.openstack.org/havana"
"/install-guide/install/apt/content/\"><citetitle>OpenStack Installation "
"Guide</citetitle></link> and upgrading to the same architecture for Havana. "
"All nodes should run Ubuntu 12.04 LTS. This section primarily addresses "
"upgrading core OpenStack services, such as the Identity Service (keystone), "
"Image Service (glance), Compute (nova) including networking, Block Storage "
"(cinder), and the dashboard.<indexterm class=\"startofrange\" "
"xml:id=\"UPubuntu\"><primary>upgrading</primary><secondary>Grizzly to Havana"
" (Ubuntu)</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml331(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml702(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1081(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1519(title)
msgid "Impact on Users"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml333(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml704(para)
msgid ""
"The upgrade process interrupts management of your environment, including the"
" dashboard. If you properly prepare for this upgrade, tenant instances "
"continue to operate normally."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml340(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml711(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1090(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1528(title)
msgid "Upgrade Considerations"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml342(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml713(para)
msgid ""
"Always review the <link "
"href=\"https://wiki.openstack.org/wiki/ReleaseNotes/Havana\">release "
"notes</link> before performing an upgrade to learn about newly available "
"features that you might want to enable and deprecated features that you "
"should disable."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml350(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml721(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1098(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1536(title)
msgid "Perform a Backup"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml352(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1537(para)
msgid "Save the configuration files on all nodes, as shown here:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml361(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml731(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1107(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1546(para)
msgid ""
"You can modify this example script on each node to handle different "
"services."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml365(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1110(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1549(para)
msgid "Back up all databases on the controller:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml372(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml742(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1123(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1562(title)
msgid "Manage Repositories"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml374(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml744(para)
msgid ""
"On all nodes, remove the repository for Grizzly packages and add the "
"repository for Havana packages:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml381(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml752(para)
msgid "Make sure any automatic updates are disabled."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml386(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml763(title)
msgid "Update Configuration Files"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml388(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml765(para)
msgid ""
"Update the glance configuration on the controller node for compatibility "
"with <phrase role=\"keep-together\">Havana</phrase>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml392(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml769(para)
msgid ""
"Add or modify the following keys in the <filename>/etc/glance/glance-"
"api.conf</filename> and <filename>/etc/glance/glance-"
"registry.conf</filename> files:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml407(para)
msgid ""
"If currently present, remove the following key from the "
"<literal>[filter:authtoken]</literal> section in the <filename>/etc/glance"
"/glance-api-paste.ini</filename> and <filename>/etc/glance/glance-registry-"
"paste.ini</filename> files:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml416(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml809(para)
msgid ""
"Update the nova configuration on all nodes for compatibility with Havana."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml419(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml812(para)
msgid ""
"Add the <literal>[database]</literal> section and associated key to the "
"<filename>/etc/nova/nova.conf</filename> file:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml426(para)
msgid ""
"Remove defunct configuration from the <literal>[DEFAULT]</literal> section "
"in the <filename>/etc/nova/nova.conf</filename> file:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml433(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml824(para)
msgid ""
"Add or modify the following keys in the "
"<filename>/etc/nova/nova.conf</filename> file:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml445(para)
msgid ""
"On all compute nodes, increase the DHCP lease time (measured in seconds) in "
"the <filename>/etc/nova/nova.conf</filename> file to enable currently active"
" instances to continue leasing their IP addresses during the upgrade "
"process:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml456(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml848(para)
msgid ""
"Setting this value too high might cause more dynamic environments to run out"
" of available IP addresses. Use an appropriate value for your environment."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml461(para)
msgid ""
"You must restart dnsmasq and the networking component of Compute to enable "
"the new DHCP lease time:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml467(para)
msgid ""
"Update the Cinder configuration on the controller and storage nodes for "
"compatibility with Havana."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml470(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml876(para)
msgid ""
"Add or modify the following key in the "
"<filename>/etc/cinder/cinder.conf</filename> file:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml476(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml882(para)
msgid ""
"Update the dashboard configuration on the controller node for compatibility "
"with Havana."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml479(para)
msgid ""
"The dashboard installation procedure and configuration file changed "
"substantially between Grizzly and Havana. Particularly, if you are running "
"Django 1.5 or later, you must ensure that <filename>/etc/openstack-"
"dashboard/local_settings</filename> contains a correctly configured "
"<option>ALLOWED_HOSTS</option> key that contains a list of host names "
"recognized by the dashboard."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml488(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml894(para)
msgid ""
"If users access your dashboard by using "
"<emphasis>http://dashboard.example.com</emphasis>, define "
"<option>ALLOWED_HOSTS</option>, as follows:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml494(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml900(para)
msgid ""
"If users access your dashboard on the local system, define "
"<option>ALLOWED_HOSTS</option>, as follows:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml499(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml905(para)
msgid ""
"If users access your dashboard by using an IP address in addition to a host "
"name, define <option>ALLOWED_HOSTS</option>, as follows:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml507(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml913(title)
msgid "Upgrade Packages on the Controller Node"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml509(para)
msgid "Upgrade packages on the controller node to Havana, as follows:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml516(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1179(para)
msgid ""
"Depending on your specific configuration, performing a <code>dist-"
"upgrade</code> might restart services supplemental to your OpenStack "
"environment. For example, if you use Open-iSCSI for Block Storage volumes "
"and the upgrade includes a new <code>open-scsi</code> package, the package "
"manager restarts Open-iSCSI services, which might cause the volumes for your"
" users to be disconnected."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml525(para)
msgid ""
"The package manager prompts you to update various configuration files. "
"Reject these changes. The package manager appends <filename>.dpkg-"
"dist</filename> to the newer versions of existing configuration files. You "
"should consider adopting conventions associated with the newer configuration"
" files and merging them with your existing configuration files after "
"completing the upgrade process."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml535(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml942(title)
msgid ""
"Stop Services, Update Database Schemas, and Restart Services on the "
"Controller Node"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml538(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml945(para)
msgid ""
"Stop each service, run the database synchronization command if necessary to "
"update the associated database schema, and restart each service to apply the"
" new configuration. Some services require additional commands:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml545(term)
#: ./doc/openstack-ops/ch_ops_upgrades.xml952(term)
msgid "OpenStack Identity"
msgstr "OpenStack Identity"

#: ./doc/openstack-ops/ch_ops_upgrades.xml556(term)
#: ./doc/openstack-ops/ch_ops_upgrades.xml963(term)
msgid "OpenStack Image Service"
msgstr "OpenStack Image Service"

#: ./doc/openstack-ops/ch_ops_upgrades.xml568(term)
#: ./doc/openstack-ops/ch_ops_upgrades.xml975(term)
msgid "OpenStack Compute"
msgstr "OpenStack Compute"

#: ./doc/openstack-ops/ch_ops_upgrades.xml588(term)
#: ./doc/openstack-ops/ch_ops_upgrades.xml995(term)
msgid "OpenStack Block Storage"
msgstr "OpenStack Block Storage"

#: ./doc/openstack-ops/ch_ops_upgrades.xml600(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1007(para)
msgid ""
"The controller node update is complete. Now you can upgrade the compute "
"nodes."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml605(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1012(title)
msgid "Upgrade Packages and Restart Services on the Compute Nodes"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml608(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1015(para)
msgid "Upgrade packages on the compute nodes to Havana:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml614(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml660(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1020(para)
msgid ""
"Make sure you have removed the repository for Grizzly packages and added the"
" repository for Havana packages."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml620(para)
msgid ""
"Due to a packaging issue, this command might fail with the following error:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml632(para)
msgid "Fix this issue by running this command:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml637(para)
msgid ""
"The packaging system prompts you to update the <filename>/etc/nova/api-"
"paste.ini</filename> file. As with the controller upgrade, we recommend that"
" you reject these changes and review the <filename>.dpkg-dist</filename> "
"file after the upgrade process completes."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml643(para)
msgid "To restart compute services:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml651(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1038(title)
msgid "Upgrade Packages and Restart Services on the Block Storage Nodes"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml654(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1041(para)
msgid "Upgrade packages on the storage nodes to Havana:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml665(para)
msgid ""
"The packaging system prompts you to update the <filename>/etc/cinder/api-"
"paste.ini</filename> file. Like the controller upgrade, reject these changes"
" and review the <filename>.dpkg-dist</filename> file after the the upgrade "
"process completes."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml673(para)
msgid ""
"To restart Block Storage services:<indexterm class=\"endofrange\" "
"startref=\"UPubuntu\"/>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml681(title)
msgid ""
"How to Perform an Upgrade from Grizzly to Havana—Red Hat Enterprise Linux "
"and Derivatives"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml686(para)
msgid ""
"For this section, we assume that you are starting with the architecture "
"provided in the OpenStack <link href=\"http://docs.openstack.org/havana"
"/install-guide/install/yum/content/\"><citetitle>OpenStack Installation "
"Guide</citetitle></link> and upgrading to the same architecture for Havana. "
"All nodes should run Red Hat Enterprise Linux 6.4 or compatible derivatives."
" Newer minor releases should also work. This section primarily addresses "
"upgrading core OpenStack services, such as the Identity Service (keystone), "
"Image Service (glance), Compute (nova) including networking, Block Storage "
"(cinder), and the dashboard.<indexterm class=\"startofrange\" "
"xml:id=\"UPredhat\"><primary>upgrading</primary><secondary>Grizzly to Havana"
" (Red Hat)</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml723(para)
msgid "First, save the configuration files on all nodes:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml735(para)
msgid "Next, back up all databases on the controller:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml756(para)
msgid ""
"Consider checking for newer versions of the <link "
"href=\"https://repos.fedorapeople.org/repos/openstack/openstack-"
"havana/\">Havana repository</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml800(para)
msgid ""
"If currently present, remove the following key from the [filter:authtoken] "
"section in the <filename>/etc/glance/glance-api-paste.ini</filename> and "
"<filename>/etc/glance/glance-registry-paste.ini</filename> files:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml819(para)
msgid ""
"Remove defunct database configuration from the "
"<filename>/etc/nova/nova.conf</filename> file:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml838(para)
msgid ""
"On all compute nodes, increase the DHCP lease time (measured in seconds) in "
"the <filename>/etc/nova/nova.conf</filename> file to enable currently active"
" instances to continue leasing their IP addresses during the upgrade "
"process, as follows:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml855(para)
msgid ""
"You must restart dnsmasq and the nova networking service to enable the new "
"DHCP lease time:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml861(para)
msgid ""
"Update the cinder configuration on the controller and storage nodes for "
"compatibility with Havana."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml864(para)
msgid ""
"Add the <literal>[database]</literal> section and associated key to the "
"<filename>/etc/cinder/cinder.conf</filename> file:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml871(para)
msgid ""
"Remove defunct database configuration from the "
"<filename>/etc/cinder/cinder.conf</filename> file:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml885(para)
msgid ""
"The dashboard installation procedure and configuration file changed "
"substantially between Grizzly and Havana. Particularly, if you are running "
"Django 1.5 or later, you must ensure that the <filename>/etc/openstack-"
"dashboard/local_settings</filename> file contains a correctly configured "
"<option>ALLOWED_HOSTS</option> key that contains a list of host names "
"recognized by the dashboard."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml915(para)
msgid "Upgrade packages on the controller node to Havana:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml920(para)
msgid ""
"Some services might terminate with an error during the package upgrade "
"process. If this error might cause a problem with your environment, consider"
" stopping all services before upgrading them to Havana."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml926(para)
msgid "Install the OpenStack SELinux package on the controller node:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml932(para)
msgid ""
"The package manager appends <filename>.rpmnew</filename> to the end of newer"
" versions of existing configuration files. You should consider adopting "
"conventions associated with the newer configuration files and merging them "
"with your existing configuration files after completing the upgrade process."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1025(para)
msgid "Install the OpenStack SELinux package on the compute nodes:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1030(para)
msgid "Restart compute services:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1046(para)
msgid ""
"Make sure you have removed the repository for Grizzly packages and added the"
" repository for Havana packages.<indexterm class=\"endofrange\" "
"startref=\"UPredhat\"/>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1052(para)
msgid "Install the OpenStack SELinux package on the storage nodes:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1057(para)
msgid "Restart Block Storage services:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1063(title)
msgid "How to Perform an Upgrade from Havana to Icehouse—Ubuntu"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1066(para)
msgid ""
"For this section, we assume that you are starting with the architecture "
"provided in the <link href=\"http://docs.openstack.org/havana/install-"
"guide/install/apt/content/\"><citetitle>OpenStack Installation "
"Guide</citetitle></link> and upgrading to the same architecture for "
"Icehouse. All nodes should run Ubuntu 12.04 LTS with Linux kernel 3.11 and "
"the latest Havana packages installed and operational. This section primarily"
" addresses upgrading core OpenStack services such as Identity (keystone), "
"Image Service (glance), Compute (nova), Networking (neutron), Block Storage "
"(cinder), and the dashboard. The Networking upgrade includes conversion from"
" the Open vSwitch (OVS) plug-in to the Modular Layer 2 (M2) plug-in. This "
"section does not cover the upgrade process from Ubuntu 12.04 LTS to Ubuntu "
"14.04 LTS."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1082(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1520(para)
msgid ""
"The upgrade process interrupts management of your environment, including the"
" dashboard. If you properly prepare for this upgrade, tenant instances "
"continue to operate normally. However, instances might experience "
"intermittent network interruptions while the Networking service rebuilds "
"virtual networking infrastructure."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1091(para)
msgid ""
"Always review the <link "
"href=\"https://wiki.openstack.org/wiki/ReleaseNotes/Icehouse\">Icehouse "
"Release Notes</link> before you upgrade to learn about newly available "
"features that you might want to enable and deprecated features that you "
"should disable."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1099(para)
msgid "Save the configuration files on all nodes:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1113(para)
msgid ""
"Although not necessary, you should consider updating your MySQL server "
"configuration as described in the <link "
"href=\"http://docs.openstack.org/icehouse/install-guide/install/apt/content"
"/basics-database-controller.html\">MySQL controller setup</link> section of "
"the <link href=\"http://docs.openstack.org/icehouse/install-"
"guide/install/apt/content/\"><citetitle>OpenStack Installation "
"Guide</citetitle></link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1124(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1563(para)
msgid ""
"On all nodes, remove the repository for Havana packages and add the "
"repository for Icehouse packages:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1129(para)
msgid ""
"Disable any <link href=\"https://help.ubuntu.com/12.04/serverguide"
"/automatic-updates.html\">automatic package updates</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1135(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1578(title)
msgid "Upgrade Notes"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1138(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1581(para)
msgid "Disable Compute file injection:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1139(para)
msgid ""
"Icehouse disables file injection by default per the <link "
"href=\"https://wiki.openstack.org/wiki/ReleaseNotes/Icehouse\">Icehouse "
"Release Notes</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1143(para)
msgid ""
"If you plan to deploy Icehouse in stages, you must disable file injection on"
" all compute nodes that remain on Havana."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1146(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1589(para)
msgid "Edit the <filename>/etc/nova/nova-compute.conf</filename> file:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1154(para)
msgid "Convert from the OVS plug-in to the ML2 plug-in:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1156(para)
msgid ""
"You must convert the configuration for your environment contained in the "
"<filename>/etc/neutron/neutron.conf</filename> and "
"<filename>/etc/neutron/plugins/openvswitch/ovs_neutron_plugin.ini</filename>"
" files from OVS to ML2. For example, the <link "
"href=\"http://docs.openstack.org/icehouse/install-"
"guide/install/apt/content/\"><citetitle>OpenStack Installation "
"Guide</citetitle></link> covers <link "
"href=\"http://docs.openstack.org/icehouse/install-guide/install/apt/content"
"/section_neutron-networking-ml2.html\">ML2 plug-in configuration</link> "
"using GRE tunnels."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1167(para)
msgid ""
"Keep the OVS plug-in packages and configuration files until you verify the "
"upgrade."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1173(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1615(title)
msgid "Upgrade the Controller Node"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1174(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1616(para)
msgid "Upgrade packages on the controller node to Icehouse, as follows:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1187(para)
msgid ""
"The package manager prompts you to update various configuration files. "
"Reject these changes. The package manager appends <filename>.dpkg-"
"dist</filename> to the newer versions of existing configuration files. You "
"should consider adopting conventions associated with the newer configuration"
" files and merging them with your existing configuration files after "
"completing the upgrade process. You can find newer versions of existing "
"configuration files with the following command:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1199(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1631(title)
msgid "Upgrade Each Service"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1200(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1632(para)
msgid ""
"The upgrade procedure for each service typically requires that you stop the "
"service, run the database synchronization command to update the associated "
"database, and start the service to apply the new configuration. You need "
"administrator privileges for these procedures. Some services require "
"additional steps."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1208(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1640(para)
msgid "OpenStack Identity:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1209(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1641(para)
msgid "Update the configuration file for compatibility with Icehouse."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1211(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1643(para)
msgid "Edit the <filename>/etc/keystone/keystone.conf</filename> file:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1214(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1252(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1646(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1684(para)
msgid "Add the <literal>[database]</literal> section."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1215(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1647(para)
msgid ""
"Move the <option>connection</option> key from the <literal>[sql]</literal> "
"section to the <literal>[database]</literal> section."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1218(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1293(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1404(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1650(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1721(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1838(para)
msgid "Stop services, upgrade the database, and start services."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1226(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1658(para)
msgid "OpenStack Image Service:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1227(para)
msgid ""
"Before upgrading the Image Service database, you must convert the character "
"set for each table to UTF-8."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1229(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1313(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1741(para)
msgid "Use the MySQL client to execute the following commands:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1242(para)
msgid ""
"Your environment might contain different or additional tables that you must "
"also convert to UTF-8 by using similar commands."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1246(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1279(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1416(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1678(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1707(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1850(para)
msgid "Update the configuration for compatibility with Icehouse."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1248(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1680(para)
msgid ""
"Edit the <filename>/etc/glance/glance-api.conf</filename> and "
"<filename>/etc/glance/glance-registry.conf</filename> files:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1253(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1685(para)
msgid ""
"Rename the <option>sql_connection</option> key to "
"<option>connection</option> and move it to the <literal>[database]</literal>"
" section."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1256(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1688(para)
msgid "Edit the <filename>/etc/glance/glance-api.conf</filename> file:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1259(para)
msgid ""
"Add RabbitMQ message broker keys to the <literal>[DEFAULT]</literal> "
"section."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1261(para)
msgid ""
"Replace <replaceable>RABBIT_PASS</replaceable> with the password you chose "
"for the <literal>guest</literal> account in "
"<application>RabbitMQ</application>."
msgstr "<replaceable>RABBIT_PASS</replaceable> を <application>RabbitMQ</application> の <literal>guest</literal> アカウント用に選んだパスワードで置き換えます。"

#: ./doc/openstack-ops/ch_ops_upgrades.xml1267(replaceable)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1393(replaceable)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1397(replaceable)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1696(replaceable)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1827(replaceable)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1831(replaceable)
msgid "controller"
msgstr "controller"

#: ./doc/openstack-ops/ch_ops_upgrades.xml1268(replaceable)
msgid "RABBIT_PASS"
msgstr "RABBIT_PASS"

#: ./doc/openstack-ops/ch_ops_upgrades.xml1269(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1697(para)
msgid "Stop services, upgrade the database, and start services:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1278(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1706(para)
msgid "OpenStack Compute:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1281(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1709(para)
msgid "Edit the <filename>/etc/nova/nova.conf</filename> file:"
msgstr "<filename>/etc/nova/nova.conf</filename> ファイルを編集します。"

#: ./doc/openstack-ops/ch_ops_upgrades.xml1283(para)
msgid ""
"Change the <option>rpc_backend</option> key from "
"<literal>nova.rpc.impl_kombu</literal> to <literal>rabbit</literal>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1286(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1714(para)
msgid "Edit the <filename>/etc/nova/api-paste.ini</filename> file:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1288(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1716(para)
msgid ""
"Comment out or remove any keys in the <literal>[filter:authtoken]</literal> "
"section beneath the <literal>paste.filter_factory = "
"keystoneclient.middleware.auth_token:filter_factory</literal> statement."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1310(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1738(para)
msgid "OpenStack Networking:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1311(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1739(para)
msgid ""
"Before upgrading the Networking database, you must convert the character set"
" for each table to UTF-8."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1350(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1778(para)
msgid ""
"Your environment might use a different database name. Also, it might contain"
" different or additional tables that you must also convert to UTF-8 by using"
" similar commands."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1355(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1785(para)
msgid ""
"Populate the <filename>/etc/neutron/plugins/ml2/ml2_conf.ini</filename> file"
" with the equivalent configuration for your environment. Do not edit the "
"<filename>/etc/neutron/neutron.conf</filename> file until after the "
"conversion steps."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1361(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1795(para)
msgid ""
"Stop services, upgrade the database, and perform the conversion from OVS to "
"ML2."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1363(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1797(para)
msgid ""
"Replace <replaceable>NEUTRON_DBPASS</replaceable> with the password you "
"chose for the database."
msgstr "<replaceable>NEUTRON_PASS</replaceable> をデータベース用に選んだパスワードで置き換えます。"

#: ./doc/openstack-ops/ch_ops_upgrades.xml1366(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1800(para)
msgid ""
"We highly recommend that you perform a database backup prior to executing "
"the following commands as the conversion script cannot roll back."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1377(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1811(para)
msgid ""
"Edit the <filename>/etc/neutron/neutron.conf</filename> file to use the ML2 "
"plug-in and enable network change notifications:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1381(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1815(para)
msgid ""
"Replace <replaceable>SERVICE_TENANT_ID</replaceable> with the service tenant"
" identifier (id) in the Identity service and "
"<replaceable>NOVA_PASS</replaceable> with the password you chose for the "
"<literal>nova</literal> user in the Identity service."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1395(replaceable)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1829(replaceable)
msgid "SERVICE_TENANT_ID"
msgstr "SERVICE_TENANT_ID"

#: ./doc/openstack-ops/ch_ops_upgrades.xml1396(replaceable)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1830(replaceable)
msgid "NOVA_PASS"
msgstr "NOVA_PASS"

#: ./doc/openstack-ops/ch_ops_upgrades.xml1399(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1833(para)
msgid "Start Networking services."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1403(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1837(para)
msgid "OpenStack Block Storage:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1415(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1849(para)
msgid "Dashboard:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1418(para)
msgid ""
"Edit the <filename>/etc/openstack-dashboard/local_settings.py</filename> "
"file:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1421(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1855(para)
msgid ""
"Change the <option>OPENSTACK_KEYSTONE_DEFAULT_ROLE</option> key from "
"<literal>\"Member\"</literal> to <literal>\"_member_\"</literal>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1425(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1859(para)
msgid "Restart Dashboard services."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1429(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1863(para)
msgid ""
"The controller node update is complete. Now you can upgrade the remaining "
"nodes."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1433(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1867(title)
msgid "Upgrade the Network Node"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1434(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1868(para)
msgid "Upgrade packages on the network node to Icehouse:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1436(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1463(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1489(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1870(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1901(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1931(para)
msgid ""
"Make sure you have removed the repository for Havana packages and added the "
"repository for Icehouse packages."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1442(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1469(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1877(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1908(para)
msgid ""
"Edit the <filename>/etc/neutron/neutron.conf</filename> file to use the ML2 "
"plug-in:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1447(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1474(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1882(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1913(para)
msgid ""
"Populate the <filename>/etc/neutron/plugins/ml2/ml2_conf.ini</filename> file"
" with the equivalent configuration for your environment."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1451(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1478(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1889(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1920(para)
msgid "Clean the active OVS configuration:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1453(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1480(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1891(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1922(para)
msgid "Restart Networking services:"
msgstr "Networking サービスを再起動します。"

#: ./doc/openstack-ops/ch_ops_upgrades.xml1460(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1898(title)
msgid "Upgrade the Compute Nodes"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1461(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1899(para)
msgid "Upgrade packages on the compute nodes to Icehouse:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1482(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1924(para)
msgid "Restart Compute services:"
msgstr "Compute サービスを再起動します。"

#: ./doc/openstack-ops/ch_ops_upgrades.xml1486(title)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1928(title)
msgid "Upgrade the Storage Nodes"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1487(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1929(para)
msgid "Upgrade packages on the storage nodes to Icehouse:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1495(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1936(para)
msgid "Restart Block Storage services."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1501(title)
msgid ""
"How to Perform an Upgrade from Havana to Icehouse—Red Hat Enterprise Linux "
"and Derivatives"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1504(para)
msgid ""
"For this section, we assume that you are starting with the architecture "
"provided in the OpenStack <link href=\"http://docs.openstack.org/havana"
"/install-guide/install/yum/content/\"><citetitle>OpenStack Installation "
"Guide</citetitle></link> and upgrading to the same architecture for "
"Icehouse. All nodes should run Red Hat Enterprise Linux 6.5 or compatible "
"derivatives such as CentOS and Scientific Linux with the latest Havana "
"packages installed and operational. This section primarily addresses "
"upgrading core OpenStack services such as Identity (keystone), Image Service"
" (glance), Compute (nova), Networking (neutron), Block Storage (cinder), and"
" the dashboard. The Networking upgrade procedure includes conversion from "
"the Open vSwitch (OVS) plug-in to the Modular Layer 2 (ML2) plug-in."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1529(para)
msgid ""
"Always review the <link "
"href=\"https://wiki.openstack.org/wiki/ReleaseNotes/Icehouse\">release "
"notes</link> before performing an upgrade to learn about newly available "
"features that you might want to enable and deprecated features that you "
"should disable."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1552(para)
msgid ""
"You must update your MySQL server configuration and restart the service as "
"described in the <link href=\"http://docs.openstack.org/icehouse/install-"
"guide/install/yum/content/basics-database-controller.html\">MySQL controller"
" setup</link> section of the <link href=\"http://docs.openstack.org/icehouse"
"/install-guide/install/yum/content/\"><citetitle>OpenStack Installation "
"Guide</citetitle></link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1569(para)
msgid "Disable any automatic package updates."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1572(para)
msgid ""
"Consider checking for newer versions of the <link "
"href=\"http://repos.fedorapeople.org/repos/openstack/openstack-"
"icehouse/\">Icehouse repository</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1582(para)
msgid ""
"Icehouse disables file injection by default per the <link "
"href=\"https://wiki.openstack.org/wiki/ReleaseNotes/Icehouse\">release "
"notes</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1586(para)
msgid ""
"If you plan to deploy Icehouse in stages, you must disable file injection on"
" all compute nodes that will remain on Havana."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1597(para)
msgid "Convert from OVS to ML2 plug-in:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1598(para)
msgid ""
"You must convert the configuration for your environment contained in the "
"<filename>/etc/neutron/neutron.conf</filename> and "
"<filename>/etc/neutron/plugins/openvswitch/ovs_neutron_plugin.ini</filename>"
" files from OVS to ML2. For example, the <link "
"href=\"http://docs.openstack.org/icehouse/install-"
"guide/install/yum/content/\"><citetitle>OpenStack Installation "
"Guide</citetitle></link> covers <link "
"href=\"http://docs.openstack.org/icehouse/install-guide/install/yum/content"
"/section_neutron-networking-ml2.html\">ML2 plug-in configuration</link> "
"using GRE tunnels."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1609(para)
msgid ""
"We recommend keeping the OVS plug-in packages and configuration files until "
"you verify the upgrade."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1620(para)
msgid ""
"The package manager appends <filename>.rpmnew</filename> to the end of newer"
" versions of existing configuration files. You should consider adopting "
"conventions associated with the newer configuration files and merging them "
"with your existing configuration files after completing the upgrade process."
" You can find newer versions of existing configuration files with the "
"following command:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1659(para)
msgid ""
"Before you upgrade the Image Service database, convert the character set for"
" each table to UTF-8."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1661(para)
msgid "Use the MySQL client to run the following commands:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1674(para)
msgid ""
"Your environment might contain different or additional tables that you must "
"convert to UTF-8 by using similar commands."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1691(para)
msgid ""
"Add Qpid message broker keys to the <literal>[DEFAULT]</literal> section."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1711(para)
msgid ""
"Change the <option>rpc_backend</option> key from "
"<literal>nova.openstack.common.rpc.impl_qpid</literal> to "
"<literal>qpid</literal>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1783(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1875(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1906(para)
msgid "Install the ML2 plug-in package:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1791(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1886(para)
#: ./doc/openstack-ops/ch_ops_upgrades.xml1917(para)
msgid ""
"Change the <filename>/etc/neutron/plugin.ini</filename> symbolic link to "
"reference <filename>/etc/neutron/plugins/ml2/ml2_conf.ini</filename>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1852(para)
msgid ""
"Edit the <filename>/etc/openstack-dashboard/local_settings</filename> file:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1941(title)
msgid "Cleaning Up and Final Configuration File Updates"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1943(para)
msgid ""
"On all distributions, you must perform some final tasks to complete the "
"upgrade process.<indexterm "
"class=\"singular\"><primary>upgrading</primary><secondary>final "
"steps</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1949(para)
msgid ""
"Decrease DHCP timeouts by modifying <filename>/etc/nova/nova.conf</filename>"
" on the compute nodes back to the original value for your environment."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1953(para)
msgid ""
"Update all <filename>.ini</filename> files to match passwords and pipelines "
"as required for Havana in your environment."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1957(para)
msgid ""
"After a migration, your users see different results from <placeholder-1/> "
"and <placeholder-2/> unless you match policies for access to private images."
" To do so, edit the <filename>/etc/glance/policy.json</filename> and "
"<filename>/etc/nova/policy.json</filename> files to contain "
"<code>\"context_is_admin\": \"role:admin\"</code>, which limits access to "
"private images for projects."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1966(para)
msgid ""
"Thoroughly test the environment. Then, let your users know that their cloud "
"is running normally again."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1971(title)
msgid "Rolling Back a Failed Upgrade"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1973(para)
msgid ""
"Upgrades involve complex operations and can fail. This section provides "
"guidance for rolling back to a previous release of OpenStack. Although only "
"tested on Ubuntu, other distributions follow a similar <phrase role=\"keep-"
"together\">procedure</phrase>.<indexterm "
"class=\"singular\"><primary>rollbacks</primary><secondary>process "
"for</secondary></indexterm><indexterm "
"class=\"singular\"><primary>upgrading</primary><secondary>rolling back "
"failures</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1985(para)
msgid ""
"In this section, we consider only the most immediate case: you have taken "
"down production management services in preparation for an upgrade, completed"
" part of the upgrade process, discovered one or more problems not "
"encountered during testing, and you must roll back your environment to the "
"original \"known good\" state. Make sure that you did not make any state "
"changes after attempting the upgrade process: no new instances, networks, "
"storage volumes, and so on."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1994(para)
msgid ""
"Within this scope, you must complete these steps to successfully roll back "
"your environment:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml1999(para)
msgid "Roll back configuration files."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml2003(para)
msgid "Roll back databases."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml2007(para)
msgid "Roll back packages."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml2011(para)
msgid ""
"The upgrade instructions provided in earlier sections ensure that you have "
"proper backups of your databases and configuration files. Read through this "
"section carefully and verify that you have the requisite backups to restore."
" Rolling back upgrades is a tricky process because distributions tend to put"
" much more effort into testing upgrades than downgrades. Broken downgrades "
"often take significantly more effort to troubleshoot and, hopefully, resolve"
" than broken upgrades. Only you can weigh the risks of trying to push a "
"failed upgrade forward versus rolling it back. Generally, consider rolling "
"back as the very last option."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml2023(para)
msgid ""
"The following steps described for Ubuntu have worked on at least one "
"production environment, but they might not work for all environments."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml2028(title)
msgid "To perform the rollback from Havana to Grizzly"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml2031(para)
msgid "Stop all OpenStack services."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml2035(para)
msgid ""
"Copy contents of configuration backup directories "
"<filename>/etc/&lt;service&gt;.grizzly</filename> that you created during "
"the upgrade process back to <filename>/etc/&lt;service&gt;</filename>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml2042(para)
msgid ""
"Restore databases from the <filename>grizzly-db-backup.sql</filename> backup"
" file that you created with the <placeholder-1/> command during the upgrade "
"process:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml2049(para)
msgid ""
"If you created this backup by using the <option>--add-drop-database</option>"
" flag as instructed, you can proceed to the next step. If you omitted this "
"flag, MySQL reverts all tables that existed in Grizzly, but does not drop "
"any tables created during the database migration for Havana. In this case, "
"you must manually determine which tables to drop, and drop them to prevent "
"issues with your next upgrade <phrase role=\"keep-"
"together\">attempt</phrase>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml2061(para)
msgid "Downgrade OpenStack packages."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml2064(para)
msgid ""
"Downgrading packages is by far the most complicated step; it is highly "
"dependent on the distribution and the overall administration of the system."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml2071(para)
msgid ""
"Determine which OpenStack packages are installed on your system. Use the "
"<placeholder-1/> command. Filter for OpenStack packages, filter again to "
"omit packages explicitly marked in the <code>deinstall</code> state, and "
"save the final output to a file. For example, the following command covers a"
" controller node with keystone, glance, nova, neutron, and cinder:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml2119(para)
msgid ""
"Depending on the type of server, the contents and order of your package list"
" might vary from this example."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml2126(para)
msgid ""
"You can determine the package versions available for reversion by using the "
"<placeholder-1/> command. If you removed the Grizzly repositories, you must "
"first reinstall them and run <placeholder-2/>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml2157(para)
msgid ""
"This tells us the currently installed version of the package, newest "
"candidate version, and all versions along with the repository that contains "
"each version. Look for the appropriate Grizzly "
"version—<code>1:2013.1.4-0ubuntu1~cloud0</code> in this case. The process of"
" manually picking through this list of packages is rather tedious and prone "
"to errors. You should consider using the following script to help with this "
"process:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml2209(para)
msgid ""
"If you decide to continue this step manually, don't forget to change "
"<code>neutron</code> to <code>quantum</code> where applicable."
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml2216(para)
msgid ""
"Use the <placeholder-1/> command to install specific versions of each "
"package by specifying <code>&lt;package-name&gt;=&lt;version&gt;</code>. The"
" script in the previous step conveniently created a list of "
"<code>package=version</code> pairs for you:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_upgrades.xml2225(para)
msgid ""
"This step completes the rollback procedure. You should remove the Havana "
"repository and run <placeholder-1/> to prevent accidental upgrades until you"
" solve whatever issue caused you to roll back your environment."
msgstr ""

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/preface_ops.xml589(None)
msgid ""
"@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc"
"/openstack-ops/figures/osog_00in01.png'; md5=THIS FILE DOESN'T EXIST"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml12(title)
msgid "Preface"
msgstr "はじめに"

#: ./doc/openstack-ops/preface_ops.xml14(para)
msgid ""
"OpenStack is an open source platform that lets you build an Infrastructure "
"as a Service (IaaS) cloud that runs on commodity hardware."
msgstr "OpenStack はオープンソースプラットフォームで、OpenStack を使うと、コモディティハードウェア上で動作する Infrastructure as a Service (IaaS) クラウドを自分で構築できます。"

#: ./doc/openstack-ops/preface_ops.xml19(title)
msgid "Introduction to OpenStack"
msgstr "OpenStack の概要"

#: ./doc/openstack-ops/preface_ops.xml21(para)
msgid ""
"OpenStack believes in open source, open design, open development, all in an "
"open community that encourages participation by anyone. The long-term vision"
" for OpenStack is to produce a ubiquitous open source cloud computing "
"platform that meets the needs of public and private cloud providers "
"regardless of size. OpenStack services control large pools of compute, "
"storage, and networking resources throughout a data center."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml30(para)
msgid ""
"The technology behind OpenStack consists of a series of interrelated "
"projects delivering various components for a cloud infrastructure solution. "
"Each service provides an open API so that all of these resources can be "
"managed through a dashboard that gives administrators control while "
"empowering users to provision resources through a web interface, a command-"
"line client, or software development kits that support the API. Many "
"OpenStack APIs are extensible, meaning you can keep compatibility with a "
"core set of calls while providing access to more resources and innovating "
"through API extensions. The OpenStack project is a global collaboration of "
"developers and cloud computing technologists. The project produces an open "
"standard cloud computing platform for both public and private clouds. By "
"focusing on ease of implementation, massive scalability, a variety of rich "
"features, and tremendous extensibility, the project aims to deliver a "
"practical and reliable cloud solution for all types of organizations."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml50(title)
msgid "Getting Started with OpenStack"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml52(para)
msgid ""
"As an open source project, one of the unique aspects of OpenStack is that it"
" has many different levels at which you can begin to engage with it—you "
"don't have to do everything yourself."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml58(title)
msgid "Using OpenStack"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml60(para)
msgid ""
"You could ask, \"Do I even need to build a cloud?\" If you want to start "
"using a compute or storage service by just swiping your credit card, you can"
" go to eNovance, HP, Rackspace, or other organizations to start using their "
"public OpenStack clouds. Using their OpenStack cloud resources is similar to"
" accessing the publicly available Amazon Web Services Elastic Compute Cloud "
"(EC2) or Simple Storage Solution (S3)."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml71(title)
msgid "Plug and Play OpenStack"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml73(para)
msgid ""
"However, the enticing part of OpenStack might be to build your own private "
"cloud, and there are several ways to accomplish this goal. Perhaps the "
"simplest of all is an appliance-style solution. You purchase an appliance, "
"unpack it, plug in the power and the network, and watch it transform into an"
" OpenStack cloud with minimal additional configuration. Few, if any, other "
"open source cloud products have such turnkey options. If a turnkey solution "
"is interesting to you, take a look at Nebula One."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml82(para)
msgid ""
"However, hardware choice is important for many applications, so if that "
"applies to you, consider that there are several software distributions "
"available that you can run on servers, storage, and network products of your"
" choosing. Canonical (where OpenStack replaced Eucalyptus as the default "
"cloud option in 2011), Red Hat, and SUSE offer enterprise OpenStack "
"solutions and support. You may also want to take a look at some of the "
"specialized distributions, such as those from Rackspace, Piston, SwiftStack,"
" or Cloudscaling."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml91(para)
msgid ""
"Alternatively, if you want someone to help guide you through the decisions "
"about the underlying hardware or your applications, perhaps adding in a few "
"features or integrating components along the way, consider contacting one of"
" the system integrators with OpenStack experience, such as Mirantis or "
"Metacloud."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml97(para)
msgid ""
"If your preference is to build your own OpenStack expertise internally, a "
"good way to kick-start that might be to attend or arrange a training "
"session. The OpenStack Foundation recently launched a <link "
"href=\"http://www.openstack.org/marketplace/training\">Training "
"Marketplace</link> where you can look for nearby events. Also, the OpenStack"
" community is <link href=\"https://wiki.openstack.org/wiki/Training-"
"manuals\">working to produce</link> open source training materials."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml107(title)
msgid "Roll Your Own OpenStack"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml109(para)
msgid ""
"However, this guide has a different audience—those seeking flexibility from "
"the OpenStack framework by conducting do-it-yourself solutions."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml113(para)
msgid ""
"OpenStack is designed for horizontal scalability, so you can easily add new "
"compute, network, and storage resources to grow your cloud over time. In "
"addition to the pervasiveness of massive OpenStack public clouds, many "
"organizations, such as PayPal, Intel, and Comcast, build large-scale private"
" clouds. OpenStack offers much more than a typical software package because "
"it lets you integrate a number of different technologies to construct a "
"cloud. This approach provides great flexibility, but the number of options "
"might be daunting at first."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml126(title)
msgid "Who This Book Is For"
msgstr "この本の対象読者"

#: ./doc/openstack-ops/preface_ops.xml127(para)
msgid ""
"This book is for those of you starting to run OpenStack clouds as well as "
"those of you who were handed an operational one and want to keep it running "
"well. Perhaps you're on a DevOps team, perhaps you are a system "
"administrator starting to dabble in the cloud, or maybe you want to get on "
"the OpenStack cloud team at your company. This book is for all of you."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml133(para)
msgid ""
"This guide assumes that you are familiar with a Linux distribution that "
"supports OpenStack, SQL databases, and virtualization. You must be "
"comfortable administering and configuring multiple Linux machines for "
"networking. You must install and maintain an SQL database and occasionally "
"run queries against it."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml139(para)
msgid ""
"One of the most complex aspects of an OpenStack cloud is the networking "
"configuration. You should be familiar with concepts such as DHCP, Linux "
"bridges, VLANs, and iptables. You must also have access to a network "
"hardware expert who can configure the switches and routers required in your "
"OpenStack cloud."
msgstr "OpenStack クラウドの最も複雑な点の一つにネットワーク設定があります。DHCP、Linux ブリッジ、VLAN、iptables といった考え方をよく理解していなければなりません。OpenStack クラウドで必要となるスイッチやルータを設定できるネットワークハードウェアの専門家と話をする必要もあります。"

#: ./doc/openstack-ops/preface_ops.xml145(para)
msgid ""
"Cloud computing is a quite advanced topic, and this book requires a lot of "
"background knowledge. However, if you are fairly new to cloud computing, we "
"recommend that you make use of the <xref linkend=\"openstack_glossary\"/> at"
" the back of the book, as well as the online documentation for OpenStack and"
" additional resources mentioned in this book in <xref linkend=\"recommended-"
"reading\"/>."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml154(title)
msgid "Further Reading"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml155(para)
msgid ""
"There are other books on the <link "
"href=\"http://docs.openstack.org\">OpenStack documentation website</link> "
"that can help you get the job done."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml160(title)
msgid "OpenStack Guides"
msgstr "OpenStack の各種ガイド"

#: ./doc/openstack-ops/preface_ops.xml162(term)
msgid "OpenStack Installation Guides"
msgstr "OpenStack インストールガイド"

#: ./doc/openstack-ops/preface_ops.xml164(para)
msgid ""
"Describes a manual installation process, as in, by hand, without automation,"
" for multiple distributions based on a packaging system:"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml196(link)
msgid "OpenStack Configuration Reference"
msgstr "OpenStack 設定レファレンス"

#: ./doc/openstack-ops/preface_ops.xml200(para)
msgid ""
"Contains a reference listing of all configuration options for core and "
"integrated OpenStack services by release version"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml211(para)
msgid ""
"Contains how-to information for managing an OpenStack cloud as needed for "
"your use cases, such as storage, computing, or software-defined-networking"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml219(link)
msgid "OpenStack High Availability Guide"
msgstr "OpenStack 高可用性ガイド"

#: ./doc/openstack-ops/preface_ops.xml223(para)
msgid ""
"Describes potential strategies for making your OpenStack services and "
"related controllers and data stores highly available"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml230(link)
msgid "OpenStack Security Guide"
msgstr "OpenStack セキュリティガイド"

#: ./doc/openstack-ops/preface_ops.xml234(para)
msgid ""
"Provides best practices and conceptual information about securing an "
"OpenStack cloud"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml240(link)
msgid "Virtual Machine Image Guide"
msgstr "仮想マシンイメージガイド"

#: ./doc/openstack-ops/preface_ops.xml244(para)
msgid ""
"Shows you how to obtain, create, and modify virtual machine images that are "
"compatible with OpenStack"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml250(link)
msgid "OpenStack End User Guide"
msgstr "OpenStack エンドユーザーガイド"

#: ./doc/openstack-ops/preface_ops.xml254(para)
msgid ""
"Shows OpenStack end users how to create and manage resources in an OpenStack"
" cloud with the OpenStack dashboard and OpenStack client commands"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml261(link)
msgid "OpenStack Admin User Guide"
msgstr "OpenStack 管理ユーザーガイド"

#: ./doc/openstack-ops/preface_ops.xml265(para)
msgid ""
"Shows OpenStack administrators how to create and manage resources in an "
"OpenStack cloud with the OpenStack dashboard and OpenStack client <phrase "
"role=\"keep-together\">commands</phrase>"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml273(link)
msgid "OpenStack API Quick Start"
msgstr "OpenStack API クイックスタート"

#: ./doc/openstack-ops/preface_ops.xml277(para)
msgid ""
"A brief overview of how to send REST API requests to endpoints for OpenStack"
" services"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml286(title)
msgid "How This Book Is Organized"
msgstr "この本の構成"

#: ./doc/openstack-ops/preface_ops.xml288(para)
msgid ""
"This book is organized in two parts: the architecture decisions for "
"designing OpenStack clouds and the repeated operations for running OpenStack"
" clouds."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml292(emphasis)
msgid "Part I:"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml299(para)
msgid ""
"Because of all the decisions the other chapters discuss, this chapter "
"describes the decisions made for this particular book and much of the "
"justification for the example architecture."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml310(para)
msgid ""
"While this book doesn't describe installation, we do recommend automation "
"for deployment and configuration, discussed in this chapter."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml320(para)
msgid ""
"The cloud controller is an invention for the sake of consolidating and "
"describing which services run on which nodes. This chapter discusses "
"hardware and network considerations as well as how to design the cloud "
"controller for performance and separation of services."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml333(para)
msgid ""
"This chapter describes the compute nodes, which are dedicated to running "
"virtual machines. Some hardware choices come into play here, as well as "
"logging and networking descriptions."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml344(para)
msgid ""
"This chapter discusses the growth of your cloud resources through scaling "
"and segregation considerations."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml354(para)
msgid ""
"As with other architecture decisions, storage concepts within OpenStack take"
" a lot of consideration, and this chapter lays out the choices for you."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml364(para)
msgid ""
"Your OpenStack cloud networking needs to fit into your existing networks "
"while also enabling the best design for your users and administrators, and "
"this chapter gives you in-depth information about networking decisions."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml372(emphasis)
msgid "Part II:"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml379(para)
msgid ""
"This chapter is written to let you get your hands wrapped around your "
"OpenStack cloud through command-line tools and understanding what is already"
" set up in your cloud."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml390(para)
msgid ""
"This chapter walks through user-enabling processes that all admins must face"
" to manage users, give them quotas to parcel out resources, and so on."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml400(para)
msgid ""
"This chapter shows you how to use OpenStack cloud resources and train your "
"users as well."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml409(para)
msgid ""
"This chapter goes into the common failures that the authors have seen while "
"running clouds in production, including troubleshooting."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml419(para)
msgid ""
"Because network troubleshooting is especially difficult with virtual "
"resources, this chapter is chock-full of helpful tips and tricks for tracing"
" network traffic, finding the root cause of networking failures, and "
"debugging related services, such as DHCP and DNS."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml432(para)
msgid ""
"This chapter shows you where OpenStack places logs and how to best read and "
"manage logs for monitoring purposes."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml442(para)
msgid ""
"This chapter describes what you need to back up within OpenStack as well as "
"best practices for recovering backups."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml452(para)
msgid ""
"For readers who need to get a specialized feature into OpenStack, this "
"chapter describes how to use DevStack to write custom middleware or a custom"
" scheduler to rebalance your resources."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml463(para)
msgid ""
"Because OpenStack is so, well, open, this chapter is dedicated to helping "
"you navigate the community and find out where you can help and where you can"
" get help."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml473(para)
msgid ""
"Much of OpenStack is driver-oriented, so you can plug in different solutions"
" to the base set of services. This chapter describes some advanced "
"configuration <phrase role=\"keep-together\">topics</phrase>."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml484(para)
msgid ""
"This chapter provides upgrade information based on the architectures used in"
" this book."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml492(emphasis)
msgid "Back matter:"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml499(para)
msgid ""
"You can read a small selection of use cases from the OpenStack community "
"with some technical details and further resources."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml509(para)
msgid ""
"These are shared legendary tales of image disappearances, VM massacres, and "
"crazy troubleshooting techniques to share those hard-learned lessons and "
"<phrase role=\"keep-together\">wisdom</phrase>."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml520(para)
msgid ""
"Read about how to track the OpenStack roadmap through the open and "
"transparent development processes."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml529(para)
msgid ""
"So many OpenStack resources are available online because of the fast-moving "
"nature of the project, but there are also resources listed here that the "
"authors found helpful while learning themselves."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml540(para)
msgid ""
"A list of terms used in this book is included, which is a subset of the "
"larger OpenStack glossary available online."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml549(title)
msgid "Why and How We Wrote This Book"
msgstr "この本をなぜ書いたか？どうやって書いたか？"

#: ./doc/openstack-ops/preface_ops.xml551(para)
msgid ""
"We wrote this book because we have deployed and maintained OpenStack clouds "
"for at least a year, and wanted to be able to distribute this knowledge to "
"others. After months of being the point people for an OpenStack cloud, we "
"also wanted to have a document to hand to our system administrators so that "
"they'd know how to operate the cloud on a daily basis—both reactively and "
"pro-actively. We wanted to provide more detailed technical information about"
" the decisions that deployers make along the way."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml563(para)
msgid ""
"Design and create an architecture for your first nontrivial OpenStack cloud."
" After you read this guide, you'll know which questions to ask and how to "
"organize your compute, networking, and storage resources and the associated "
"software packages."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml571(para)
msgid "Perform the day-to-day tasks required to administer a cloud."
msgstr "クラウドを管理する上で必要となる日々のタスクの実行。"

#: ./doc/openstack-ops/preface_ops.xml561(para)
msgid "We wrote this book to help you:<placeholder-1/>"
msgstr "次のような場面であなたの助けとなるように、この本を書きました。<placeholder-1/>"

#: ./doc/openstack-ops/preface_ops.xml576(para)
msgid ""
"We wrote this book in a book sprint, which is a facilitated, rapid "
"development production method for books. For more information, see the <link"
" href=\"http://www.booksprints.net/\">BookSprints site</link>. Your authors "
"cobbled this book together in five days during February 2013, fueled by "
"caffeine and the best takeout food that Austin, Texas, could <phrase role"
"=\"keep-together\">offer</phrase>."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml584(para)
msgid ""
"On the first day, we filled white boards with colorful sticky notes to start"
" to shape this nebulous book about how to architect and operate "
"clouds:<placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml594(para)
msgid ""
"We wrote furiously from our own experiences and bounced ideas between each "
"other. At regular intervals we reviewed the shape and organization of the "
"book and further molded it, leading to what you see today."
msgstr "私たちは一心不乱に自分たちの経験に基づき執筆を行い、互いに意見をぶつけ合いました。一定の間隔で、本の現在の状況や構成をレビューし、本を作り上げていき、今皆さんが見ているものができあがりました。"

#: ./doc/openstack-ops/preface_ops.xml599(para)
msgid "The team includes:"
msgstr "以下が執筆チームのメンバーです。"

#: ./doc/openstack-ops/preface_ops.xml603(term)
msgid "Tom Fifield"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml606(para)
msgid ""
"After learning about scalability in computing from particle physics "
"experiments, such as ATLAS at the Large Hadron Collider (LHC) at CERN, Tom "
"worked on OpenStack clouds in production to support the Australian public "
"research sector. Tom currently serves as an OpenStack community manager and "
"works on OpenStack documentation in his spare time."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml617(term)
msgid "Diane Fleming"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml620(para)
msgid ""
"Diane works on the OpenStack API documentation tirelessly. She helped out "
"wherever she could on this project."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml627(term)
msgid "Anne Gentle"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml630(para)
msgid ""
"Anne is the documentation coordinator for OpenStack and also served as an "
"individual contributor to the Google Documentation Summit in 2011, working "
"with the Open Street Maps team. She has worked on book sprints in the past, "
"with FLOSS Manuals’ Adam Hyde facilitating. Anne lives in Austin, Texas."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml640(term)
msgid "Lorin Hochstein"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml643(para)
msgid ""
"An academic turned software-developer-slash-operator, Lorin worked as the "
"lead architect for Cloud Services at Nimbis Services, where he deploys "
"OpenStack for technical computing applications. He has been working with "
"OpenStack since the Cactus release. Previously, he worked on high-"
"performance computing extensions for OpenStack at University of Southern "
"California's Information Sciences Institute (USC-ISI)."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml655(term)
msgid "Adam Hyde"
msgstr "Adam Hyde"

#: ./doc/openstack-ops/preface_ops.xml658(para)
msgid ""
"Adam facilitated this book sprint. He also founded the books sprint "
"methodology and is the most experienced book-sprint facilitator around. See "
"<link href=\"http://www.booksprints.net\"/> for more information. Adam "
"founded FLOSS Manuals—a community of some 3,000 individuals developing Free "
"Manuals about Free Software. He is also the founder and project manager for "
"Booktype, an open source project for writing, editing, and publishing books "
"online and in print."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml671(term)
msgid "Jonathan Proulx"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml674(para)
msgid ""
"Jon has been piloting an OpenStack cloud as a senior technical architect at "
"the MIT Computer Science and Artificial Intelligence Lab for his researchers"
" to have as much computing power as they need. He started contributing to "
"OpenStack documentation and reviewing the documentation so that he could "
"accelerate his learning."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml684(term)
msgid "Everett Toews"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml687(para)
msgid ""
"Everett is a developer advocate at Rackspace making OpenStack and the "
"Rackspace Cloud easy to use. Sometimes developer, sometimes advocate, and "
"sometimes operator, he's built web applications, taught workshops, given "
"presentations around the world, and deployed OpenStack for production use by"
" academia and business."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml697(term)
msgid "Joe Topjian"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml700(para)
msgid ""
"Joe has designed and deployed several clouds at Cybera, a nonprofit where "
"they are building e-infrastructure to support entrepreneurs and local "
"researchers in Alberta, Canada. He also actively maintains and operates "
"these clouds as a systems architect, and his experiences have generated a "
"wealth of troubleshooting skills for cloud environments."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml711(term)
msgid "OpenStack community members"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml714(para)
msgid ""
"Many individual efforts keep a community book alive. Our community members "
"updated content for this book year-round. Also, a year after the first "
"sprint, Jon Proulx hosted a second two-day mini-sprint at MIT with the goal "
"of updating the book for the latest release. Since the book's inception, "
"more than 30 contributors have supported this book. We have a tool chain for"
" reviews, continuous builds, and translations. Writers and developers "
"continuously review patches, enter doc bugs, edit content, and fix doc bugs."
" We want to recognize their efforts!"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml726(para)
msgid ""
"The following people have contributed to this book: Akihiro Motoki, "
"Alejandro Avella, Alexandra Settle, Andreas Jaeger, Andy McCallum, Benjamin "
"Stassart, Chandan Kumar, Chris Ricker, David Cramer, David Wittman, Denny "
"Zhang, Emilien Macchi, Gauvain Pocentek, Ignacio Barrio, James E. Blair, Jay"
" Clark, Jeff White, Jeremy Stanley, K Jonathan Harker, KATO Tomoyuki, Lana "
"Brindley, Laura Alves, Lee Li, Lukasz Jernas, Mario B. Codeniera, Matthew "
"Kassawara, Michael Still, Monty Taylor, Nermina Miller, Nigel Williams, Phil"
" Hopkins, Russell Bryant, Sahid Orentino Ferdjaoui, Sandy Walsh, Sascha "
"Peilicke, Sean M. Collins, Sergey Lukjanov, Shilla Saebi, Stephen Gordon, "
"Summer Long, Uwe Stuehler, Vaibhav Bhatkar, Veronica Musso, Ying Chun "
"\"Daisy\" Guo, Zhengguang Ou, and ZhiQiang Fan."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml747(title)
msgid "How to Contribute to This Book"
msgstr "この本の作成に参加するには"

#: ./doc/openstack-ops/preface_ops.xml749(para)
msgid ""
"The genesis of this book was an in-person event, but now that the book is in"
" your hands, we want you to contribute to it. OpenStack documentation "
"follows the coding principles of iterative work, with bug logging, "
"investigating, and fixing. We also store the source content on GitHub and "
"invite collaborators through the OpenStack Gerrit installation, which offers"
" reviews. For the O'Reilly edition of this book, we are using the company's "
"Atlas system, which also stores source content on GitHub and enables "
"collaboration among contributors."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml759(para)
msgid ""
"Learn more about how to contribute to the OpenStack docs at <link "
"href=\"https://wiki.openstack.org/wiki/Documentation/HowTo\">Documentation "
"How To</link>."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml763(para)
msgid ""
"If you find a bug and can't fix it or aren't sure it's really a doc bug, log"
" a bug at <link href=\"https://bugs.launchpad.net/openstack-"
"manuals\">OpenStack Manuals</link>. Tag the bug under "
"<guilabel>Extra</guilabel> options with the <literal>ops-guide</literal> tag"
" to indicate that the bug is in this guide. You can assign the bug to "
"yourself if you know how to fix it. Also, a member of the OpenStack doc-core"
" team can triage the doc bug."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml776(title)
msgid "Conventions Used in This Book"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml778(para)
msgid "The following typographical conventions are used in this book:"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml783(emphasis)
msgid "Italic"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml786(para)
msgid ""
"Indicates new terms, URLs, email addresses, filenames, and file extensions."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml792(literal)
msgid "Constant width"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml795(para)
msgid ""
"Used for program listings, as well as within paragraphs to refer to program "
"elements such as variable or function names, databases, data types, "
"environment variables, statements, and keywords."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml806(para)
msgid ""
"Shows commands or other text that should be typed literally by the user."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml812(replaceable)
msgid "Constant width italic"
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml815(para)
msgid ""
"Shows text that should be replaced with user-supplied values or by values "
"determined by context."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml821(term)
msgid "Command prompts"
msgstr "コマンドプロンプト"

#: ./doc/openstack-ops/preface_ops.xml824(para)
msgid ""
"Commands prefixed with the <literal>#</literal> prompt should be executed by"
" the <literal>root</literal> user. These examples can also be executed using"
" the <literal>sudo</literal> command, if available."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml829(para)
msgid ""
"Commands prefixed with the <literal>$</literal> prompt can be executed by "
"any user, including <literal>root</literal>."
msgstr "<literal>$</literal> プロンプトから始まるコマンドは、<literal>root</literal> を含む、すべてのユーザーにより実行できます。"

#: ./doc/openstack-ops/preface_ops.xml837(para)
msgid "This element signifies a tip or suggestion."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml841(para)
msgid "This element signifies a general note."
msgstr ""

#: ./doc/openstack-ops/preface_ops.xml845(para)
msgid "This element indicates a warning or caution."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml15(title)
msgid "Scaling"
msgstr "スケーリング"

#: ./doc/openstack-ops/ch_arch_scaling.xml17(para)
msgid ""
"Whereas traditional applications required larger hardware to scale "
"(\"vertical scaling\"), cloud-based applications typically request more, "
"discrete hardware (\"horizontal scaling\"). If your cloud is successful, "
"eventually you must add resources to meet the increasing demand.<indexterm "
"class=\"singular\"><primary>scaling</primary><secondary>vertical vs. "
"horizontal</secondary></indexterm>"
msgstr "従来のアプリケーションでは、スケーリングするには、より大きいハードウェアが必要でした (垂直スケーリング) が、クラウドベースのアプリケーションは通常、別のハードウェアを必要とします(水平スケーリング)。クラウドを正常に設定できた場合、需要が増すとそれに合うようにリソースを追加する必要がでてきます。<indexterm class=\"singular\"><primary>スケーリング</primary><secondary>垂直 vs 水平</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_scaling.xml27(para)
msgid ""
"To suit the cloud paradigm, OpenStack itself is designed to be horizontally "
"scalable. Rather than switching to larger servers, you procure more servers "
"and simply install identically configured services. Ideally, you scale out "
"and load balance among groups of functionally identical services (for "
"example, compute nodes or <literal>nova-api</literal> nodes), that "
"communicate on a message bus."
msgstr "クラウドのパラダイムに合わせるため、OpenStack は水平的にスケーリングできるように設計されています。容量の大きいサーバーに切り替えるのではなく、サーバーを多く調達して同じように設定したサービスをインストールするだけです。理想としては、メッセージバスを通信する、機能的に同じサービス (例: コンピュートノードや <literal>nova-api</literal> ノード) グループでスケールアウト、負荷分散します。"

#: ./doc/openstack-ops/ch_arch_scaling.xml35(title)
msgid "The Starting Point"
msgstr "出発点"

#: ./doc/openstack-ops/ch_arch_scaling.xml37(para)
msgid ""
"Determining the scalability of your cloud and how to improve it is an "
"exercise with many variables to balance. No one solution meets everyone's "
"scalability goals. However, it is helpful to track a number of metrics. "
"Since you can define virtual hardware templates, called \"flavors\" in "
"OpenStack, you can start to make scaling decisions based on the flavors "
"you'll provide. These templates define sizes for memory in RAM, root disk "
"size, amount of ephemeral data disk space available, and number of cores for"
" starters.<indexterm class=\"singular\"><primary>virtual machine "
"(VM)</primary></indexterm><indexterm "
"class=\"singular\"><primary>hardware</primary><secondary>virtual "
"hardware</secondary></indexterm><indexterm "
"class=\"singular\"><primary>flavor</primary></indexterm><indexterm "
"class=\"singular\"><primary>scaling</primary><secondary>metrics "
"for</secondary></indexterm>"
msgstr "多くのアイテムでバランスを取りながら、クラウドのスケーラビリティや改善方法を決定していきます。ソリューション 1 つだけでは、スケーラビリティの目的を達成することはできません。しかし、複数のメトリクスをトラッキングすると役に立ちます。仮想ハードウェアのテンプレート (OpenStack ではフレーバーと呼ばれる) を定義できるため、用意するフレーバーをもとにスケーリングの意思決定を行うことができます。これらのテンプレートは、メモリーのサイズ (RAM)、root ディスクのサイズ、一時データディスクの空き容量、スターターのコア数を定義します。<indexterm class=\"singular\"><primary>仮想マシン</primary></indexterm><indexterm class=\"singular\"><primary>ハードウェア</primary><secondary>仮想ハードウェア</secondary></indexterm><indexterm class=\"singular\"><primary>フレーバー</primary></indexterm><indexterm class=\"singular\"><primary>スケーリング</primary><secondary>メトリクス</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_scaling.xml58(para)
msgid ""
"The default OpenStack flavors are shown in <xref linkend=\"os-flavors-"
"table\"/>."
msgstr "デフォルトの OpenStack フレーバーは <xref linkend=\"os-flavors-table\"/> に表示されています。"

#: ./doc/openstack-ops/ch_arch_scaling.xml64(caption)
msgid "OpenStack default flavors"
msgstr "OpenStack デフォルトのフレーバー"

#: ./doc/openstack-ops/ch_arch_scaling.xml80(th)
msgid "Virtual cores"
msgstr "仮想コア数"

#: ./doc/openstack-ops/ch_arch_scaling.xml82(th)
msgid "Memory"
msgstr "メモリ"

#: ./doc/openstack-ops/ch_arch_scaling.xml92(para)
msgid "m1.tiny"
msgstr "m1.tiny"

#: ./doc/openstack-ops/ch_arch_scaling.xml94(para)
#: ./doc/openstack-ops/ch_arch_scaling.xml106(para)
#: ./doc/openstack-ops/ch_ops_maintenance.xml766(para)
msgid "1"
msgstr "1"

#: ./doc/openstack-ops/ch_arch_scaling.xml96(para)
msgid "512 MB"
msgstr "512 MB"

#: ./doc/openstack-ops/ch_arch_scaling.xml98(para)
msgid "1 GB"
msgstr "1 GB"

#: ./doc/openstack-ops/ch_arch_scaling.xml100(para)
msgid "0 GB"
msgstr "0 GB"

#: ./doc/openstack-ops/ch_arch_scaling.xml104(para)
msgid "m1.small"
msgstr "m1.small"

#: ./doc/openstack-ops/ch_arch_scaling.xml108(para)
msgid "2 GB"
msgstr "2 GB"

#: ./doc/openstack-ops/ch_arch_scaling.xml110(para)
#: ./doc/openstack-ops/ch_arch_scaling.xml122(para)
#: ./doc/openstack-ops/ch_arch_scaling.xml134(para)
#: ./doc/openstack-ops/ch_arch_scaling.xml146(para)
msgid "10 GB"
msgstr "10 GB"

#: ./doc/openstack-ops/ch_arch_scaling.xml112(para)
msgid "20 GB"
msgstr "20 GB"

#: ./doc/openstack-ops/ch_arch_scaling.xml116(para)
msgid "m1.medium"
msgstr "m1.medium"

#: ./doc/openstack-ops/ch_arch_scaling.xml118(para)
#: ./doc/openstack-ops/ch_ops_maintenance.xml772(para)
msgid "2"
msgstr "2"

#: ./doc/openstack-ops/ch_arch_scaling.xml120(para)
msgid "4 GB"
msgstr "4 GB"

#: ./doc/openstack-ops/ch_arch_scaling.xml124(para)
msgid "40 GB"
msgstr "40 GB"

#: ./doc/openstack-ops/ch_arch_scaling.xml128(para)
msgid "m1.large"
msgstr "m1.large"

#: ./doc/openstack-ops/ch_arch_scaling.xml130(para)
#: ./doc/openstack-ops/ch_ops_maintenance.xml785(para)
msgid "4"
msgstr "4"

#: ./doc/openstack-ops/ch_arch_scaling.xml132(para)
msgid "8 GB"
msgstr "8 GB"

#: ./doc/openstack-ops/ch_arch_scaling.xml136(para)
msgid "80 GB"
msgstr "80 GB"

#: ./doc/openstack-ops/ch_arch_scaling.xml140(para)
msgid "m1.xlarge"
msgstr "m1.xlarge"

#: ./doc/openstack-ops/ch_arch_scaling.xml142(para)
msgid "8"
msgstr "8"

#: ./doc/openstack-ops/ch_arch_scaling.xml144(para)
msgid "16 GB"
msgstr "16 GB"

#: ./doc/openstack-ops/ch_arch_scaling.xml148(para)
msgid "160 GB"
msgstr "160 GB"

#: ./doc/openstack-ops/ch_arch_scaling.xml156(para)
msgid ""
"The number of virtual machines (VMs) you expect to run, <code>((overcommit "
"fraction </code>"
msgstr "実行する必要のある仮想マシン数。<code>((overcommit fraction </code>"

#: ./doc/openstack-ops/ch_arch_scaling.xml162(para)
msgid "How much storage is required <code>(flavor disk size </code>"
msgstr "必要とされるストレージ容量<code>(flavor disk size </code>"

#: ./doc/openstack-ops/ch_arch_scaling.xml153(para)
msgid ""
"The starting point for most is the core count of your cloud. By applying "
"some ratios, you can gather information about: <placeholder-1/> You can use "
"these ratios to determine how much additional infrastructure you need to "
"support your cloud."
msgstr "多くの場合、クラウドのコア数から始めます。比率を適用することで、 <placeholder-1/> に関する情報を取得できます。これらの比率を使用して、クラウドのサポートに必要なインフラストラクチャーがどの程度必要か判断することができます。"

#: ./doc/openstack-ops/ch_arch_scaling.xml168(para)
msgid ""
"Here is an example using the ratios for gathering scalability information "
"for the number of VMs expected as well as the storage needed. The following "
"numbers support (200 / 2) 16 = 1600 VM instances and require 80 TB of "
"storage for /var/lib/nova/instances:"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml175(para)
msgid "200 physical cores."
msgstr "物理コア 200 個"

#: ./doc/openstack-ops/ch_arch_scaling.xml179(para)
msgid ""
"Most instances are size m1.medium (two virtual cores, 50 GB of storage)."
msgstr "ほとんどのインスタンスのサイズは m1.medium (仮想コア数2、ストレージ50GB) とします。"

#: ./doc/openstack-ops/ch_arch_scaling.xml184(para)
msgid ""
"Default CPU overcommit ratio (<code>cpu_allocation_ratio</code> in "
"nova.conf) of 16:1."
msgstr "デフォルトの CPU オーバーコミット比率 (<code>cpu_allocation_ratio</code> in nova.conf) は 16:1 とします。"

#: ./doc/openstack-ops/ch_arch_scaling.xml189(para)
msgid ""
"However, you need more than the core count alone to estimate the load that "
"the API services, database servers, and queue servers are likely to "
"encounter. You must also consider the usage patterns of your cloud."
msgstr "しかし、APIサービスやデータベースサーバー、MQサーバーがおそらく遭遇する負荷を見積もるためには、コア数以外の検討も行う必要があります。クラウドの利用パターンも考慮しなければなりません。"

#: ./doc/openstack-ops/ch_arch_scaling.xml194(para)
msgid ""
"As a specific example, compare a cloud that supports a managed web-hosting "
"platform with one running integration tests for a development project that "
"creates one VM per code commit. In the former, the heavy work of creating a "
"VM happens only every few months, whereas the latter puts constant heavy "
"load on the cloud controller. You must consider your average VM lifetime, as"
" a larger number generally means less load on the cloud "
"controller.<indexterm class=\"singular\"><primary>cloud "
"controllers</primary><secondary>scalability and</secondary></indexterm>"
msgstr "特定の例としては、マネージド Web ホスティングプラットフォームをサポートするクラウドと、コードコミットごとに仮想マシンを１つ作成するような開発プロジェクトの統合テストを実行するクラウドを比較してみましょう。前者では、VMを作成する負荷の大きい処理は数か月に 一度しか発生しないのに対して、後者ではクラウドコントローラに常に負荷の大きい処理が発生します。一般論として、VMの平均寿命が長いということは、クラウドコントローラの負荷が軽いことを意味するため、平均的なVMの寿命を検討する必要があります。<indexterm class=\"singular\"><primary>クラウドコントローラー</primary><secondary>スケーラビリティ</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_scaling.xml206(para)
msgid ""
"Aside from the creation and termination of VMs, you must consider the impact"
" of users accessing the service—particularly on <literal>nova-api</literal> "
"and its associated database. Listing instances garners a great deal of "
"information and, given the frequency with which users run this operation, a "
"cloud with a large number of users can increase the load significantly. This"
" can occur even without their knowledge—leaving the OpenStack dashboard "
"instances tab open in the browser refreshes the list of VMs every 30 "
"seconds."
msgstr "仮想マシンの作成、停止以外に、特に <literal>nova-api</literal> や関連のデータベースといったサービスにアクセスする際の影響について考慮する必要があります。インスタンスを一覧表示することで膨大な量の情報を収集し、この操作の実行頻度を前提として、ユーザー数の多いクラウドで負荷を大幅に増加させることができます。これはユーザーには透過的に行われます。OpenStack のダッシュボードをブラウザで開いた状態にすると、仮想マシンの一覧が 30 秒毎に更新されます。"

#: ./doc/openstack-ops/ch_arch_scaling.xml215(para)
msgid ""
"After you consider these factors, you can determine how many cloud "
"controller cores you require. A typical eight core, 8 GB of RAM server is "
"sufficient for up to a rack of compute nodes — given the above caveats."
msgstr "これらの要素を検討した後、クラウドコントローラにどのくらいのコア数が必要なのか決定することができます。上記で説明した留意事項の下、典型的には、ラック 1 本分のコンピュートノードに対して8 コア、メモリ 8GB のサーバで充分です。"

#: ./doc/openstack-ops/ch_arch_scaling.xml220(para)
msgid ""
"You must also consider key hardware specifications for the performance of "
"user VMs, as well as budget and performance needs, including storage "
"performance (spindles/core), memory availability (RAM/core), network "
"bandwidth<indexterm "
"class=\"singular\"><primary>bandwidth</primary><secondary>hardware "
"specifications and</secondary></indexterm> (Gbps/core), and overall CPU "
"performance (CPU/core)."
msgstr "また、仮想マシンのパフォーマンス、ストレージの性能 (スピンドル/コア)、メモリーの空き容量 (RAM/コア)、ネットワークの帯域幅など、予算や性能のニーズに関して、主なハードウェアの仕様を考慮する必要もあります。<indexterm class=\"singular\"><primary>帯域幅</primary><secondary>ハードウェアの仕様</secondary></indexterm> (Gbps/コア)、全体的な CPU のパフォーマンス (CPU/コア)"

#: ./doc/openstack-ops/ch_arch_scaling.xml230(para)
msgid ""
"For a discussion of metric tracking, including how to extract metrics from "
"your cloud, see <xref linkend=\"logging_monitoring\"/>."
msgstr "クラウドからメトリクスを抽出する方法など、メトリクスの追跡については、<xref linkend=\"logging_monitoring\"/> を参照してください。"

#: ./doc/openstack-ops/ch_arch_scaling.xml237(title)
msgid "Adding Cloud Controller Nodes"
msgstr "クラウドコントローラーノードの追加"

#: ./doc/openstack-ops/ch_arch_scaling.xml239(para)
msgid ""
"You can facilitate the horizontal expansion of your cloud by adding nodes. "
"Adding compute nodes is straightforward—they are easily picked up by the "
"existing installation. However, you must consider some important points when"
" you design your cluster to be highly available.<indexterm "
"class=\"singular\"><primary>compute "
"nodes</primary><secondary>adding</secondary></indexterm><indexterm "
"class=\"singular\"><primary>high "
"availability</primary></indexterm><indexterm "
"class=\"singular\"><primary>configuration options</primary><secondary>high "
"availability</secondary></indexterm><indexterm "
"class=\"singular\"><primary>cloud controller "
"nodes</primary><secondary>adding</secondary></indexterm><indexterm "
"class=\"singular\"><primary>scaling</primary><secondary>adding cloud "
"controller nodes</secondary></indexterm>"
msgstr "ノードを追加することで、垂直に拡張するのが容易になります。コンピュートノードの追加は単純で、既存のインストール環境から簡単にピックアップすることができます。しかし、高可用性のクラスターを設計するには、重要なポイントを考慮する必要があります。<indexterm class=\"singular\"><primary>コンピュートノード</primary><secondary>追加</secondary></indexterm><indexterm class=\"singular\"><primary>高可用性</primary></indexterm><indexterm class=\"singular\"><primary>設定オプション</primary><secondary>高可用性</secondary></indexterm><indexterm class=\"singular\"><primary>クラウドコントローラーノード</primary><secondary>追加</secondary></indexterm><indexterm class=\"singular\"><primary>スケーリング</primary><secondary>クラウドコントローラーノードの追加</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_scaling.xml263(para)
msgid ""
"Recall that a cloud controller node runs several different services. You can"
" install services that communicate only using the message queue "
"internally—<code>nova-scheduler</code> and <code>nova-console</code>—on a "
"new server for expansion. However, other integral parts require more care."
msgstr "クラウドコントローラは、異なるサービスを複数実行することを思い出してください。拡張のための新しいサーバには、<code>nova-scheduler</code> や <code>nova-console</code> のようなメッセージキューのみを使用して内部通信を行うサービスをインストールすることができます。しかし、その他の不可欠な部分はさらに細心の注意が必要です。"

#: ./doc/openstack-ops/ch_arch_scaling.xml269(para)
msgid ""
"You should load balance user-facing services such as dashboard, <code>nova-"
"api</code>, or the Object Storage proxy. Use any standard HTTP load-"
"balancing method (DNS round robin, hardware load balancer, or software such "
"as Pound or HAProxy). One caveat with dashboard is the VNC proxy, which uses"
" the WebSocket protocol—something that an L7 load balancer might struggle "
"with. See also <link "
"href=\"http://docs.openstack.org/developer/horizon/topics/deployment.html"
"#session-storage\" title=\"Horizon session storage\">Horizon session "
"storage</link>."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml279(para)
msgid ""
"You can configure some services, such as <code>nova-api</code> and <code"
">glance-api</code>, to use multiple processes by changing a flag in their "
"configuration file—allowing them to share work between multiple cores on the"
" one machine."
msgstr "<code>nova-api</code> や <code>glance-api</code> などのサービスは、環境設定ファイルのフラグを変更することによって複数プロセスで処理させるように設定できます。これによって 1 台のサーバー上にある複数のコアの間で処理を共有できるようになります。"

#: ./doc/openstack-ops/ch_arch_scaling.xml285(para)
msgid ""
"Several options are available for MySQL load balancing, and the supported "
"AMQP brokers have built-in clustering support. Information on how to "
"configure these and many of the other services can be found in <xref "
"linkend=\"operations\" xrefstyle=\"part-num-title\"/>.<indexterm "
"class=\"singular\"><primary>Advanced Message Queuing Protocol "
"(AMQP)</primary></indexterm>"
msgstr "MySQL の負荷分散には複数のオプションがあり、サポートされている AMQP ブローカーにはクラスタリングサポートが含まれています。これらの設定方法やその他多くのサービスに関する情報は、 <xref linkend=\"operations\" xrefstyle=\"part-num-title\"/> を参照してください。<indexterm class=\"singular\"><primary>Advanced Message Queuing Protocol (AMQP)</primary></indexterm>"

#: ./doc/openstack-ops/ch_arch_scaling.xml296(title)
msgid "Segregating Your Cloud"
msgstr "クラウドの分離"

#: ./doc/openstack-ops/ch_arch_scaling.xml298(para)
msgid ""
"When you want to offer users different regions to provide legal "
"considerations for data storage, redundancy across earthquake fault lines, "
"or for low-latency API calls, you segregate your cloud. Use one of the "
"following OpenStack methods to segregate your cloud: "
"<emphasis>cells</emphasis>, <emphasis>regions</emphasis>, "
"<emphasis>availability zones</emphasis>, or <emphasis>host "
"aggregates</emphasis>.<indexterm class=\"singular\"><primary>segregation "
"methods</primary></indexterm><indexterm "
"class=\"singular\"><primary>scaling</primary><secondary>cloud "
"segregation</secondary></indexterm>"
msgstr "法的に考慮したデータストレージ、耐震ラインでの冗長性、低遅延の API コールを提供する様々なリージョンを提供するには、クラウドを分割します。<emphasis>セル</emphasis>、<emphasis>リージョン</emphasis>、<emphasis>アベイラビリティゾーン</emphasis>、<emphasis>ホストアグリゲート</emphasis> のいずれかの OpenStack メソッドを使用して、クラウドを分割します。<indexterm class=\"singular\"><primary>分割メソッド</primary></indexterm><indexterm class=\"singular\"><primary>スケーリング</primary><secondary>クラウド分割</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_scaling.xml312(para)
msgid ""
"Each method provides different functionality and can be best divided into "
"two groups:"
msgstr "メソッド毎に異なる機能を提供しますが、このメソッドは 2 つのグループに分類すると良いでしょう。"

#: ./doc/openstack-ops/ch_arch_scaling.xml317(para)
msgid ""
"Cells and regions, which segregate an entire cloud and result in running "
"separate Compute deployments."
msgstr "セルおよびリージョン。クラウド全体を分離し、個別にコンピュートデプロイメントを稼働します。"

#: ./doc/openstack-ops/ch_arch_scaling.xml322(para)
msgid ""
"<glossterm baseform=\"Availability zone\">Availability zones</glossterm> and"
" host aggregates, which merely divide a single Compute deployment."
msgstr "<glossterm baseform=\"Availability zone\">アベイラビリティゾーン</glossterm> およびホストアグリゲート。コンピュートのデプロイメントの分割のみを行います。"

#: ./doc/openstack-ops/ch_arch_scaling.xml328(para)
msgid ""
"<xref linkend=\"segragation_methods\"/> provides a comparison view of each "
"segregation method currently provided by OpenStack Compute.<indexterm "
"class=\"singular\"><primary>endpoints</primary><secondary>API "
"endpoint</secondary></indexterm>"
msgstr "<xref linkend=\"segragation_methods\"/> では、OpenStack Compute が現在提供している各分割メソッドの比較ビューを提供しています。<indexterm class=\"singular\"><primary>エンドポイント</primary><secondary>API エンドポイント</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_scaling.xml337(caption)
msgid "OpenStack segregation methods"
msgstr "OpenStack 分離の手法"

#: ./doc/openstack-ops/ch_arch_scaling.xml343(th)
msgid "Cells"
msgstr "セル"

#: ./doc/openstack-ops/ch_arch_scaling.xml345(th)
msgid "Regions"
msgstr "リージョン"

#: ./doc/openstack-ops/ch_arch_scaling.xml347(th)
msgid "Availability zones"
msgstr "アベイラビリティゾーン"

#: ./doc/openstack-ops/ch_arch_scaling.xml349(th)
msgid "Host aggregates"
msgstr "ホスト・アグリゲート"

#: ./doc/openstack-ops/ch_arch_scaling.xml355(emphasis)
msgid "Use when you need"
msgstr "用途"

#: ./doc/openstack-ops/ch_arch_scaling.xml358(para)
msgid ""
"A single <glossterm>API endpoint</glossterm> for compute, or you require a "
"second level of scheduling."
msgstr "コンピュート資源に対する単一の <glossterm>API エンドポイント</glossterm>、もしくは２段階スケジューリングが必要な場合"

#: ./doc/openstack-ops/ch_arch_scaling.xml361(para)
msgid ""
"Discrete regions with separate API endpoints and no coordination between "
"regions."
msgstr "リージョンごとに別々のAPIエンドポイントが必要で、リージョン間で協調する必要がない場合"

#: ./doc/openstack-ops/ch_arch_scaling.xml364(para)
msgid ""
"Logical separation within your nova deployment for physical isolation or "
"redundancy."
msgstr "物理的な隔離や冗長性のために、Nova デプロイメントの中で論理的な分離が必要な場合"

#: ./doc/openstack-ops/ch_arch_scaling.xml367(para)
msgid "To schedule a group of hosts with common features."
msgstr "共通の機能を持ったホストのグループに対してスケジューリングしたい場合"

#: ./doc/openstack-ops/ch_arch_scaling.xml372(emphasis)
msgid "Example"
msgstr "例"

#: ./doc/openstack-ops/ch_arch_scaling.xml374(para)
msgid ""
"A cloud with multiple sites where you can schedule VMs \"anywhere\" or on a "
"particular site."
msgstr "複数サイトで構成されるクラウドで、仮想マシンを「任意のサイト」または特定のサイトにスケジューリングしたい場合"

#: ./doc/openstack-ops/ch_arch_scaling.xml377(para)
msgid ""
"A cloud with multiple sites, where you schedule VMs to a particular site and"
" you want a shared infrastructure."
msgstr "複数サイトで構成されるクラウドで、仮想マシンを特定のサイトに対してスケジューリングでき、かつ共有インフラを利用したい場合"

#: ./doc/openstack-ops/ch_arch_scaling.xml380(para)
msgid "A single-site cloud with equipment fed by separate power supplies."
msgstr "分離された電源供給ラインを持つ設備で構成される、単一サイトのクラウド。"

#: ./doc/openstack-ops/ch_arch_scaling.xml383(para)
msgid "Scheduling to hosts with trusted hardware support."
msgstr "トラステッドコンピューティング機能に対応したホスト群に対してスケジューリングしたい場合"

#: ./doc/openstack-ops/ch_arch_scaling.xml388(emphasis)
msgid "Overhead"
msgstr "オーバーヘッド"

#: ./doc/openstack-ops/ch_arch_scaling.xml390(para)
msgid "Considered experimental."
msgstr "試験として使用"

#: ./doc/openstack-ops/ch_arch_scaling.xml390(para)
msgid "A new service, nova-cells."
msgstr "新規サービス、nova-cells"

#: ./doc/openstack-ops/ch_arch_scaling.xml391(para)
msgid "Each cell has a full nova installation except nova-api."
msgstr "各セルには nova-api　以外の全 nova 設定が含まれています。"

#: ./doc/openstack-ops/ch_arch_scaling.xml394(para)
msgid "A different API endpoint for every region."
msgstr "リージョン毎に別々のAPIエンドポイントが必要"

#: ./doc/openstack-ops/ch_arch_scaling.xml395(para)
msgid "Each region has a full nova installation."
msgstr "各リージョンにフルセットのNovaサービスが必要"

#: ./doc/openstack-ops/ch_arch_scaling.xml398(para)
#: ./doc/openstack-ops/ch_arch_scaling.xml400(para)
msgid "Configuration changes to <filename>nova.conf</filename>."
msgstr "<filename>nova.conf</filename> の設定を変更"

#: ./doc/openstack-ops/ch_arch_scaling.xml404(emphasis)
msgid "Shared services"
msgstr "共有サービス"

#: ./doc/openstack-ops/ch_arch_scaling.xml407(para)
#: ./doc/openstack-ops/ch_arch_scaling.xml409(para)
#: ./doc/openstack-ops/ch_arch_scaling.xml411(para)
#: ./doc/openstack-ops/ch_arch_scaling.xml413(para)
msgid "Keystone"
msgstr "Keystone"

#: ./doc/openstack-ops/ch_arch_scaling.xml407(code)
msgid "nova-api"
msgstr "nova-api"

#: ./doc/openstack-ops/ch_arch_scaling.xml411(para)
#: ./doc/openstack-ops/ch_arch_scaling.xml413(para)
msgid "All nova services"
msgstr "すべての Nova サービス"

#: ./doc/openstack-ops/ch_arch_scaling.xml419(title)
msgid "Cells and Regions"
msgstr "セルとリージョン"

#: ./doc/openstack-ops/ch_arch_scaling.xml421(para)
msgid ""
"OpenStack Compute cells are designed to allow running the cloud in a "
"distributed fashion without having to use more complicated technologies, or "
"be invasive to existing nova installations. Hosts in a cloud are partitioned"
" into groups called <emphasis>cells</emphasis>. Cells are configured in a "
"tree. The top-level cell (\"API cell\") has a host that runs the <code>nova-"
"api</code> service, but no <code>nova-compute</code> services. Each child "
"cell runs all of the other typical <code>nova-*</code> services found in a "
"regular installation, except for the <code>nova-api</code> service. Each "
"cell has its own message queue and database service and also runs <code"
">nova-cells</code>, which manages the communication between the API cell and"
" child cells.<indexterm "
"class=\"singular\"><primary>scaling</primary><secondary>cells and "
"regions</secondary></indexterm><indexterm "
"class=\"singular\"><primary>cells</primary><secondary>cloud "
"segregation</secondary></indexterm><indexterm "
"class=\"singular\"><primary>region</primary></indexterm>"
msgstr "OpenStack Compute のセルによって、より複雑な技術を持ち込むことなしに、また既存のNovaシステムに悪影響を与えることなしに、クラウドを分散された環境で運用することができます。１つのクラウドの中のホストは、<emphasis>セル</emphasis> と呼ばれるグループに分割されます。セルは、木構造に構成されてます。最上位のセル (「API セル」) は<code>nova-api</code>サービスを実行するホストを持ちますが、<code>nova-compute</code> サービスを実行するホストは持ちません。それぞれの子セルは、<code>nova-api</code>サービス以外の、普通のNovaシステムに見られる他のすべての典型的な <code>nova-*</code> サービスを実行します。それぞれのセルは自分のメッセージキューとデータベースサービスを持ち、またAPIセルと子セルの間の通信を制御する <code>nova-cells</code> サービスを実行します。<indexterm class=\"singular\"><primary>スケーリング</primary><secondary>セルとリージョン</secondary></indexterm><indexterm class=\"singular\"><primary>セル</primary><secondary>クラウド分割</secondary></indexterm><indexterm class=\"singular\"><primary>リージョン</primary></indexterm>"

#: ./doc/openstack-ops/ch_arch_scaling.xml444(para)
msgid ""
"This allows for a single API server being used to control access to multiple"
" cloud installations. Introducing a second level of scheduling (the cell "
"selection), in addition to the regular <code>nova-scheduler</code> selection"
" of hosts, provides greater flexibility to control where virtual machines "
"are run."
msgstr "これによって、複数のクラウドシステムに対するアクセスを、１つのAPIサーバで制御することができます。通常の<code>nova-scheduler</code>によるホストの選択に加えて、第二段階のスケジューリング(セルの選択)を導入することにより、仮想マシンを実行する場所の制御の柔軟性が大きく向上します。"

#: ./doc/openstack-ops/ch_arch_scaling.xml450(para)
msgid ""
"Contrast this with regions. Regions have a separate API endpoint per "
"installation, allowing for a more discrete separation. Users wanting to run "
"instances across sites have to explicitly select a region. However, the "
"additional complexity of a running a new service is not required."
msgstr "セルをリージョンと比較してみましょう。リージョンは、クラウドごとに別々のAPIエンドポイントを持ち、より細かい分離を実現できます。複数の拠点にまたがってインスタンスを実行するユーザーは、明示的にリージョンを指定しなければなりません。しかし、新規サービスを実行するなど、複雑化しなくて済みます。"

#: ./doc/openstack-ops/ch_arch_scaling.xml456(para)
msgid ""
"The OpenStack dashboard (horizon) currently uses only a single region, so "
"one dashboard service should be run per region. Regions are a robust way to "
"share some infrastructure between OpenStack Compute installations, while "
"allowing for a high degree of failure tolerance."
msgstr "現在のところ、OpenStack ダッシュボード (Horizon)　は１つのリージョンだけを操作対象とします。したがって、リージョンごとにダッシュボードサービスを実行するべきです。リージョンは、高度な故障耐性を実現しつつ、複数の OpenStack Compute のシステム間でインフラストラクチャーの一部を共有するための堅牢な方法です。"

#: ./doc/openstack-ops/ch_arch_scaling.xml464(title)
msgid "Availability Zones and Host Aggregates"
msgstr "アベイラビリティゾーンとホストアグリゲート"

#: ./doc/openstack-ops/ch_arch_scaling.xml466(para)
msgid ""
"You can use availability zones, host aggregates, or both to partition a nova"
" deployment.<indexterm "
"class=\"singular\"><primary>scaling</primary><secondary>availability "
"zones</secondary></indexterm>"
msgstr "アベイラビリティゾーン、ホストアグリゲート、または両方を使用して、nova デプロイメントを分割することができます。<indexterm class=\"singular\"><primary>スケーリング</primary><secondary>アベイラビリティゾーン</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_scaling.xml473(para)
msgid ""
"Availability zones are implemented through and configured in a similar way "
"to host aggregates."
msgstr "アベイラビリティゾーンは、ホストアグリゲートを利用して実装されており、ホストアグリゲートと同様の方法で設定します。"

#: ./doc/openstack-ops/ch_arch_scaling.xml476(para)
msgid "However, you use them for different reasons."
msgstr "しかし、アベイラビリティゾーンとホストアグリゲートは別の用途で使用します。"

#: ./doc/openstack-ops/ch_arch_scaling.xml479(title)
msgid "Availability zone"
msgstr "アベイラビリティゾーン"

#: ./doc/openstack-ops/ch_arch_scaling.xml481(para)
msgid ""
"This enables you to arrange OpenStack compute hosts into logical groups and "
"provides a form of physical isolation and redundancy from other availability"
" zones, such as by using a separate power supply or network "
"equipment.<indexterm class=\"singular\"><primary>availability "
"zone</primary></indexterm>"
msgstr "アベイラビリティゾーンにより、OpenStack Compute ホストを論理グループにまとめて、（独立した電源系統やネットワーク装置を使うことなどで）他のアベイラビリティゾーンとの物理的な分離や冗長性を実現できます。<indexterm class=\"singular\"><primary>アベイラビリティゾーン</primary></indexterm>"

#: ./doc/openstack-ops/ch_arch_scaling.xml488(para)
msgid ""
"You define the availability zone in which a specified compute host resides "
"locally on each server. An availability zone is commonly used to identify a "
"set of servers that have a common attribute. For instance, if some of the "
"racks in your data center are on a separate power source, you can put "
"servers in those racks in their own availability zone. Availability zones "
"can also help separate different classes of hardware."
msgstr "指定したコンピュートホストがローカルでサーバー毎に所属するアベイラビリティゾーンを定義します。アベイラビリティゾーンは一般的に、共通の属性を持つサーバーを識別するために使用されます。例えば、データセンターのラックの一部が別の電源を仕様している場合、このラックのサーバーを独自のアベイラビリティゾーンに入れることができます。アベイラビリティゾーンは、異なるハードウェアクラスを分割することもできます。"

#: ./doc/openstack-ops/ch_arch_scaling.xml496(para)
msgid ""
"When users provision resources, they can specify from which availability "
"zone they want their instance to be built. This allows cloud consumers to "
"ensure that their application resources are spread across disparate machines"
" to achieve high availability in the event of hardware failure."
msgstr "リソースのプロビジョニングの際には、インスタンスを作成するアベイラビリティゾーンを指定することができます。これによって、クラウドの利用者は、アプリケーションのリソースが異なるマシンに分散して配置され、ハードウェア故障が発生した場合でも高可用性を達成することができます。"

#: ./doc/openstack-ops/ch_arch_scaling.xml504(title)
msgid "Host aggregates zone"
msgstr "ホストアグリゲートゾーン"

#: ./doc/openstack-ops/ch_arch_scaling.xml506(para)
msgid ""
"This enables you to partition OpenStack Compute deployments into logical "
"groups for load balancing and instance distribution. You can use host "
"aggregates to further partition an availability zone. For example, you might"
" use host aggregates to partition an availability zone into groups of hosts "
"that either share common resources, such as storage and network, or have a "
"special property, such as trusted computing hardware.<indexterm "
"class=\"singular\"><primary>scaling</primary><secondary>host "
"aggregate</secondary></indexterm><indexterm class=\"singular\"><primary>host"
" aggregate</primary></indexterm>"
msgstr "これにより、OpenStack コンピュートデプロイメントを負荷分散やインスタンスディストリビューション用の論理グループに分割することができます。ホストアグリゲートをシヨ空いて、アベイラビリティゾーンをさらに分割することができます。例えば、ホストアグリゲートを使用してアベイラビリティゾーンをストレージやネットワークなどの共通のリソースを共有するか、信頼済みのコンピューティングハードウェアなどの特別なプロパティを持つホストグループに分割することができます。<indexterm class=\"singular\"><primary>スケーリング</primary><secondary>ホストアグリゲート</secondary></indexterm><indexterm class=\"singular\"><primary>ホストアグリゲート</primary></indexterm>"

#: ./doc/openstack-ops/ch_arch_scaling.xml520(para)
msgid ""
"A common use of host aggregates is to provide information for use with the "
"<literal>nova-scheduler</literal>. For example, you might use a host "
"aggregate to group a set of hosts that share specific flavors or images."
msgstr "ホストアグリゲートの一般的な用途は <literal>nova-scheduler</literal> で使用する情報を提供することです。例えば、ホストアグリゲートを使って、特定のフレーバーやイメージを共有するホストの集合を作成することができます。"

#: ./doc/openstack-ops/ch_arch_scaling.xml525(para)
msgid ""
"The general case for this is setting key-value pairs in the aggregate "
"metadata and matching key-value pairs in flavor's "
"<parameter>extra_specs</parameter> metadata. The "
"<parameter>AggregateInstanceExtraSpecsFilter</parameter> in the filter "
"scheduler will enforce that instances be scheduled only on hosts in "
"aggregates that define the same key to the same value."
msgstr "この一般的なケースは、アグリゲートメタデータで key-value ペアを設定して、フレーバーの <parameter>extra_specs</parameter> メタデータで key-value ペアを一致させます。フィルタースケジューラーの <parameter>AggregateInstanceExtraSpecsFilter</parameter> は、強制的にインスタンスが、同じ値に同じキーが定義されているアグリゲートのホストに対してのみスケジューリングするようにします。"

#: ./doc/openstack-ops/ch_arch_scaling.xml531(para)
msgid ""
"An advanced use of this general concept allows different flavor types to run"
" with different CPU and RAM allocation ratios so that high-intensity "
"computing loads and low-intensity development and testing systems can share "
"the same cloud without either starving the high-use systems or wasting "
"resources on low-utilization systems. This works by setting "
"<parameter>metadata</parameter> in your host aggregates and matching "
"<parameter>extra_specs</parameter> in your flavor types."
msgstr "この一般的なコンセプトを高度なレベルで使用すると、集中度の高いコンピュートロードや負荷の低い開発やテストシステムが使用量の多いシステムのリソースが不足したり、使用量の低いシステムでリソースを無駄にしたりしないで、同じクラウドを共有できるように、異なるフレーバーの種別が、異なる CPU および RAM 割当の比率で実行できるようになります。 これは、ホストアグリゲートに  <parameter>metadata</parameter> を設定して、フレーバー種別の<parameter>extra_specs</parameter> と一致させると機能します。"

#: ./doc/openstack-ops/ch_arch_scaling.xml540(para)
msgid ""
"The first step is setting the aggregate metadata keys "
"<parameter>cpu_allocation_ratio</parameter> and "
"<parameter>ram_allocation_ratio</parameter> to a floating-point value. The "
"filter schedulers <parameter>AggregateCoreFilter</parameter> and "
"<parameter>AggregateRamFilter</parameter> will use those values rather than "
"the global defaults in <filename>nova.conf</filename> when scheduling to "
"hosts in the aggregate. It is important to be cautious when using this "
"feature, since each host can be in multiple aggregates but should have only "
"one allocation ratio for each resources. It is up to you to avoid putting a "
"host in multiple aggregates that define different values for the same "
"<phrase role=\"keep-together\">resource</phrase>."
msgstr "最初のステップは、<parameter>cpu_allocation_ratio</parameter> と <parameter>ram_allocation_ratio</parameter> のアグリゲートメタデータキーを浮動小数点の値に設定します。<parameter>AggregateCoreFilter</parameter> と <parameter>AggregateRamFilter</parameter> のフィルタースケジューラーは、アグリゲートのホストにスケジューリングしている場合、<filename>nova.conf</filename> のグローバルの初期値を仕様するのではなく、この値を使用します。各ホストは複数のアグリゲートに含まれていますがリソースごとに 1 つの割当比率しか指定されていないため、この機能の使用時は、注意が必要です。同じ <phrase role=\"keep-together\">リソース</phrase> に対して別の値が定義されている複数のアグリゲートにホストを設置しないように注意してください。"

#: ./doc/openstack-ops/ch_arch_scaling.xml554(para)
msgid ""
"This is the first half of the equation. To get flavor types that are "
"guaranteed a particular ratio, you must set the "
"<parameter>extra_specs</parameter> in the flavor type to the key-value pair "
"you want to match in the aggregate. For example, if you define "
"<parameter>extra_specs</parameter><parameter>cpu_allocation_ratio</parameter>"
" to \"1.0\", then instances of that type will run in aggregates only where "
"the metadata key <parameter>cpu_allocation_ratio</parameter> is also defined"
" as \"1.0.\" In practice, it is better to define an additional key-value "
"pair in the aggregate metadata to match on rather than match directly on "
"<parameter>cpu_allocation_ratio</parameter> or "
"<parameter>core_allocation_ratio</parameter>. This allows better "
"abstraction. For example, by defining a key "
"<parameter>overcommit</parameter> and setting a value of \"high,\" "
"\"medium,\" or \"low,\" you could then tune the numeric allocation ratios in"
" the aggregates without also needing to change all flavor types relating to "
"them."
msgstr "これは前半部分です。特定の比率を保証するフレーバー種別を取得するには、フレーバー種別の <parameter>extra_specs</parameter> をアグリゲートでマッチする key-value ペアに設定する必要があります。たとえば、<parameter>extra_specs</parameter><parameter>cpu_allocation_ratio</parameter> を 1.0 に定義すると、その種別のインスタンスは、メタデータキー <parameter>cpu_allocation_ratio</parameter> も 1.0 と定義されているアグリゲートのみで実行されます。実際は、 <parameter>cpu_allocation_ratio</parameter> または <parameter>core_allocation_ratio</parameter> で直接マッチさせるのではなく、マッチするアグリゲートメタデータに追加の key-value ペアを定義すると良いでしょう。これにより抽象化が改善されます。たとえば、<parameter>overcommit</parameter> キーを定義して、高、中、低の値を設定することで、関連するフレーバー種別をすべて変更する必要なしに、アグリゲートの割合比を調節することができます。"

#: ./doc/openstack-ops/ch_arch_scaling.xml573(para)
msgid ""
"Previously, all services had an availability zone. Currently, only the "
"<literal>nova-compute</literal> service has its own availability zone. "
"Services such as <literal>nova-scheduler</literal>, <literal>nova-"
"network</literal>, and <literal>nova-conductor</literal> have always spanned"
" all availability zones."
msgstr "以前のバージョンでは、全サービスにアベイラビリティゾーンがありました。現在は、<literal>nova-compute</literal> サービスには独自のアベイラビリティゾーンがあります。 <literal>nova-scheduler</literal>、 <literal>nova-network</literal>、<literal>nova-conductor</literal> などのサービスは、常にすべてのアベイラビリティゾーンに対応します。"

#: ./doc/openstack-ops/ch_arch_scaling.xml584(para)
msgid "nova host-list (os-hosts)"
msgstr "nova host-list (os-hosts)"

#: ./doc/openstack-ops/ch_arch_scaling.xml588(para)
msgid "euca-describe-availability-zones verbose"
msgstr "euca-describe-availability-zones verbose"

#: ./doc/openstack-ops/ch_arch_scaling.xml592(para)
msgid "<literal>nova-manage</literal> service list"
msgstr "<literal>nova-manage</literal> サービス一覧"

#: ./doc/openstack-ops/ch_arch_scaling.xml580(para)
msgid ""
"When you run any of the following operations, the services appear in their "
"own internal availability zone (CONF.internal_service_availability_zone): "
"<placeholder-1/>The internal availability zone is hidden in euca-describe-"
"availability_zones (nonverbose)."
msgstr "以下の操作のいずれかを実行する場合、サービスは独自の内部アベイラビリティゾーン(CONF.internal_service_availability_zone) に表示されます。<placeholder-1/>内部のアベイラビリティゾーンは、euca-describe-availability_zones (nonverbose) に隠し設定されています。"

#: ./doc/openstack-ops/ch_arch_scaling.xml597(para)
msgid ""
"CONF.node_availability_zone has been renamed to "
"CONF.default_availability_zone and is used only by the <literal>nova-"
"api</literal> and <literal>nova-scheduler</literal> services."
msgstr "CONF.node_availability_zone は、CONF.default_availability_zone に名前が変更され、<literal>nova-api</literal> および <literal>nova-scheduler</literal> サービスのみで使用されます。"

#: ./doc/openstack-ops/ch_arch_scaling.xml602(para)
msgid "CONF.node_availability_zone still works but is deprecated."
msgstr "CONF.node_availability_zone は今も機能しますが、非推奨扱いです。"

#: ./doc/openstack-ops/ch_arch_scaling.xml610(title)
msgid "Scalable Hardware"
msgstr "スケーラブルハードウェア"

#: ./doc/openstack-ops/ch_arch_scaling.xml612(para)
msgid ""
"While several resources already exist to help with deploying and installing "
"OpenStack, it's very important to make sure that you have your deployment "
"planned out ahead of time. This guide presumes that you have at least set "
"aside a rack for the OpenStack cloud but also offers suggestions for when "
"and what to scale."
msgstr "OpenStack のデプロイやインストールの助けとなるリソースがすでに複数存在している場合でも、時間に余裕を持ってデプロイメントの系っ買うを立てることは非常に重要です。本書は、OpenStack クラウド用のラックを少なくとも 1 つ用意しているとの前提で、何を度のタイミングでスケールするかの提案をしていきます。"

#: ./doc/openstack-ops/ch_arch_scaling.xml619(title)
msgid "Hardware Procurement"
msgstr "ハードウェア調達"

#: ./doc/openstack-ops/ch_arch_scaling.xml621(para)
msgid ""
"“The Cloud” has been described as a volatile environment where servers can "
"be created and terminated at will. While this may be true, it does not mean "
"that your servers must be volatile. Ensuring that your cloud’s hardware is "
"stable and configured correctly means that your cloud environment remains up"
" and running. Basically, put effort into creating a stable hardware "
"environment so that you can host a cloud that users may treat as unstable "
"and volatile.<indexterm "
"class=\"singular\"><primary>servers</primary><secondary>avoiding volatility "
"in</secondary></indexterm><indexterm "
"class=\"singular\"><primary>hardware</primary><secondary>scalability "
"planning</secondary></indexterm><indexterm "
"class=\"singular\"><primary>scaling</primary><secondary>hardware "
"procurement</secondary></indexterm>"
msgstr "「クラウド」とは、サーバーを自由に作成、終了でき、不安定な環境と説明されてきました。これは真実ですが、サーバー自体が不安定なわけではありません。クラウドのハードウェアは、安定して正しく設定されているようにすることで、クラウド環境は稼動状態を保ちます。基本的に、安定したハードウェア環境を構築するように努めることで、ユーザーが不安定かつ変化しやすいものとして処理を行う可能性のあるクラウドをホストすることができます。<indexterm class=\"singular\"><primary>servers</primary><secondary>不安定性の回避</secondary></indexterm><indexterm class=\"singular\"><primary>ハードウェア</primary><secondary>拡張性プランニング</secondary></indexterm><indexterm class=\"singular\"><primary>スケーリング</primary><secondary>ハードウェア調達</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_scaling.xml641(para)
msgid ""
"OpenStack can be deployed on any hardware supported by an OpenStack-"
"compatible Linux distribution."
msgstr "OpenStack は、OpenStack と互換性のある Linux ディストリビューションによりサポートされているハードウェアにデプロイすることができます。"

#: ./doc/openstack-ops/ch_arch_scaling.xml644(para)
msgid ""
"Hardware does not have to be consistent, but it should at least have the "
"same type of CPU to support instance migration."
msgstr "ハードウェアに一貫性を持たせる必要はありませんが、インスタンスのマイグレーションをサポートできるように、最低限、CPU の種類は同じにする必要があります。"

#: ./doc/openstack-ops/ch_arch_scaling.xml647(para)
msgid ""
"The typical hardware recommended for use with OpenStack is the standard "
"value-for-money offerings that most hardware vendors stock. It should be "
"straightforward to divide your procurement into building blocks such as "
"\"compute,\" \"object storage,\" and \"cloud controller,\" and request as "
"many of these as you need. Alternatively, should you be unable to spend "
"more, if you have existing servers—provided they meet your performance "
"requirements and virtualization technology—they are quite likely to be able "
"to support OpenStack."
msgstr "OpenStack での使用に推奨しているハードウェアは一般的に、多くのハードウェアベンダーが提供している、コストパフォーマンスの高い標準オファリングです。調達すべきものをコンピュート、オブジェクトストレージ、クラウドコントローラなどのビルディングブロックに分類し、必要に応じ依頼していくと分かりやすいでしょう。また、投資額をこれ以上かけられない場合、既存サーバーがありパフォーマンス要件や仮想化技術に対応しているのであれば、高い確率で OpenStack をサポートしているはずです。"

#: ./doc/openstack-ops/ch_arch_scaling.xml658(title)
msgid "Capacity Planning"
msgstr "キャパシティプランニング"

#: ./doc/openstack-ops/ch_arch_scaling.xml660(para)
msgid ""
"OpenStack is designed to increase in size in a straightforward manner. "
"Taking into account the considerations that we've mentioned in this "
"chapter—particularly on the sizing of the cloud controller—it should be "
"possible to procure additional compute or object storage nodes as needed. "
"New nodes do not need to be the same specification, or even vendor, as "
"existing nodes.<indexterm "
"class=\"singular\"><primary>capability</primary><secondary>scaling "
"and</secondary></indexterm><indexterm "
"class=\"singular\"><primary>weight</primary></indexterm><indexterm "
"class=\"singular\"><primary>capacity "
"planning</primary></indexterm><indexterm "
"class=\"singular\"><primary>scaling</primary><secondary>capacity "
"planning</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml679(para)
msgid ""
"For compute nodes, <code>nova-scheduler</code> will take care of differences"
" in sizing having to do with core count and RAM amounts; however, you should"
" consider that the user experience changes with differing CPU speeds. When "
"adding object storage nodes, a <glossterm>weight</glossterm> should be "
"specified that reflects the <glossterm>capability</glossterm> of the node."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml686(para)
msgid ""
"Monitoring the resource usage and user growth will enable you to know when "
"to procure. <xref linkend=\"logging_monitoring\"/> details some useful "
"metrics."
msgstr ""

#: ./doc/openstack-ops/ch_arch_scaling.xml692(title)
msgid "Burn-in Testing"
msgstr "エージング試験"

#: ./doc/openstack-ops/ch_arch_scaling.xml694(para)
msgid ""
"Server hardware's chance of failure is high at the start and the end of its "
"life. As a result, much effort in dealing with hardware failures while in "
"production can be avoided by appropriate burn-in testing to attempt to "
"trigger the early-stage failures. The general principle is to stress the "
"hardware to its limits. Examples of burn-in tests include running a CPU or "
"disk benchmark for several days.<indexterm "
"class=\"singular\"><primary>testing</primary><secondary>burn-in "
"testing</secondary></indexterm><indexterm "
"class=\"singular\"><primary>troubleshooting</primary><secondary>burn-in "
"testing</secondary></indexterm><indexterm class=\"singular\"><primary>burn-"
"in testing</primary></indexterm><indexterm "
"class=\"singular\"><primary>scaling</primary><secondary>burn-in "
"testing</secondary></indexterm>"
msgstr ""

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/ch_arch_storage.xml439(None)
#: ./doc/openstack-ops/ch_arch_storage.xml456(None)
#: ./doc/openstack-ops/ch_arch_storage.xml469(None)
#: ./doc/openstack-ops/ch_arch_storage.xml476(None)
#: ./doc/openstack-ops/ch_arch_storage.xml489(None)
#: ./doc/openstack-ops/ch_arch_storage.xml496(None)
#: ./doc/openstack-ops/ch_arch_storage.xml503(None)
#: ./doc/openstack-ops/ch_arch_storage.xml516(None)
#: ./doc/openstack-ops/ch_arch_storage.xml523(None)
#: ./doc/openstack-ops/ch_arch_storage.xml536(None)
#: ./doc/openstack-ops/ch_arch_storage.xml547(None)
#: ./doc/openstack-ops/ch_arch_storage.xml553(None)
msgid ""
"@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc"
"/openstack-ops/figures/Check_mark_23x20_02.png'; md5=THIS FILE DOESN'T EXIST"
msgstr "@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/openstack-ops/figures/Check_mark_23x20_02.png'; md5=THIS FILE DOESN'T EXIST"

#: ./doc/openstack-ops/ch_arch_storage.xml12(title)
msgid "Storage Decisions"
msgstr "ストレージ選定"

#: ./doc/openstack-ops/ch_arch_storage.xml14(para)
msgid ""
"Storage is found in many parts of the OpenStack stack, and the differing "
"types can cause confusion to even experienced cloud engineers. This section "
"focuses on persistent storage options you can configure with your cloud. "
"It's important to understand the distinction between <glossterm "
"baseform=\"ephemeral volume\"> ephemeral</glossterm> storage and <glossterm "
"baseform=\"persistent volume\"> persistent</glossterm> storage."
msgstr "ストレージは、OpenStack のスタックの多くの箇所で使用されており、ストレージの種別が異なると、経験豊かなエンジニアでも混乱する可能性があります。本章は、お使いのクラウドで設定可能な永続ストレージオプションにフォーカスします。<glossterm baseform=\"ephemeral volume\"> 一時</glossterm> ストレージと <glossterm baseform=\"persistent volume\"> 永続</glossterm> ストレージの相違点を理解することが重要です。"

#: ./doc/openstack-ops/ch_arch_storage.xml22(title)
msgid "Ephemeral Storage"
msgstr "一時ストレージ"

#: ./doc/openstack-ops/ch_arch_storage.xml24(para)
msgid ""
"If you deploy only the OpenStack Compute Service (nova), your users do not "
"have access to any form of persistent storage by default. The disks "
"associated with VMs are \"ephemeral,\" meaning that (from the user's point "
"of view) they effectively disappear when a virtual machine is "
"terminated.<indexterm "
"class=\"singular\"><primary>storage</primary><secondary>ephemeral</secondary></indexterm>"
msgstr "OpenStack Compute Service (nova) のみをデプロイする場合、デフォルトでは、どのような形式の永続ストレージにもアクセスできません。仮想マシンに関連付けされているディスクは一時的です。つまり、(ユーザー視点から) 仮想マシンが終了されるとこのストレージは効率的に表示がなくなります。<indexterm class=\"singular\"><primary>ストレージ</primary><secondary>一時</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_storage.xml36(title)
msgid "Persistent Storage"
msgstr "永続ストレージ"

#: ./doc/openstack-ops/ch_arch_storage.xml38(para)
msgid ""
"Persistent storage means that the storage resource outlives any other "
"resource and is always available, regardless of the state of a running "
"instance."
msgstr "永続ストレージとは、実行中のインスタンスの状態が何であっても、ストレージリソースが他のリソースよりも長く存在して、常に利用できる状態のストレージを指します。"

#: ./doc/openstack-ops/ch_arch_storage.xml42(para)
msgid ""
"Today, OpenStack clouds explicitly support two types of persistent storage: "
"<emphasis>object storage</emphasis> and <emphasis>block "
"storage</emphasis>.<indexterm "
"class=\"singular\"><primary>swift</primary><secondary>Object Storage "
"API</secondary></indexterm><indexterm class=\"singular\"><primary>persistent"
" storage</primary></indexterm><indexterm "
"class=\"singular\"><primary>objects</primary><secondary>persistent storage "
"of</secondary></indexterm><indexterm class=\"singular\"><primary>Object "
"Storage</primary><secondary>Object Storage "
"API</secondary></indexterm><indexterm "
"class=\"singular\"><primary>storage</primary><secondary>object "
"storage</secondary></indexterm>"
msgstr "現在、OpenStack クラウドは、<emphasis>オブジェクトストレージ</emphasis> および<emphasis>ブロックストレージ</emphasis> の 2 種類の永続ストレージを明示的にサポートしています。<indexterm class=\"singular\"><primary>swift</primary><secondary>Object Storage API</secondary></indexterm><indexterm class=\"singular\"><primary>永続ストレージ</primary></indexterm><indexterm class=\"singular\"><primary>オブジェクト</primary><secondary>永続ストレージ</secondary></indexterm><indexterm class=\"singular\"><primary>オブジェクトストレージ</primary><secondary>Object Storage API</secondary></indexterm><indexterm class=\"singular\"><primary>storage</primary><secondary>オブジェクトストレージ</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_storage.xml65(title)
#: ./doc/openstack-ops/ch_ops_backup_recovery.xml211(title)
msgid "Object Storage"
msgstr "オブジェクトストレージ"

#: ./doc/openstack-ops/ch_arch_storage.xml67(para)
msgid ""
"With object storage, users access binary objects through a REST API. You may"
" be familiar with Amazon S3, which is a well-known example of an object "
"storage system. Object storage is implemented in OpenStack by the OpenStack "
"Object Storage (swift) project. If your intended users need to archive or "
"manage large datasets, you want to provide them with object storage. In "
"addition, OpenStack can store your virtual <phrase role=\"keep-"
"together\">machine</phrase> (VM) images inside of an object storage system, "
"as an alternative to storing the images on a file system.<indexterm "
"class=\"singular\"><primary>binary</primary><secondary>binary "
"objects</secondary></indexterm>"
msgstr "オブジェクトストレージでは、REST API を使用してバイナリオブジェクトにアクセスします。オブジェクトストレージで有名な例として、Amazon S3 は知られています。オブジェクトストレージは、OpenStack Object Storage (swift) プロジェクトにより、OpenStack に実装されています。ユーザーが、大規模なデータセットをアーカイブまたは管理する場合オブジェクトストレージを提供します。さらに OpenStack では、ファイルシステムにイメージを格納する代わりに、仮想<phrase role=\"keep-together\">マシン</phrase> (VM) のイメージを、オブジェクトストレージシステムの中に格納できます。<indexterm class=\"singular\"><primary>バイナリ</primary><secondary>バイナリオブジェクト</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_storage.xml81(para)
msgid ""
"OpenStack Object Storage provides a highly scalable, highly available "
"storage solution by relaxing some of the constraints of traditional file "
"systems. In designing and procuring for such a cluster, it is important to "
"understand some key concepts about its operation. Essentially, this type of "
"storage is built on the idea that all storage hardware fails, at every "
"level, at some point. Infrequently encountered failures that would hamstring"
" other storage systems, such as issues taking down RAID cards or entire "
"servers, are handled gracefully with OpenStack Object Storage.<indexterm "
"class=\"singular\"><primary>scaling</primary><secondary>Object Storage "
"and</secondary></indexterm>"
msgstr "OpenStack Object Storage は、従来のファイルシステムの制約の一部を緩和することで、高可用性かつ高拡張性のストレージソリューションを提供します。このようなクラスターの設計、調達には、操作に関する主なコンセプトを理解することが重要です。基本的に、このタイプのストレージハードウェアはすべて、どこかの段階で、どのレベルであっても故障するというコンセプトをベースに、この種類のストレージは構築されています。 RAID カードやサーバー全体での問題など、他のストレージシステムに影響を与える障害に遭遇することがまれにあります。このような場合、OpenStack Object Storageでは滞りなく処理されます。<indexterm class=\"singular\"><primary>スケーリング</primary><secondary>オブジェクトストレージ</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_storage.xml95(para)
msgid ""
"A good document describing the Object Storage architecture is found within "
"<link "
"href=\"http://docs.openstack.org/developer/swift/overview_architecture.html\""
" title=\"OpenStack wiki\">the developer documentation</link>—read this "
"first. Once you understand the architecture, you should know what a proxy "
"server does and how zones work. However, some important points are often "
"missed at first glance."
msgstr "オブジェクトストレージのアーキテクチャーについて詳しく説明したドキュメントは <link href=\"http://docs.openstack.org/developer/swift/overview_architecture.html\" title=\"OpenStack wiki\">the developer documentation</link>にあります。これをまず参照してください。アーキテクチャーを理解したら、プロキシサーバーの役割やゾーンの機能について理解できるはずです。しかし、少し見ただけでは、頻繁に重要なポイントを逃してしまうことがあります。"

#: ./doc/openstack-ops/ch_arch_storage.xml102(para)
msgid ""
"When designing your cluster, you must consider durability and availability. "
"Understand that the predominant source of these is the spread and placement "
"of your data, rather than the reliability of the hardware. Consider the "
"default value of the number of replicas, which is three. This means that "
"before an object is marked as having been written, at least two copies "
"exist—in case a single server fails to write, the third copy may or may not "
"yet exist when the write operation initially returns. Altering this number "
"increases the robustness of your data, but reduces the amount of storage you"
" have available. Next, look at the placement of your servers. Consider "
"spreading them widely throughout your data center's network and power-"
"failure zones. Is a zone a rack, a server, or a disk?"
msgstr "クラスターの設計時には、耐久性と可用性を考慮する必要があります。耐久性や可用性は主に、ハードウェアの信頼性に頼るのではなく、データを分散して設置することで確保されることを理解してください。レプリカの数のデフォルト値は 3 である点も考慮します。つまり、オブジェクトが書き込みされたとマークされる前でも、少なくともコピーが 2 つ存在します。1 つのサーバーが書き込みに失敗しても、書き込み操作が最初に返された時点で、3 番めのコピーが存在する可能性があります。この数字を変更することで、データの堅牢性を高めることができますが、利用可能なストレージ数が減少します。次に、サーバーの設置について見ていきます。データセンターのネットワークや停電ゾーン全体に設定するようにします。ゾーンには、ラック、サーバー、ディスクのいずれを使用していますか？"

#: ./doc/openstack-ops/ch_arch_storage.xml128(para)
msgid ""
"Among <glossterm>object</glossterm>, <glossterm>container</glossterm>, and "
"<glossterm>account server</glossterm>s"
msgstr "<glossterm>object server</glossterm> 、 <glossterm>container server</glossterm> 、  <glossterm>account server</glossterm> 間"

#: ./doc/openstack-ops/ch_arch_storage.xml134(para)
msgid "Between those servers and the proxies"
msgstr "object/container/account server と proxy server の間"

#: ./doc/openstack-ops/ch_arch_storage.xml138(para)
msgid "Between the proxies and your users"
msgstr "proxy server と 利用者の間"

#: ./doc/openstack-ops/ch_arch_storage.xml115(para)
msgid ""
"Object Storage's network patterns might seem unfamiliar at first. Consider "
"these main traffic flows: <indexterm "
"class=\"singular\"><primary>objects</primary><secondary>storage decisions "
"and</secondary></indexterm><indexterm "
"class=\"singular\"><primary>containers</primary><secondary>storage decisions"
" and</secondary></indexterm><indexterm class=\"singular\"><primary>account "
"server</primary></indexterm><placeholder-1/>"
msgstr "オブジェクトストレージのネットワークパターンは、最初は見慣れないかもしれません。これらのメイントラフィックの流れを見てみましょう。 <indexterm class=\"singular\"><primary>objects</primary><secondary>ストレージの決定</secondary></indexterm><indexterm class=\"singular\"><primary>コンテナー</primary><secondary>ストレージの決定</secondary></indexterm><indexterm class=\"singular\"><primary>アカウントサーバー</primary></indexterm><placeholder-1/>"

#: ./doc/openstack-ops/ch_arch_storage.xml142(para)
msgid ""
"Object Storage is very \"chatty\" among servers hosting data—even a small "
"cluster does megabytes/second of traffic, which is predominantly, “Do you "
"have the object?”/“Yes I have the object!” Of course, if the answer to the "
"aforementioned question is negative or the request times out, replication of"
" the object begins."
msgstr "オブジェクトストレージは、データをホストするサーバーの中で非常に呼び出しが多く、小さいクラスターでも一秒に MB 単位のトラフィックがあります。「オブジェクトがありますか？はい、あります。」当然、この質問に対する答えがNoの場合、または要求がタイムアウトした場合、オブジェクトの複製が開始されます。"

#: ./doc/openstack-ops/ch_arch_storage.xml148(para)
msgid ""
"Consider the scenario where an entire server fails and 24 TB of data needs "
"to be transferred \"immediately\" to remain at three copies—this can put "
"significant load on the network."
msgstr "サーバー全体が停止し、24 TB 分のデータを即時に 3 つのコピーに残るように移行するというシナリオを思い浮かべてください。これは、ネットワークに大きな負荷がかかる可能性があります。"

#: ./doc/openstack-ops/ch_arch_storage.xml154(para)
msgid ""
"Another fact that's often forgotten is that when a new file is being "
"uploaded, the proxy server must write out as many streams as there are "
"replicas—giving a multiple of network traffic. For a three-replica cluster, "
"10 Gbps in means 30 Gbps out. Combining this with the previous high "
"bandwidth<indexterm "
"class=\"singular\"><primary>bandwidth</primary><secondary>private vs. public"
" network recommendations</secondary></indexterm> demands of replication is "
"what results in the recommendation that your private network be of "
"significantly higher bandwidth than your public need be. Oh, and OpenStack "
"Object Storage communicates internally with unencrypted, unauthenticated "
"rsync for performance—you do want the private network to be private."
msgstr "また、新規ファイルがアップロードされると、プロキシサーバーはレプリカの数だけ書き込みが行われ、複数のネットワークトラフィックが発生するという点も頻繁に忘れられています。 レプリカが３つのクラスターでは、受信トラフィックが 10 Gbps とすると、送信トラフィックは 30 Gbps ということになります。これを以前のレプリカの帯域幅の需要が<indexterm class=\"singular\"><primary>bandwidth</primary><secondary>プライベート vs. パブリックネットワークの推奨事項</secondary></indexterm>  高いことと合わせて考えると、パブリックネットワークよりもプライベートネットワークのほうがはるかに高い帯域幅が必要であることが分かります。OpenStack Object Storage はパフォーマンスを保つために内部では、暗号化なし、認証なしの rsync と通信します (プライベートネットワークをプライベートに保つため)。"

#: ./doc/openstack-ops/ch_arch_storage.xml168(para)
msgid ""
"The remaining point on bandwidth is the public-facing portion. The <literal"
">swift-proxy</literal> service is stateless, which means that you can easily"
" add more and use HTTP load-balancing methods to share bandwidth and "
"availability between them."
msgstr "帯域幅に関する残りのポイントは、パブリック側の部分です。<literal>swift-proxy</literal> サービスは、ステートレスです。ステートレスとは、HTTP 負荷分散メソッドを簡単に追加、使用して帯域幅や可用性を共有できるという意味です。"

#: ./doc/openstack-ops/ch_arch_storage.xml173(para)
msgid "More proxies means more bandwidth, if your storage can keep up."
msgstr "ストレージ側の性能が十分であれば、proxy server の増加は帯域の増加になります。"

#: ./doc/openstack-ops/ch_arch_storage.xml180(para)
msgid ""
"Block storage (sometimes referred to as volume storage) provides users with "
"access to block-storage devices. Users interact with block storage by "
"attaching volumes to their running VM instances.<indexterm "
"class=\"singular\"><primary>volume storage</primary></indexterm><indexterm "
"class=\"singular\"><primary>block storage</primary></indexterm><indexterm "
"class=\"singular\"><primary>storage</primary><secondary>block "
"storage</secondary></indexterm>"
msgstr "Block storage (ボリュームストレージと呼ばれる場合もある) は、ユーザーがブロックストレージデバイスにアクセスできるようにします。ユーザーは、実行中の仮想マシンインスタンスにボリュームを接続することで、ブロックストレージと対話します。<indexterm class=\"singular\"><primary>ボリュームストレージ</primary></indexterm><indexterm class=\"singular\"><primary>ブロックストレージ</primary></indexterm><indexterm class=\"singular\"><primary>ストレージ</primary><secondary>ブロックストレージ</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_storage.xml193(para)
msgid ""
"These volumes are persistent: they can be detached from one instance and re-"
"attached to another, and the data remains intact. Block storage is "
"implemented in OpenStack by the OpenStack Block Storage (cinder) project, "
"which supports multiple backends in the form of drivers. Your choice of a "
"storage backend must be supported by a Block Storage driver."
msgstr "これらのボリュームは永続的であるため、インスタンスから切り離して、データをそのまま維持しつつ、別のインスタンスに再接続することができます。ブロックストレージは、ドライバー形式で複数のバックエンドをサポートする、OpenStack Block Storage (Cinder) プロジェクトで OpenStack に実装されています。お使いのストレージバックエンドは、Block Storage ドライバーでサポートされている必要があります。"

#: ./doc/openstack-ops/ch_arch_storage.xml200(para)
msgid ""
"Most block storage drivers allow the instance to have direct access to the "
"underlying storage hardware's block device. This helps increase the overall "
"read/write IO."
msgstr "多くのストレージドライバはインスタンスが直接ストレージハードウェアのブロックデバイスへアクセスできるようにします。これは リード/ライト I/O 性能の向上に役立ちます。"

#: ./doc/openstack-ops/ch_arch_storage.xml204(para)
msgid ""
"Experimental support for utilizing files as volumes began in the Folsom "
"release. This initially started as a reference driver for using NFS with "
"cinder. By Grizzly's release, this has expanded into a full NFS driver as "
"well as a GlusterFS driver."
msgstr "ファイルをボリュームとして活用するサポートは、Folsom リリースで試験的に開始されました。これは、Cinder で NFS を使用する参照ドライバーとして始まりました。Grizzly のリリースまでには、完全な NFS ドライバーおよび GlusterFS ドライバーまで展開されました。"

#: ./doc/openstack-ops/ch_arch_storage.xml209(para)
msgid ""
"These drivers work a little differently than a traditional \"block\" storage"
" driver. On an NFS or GlusterFS file system, a single file is created and "
"then mapped as a \"virtual\" volume into the instance. This "
"mapping/translation is similar to how OpenStack utilizes QEMU's file-based "
"virtual machines stored in <code>/var/lib/nova/instances</code>."
msgstr "これらのドライバーは従来のブロックストレージドライバとは少々異なる動作をします。NFSやGlusterFSでは1つのファイルが作成され、インスタンスに対して「仮想」ボリュームとしてマッピングされます。このマッピング/変換は<code>/var/lib/nova/instances</code> 下に保存される、QEMUのファイルベースの仮想マシンの、OpenStackによる扱い方と同様です。"

#: ./doc/openstack-ops/ch_arch_storage.xml219(title)
msgid "OpenStack Storage Concepts"
msgstr "ストレージのコンセプト"

#: ./doc/openstack-ops/ch_arch_storage.xml221(para)
msgid ""
"<xref linkend=\"openstack_storage\"/> explains the different storage "
"concepts provided by OpenStack.<indexterm class=\"singular\"><primary>block "
"device</primary></indexterm><indexterm "
"class=\"singular\"><primary>storage</primary><secondary>overview of "
"concepts</secondary></indexterm>"
msgstr "<xref linkend=\"openstack_storage\"/> は、OpenStack で提供されているさまざまなストレージのコンセプトについて説明しています。<indexterm class=\"singular\"><primary>ブロックデバイス</primary></indexterm><indexterm class=\"singular\"><primary>ストレージ</primary><secondary>oコンセプトの概要</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_storage.xml231(caption)
msgid "OpenStack storage"
msgstr "OpenStack ストレージ"

#: ./doc/openstack-ops/ch_arch_storage.xml237(th)
msgid "Ephemeral storage"
msgstr "エフェメラルストレージ"

#: ./doc/openstack-ops/ch_arch_storage.xml239(th)
msgid "Block storage"
msgstr "ブロックストレージ"

#: ./doc/openstack-ops/ch_arch_storage.xml247(para)
msgid "Used to…"
msgstr "使用目的"

#: ./doc/openstack-ops/ch_arch_storage.xml249(para)
msgid "Run operating system and scratch space"
msgstr "OS を起動し、空き領域に記録する"

#: ./doc/openstack-ops/ch_arch_storage.xml251(para)
msgid "Add additional persistent storage to a virtual machine (VM)"
msgstr "永続的なストレージを仮想マシン（VM）へ追加する"

#: ./doc/openstack-ops/ch_arch_storage.xml254(para)
msgid "Store data, including VM images"
msgstr "データを保存する（VMイメージも含む）"

#: ./doc/openstack-ops/ch_arch_storage.xml258(para)
msgid "Accessed through…"
msgstr "アクセス方法"

#: ./doc/openstack-ops/ch_arch_storage.xml260(para)
msgid "A file system"
msgstr "ファイルシステム"

#: ./doc/openstack-ops/ch_arch_storage.xml262(para)
msgid ""
"A <glossterm>block device</glossterm> that can be partitioned, formatted, "
"and mounted (such as, /dev/vdc)"
msgstr "パーティション分割、フォーマット、マウントが可能な <glossterm>ブロックデバイス</glossterm> (/dev/vdc など)"

#: ./doc/openstack-ops/ch_arch_storage.xml265(para)
msgid "The REST API"
msgstr "REST API"

#: ./doc/openstack-ops/ch_arch_storage.xml269(para)
msgid "Accessible from…"
msgstr "アクセス可能な場所"

#: ./doc/openstack-ops/ch_arch_storage.xml271(para)
#: ./doc/openstack-ops/ch_arch_storage.xml273(para)
msgid "Within a VM"
msgstr "VM内"

#: ./doc/openstack-ops/ch_arch_storage.xml275(para)
msgid "Anywhere"
msgstr "どこからでも"

#: ./doc/openstack-ops/ch_arch_storage.xml279(para)
msgid "Managed by…"
msgstr "管理元"

#: ./doc/openstack-ops/ch_arch_storage.xml281(para)
msgid "OpenStack Compute (nova)"
msgstr "OpenStack Compute (nova)"

#: ./doc/openstack-ops/ch_arch_storage.xml283(para)
msgid "OpenStack Block Storage (cinder)"
msgstr "OpenStack Block Storage (cinder)"

#: ./doc/openstack-ops/ch_arch_storage.xml289(para)
msgid "Persists until…"
msgstr "データの残存期間"

#: ./doc/openstack-ops/ch_arch_storage.xml291(para)
msgid "VM is terminated"
msgstr "VM終了まで"

#: ./doc/openstack-ops/ch_arch_storage.xml293(para)
#: ./doc/openstack-ops/ch_arch_storage.xml295(para)
msgid "Deleted by user"
msgstr "ユーザーが削除するまで"

#: ./doc/openstack-ops/ch_arch_storage.xml299(para)
msgid "Sizing determined by…"
msgstr "容量の指定"

#: ./doc/openstack-ops/ch_arch_storage.xml301(para)
msgid ""
"Administrator configuration of size settings, known as "
"<emphasis>flavors</emphasis>"
msgstr "<emphasis>フレーバー</emphasis> として知られる管理者のサイズ設定"

#: ./doc/openstack-ops/ch_arch_storage.xml304(para)
msgid "User specification in initial request"
msgstr "初回要求のユーザー仕様"

#: ./doc/openstack-ops/ch_arch_storage.xml306(para)
msgid "Amount of available physical storage"
msgstr "利用可能な物理ディスクの総量で決まる"

#: ./doc/openstack-ops/ch_arch_storage.xml310(para)
msgid "Example of typical usage…"
msgstr "典型的な利用例"

#: ./doc/openstack-ops/ch_arch_storage.xml312(para)
msgid "10 GB first disk, 30 GB second disk"
msgstr "1 番目のディスク 10 GB、2 番目のディスク 30 GB"

#: ./doc/openstack-ops/ch_arch_storage.xml314(para)
msgid "1 TB disk"
msgstr "1TBディスク"

#: ./doc/openstack-ops/ch_arch_storage.xml316(para)
msgid "10s of TBs of dataset storage"
msgstr "数十TBのデータセットストレージ"

#: ./doc/openstack-ops/ch_arch_storage.xml322(title)
msgid "File-level Storage (for Live Migration)"
msgstr "ファイルレベルのストレージ (ライブマイグレーション用)"

#: ./doc/openstack-ops/ch_arch_storage.xml324(para)
msgid ""
"With file-level storage, users access stored data using the operating "
"system's file system interface. Most users, if they have used a network "
"storage solution before, have encountered this form of networked storage. In"
" the Unix world, the most common form of this is NFS. In the Windows world, "
"the most common form is called CIFS (previously, SMB).<indexterm "
"class=\"singular\"><primary>migration</primary></indexterm><indexterm "
"class=\"singular\"><primary>live migration</primary></indexterm><indexterm "
"class=\"singular\"><primary>storage</primary><secondary>file-"
"level</secondary></indexterm>"
msgstr "ファイルレベルのストレージでは、ユーザーは、オペレーティングシステムのファイルシステムインターフェースを使用して保存したデータにアクセスします。ネットワークストレージソリューションの使用経験のあるユーザーの多くは、この形式のネットワークストレージを使用したことがあります。Unix の分野では、ネットワークストレージで最も一般的なものが NFS で、Windows では CIFS (旧称 SMB) です。<indexterm class=\"singular\"><primary>migration</primary></indexterm><indexterm class=\"singular\"><primary>ライブマイグレーション</primary></indexterm><indexterm class=\"singular\"><primary>storage</primary><secondary>ファイルレベル</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_storage.xml339(para)
msgid ""
"OpenStack clouds do not present file-level storage to end users. However, it"
" is important to consider file-level storage for storing instances under "
"<code>/var/lib/nova/instances</code> when designing your cloud, since you "
"must have a shared file system if you want to support live migration."
msgstr "OpenStack クラウドは、ファイルレベルのストレージはエンドユーザーには見えませんが、クラウドの設計時に <code>/var/lib/nova/instances</code> の配下にインスタンスを格納する、ファイルレベルのストレージを検討してください。これは、ライブマイグレーションのサポートには、共有ファイルシステムが必要であるためです。"

#: ./doc/openstack-ops/ch_arch_storage.xml348(title)
msgid "Choosing Storage Backends"
msgstr "ストレージバックエンドの選択"

#: ./doc/openstack-ops/ch_arch_storage.xml350(para)
msgid ""
"Users will indicate different needs for their cloud use cases. Some may need"
" fast access to many objects that do not change often, or want to set a "
"time-to-live (TTL) value on a file. Others may access only storage that is "
"mounted with the file system itself, but want it to be replicated instantly "
"when starting a new instance. For other systems, ephemeral storage—storage "
"that is released when a VM attached to it is shut down— is the preferred "
"way. When you select <glossterm>storage backend</glossterm>s, <indexterm "
"class=\"singular\"><primary>storage</primary><secondary>choosing "
"backends</secondary></indexterm><indexterm "
"class=\"singular\"><primary>storage backend</primary></indexterm><indexterm "
"class=\"singular\"><primary>backend "
"interactions</primary><secondary>store</secondary></indexterm>ask the "
"following questions on behalf of your users:"
msgstr "クラウドのユースケースごとにニーズが異なります。頻繁に変更が発生しない多数のオブジェクトに素早くアクセスする必要がある場合、ファイルに Time-to-Live (TTL) の値を設定する場合、ファイルシステムのみにマウントされているストレージのみにアクセスするが、新しいインスタンスの起動時には即時にそのストレージを複製する場合などがあります。他のシステムの場合は、一時ストレージ (ストレージに接続された仮想マシンがシャットダウンされている場合に開放されるストレージ) がより良い方法です。<glossterm>ストレージのバックエンド</glossterm>の選択時は、<indexterm class=\"singular\"><primary>ストレージ</primary><secondary>バックエンドの選択</secondary></indexterm><indexterm class=\"singular\"><primary>ストレージバックエンド</primary></indexterm><indexterm class=\"singular\"><primary>バックエンドの対話</primary><secondary>store</secondary></indexterm>ユーザーの代わりに以下の質問を確認してください。"

#: ./doc/openstack-ops/ch_arch_storage.xml371(para)
msgid "Do my users need block storage?"
msgstr "ユーザがブロックストレージを必要とするか？"

#: ./doc/openstack-ops/ch_arch_storage.xml375(para)
msgid "Do my users need object storage?"
msgstr "ユーザがオブジェクトストレージを必要とするか？"

#: ./doc/openstack-ops/ch_arch_storage.xml379(para)
msgid "Do I need to support live migration?"
msgstr "管理者がライブマイグレーションを必要とするか？"

#: ./doc/openstack-ops/ch_arch_storage.xml383(para)
msgid ""
"Should my persistent storage drives be contained in my compute nodes, or "
"should I use external storage?"
msgstr "永続的ストレージをコンピュートノード内に持つべきか？それとも外部ストレージに持つべきか？"

#: ./doc/openstack-ops/ch_arch_storage.xml388(para)
msgid ""
"What is the platter count I can achieve? Do more spindles result in better "
"I/O despite network access?"
msgstr "実現可能な容量は？ネットワークアクセスでも、より多くのディスクがより良い I/O 性能に繋がるか？"

#: ./doc/openstack-ops/ch_arch_storage.xml393(para)
msgid ""
"Which one results in the best cost-performance scenario I'm aiming for?"
msgstr "どちらが自分の意図した最高のコストパフォーマンスシナリオを実現するか？"

#: ./doc/openstack-ops/ch_arch_storage.xml398(para)
msgid "How do I manage the storage operationally?"
msgstr "ストレージの運用管理をどうするか？"

#: ./doc/openstack-ops/ch_arch_storage.xml402(para)
msgid ""
"How redundant and distributed is the storage? What happens if a storage node"
" fails? To what extent can it mitigate my data-loss disaster scenarios?"
msgstr "ストレージの冗長性と分散をどうするか？ストレージノード障害でどうなるか？災害時、自分のデータ消失をどの程度軽減できるのか？"

#: ./doc/openstack-ops/ch_arch_storage.xml408(para)
msgid ""
"To deploy your storage by using only commodity hardware, you can use a "
"number of open-source packages, as shown in <xref "
"linkend=\"storage_solutions\"/>."
msgstr "<xref linkend=\"storage_solutions\"/>で記載されているように、コモディティハードウェアを使用してストレージをデプロイする場合、オープンソースのパッケージを使用することができます。"

#: ./doc/openstack-ops/ch_arch_storage.xml413(caption)
msgid "Persistent file-based storage support"
msgstr "永続ファイルベースのストレージサポート"

#: ./doc/openstack-ops/ch_arch_storage.xml417(th)
#: ./doc/openstack-ops/ch_arch_storage.xml445(para)
#: ./doc/openstack-ops/ch_arch_storage.xml451(para)
#: ./doc/openstack-ops/ch_arch_storage.xml460(para)
#: ./doc/openstack-ops/ch_arch_storage.xml531(para)
#: ./doc/openstack-ops/ch_arch_storage.xml540(para)
msgid " "
msgstr " "

#: ./doc/openstack-ops/ch_arch_storage.xml419(th)
msgid "Object"
msgstr "オブジェクトストレージ"

#: ./doc/openstack-ops/ch_arch_storage.xml421(th)
msgid "Block"
msgstr "ブロックストレージ"

#: ./doc/openstack-ops/ch_arch_storage.xml424(para)
msgid ""
"This list of open source file-level shared storage solutions is not "
"exhaustive; other open source solutions exist (MooseFS). Your organization "
"may already have deployed a file-level shared storage solution that you can "
"use."
msgstr "オープンソースのファイルレベルの共有ストレージソリューションに関する一覧は完全ではありません。その他のオープンソースソリューションも存在します (MooseFS)。ユーザーの所属組織では、すでにユーザーが使用できるように、ファイルレベルの共有ストレージソリューションがデプロイされている可能性があります。"

#: ./doc/openstack-ops/ch_arch_storage.xml423(th)
msgid "File-level<placeholder-1/>"
msgstr "ファイルレベル<placeholder-1/>"

#: ./doc/openstack-ops/ch_arch_storage.xml434(para)
msgid "Swift"
msgstr "Swift"

#: ./doc/openstack-ops/ch_arch_storage.xml449(para)
msgid "LVM"
msgstr "LVM"

#: ./doc/openstack-ops/ch_arch_storage.xml464(para)
msgid "Ceph"
msgstr "Ceph"

#: ./doc/openstack-ops/ch_arch_storage.xml480(para)
msgid "Experimental"
msgstr "テスト用"

#: ./doc/openstack-ops/ch_arch_storage.xml484(para)
msgid "Gluster"
msgstr "Gluster"

#: ./doc/openstack-ops/ch_arch_storage.xml509(para)
msgid "NFS"
msgstr "NFS"

#: ./doc/openstack-ops/ch_arch_storage.xml529(para)
msgid "ZFS"
msgstr "ZFS"

#: ./doc/openstack-ops/ch_arch_storage.xml543(para)
msgid "Sheepdog"
msgstr "Sheepdog"

#: ./doc/openstack-ops/ch_arch_storage.xml562(title)
msgid "Storage Driver Support"
msgstr "ストレージドライバーズサポート"

#: ./doc/openstack-ops/ch_arch_storage.xml564(para)
msgid ""
"In addition to the open source technologies, there are a number of "
"proprietary solutions that are officially supported by OpenStack Block "
"Storage.<indexterm "
"class=\"singular\"><primary>storage</primary><secondary>storage driver "
"support</secondary></indexterm> They are offered by the following vendors:"
msgstr "オープンソースのテクノロジーに加え、OpenStack Block Storage で正式にサポートされる専用ソリューションが多数存在します。<indexterm class=\"singular\"><primary>ストレージ</primary><secondary>ストレージドライバーのサポート</secondary></indexterm>以下のベンダーによりサポートされています。"

#: ./doc/openstack-ops/ch_arch_storage.xml574(para)
msgid "IBM (Storwize family/SVC, XIV)"
msgstr "IBM (Storwize family/SVC, XIV)"

#: ./doc/openstack-ops/ch_arch_storage.xml578(para)
msgid "NetApp"
msgstr "NetApp"

#: ./doc/openstack-ops/ch_arch_storage.xml582(para)
msgid "Nexenta"
msgstr "Nexenta"

#: ./doc/openstack-ops/ch_arch_storage.xml586(para)
msgid "SolidFire"
msgstr "SolidFire"

#: ./doc/openstack-ops/ch_arch_storage.xml590(para)
msgid ""
"You can find a matrix of the functionality provided by all of the supported "
"Block Storage drivers on the <link "
"href=\"https://wiki.openstack.org/wiki/CinderSupportMatrix\" "
"title=\"OpenStack wiki\">OpenStack wiki</link>."
msgstr "<link href=\"https://wiki.openstack.org/wiki/CinderSupportMatrix\" title=\"OpenStack wiki\">OpenStack wiki</link> で、サポートされている全ブロックストレージドライバーが提供する機能一覧を確認いただけます。"

#: ./doc/openstack-ops/ch_arch_storage.xml596(para)
msgid ""
"Also, you need to decide whether you want to support object storage in your "
"cloud. The two common use cases for providing object storage in a compute "
"cloud are:"
msgstr "クラウド内でオブジェクトストレージの利用を検討する必要があります。コンピュートクラウドで提供されるオブジェクトストレージの一般的な利用方法は以下の二つです。"

#: ./doc/openstack-ops/ch_arch_storage.xml602(para)
msgid "To provide users with a persistent storage mechanism"
msgstr "ユーザに永続的ストレージの仕組みを提供する"

#: ./doc/openstack-ops/ch_arch_storage.xml606(para)
msgid "As a scalable, reliable data store for virtual machine images"
msgstr "スケーラブルで信頼性のある仮想マシンイメージデータストアとして利用する"

#: ./doc/openstack-ops/ch_arch_storage.xml612(title)
msgid "Commodity Storage Backend Technologies"
msgstr "商用ストレージバックエンドのテクノロジー"

#: ./doc/openstack-ops/ch_arch_storage.xml614(para)
msgid ""
"This section provides a high-level overview of the differences among the "
"different commodity storage backend technologies. Depending on your cloud "
"user's needs, you can implement one or many of these technologies in "
"different combinations:<indexterm "
"class=\"singular\"><primary>storage</primary><secondary>commodity "
"storage</secondary></indexterm>"
msgstr "このセクションでは、さまざまな商用ストレージバックエンドテクノロジーにおける相違点をカンタンにまとめます。クラウドユーザーのニーズに合わせて、1 つまたは多数のテクノロジーを組み合わせて実装することができます。<indexterm class=\"singular\"><primary>storage</primary><secondary>commodity storage</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_storage.xml628(para)
msgid ""
"The official OpenStack Object Store implementation. It is a mature "
"technology that has been used for several years in production by Rackspace "
"as the technology behind Rackspace Cloud Files. As it is highly scalable, it"
" is well-suited to managing petabytes of storage. OpenStack Object Storage's"
" advantages are better <phrase role=\"keep-together\">integration</phrase> "
"with OpenStack (integrates with OpenStack Identity, works with the OpenStack"
" dashboard interface) and better support for multiple data center deployment"
" through support of asynchronous eventual consistency replication."
msgstr "公式の OpenStack Object Store 実装。Rackspace Cloud Filesのベースとなる技術として、RackSpace により実稼動環境で数年間使用された成熟テクノロジーです。拡張性が高いため、ペタバイトレベルのストレージを管理するのに非常に適しています。OpenStack Object Storage の利点は OpenStack (OpenStack Identity と統合し、OpenStack Dashboard インターフェースと連携) と<phrase role=\"keep-together\">統合でき</phrase>、非同期のイベントを一貫性を保ちながら複製できるため、複数のデータセンターのデプロイメントへのサポートも向上されています。"

#: ./doc/openstack-ops/ch_arch_storage.xml639(para)
msgid ""
"Therefore, if you eventually plan on distributing your storage cluster "
"across multiple data centers, if you need unified accounts for your users "
"for both compute and object storage, or if you want to control your object "
"storage with the OpenStack dashboard, you should consider OpenStack Object "
"Storage. More detail can be found about OpenStack Object Storage in the "
"section below.<indexterm "
"class=\"singular\"><primary>accounts</primary></indexterm>"
msgstr "そのため、最終的に、複数のデータセンターにまたがってストレージクラスターを分散するように計画した場合、Compute およびオブジェクトストレージ用に統合アカウントが必要な場合、または OpenStack Dashboard でオブジェクトストレージを制御する場合、OpenStack Object Storage を考慮してみてください。以下のセクションで OpenStack Object Storage iについて詳しく記載されています。<indexterm class=\"singular\"><primary>アカウント</primary></indexterm>"

#: ./doc/openstack-ops/ch_arch_storage.xml652(term)
msgid "Ceph<indexterm class=\"singular\"><primary>Ceph</primary></indexterm>"
msgstr "Ceph<indexterm class=\"singular\"><primary>Ceph</primary></indexterm>"

#: ./doc/openstack-ops/ch_arch_storage.xml657(para)
msgid ""
"A scalable storage solution that replicates data across commodity storage "
"nodes. Ceph was originally developed by one of the founders of DreamHost and"
" is currently used in production there."
msgstr "商用ストレージノード全体でデータを複製する拡張性の高いストレージソリューション。Ceph は、DreamHost の創設者により開発され、現在は実稼動環境で使用されています。"

#: ./doc/openstack-ops/ch_arch_storage.xml662(para)
msgid ""
"Ceph was designed to expose different types of storage interfaces to the end"
" user: it supports object storage, block storage, and file-system "
"interfaces, although the file-system interface is not yet considered "
"production-ready. Ceph supports the same API as swift for object storage and"
" can be used as a backend for cinder block storage as well as backend "
"storage for glance images. Ceph supports \"thin provisioning,\" implemented "
"using copy-on-write."
msgstr "Ceph は、異なる種類のストレージインターフェースをエンドユーザーに公開するように設計されました。Ceph は、オブジェクトストレージ、ブロックストレージ、ファイルシステムインターフェースをサポートしていますが、ファイルシステムインターフェースは、実稼動環境での使用にはまだ適していません。Ceph は、オブジェクトストレージでは swift と同じ API をサポートしており、cinder ブロックストレージのバックエンド、glance イメージのバックエンドストレージとして使用することができます。Ceph は、copy-on-write を使用して実装されたシンプロビジョニングをサポートします。"

#: ./doc/openstack-ops/ch_arch_storage.xml671(para)
msgid ""
"This can be useful when booting from volume because a new volume can be "
"provisioned very quickly. Ceph also supports keystone-based authentication "
"(as of version 0.56), so it can be a seamless swap in for the default "
"OpenStack swift implementation."
msgstr "新規ボリュームは非常に早くプロビジョニングされるため、ボリュームからの起動に便利です。また、Ceph は keystone ベースの認証 (バージョン 0.56 以降) もサポートするため、デフォルトの OpenStack swift 実装とシームレスに切り替えることができます。"

#: ./doc/openstack-ops/ch_arch_storage.xml677(para)
msgid ""
"Ceph's advantages are that it gives the administrator more fine-grained "
"control over data distribution and replication strategies, enables you to "
"consolidate your object and block storage, enables very fast provisioning of"
" boot-from-volume instances using thin provisioning, and supports a "
"distributed file-system interface, though this interface is <link "
"href=\"http://ceph.com/docs/master/cephfs/\" title=\"OpenStack wiki\">not "
"yet recommended</link> for use in production deployment by the Ceph project."
msgstr "Ceph の利点は、管理者がより細かくデータの分散やレプリカのストラテジーを管理できるようになり、オブジェクトとブロックストレージを統合し、シンプロビジョニングでボリュームから起動するインスタンスを非常に早くプロビジョニングできるだけでなく、分散ファイルシステムのインターフェースもサポートしている点です。ただし、このインターフェースは、Ceph プロジェクトによる実稼動デプロイメントでの使用には、 <link href=\"http://ceph.com/docs/master/cephfs/\" title=\"OpenStack wiki\">推奨されていません</link>。"

#: ./doc/openstack-ops/ch_arch_storage.xml687(para)
msgid ""
"If you want to manage your object and block storage within a single system, "
"or if you want to support fast boot-from-volume, you should consider Ceph."
msgstr "単一システムでオブジェクトストレージとブロックストレージを管理する場合、またはボリュームから素早く起動するサポートが必要な場合、Ceph の使用を検討してください。"

#: ./doc/openstack-ops/ch_arch_storage.xml694(term)
msgid ""
"Gluster<indexterm "
"class=\"singular\"><primary>GlusterFS</primary></indexterm>"
msgstr "Gluster<indexterm class=\"singular\"><primary>GlusterFS</primary></indexterm>"

#: ./doc/openstack-ops/ch_arch_storage.xml699(para)
msgid ""
"A distributed, shared file system. As of Gluster version 3.3, you can use "
"Gluster to consolidate your object storage and file storage into one unified"
" file and object storage solution, which is called Gluster For OpenStack "
"(GFO). GFO uses a customized version of swift that enables Gluster to be "
"used as the backend storage."
msgstr "分散型の共有ファイルシステム。Gluster バージョン 3.3 以降、Gluster を使用して、オブジェクトストレージとファイルストレージを1 つの統合ファイルとオブジェクトストレージソリューションにまとめることができるようになりました。これはGluster For OpenStack (GFO) と呼ばれます。GFO は、swift のカスタマイズバージョンを使用しており、Gluster がバックエンドストレージを使用できるようになっています。"

#: ./doc/openstack-ops/ch_arch_storage.xml706(para)
msgid ""
"The main reason to use GFO rather than regular swift is if you also want to "
"support a distributed file system, either to support shared storage live "
"migration or to provide it as a separate service to your end users. If you "
"want to manage your object and file storage within a single system, you "
"should consider GFO."
msgstr "通常の swift ではなく GFO を使用するのは、主に、分散ファイルシステムのサポートや、共有ストレージのライブマイグレーションのサポートを提供したり、エンドユーザーに個別サービスとして提供したりするためです。単一システムでオブジェクトとファイルストレージを管理する場合は、GFO の使用を検討してください。"

#: ./doc/openstack-ops/ch_arch_storage.xml716(term)
msgid ""
"LVM<indexterm class=\"singular\"><primary>LVM (Logical Volume "
"Manager)</primary></indexterm>"
msgstr "LVM<indexterm class=\"singular\"><primary>LVM (Logical Volume Manager)</primary></indexterm>"

#: ./doc/openstack-ops/ch_arch_storage.xml721(para)
msgid ""
"The Logical Volume Manager is a Linux-based system that provides an "
"abstraction layer on top of physical disks to expose logical volumes to the "
"operating system. The LVM backend implements block storage as LVM logical "
"partitions."
msgstr "論理ボリュームマネージャー (LVM) は Linux ベースのシステムで、物理ディスク上に抽象層を提供して論理ボリュームをオペレーティングシステムに公開します。LVM バックエンドは、LVM 論理パーティションとしてブロックストレージを実装します。"

#: ./doc/openstack-ops/ch_arch_storage.xml726(para)
msgid ""
"On each host that will house block storage, an administrator must initially "
"create a volume group dedicated to Block Storage volumes. Blocks are created"
" from LVM logical volumes."
msgstr "ブロックストレージを収容する各ホストでは、管理者は事前にブロックストレージ専用のボリュームグループを作成しておく必要があります。ブロックストレージはLVM論理ボリュームから作られます。"

#: ./doc/openstack-ops/ch_arch_storage.xml731(para)
msgid ""
"LVM does <emphasis>not</emphasis> provide any replication. Typically, "
"administrators configure RAID on nodes that use LVM as block storage to "
"protect against failures of individual hard drives. However, RAID does not "
"protect against a failure of the entire host."
msgstr "LVMはレプリケーションを<emphasis>提供しません</emphasis>。通常、管理者はブロックストレージとしてLVMを利用するホスト上にRAIDを構成し、ここのハードディスク障害からブロックストレージを保護します。しかしRAIDではホストそのものの障害には対応できません。"

#: ./doc/openstack-ops/ch_arch_storage.xml741(term)
msgid "ZFS<indexterm class=\"singular\"><primary>ZFS</primary></indexterm>"
msgstr "ZFS<indexterm class=\"singular\"><primary>ZFS</primary></indexterm>"

#: ./doc/openstack-ops/ch_arch_storage.xml746(para)
msgid ""
"The Solaris iSCSI driver for OpenStack Block Storage implements blocks as "
"ZFS entities. ZFS is a file system that also has the functionality of a "
"volume manager. This is unlike on a Linux system, where there is a "
"separation of volume manager (LVM) and file system (such as, ext3, ext4, "
"xfs, and btrfs). ZFS has a number of advantages over ext4, including "
"improved data-integrity checking."
msgstr "OpenStack Block Storage 用の Solaris iSCSI ドライバーは、ZFS エンティティーとしてブロックを実装します。ZFS は、ボリュームManagerの機能が備わっているファイルシステムです。これは、ボリュームマネージャー (LVM) およびファイルシステム (ext3、ext4、xfs、btrfs など) が分離している Linux システムとは違います。ZFS は、向上されたデータ整合性チェックなど、ext4 よりも多数利点があります。"

#: ./doc/openstack-ops/ch_arch_storage.xml754(para)
msgid ""
"The ZFS backend for OpenStack Block Storage supports only Solaris-based "
"systems, such as Illumos. While there is a Linux port of ZFS, it is not "
"included in any of the standard Linux distributions, and it has not been "
"tested with OpenStack Block Storage. As with LVM, ZFS does not provide "
"replication across hosts on its own; you need to add a replication solution "
"on top of ZFS if your cloud needs to be able to handle storage-node "
"failures."
msgstr "OpenStack Block Storage の ZFS バックエンドは、Illumos などの Solaris ベースのシステムのみをサポートします。ZFS の Linux ポートは存在するものの、標準の Linux ディストリビューションには含まれておらず、OpenStack Block Storage ではテストされていません。LVM では、ZFS はこれだけではホスト間の複製ができません。つまり、お使いのクラウドでストレージノードの問題を処理する機能が必要な場合、ZFS に複製ソリューションを追加する必要があります。"

#: ./doc/openstack-ops/ch_arch_storage.xml763(para)
msgid ""
"We don't recommend ZFS unless you have previous experience with deploying "
"it, since the ZFS backend for Block Storage requires a Solaris-based "
"operating system, and we assume that your experience is primarily with "
"Linux-based systems."
msgstr "本書は、Linux ベースシステムを主に使用するユーザーを想定しており、Block Storage の ZFS バックエンドには Solaris ベースのオペレーティングシステムが必要であるため、ZFS でのデプロイ経験がない場合は、ZFS は推奨していません。"

#: ./doc/openstack-ops/ch_arch_storage.xml776(para)
msgid ""
"We hope that you now have some considerations in mind and questions to ask "
"your future cloud users about their storage use cases. As you can see, your "
"storage decisions will also influence your network design for performance "
"and security needs. Continue with us to make more informed decisions about "
"your OpenStack cloud <phrase role=\"keep-together\">design</phrase>."
msgstr "今後のクラウドユーザーにストレージのユースケースに関する質問事項および、懸念点など理解いただけたかと思います。ストレージの決定はパフォーマンスやセキュリティのニーズにあったネットワーク設計をする際に影響を与えます。OpenStack クラウド <phrase role=\"keep-together\">設計</phrase> について理解したうえで意思決定が行えるように、本書を読み進めてください。"

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/ch_ops_projects_users.xml110(None)
msgid ""
"@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc"
"/openstack-ops/figures/osog_0901.png'; md5=THIS FILE DOESN'T EXIST"
msgstr "@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/openstack-ops/figures/osog_0901.png'; md5=THIS FILE DOESN'T EXIST"

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/ch_ops_projects_users.xml866(None)
msgid ""
"@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc"
"/openstack-ops/figures/osog_0902.png'; md5=THIS FILE DOESN'T EXIST"
msgstr "@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc/openstack-ops/figures/osog_0902.png'; md5=THIS FILE DOESN'T EXIST"

#: ./doc/openstack-ops/ch_ops_projects_users.xml12(title)
msgid "Managing Projects and Users"
msgstr "プロジェクトとユーザーの管理"

#: ./doc/openstack-ops/ch_ops_projects_users.xml14(para)
msgid ""
"An OpenStack cloud does not have much value without users. This chapter "
"covers topics that relate to managing users, projects, and quotas. This "
"chapter describes users and projects as described by version 2 of the "
"OpenStack Identity API."
msgstr "OpenStack クラウドは、ユーザーなしでは特に価値はありません。本章では、ユーザー、プロジェクト、クォータの管理に関するトピックを記載します。また、OpenStack Identity API のバージョン 2 で説明されているように、ユーザーとプロジェクトについても説明します。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml20(para)
msgid ""
"While version 3 of the Identity API is available, the client tools do not "
"yet implement those calls, and most OpenStack clouds are still implementing "
"Identity API v2.0.<indexterm class=\"singular\"><primary>Identity "
"Service</primary><secondary>Identity Service API</secondary></indexterm>"
msgstr "Identity API バージョン 3 が利用できますが、クライアントツールにはこれらの呼び出しがまだ実装されておらず、多くの OpenStack クラウドは Identity API v2.0 を実装しています。<indexterm class=\"singular\"><primary>Identity Service</primary><secondary>Identity Service API</secondary></indexterm>"

#: ./doc/openstack-ops/ch_ops_projects_users.xml30(title)
msgid "Projects or Tenants?"
msgstr "プロジェクトかテナントか?"

#: ./doc/openstack-ops/ch_ops_projects_users.xml32(para)
msgid ""
"In OpenStack user interfaces and documentation, a group of users is referred"
" to as a <glossterm>project</glossterm> or <glossterm>tenant</glossterm>. "
"These terms are interchangeable.<indexterm class=\"singular\"><primary>user "
"management</primary><secondary>terminology "
"for</secondary></indexterm><indexterm "
"class=\"singular\"><primary>tenant</primary><secondary>definition "
"of</secondary></indexterm><indexterm "
"class=\"singular\"><primary>projects</primary><secondary>definition "
"of</secondary></indexterm>"
msgstr "OpenStack ユーザーインターフェースとドキュメントでは、ユーザーのグループは <glossterm>プロジェクト</glossterm> または <glossterm>テナント</glossterm> と呼ばれます。これらの用語は同義です。<indexterm class=\"singular\"><primary>ユーザー管理</primary><secondary>用語</secondary></indexterm><indexterm class=\"singular\"><primary>テナント</primary><secondary>定義</secondary></indexterm><indexterm class=\"singular\"><primary>プロジェクト</primary><secondary>定義</secondary></indexterm>"

#: ./doc/openstack-ops/ch_ops_projects_users.xml49(para)
msgid ""
"The initial implementation of the OpenStack Compute Service (nova) had its "
"own authentication system and used the term <literal>project</literal>. When"
" authentication moved into the OpenStack Identity Service (keystone) "
"project, it used the term <literal>tenant</literal> to refer to a group of "
"users. Because of this legacy, some of the OpenStack tools refer to projects"
" and some refer to tenants."
msgstr "OpenStack Compute サービス (Nova) の初期実装は独自の認証システムを持ち、<literal>プロジェクト</literal>という用語を使用していました。認証が OpenStack Identity サービス (Keystone) プロジェクトに移行したとき、ユーザーのグループを意味する用語として<literal>テナント</literal>という用語が使用されました。このような経緯のため、いくつかの OpenStack ツールはプロジェクトを使用し、いくつかはテナントを使用します。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml58(para)
msgid ""
"This guide uses the term <literal>project</literal>, unless an example shows"
" interaction with a tool that uses the term <literal>tenant</literal>."
msgstr "このガイドは<literal>プロジェクト</literal>という用語を使用します。<literal>テナント</literal>という用語を使用するツールとやりとりする例もあります。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml65(title)
msgid "Managing Projects"
msgstr "プロジェクトの管理"

#: ./doc/openstack-ops/ch_ops_projects_users.xml67(para)
msgid ""
"Users must be associated with at least one project, though they may belong "
"to many. Therefore, you should add at least one project before adding "
"users.<indexterm class=\"singular\"><primary>user "
"management</primary><secondary>adding projects</secondary></indexterm>"
msgstr "ユーザーは、多数のプロジェクトに所属することは可能ですが、最低でも 1 つのプロジェクトと関連付ける必要があります。そのため、ユーザー追加の前にプロジェクトを 1 つ追加しておく必要があります。<indexterm class=\"singular\"><primary>ユーザー管理</primary><secondary>プロジェクトの追加</secondary></indexterm>"

#: ./doc/openstack-ops/ch_ops_projects_users.xml76(title)
msgid "Adding Projects"
msgstr "プロジェクトの追加"

#: ./doc/openstack-ops/ch_ops_projects_users.xml78(para)
msgid "To create a project through the OpenStack dashboard:"
msgstr "OpenStack Dashboard でプロジェクトを作成します。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml82(para)
msgid "Log in as an administrative user."
msgstr "管理ユーザーとしてログインします。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml86(para)
msgid "Select the <guilabel>Admin</guilabel> tab in the left navigation bar."
msgstr "左側にあるナビゲーションバーの <guilabel>管理</guilabel> タブを選択します。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml91(para)
msgid "Under Identity Panel, click <guilabel>Projects</guilabel>."
msgstr "認証パネルの <guilabel>プロジェクト</guilabel> をクリックします。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml96(para)
msgid "Click the <guibutton>Create Project</guibutton> button."
msgstr "<guibutton>プロジェクトの作成</guibutton> ボタンをクリックします。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml100(para)
msgid ""
"You are prompted for a project name and an optional, but recommended, "
"description. Select the checkbox at the bottom of the form to enable this "
"project. By default, it is enabled, as shown in <xref linkend=\"horizon-add-"
"project\"/>."
msgstr "プロジェクト名および任意の説明 (推奨) が要求されます。フォームの一番下のチェックボックスを選択してこのプロジェクトを有効にします。<xref linkend=\"horizon-add-project\"/>のように、デフォルトでは、有効になっています。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml106(title)
msgid "Dashboard's Create Project form"
msgstr "Dashboard のプロジェクトの作成フォーム"

#: ./doc/openstack-ops/ch_ops_projects_users.xml115(para)
msgid ""
"It is also possible to add project members and adjust the project quotas. "
"We'll discuss those actions later, but in practice, it can be quite "
"convenient to deal with all these operations at one time."
msgstr "プロジェクトメンバーの追加やプロジェクトのクォータの調節も可能です。このようなアクションについては後ほど説明しますが、実際にこれらの操作を扱うと非常に便利です。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml119(para)
msgid ""
"To add a project through the command line, you must use the keystone "
"utility, which uses <literal>tenant</literal> in place of "
"<literal>project</literal>:"
msgstr "コマンドラインでプロジェクトを追加するには、<literal>project</literal> の代わりに <literal>tenant</literal> を使用する keystone ユーティリティを使用する必要があります。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml125(para)
msgid ""
"This command creates a project named \"demo.\" Optionally, you can add a "
"description string by appending <code>--description <replaceable>tenant-"
"description</replaceable></code>, which can be very useful. You can also "
"create a group in a disabled state by appending <code>--enabled false</code>"
" to the command. By default, projects are created in an enabled state."
msgstr "このコマンドは、demo という名前のプロジェクトを作成します。オプションで、<code>--description <replaceable>tenant-description</replaceable></code> を追加することで、説明の文字列を追加することができ、非常に便利です。また、コマンドに <code>--enabled false</code> を追加して、グループを無効な状態で作成することもできます。デフォルトでは、有効化された状態でプロジェクトが作成されます。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml135(title)
msgid "Quotas"
msgstr "クォータ"

#: ./doc/openstack-ops/ch_ops_projects_users.xml137(para)
msgid ""
"To prevent system capacities from being exhausted without notification, you "
"can set up <glossterm baseform=\"quota\">quotas</glossterm>. Quotas are "
"operational limits. For example, the number of gigabytes allowed per tenant "
"can be controlled to ensure that a single tenant cannot consume all of the "
"disk space. Quotas are currently enforced at the tenant (or project) level, "
"rather than the user level.<indexterm class=\"startofrange\" "
"xml:id=\"quotas9\"><primary>quotas</primary></indexterm><indexterm "
"class=\"singular\"><primary>user "
"management</primary><secondary>quotas</secondary></indexterm>"
msgstr "システムの容量が通知なしに完全に消費されないように、<glossterm baseform=\"quota\">クォータ</glossterm> を設定することができます。クォータとは、運用上の制限値です。たとえば、各テナントに許容される容量 (GB) を制御して、単一のテナントで全ディスク容量すべてが消費されないようにします。現在、ユーザーレベルではなく、テナント (またはプロジェクト) レベルで、クォータを有効にすることができます。<indexterm class=\"startofrange\" xml:id=\"quotas9\"><primary>クォータ</primary></indexterm><indexterm class=\"singular\"><primary>ユーザー管理</primary><secondary>クォータ</secondary></indexterm>"

#: ./doc/openstack-ops/ch_ops_projects_users.xml152(para)
msgid ""
"Because without sensible quotas a single tenant could use up all the "
"available resources, default quotas are shipped with OpenStack. You should "
"pay attention to which quota settings make sense for your hardware "
"capabilities."
msgstr "妥当なクォータがないと、単一のテナントが利用可能なリソースをすべて使用してしまう可能性があるため、デフォルトのクォータが OpenStack には含まれています。お使いのハードウェア機能には、どのクォータ設定が適切か注意してください。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml158(para)
msgid ""
"Using the command-line interface, you can manage quotas for the OpenStack "
"Compute Service and the Block Storage Service."
msgstr "コマンドラインインターフェースを使って、OpenStack Compute サービスと Block Storage サービスのクォータを管理できます。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml161(para)
msgid ""
"Typically, default values are changed because a tenant requires more than "
"the OpenStack default of 10 volumes per tenant, or more than the OpenStack "
"default of 1 TB of disk space on a compute node."
msgstr "テナントには、10 個を超える Block Storage ボリュームまたはコンピュートノードで 1 TB 以上が必要であるため、通常クラウドのオペレーターはデフォルト値を変更します。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml166(para)
msgid "To view all tenants, run: <placeholder-1/>"
msgstr "全てのテナントを表示するには、以下のコマンドを実行します。<placeholder-1/>"

#: ./doc/openstack-ops/ch_ops_projects_users.xml180(title)
msgid "Set Image Quotas"
msgstr "イメージクォータの設定"

#: ./doc/openstack-ops/ch_ops_projects_users.xml182(para)
msgid ""
"OpenStack Havana introduced a basic quota feature for the Image service, so "
"you can now restrict a project's image storage by total number of bytes. "
"Currently, this quota is applied cloud-wide, so if you were to set an Image "
"quota limit of 5 GB, then all projects in your cloud will be able to store "
"only 5 GB of images and snapshots.<indexterm "
"class=\"singular\"><primary>Image Service</primary><secondary>quota "
"setting</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml193(para)
msgid ""
"To enable this feature, edit the <filename>/etc/glance/glance-"
"api.conf</filename> file, and under the [DEFAULT] section, add:"
msgstr "この機能を有効にするには、<filename>/etc/glance/glance-api.conf</filename> ファイルを編集して [DEFAULT] セクションに以下を追加します。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml199(para)
msgid "For example, to restrict a project's image storage to 5 GB, do this:"
msgstr "たとえば、プロジェクトのイメージストレージを 5GB に制限するには、以下を実行します。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml205(para)
msgid ""
"In the Icehouse release, there is a configuration option in <filename"
">glance-api.conf</filename> that limits the number of members allowed per "
"image, called <code>image_member_quota</code>, set to 128 by default. That "
"setting is a different quota from the storage quota.<indexterm "
"class=\"singular\"><primary>Icehouse</primary><secondary>image "
"quotas</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml218(title)
msgid "Set Compute Service Quotas"
msgstr "コンピュートサービスのクォータの設定"

#: ./doc/openstack-ops/ch_ops_projects_users.xml220(para)
msgid ""
"As an administrative user, you can update the Compute Service quotas for an "
"existing tenant, as well as update the quota defaults for a new "
"tenant.<indexterm "
"class=\"singular\"><primary>Compute</primary><secondary>Compute "
"Service</secondary></indexterm> See <xref linkend=\"compute-quota-table\"/>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml229(caption)
msgid "Compute quota descriptions"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml239(th)
msgid "Quota"
msgstr "クォータ"

#: ./doc/openstack-ops/ch_ops_projects_users.xml243(th)
#: ./doc/openstack-ops/ch_ops_projects_users.xml611(th)
msgid "Property name"
msgstr "プロパティ名"

#: ./doc/openstack-ops/ch_ops_projects_users.xml249(para)
msgid "Fixed IPs"
msgstr "固定 IP"

#: ./doc/openstack-ops/ch_ops_projects_users.xml251(para)
msgid ""
"Number of fixed IP addresses allowed per tenant. This number must be equal "
"to or greater than the number of allowed instances."
msgstr "テナント毎の固定 IP アドレスの最大数。この数はテナント毎の最大インスタンス数以上にしなければなりません。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml255(systemitem)
msgid "fixed-ips"
msgstr "fixed-ips"

#: ./doc/openstack-ops/ch_ops_projects_users.xml261(para)
msgid "Number of floating IP addresses allowed per tenant."
msgstr "テナントごとの最大 Floating IP 数"

#: ./doc/openstack-ops/ch_ops_projects_users.xml264(systemitem)
msgid "floating-ips"
msgstr "floating-ips"

#: ./doc/openstack-ops/ch_ops_projects_users.xml268(para)
msgid "Injected file content bytes"
msgstr "注入ファイルのコンテンツ (バイト)"

#: ./doc/openstack-ops/ch_ops_projects_users.xml270(para)
msgid "Number of content bytes allowed per injected file."
msgstr "injected file あたりの最大バイト数"

#: ./doc/openstack-ops/ch_ops_projects_users.xml273(systemitem)
msgid "injected-file-content-bytes"
msgstr "injected-file-content-bytes"

#: ./doc/openstack-ops/ch_ops_projects_users.xml278(para)
msgid "Injected file path bytes"
msgstr "注入ファイルのパス (バイト)"

#: ./doc/openstack-ops/ch_ops_projects_users.xml280(para)
msgid "Number of bytes allowed per injected file path."
msgstr "injected file のパス長の最大バイト数"

#: ./doc/openstack-ops/ch_ops_projects_users.xml283(systemitem)
msgid "injected-file-path-bytes"
msgstr "injected-file-path-bytes"

#: ./doc/openstack-ops/ch_ops_projects_users.xml288(para)
msgid "Injected files"
msgstr "注入ファイル"

#: ./doc/openstack-ops/ch_ops_projects_users.xml290(para)
msgid "Number of injected files allowed per tenant."
msgstr "injected file の最大数"

#: ./doc/openstack-ops/ch_ops_projects_users.xml292(systemitem)
msgid "injected-files"
msgstr "injected-files"

#: ./doc/openstack-ops/ch_ops_projects_users.xml298(para)
msgid "Number of instances allowed per tenant."
msgstr "テナントごとの最大インスタンス数"

#: ./doc/openstack-ops/ch_ops_projects_users.xml304(para)
msgid "Key pairs"
msgstr "キーペア"

#: ./doc/openstack-ops/ch_ops_projects_users.xml306(para)
msgid "Number of key pairs allowed per user."
msgstr "ユーザーごとの最大キーペア数"

#: ./doc/openstack-ops/ch_ops_projects_users.xml308(systemitem)
msgid "key-pairs"
msgstr "key-pairs"

#: ./doc/openstack-ops/ch_ops_projects_users.xml312(para)
msgid "Metadata items"
msgstr "メタデータ項目"

#: ./doc/openstack-ops/ch_ops_projects_users.xml314(para)
msgid "Number of metadata items allowed per instance."
msgstr "インスタンスごとのメタデータ項目数"

#: ./doc/openstack-ops/ch_ops_projects_users.xml317(systemitem)
msgid "metadata-items"
msgstr "metadata-items"

#: ./doc/openstack-ops/ch_ops_projects_users.xml321(para)
msgid "RAM"
msgstr "メモリー"

#: ./doc/openstack-ops/ch_ops_projects_users.xml323(para)
msgid "Megabytes of instance RAM allowed per tenant."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml326(systemitem)
msgid "ram"
msgstr "ram"

#: ./doc/openstack-ops/ch_ops_projects_users.xml330(para)
msgid "Security group rules"
msgstr "セキュリティグループルール"

#: ./doc/openstack-ops/ch_ops_projects_users.xml332(para)
msgid "Number of rules per security group."
msgstr "セキュリティグループごとのセキュリティルール数"

#: ./doc/openstack-ops/ch_ops_projects_users.xml334(systemitem)
msgid "security-group-rules"
msgstr "security-group-rules"

#: ./doc/openstack-ops/ch_ops_projects_users.xml339(para)
msgid "Security groups"
msgstr "セキュリティグループ"

#: ./doc/openstack-ops/ch_ops_projects_users.xml341(para)
msgid "Number of security groups per tenant."
msgstr "テナントごとのセキュリティグループ数"

#: ./doc/openstack-ops/ch_ops_projects_users.xml343(systemitem)
msgid "security-groups"
msgstr "security-groups"

#: ./doc/openstack-ops/ch_ops_projects_users.xml349(para)
msgid "Number of instance cores allowed per tenant."
msgstr "テナントごとのインスタンスのコア数"

#: ./doc/openstack-ops/ch_ops_projects_users.xml351(systemitem)
msgid "cores"
msgstr "cores"

#: ./doc/openstack-ops/ch_ops_projects_users.xml357(title)
msgid "View and update compute quotas for a tenant (project)"
msgstr "テナント (プロジェクト) のコンピュートクォータの表示/更新"

#: ./doc/openstack-ops/ch_ops_projects_users.xml359(para)
msgid ""
"As an administrative user, you can use the <literal>nova quota-*</literal> "
"commands, which are provided by the <literal>python-novaclient</literal> "
"package, to view and update tenant quotas."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml365(title)
msgid "To view and update default quota values"
msgstr "デフォルトのクォータ値の表示と更新"

#: ./doc/openstack-ops/ch_ops_projects_users.xml368(para)
#: ./doc/openstack-ops/ch_ops_projects_users.xml656(para)
msgid "List all default quotas for all tenants, as follows:"
msgstr "全テナントに対するクォータのデフォルト値を全て表示するには、以下のようにします。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml394(para)
msgid "Update a default value for a new tenant, as follows:"
msgstr "新規テナントに対するクォータのデフォルト値を更新するには、以下のようにします。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml396(replaceable)
msgid "value"
msgstr "value"

#: ./doc/openstack-ops/ch_ops_projects_users.xml407(title)
msgid "To view quota values for a tenant (project)"
msgstr "テナント (プロジェクト) のクォータ値の表示"

#: ./doc/openstack-ops/ch_ops_projects_users.xml410(para)
#: ./doc/openstack-ops/ch_ops_projects_users.xml704(para)
msgid "Place the tenant ID in a useable variable, as follows:"
msgstr "テナント ID を変数に格納しておきます。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml413(replaceable)
#: ./doc/openstack-ops/ch_ops_projects_users.xml450(replaceable)
#: ./doc/openstack-ops/ch_ops_projects_users.xml685(replaceable)
#: ./doc/openstack-ops/ch_ops_projects_users.xml707(replaceable)
msgid "tenantName"
msgstr "tenantName"

#: ./doc/openstack-ops/ch_ops_projects_users.xml417(para)
msgid "List the currently set quota values for a tenant, as follows:"
msgstr "テナントの現在のクォータ値を一覧表示します。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml445(title)
msgid "To update quota values for a tenant (project)"
msgstr "テナント (プロジェクト) のクォータ値の更新"

#: ./doc/openstack-ops/ch_ops_projects_users.xml448(para)
msgid "Obtain the tenant ID, as follows:"
msgstr "テナント ID を取得します。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml454(para)
#: ./doc/openstack-ops/ch_ops_projects_users.xml711(para)
msgid "Update a particular quota value, as follows:"
msgstr "指定したクォータ値を更新します。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml456(replaceable)
#: ./doc/openstack-ops/ch_ops_projects_users.xml713(replaceable)
msgid "quotaName"
msgstr "quotaName"

#: ./doc/openstack-ops/ch_ops_projects_users.xml456(replaceable)
msgid "quotaValue"
msgstr "quotaValue"

#: ./doc/openstack-ops/ch_ops_projects_users.xml456(replaceable)
#: ./doc/openstack-ops/ch_ops_projects_users.xml713(replaceable)
msgid "tenantID"
msgstr "tenantID"

#: ./doc/openstack-ops/ch_ops_projects_users.xml480(para)
msgid ""
"To view a list of options for the <literal>quota-update</literal> command, "
"run:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml491(title)
msgid "Set Object Storage Quotas"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml493(para)
msgid ""
"Object Storage quotas were introduced in Swift 1.8 (OpenStack Grizzly). "
"There are currently two categories of quotas for Object Storage:<indexterm "
"class=\"singular\"><primary>account quotas</primary></indexterm><indexterm "
"class=\"singular\"><primary>containers</primary><secondary>quota "
"setting</secondary></indexterm><indexterm class=\"singular\"><primary>Object"
" Storage</primary><secondary>quota setting</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml509(term)
msgid "Container quotas"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml512(para)
msgid ""
"Limit the total size (in bytes) or number of objects that can be stored in a"
" single container."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml518(term)
msgid "Account quotas"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml521(para)
msgid ""
"Limit the total size (in bytes) that a user has available in the Object "
"Storage <phrase role=\"keep-together\">service</phrase>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml528(para)
msgid ""
"To take advantage of either container quotas or account quotas, your Object "
"Storage proxy server must have <code>container_quotas</code> or "
"<code>account_quotas</code> (or both) added to the "
"<literal>[pipeline:main]</literal> pipeline. Each quota type also requires "
"its own section in the <filename>proxy-server.conf</filename> file:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml545(para)
msgid ""
"To view and update Object Storage quotas, use the <code>swift</code> command"
" provided by the <code>python-swiftclient</code> package. Any user included "
"in the project can view the quotas placed on their project. To update Object"
" Storage quotas on a project, you must have the role of ResellerAdmin in the"
" project that the quota is being applied to."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml554(para)
msgid "To view account quotas placed on a project:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml567(para)
msgid "To apply or update account quotas on a project:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml572(para)
msgid "For example, to place a 5 GB quota on an account:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml577(para)
msgid ""
"To verify the quota, run the <literal>swift stat</literal> command again:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml593(title)
msgid "Set Block Storage Quotas"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml595(para)
msgid ""
"As an administrative user, you can update the Block Storage Service quotas "
"for a tenant, as well as update the quota defaults for a new tenant. See "
"<xref linkend=\"block-storage-quota-table\"/>.<indexterm "
"class=\"singular\"><primary>Block Storage</primary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml603(caption)
msgid "Block Storage quota descriptions"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml619(para)
msgid "gigabytes"
msgstr "gigabytes"

#: ./doc/openstack-ops/ch_ops_projects_users.xml621(para)
msgid "Number of volume gigabytes allowed per tenant"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml626(para)
msgid "snapshots"
msgstr "snapshots"

#: ./doc/openstack-ops/ch_ops_projects_users.xml628(para)
msgid "Number of Block Storage snapshots allowed per tenant."
msgstr "テナントごとのブロックストレージスナップショット数"

#: ./doc/openstack-ops/ch_ops_projects_users.xml633(para)
msgid "volumes"
msgstr "volumes"

#: ./doc/openstack-ops/ch_ops_projects_users.xml635(para)
msgid "Number of Block Storage volumes allowed per tenant"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml644(title)
msgid "View and update Block Storage quotas for a tenant (project)"
msgstr "Block Storage サービスのテナント (プロジェクト) の クォータの表示と更新"

#: ./doc/openstack-ops/ch_ops_projects_users.xml647(para)
msgid ""
"As an administrative user, you can use the <literal>cinder quota-*</literal>"
" commands, which are provided by the <literal>python-cinderclient</literal> "
"package, to view and update tenant quotas."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml653(title)
msgid "To view and update default Block Storage quota values"
msgstr "Block Storage のデフォルトのクォータ値の表示と更新"

#: ./doc/openstack-ops/ch_ops_projects_users.xml673(para)
msgid ""
"To update a default value for a new tenant, update the property in the "
"<filename>/etc/cinder/cinder.conf</filename> file."
msgstr "新規テナントのクォータのデフォルト値を更新するには、<filename>/etc/cinder/cinder.conf</filename> ファイルの対応する項目を更新します。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml680(title)
msgid "To view Block Storage quotas for a tenant (project)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml683(para)
msgid "View quotas for the tenant, as follows:"
msgstr "特定のテナントのクォータを表示するには以下のようにします。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml701(title)
msgid "To update Block Storage quotas for a tenant (project)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml713(replaceable)
msgid "NewValue"
msgstr "NewValue"

#: ./doc/openstack-ops/ch_ops_projects_users.xml715(para)
msgid "For example:<indexterm class=\"endofrange\" startref=\"quotas9\"/>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml734(title)
msgid "User Management"
msgstr "ユーザー管理"

#: ./doc/openstack-ops/ch_ops_projects_users.xml736(para)
msgid ""
"The command-line tools for managing users are inconvenient to use directly. "
"They require issuing multiple commands to complete a single task, and they "
"use UUIDs rather than symbolic names for many items. In practice, humans "
"typically do not use these tools directly. Fortunately, the OpenStack "
"dashboard provides a reasonable interface to this. In addition, many sites "
"write custom tools for local needs to enforce local policies and provide "
"levels of self-service to users that aren't currently available with "
"packaged tools.<indexterm class=\"singular\"><primary>user "
"management</primary><secondary>creating new users</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml751(title)
msgid "Creating New Users"
msgstr "新規ユーザーの作成"

#: ./doc/openstack-ops/ch_ops_projects_users.xml753(para)
msgid "To create a user, you need the following information:"
msgstr "ユーザーを作成するには、以下の情報が必要です。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml757(para)
msgid "Username"
msgstr "ユーザー名"

#: ./doc/openstack-ops/ch_ops_projects_users.xml761(para)
msgid "Email address"
msgstr "電子メールアドレス"

#: ./doc/openstack-ops/ch_ops_projects_users.xml765(para)
msgid "Password"
msgstr "パスワード"

#: ./doc/openstack-ops/ch_ops_projects_users.xml769(para)
msgid "Primary project"
msgstr "主プロジェクト"

#: ./doc/openstack-ops/ch_ops_projects_users.xml773(para)
msgid "Role"
msgstr "役割"

#: ./doc/openstack-ops/ch_ops_projects_users.xml777(para)
msgid ""
"Username and email address are self-explanatory, though your site may have "
"local conventions you should observe. Setting and changing passwords in the "
"Identity service requires administrative privileges. As of the Folsom "
"release, users cannot change their own passwords. This is a large driver for"
" creating local custom tools, and must be kept in mind when assigning and "
"distributing passwords. The primary project is simply the first project the "
"user is associated with and must exist prior to creating the user. Role is "
"almost always going to be \"member.\" Out of the box, OpenStack comes with "
"two roles defined:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml791(term)
msgid "member"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml794(para)
msgid "A typical user"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml799(term)
msgid "admin"
msgstr "admin"

#: ./doc/openstack-ops/ch_ops_projects_users.xml802(para)
msgid ""
"An administrative super user, which has full permissions across all projects"
" and should be used with great care"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml808(para)
msgid "It is possible to define other roles, but doing so is uncommon."
msgstr "他の役割を定義できますが、一般的にはそうしません。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml811(para)
msgid ""
"Once you've gathered this information, creating the user in the dashboard is"
" just another web form similar to what we've seen before and can be found by"
" clicking the Users link in the Admin navigation bar and then clicking the "
"Create User button at the top right."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml816(para)
msgid ""
"Modifying users is also done from this Users page. If you have a large "
"number of users, this page can get quite crowded. The Filter search box at "
"the top of the page can be used to limit the users listing. A form very "
"similar to the user creation dialog can be pulled up by selecting Edit from "
"the actions dropdown menu at the end of the line for the user you are "
"modifying."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml825(title)
msgid "Associating Users with Projects"
msgstr "プロジェクトへのユーザーの割り当て"

#: ./doc/openstack-ops/ch_ops_projects_users.xml827(para)
msgid ""
"Many sites run with users being associated with only one project. This is a "
"more conservative and simpler choice both for administration and for users. "
"Administratively, if a user reports a problem with an instance or quota, it "
"is obvious which project this relates to. Users needn't worry about what "
"project they are acting in if they are only in one project. However, note "
"that, by default, any user can affect the resources of any other user within"
" their project. It is also possible to associate users with multiple "
"projects if that makes sense for your organization.<indexterm "
"class=\"singular\"><primary>Project Members "
"tab</primary></indexterm><indexterm class=\"singular\"><primary>user "
"management</primary><secondary>associating users with "
"projects</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml843(para)
msgid ""
"Associating existing users with an additional project or removing them from "
"an older project is done from the Projects page of the dashboard by "
"selecting Modify Users from the Actions column, as shown in <xref linkend"
"=\"horizon-edit-project\"/>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml848(para)
msgid ""
"From this view, you can do a number of useful things, as well as a few "
"dangerous ones."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml851(para)
msgid ""
"The first column of this form, named All Users, includes a list of all the "
"users in your cloud who are not already associated with this project. The "
"second column shows all the users who are. These lists can be quite long, "
"but they can be limited by typing a substring of the username you are "
"looking for in the filter field at the top of the <phrase role=\"keep-"
"together\">column</phrase>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml858(para)
msgid ""
"From here, click the <guiicon>+</guiicon> icon to add users to the project. "
"Click the <guiicon>-</guiicon> to remove them."
msgstr "ここから、プロジェクトにユーザーを追加するには <guiicon>+</guiicon> アイコンをクリックします。削除するには <guiicon>-</guiicon> をクリックします。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml862(title)
msgid "<guilabel>Edit Project Members</guilabel> tab"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml871(para)
msgid ""
"The dangerous possibility comes with the ability to change member roles. "
"This is the dropdown list below the username in the <guilabel>Project "
"Members</guilabel> list. In virtually all cases, this value should be set to"
" Member. This example purposefully shows an administrative user where this "
"value is admin."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml878(para)
msgid ""
"The admin is global, not per project, so granting a user the admin role in "
"any project gives the user administrative rights across the whole cloud."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml883(para)
msgid ""
"Typical use is to only create administrative users in a single project, by "
"convention the admin project, which is created by default during cloud "
"setup. If your administrative users also use the cloud to launch and manage "
"instances, it is strongly recommended that you use separate user accounts "
"for administrative access and normal operations and that they be in distinct"
" projects.<indexterm "
"class=\"singular\"><primary>accounts</primary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml893(title)
msgid "Customizing Authorization"
msgstr "権限のカスタマイズ"

#: ./doc/openstack-ops/ch_ops_projects_users.xml895(para)
msgid ""
"The default <glossterm>authorization</glossterm> settings allow "
"administrative users only to create resources on behalf of a different "
"project. OpenStack handles two kinds of authorization <phrase role=\"keep-"
"together\">policies</phrase>:<indexterm "
"class=\"singular\"><primary>authorization</primary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml906(term)
msgid "Operation based"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml909(para)
msgid ""
"Policies specify access criteria for specific operations, possibly with "
"fine-grained control over specific attributes."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml916(term)
msgid "Resource based"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml919(para)
msgid ""
"Whether access to a specific resource might be granted or not according to "
"the permissions configured for the resource (currently available only for "
"the network resource). The actual authorization policies enforced in an "
"OpenStack service vary from deployment to deployment."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml928(para)
msgid ""
"The policy engine reads entries from the <code>policy.json</code> file. The "
"actual location of this file might vary from distribution to distribution: "
"for nova, it is typically in <code>/etc/nova/policy.json</code>. You can "
"update entries while the system is running, and you do not have to restart "
"services. Currently, the only way to update such policies is to edit the "
"policy file."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml935(para)
msgid ""
"The OpenStack service's policy engine matches a policy directly. A rule "
"indicates evaluation of the elements of such policies. For instance, in a "
"<code>compute:create: [[\"rule:admin_or_owner\"]]</code> statement, the "
"policy is <code>compute:create</code>, and the rule is "
"<code>admin_or_owner</code>."
msgstr "OpenStack サービスのポリシーエンジンがポリシーと直接照合を行います。ルールはそのようなポリシーの要素の評価を意味します。たとえば、<code>compute:create: [[\"rule:admin_or_owner\"]]</code> 文において、ポリシーは <code>compute:create</code> で、ルールは <code>admin_or_owner</code> です。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml941(para)
msgid ""
"Policies are triggered by an OpenStack policy engine whenever one of them "
"matches an OpenStack API operation or a specific attribute being used in a "
"given operation. For instance, the engine tests the "
"<code>create:compute</code> policy every time a user sends a <code>POST "
"/v2/{tenant_id}/servers</code> request to the OpenStack Compute API server. "
"Policies can be also related to specific <glossterm>API "
"extension</glossterm>s. For instance, if a user needs an extension like "
"<code>compute_extension:rescue</code>, the attributes defined by the "
"provider extensions trigger the rule test for that operation."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml951(para)
msgid ""
"An authorization policy can be composed by one or more rules. If more rules "
"are specified, evaluation policy is successful if any of the rules evaluates"
" successfully; if an API operation matches multiple policies, then all the "
"policies must evaluate successfully. Also, authorization rules are "
"recursive. Once a rule is matched, the rule(s) can be resolved to another "
"rule, until a terminal rule is reached. These are the rules <phrase role"
"=\"keep-together\">defined</phrase>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml961(term)
msgid "Role-based rules"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml964(para)
msgid ""
"Evaluate successfully if the user submitting the request has the specified "
"role. For instance, <code>\"role:admin\"</code> is successful if the user "
"submitting the request is an administrator."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml972(term)
msgid "Field-based rules"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml975(para)
msgid ""
"Evaluate successfully if a field of the resource specified in the current "
"request matches a specific value. For instance, "
"<code>\"field:networks:shared=True\"</code> is successful if the attribute "
"shared of the network resource is set to <literal>true</literal>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml984(term)
msgid "Generic rules"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml987(para)
msgid ""
"Compare an attribute in the resource with an attribute extracted from the "
"user's security credentials and evaluates successfully if the comparison is "
"successful. For instance, <code>\"tenant_id:%(tenant_id)s\"</code> is "
"successful if the tenant identifier in the resource is equal to the tenant "
"identifier of the user submitting the request."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml997(para)
msgid ""
"Here are snippets of the default nova <filename>policy.json</filename> file:"
msgstr "これは標準の nova <filename>policy.json</filename> ファイルの抜粋です。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml1027(para)
msgid ""
"Shows a rule that evaluates successfully if the current user is an "
"administrator or the owner of the resource specified in the request (tenant "
"identifier is equal)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml1033(para)
msgid ""
"Shows the default policy, which is always evaluated if an API operation does"
" not match any of the policies in <code>policy.json</code>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml1039(para)
msgid ""
"Shows a policy restricting the ability to manipulate flavors to "
"administrators using the Admin API only.<indexterm "
"class=\"singular\"><primary>admin API</primary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml1047(para)
msgid ""
"In some cases, some operations should be restricted to administrators only. "
"Therefore, as a further example, let us consider how this sample policy file"
" could be modified in a scenario where we enable users to create their own "
"flavors:"
msgstr "いくつかの場合では、いくつかの操作を管理者のみに制限すべきです。そこで、次の例では、ユーザーが自分のフレーバーを作成できるようにするシナリオの場合に、このサンプルのポリシーファイルをどのように変更すればよいかを示します。"

#: ./doc/openstack-ops/ch_ops_projects_users.xml1056(title)
msgid "Users Who Disrupt Other Users"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml1058(para)
msgid ""
"Users on your cloud can disrupt other users, sometimes intentionally and "
"maliciously and other times by accident. Understanding the situation allows "
"you to make a better decision on how to handle the disruption.<indexterm "
"class=\"singular\"><primary>user management</primary><secondary>handling "
"disruptive users</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml1067(para)
msgid ""
"For example, a group of users have instances that are utilizing a large "
"amount of compute resources for very compute-intensive tasks. This is "
"driving the load up on compute nodes and affecting other users. In this "
"situation, review your user use cases. You may find that high compute "
"scenarios are common, and should then plan for proper segregation in your "
"cloud, such as host aggregation or regions."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml1074(para)
msgid ""
"Another example is a user consuming a very large amount of "
"bandwidth<indexterm "
"class=\"singular\"><primary>bandwidth</primary><secondary>recognizing DDOS "
"attacks</secondary></indexterm>. Again, the key is to understand what the "
"user is doing. If she naturally needs a high amount of bandwidth, you might "
"have to limit her transmission rate as to not affect other users or move her"
" to an area with more bandwidth available. On the other hand, maybe her "
"instance has been hacked and is part of a botnet launching DDOS attacks. "
"Resolution of this issue is the same as though any other server on your "
"network has been hacked. Contact the user and give her time to respond. If "
"she doesn't respond, shut down the instance."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml1088(para)
msgid ""
"A final example is if a user is hammering cloud resources repeatedly. "
"Contact the user and learn what he is trying to do. Maybe he doesn't "
"understand that what he’s doing is inappropriate, or maybe there is an issue"
" with the resource he is trying to access that is causing his requests to "
"queue or lag."
msgstr ""

#: ./doc/openstack-ops/ch_ops_projects_users.xml1099(para)
msgid ""
"One key element of systems administration that is often overlooked is that "
"end users are the reason systems administrators exist. Don't go the BOFH "
"route and terminate every user who causes an alert to go off. Work with "
"users to understand what they're trying to accomplish and see how your "
"environment can better assist them in achieving their goals. Meet your users"
" needs by organizing your users into projects, applying policies, managing "
"quotas, and working with them.<indexterm class=\"singular\"><primary>systems"
" administration</primary><see>user management</see></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml12(title)
msgid "Compute Nodes"
msgstr "コンピュートノード"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml14(para)
msgid ""
"In this chapter, we discuss some of the choices you need to consider when "
"building out your compute nodes. Compute nodes form the resource core of the"
" OpenStack Compute cloud, providing the processing, memory, network and "
"storage resources to run instances."
msgstr "本章では、コンピュートノードの構築時に考慮する必要のある選択肢について説明します。コンピュートノードは、OpenStack Compute クラウドのリソースコアを構成し、プロセッシング、メモリー、ネットワーク、ストレージの各リソースを提供してインスタンスを実行します。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml20(title)
msgid "Choosing a CPU"
msgstr "CPU の選択"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml22(para)
msgid ""
"The type of CPU in your compute node is a very important choice. First, "
"ensure that the CPU supports virtualization by way of "
"<emphasis>VT-x</emphasis> for Intel chips and <emphasis>AMD-v</emphasis> for"
" AMD chips.<indexterm class=\"singular\"><primary>CPUs (central processing "
"units)</primary><secondary>choosing</secondary></indexterm><indexterm "
"class=\"singular\"><primary>compute nodes</primary><secondary>CPU "
"choice</secondary></indexterm>"
msgstr "コンピュートノードの CPU タイプを選択することは非常に重要です。まず、Intel チップには <emphasis>VT-x</emphasis>、AMD チップには <emphasis>AMD-v</emphasis> という風に、CPU が仮想化をサポートするようにします。<indexterm class=\"singular\"><primary>CPU (central processing unit)</primary><secondary>選択</secondary></indexterm><indexterm class=\"singular\"><primary>コンピュートノード</primary><secondary>CPU の選択</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml36(para)
msgid ""
"Consult the vendor documentation to check for virtualization support. For "
"Intel, read <link "
"href=\"http://www.intel.com/support/processors/sb/cs-030729.htm\" "
"title=\"Intel VT-x\"> “Does my processor support Intel® Virtualization "
"Technology?”</link>. For AMD, read <link "
"href=\"http://sites.amd.com/us/business/it-solutions/virtualization/Pages"
"/client-side-virtualization.aspx\" title=\"AMD-v\"> AMD "
"Virtualization</link>. Note that your CPU may support virtualization but it "
"may be disabled. Consult your BIOS documentation for how to enable CPU "
"features.<indexterm class=\"singular\"><primary>virtualization "
"technology</primary></indexterm><indexterm class=\"singular\"><primary>AMD "
"Virtualization</primary></indexterm><indexterm "
"class=\"singular\"><primary>Intel Virtualization "
"Technology</primary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml52(para)
msgid ""
"The number of cores that the CPU has also affects the decision. It's common "
"for current CPUs to have up to 12 cores. Additionally, if an Intel CPU "
"supports hyperthreading, those 12 cores are doubled to 24 cores. If you "
"purchase a server that supports multiple CPUs, the number of cores is "
"further multiplied.<indexterm "
"class=\"singular\"><primary>cores</primary></indexterm><indexterm "
"class=\"singular\"><primary>hyperthreading</primary></indexterm><indexterm "
"class=\"singular\"><primary>multithreading</primary></indexterm>"
msgstr "CPU のコア数も選択に影響します。現在の CPU では最大 12 コアあるのが一般的です。さらに、Intel CPU がハイパースレッディングをサポートしている場合、12 コアは 2 倍の 24 コアになります。複数の CPU をサポートするサーバーを購入する場合、コア数はさらに倍になっていきます。<indexterm class=\"singular\"><primary>コア</primary></indexterm><indexterm class=\"singular\"><primary>ハイパースレッディング</primary></indexterm><indexterm class=\"singular\"><primary>マルチスレッド</primary></indexterm>"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml67(title)
msgid "Multithread Considerations"
msgstr "マルチスレッドの課題"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml69(para)
msgid ""
"Hyper-Threading is Intel's proprietary simultaneous multithreading "
"implementation used to improve parallelization on their CPUs. You might "
"consider enabling Hyper-Threading to improve the performance of "
"multithreaded applications."
msgstr "ハイパースレッディングは、Intel 専用の同時マルチスレッド実装で、CPU の並列化向上に使用されます。マルチスレッドアプリケーションのパフォーマンスを改善するには、ハイパースレッディングを有効にすることを検討してください。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml74(para)
msgid ""
"Whether you should enable Hyper-Threading on your CPUs depends upon your use"
" case. For example, disabling Hyper-Threading can be beneficial in intense "
"computing environments. We recommend that you do performance testing with "
"your local workload with both Hyper-Threading on and off to determine what "
"is more appropriate in your case.<indexterm class=\"singular\"><primary>CPUs"
" (central processing units)</primary><secondary>enabling hyperthreading "
"on</secondary></indexterm>"
msgstr "CPU のハイパースレッディングを有効にするかどうかは、それぞれのユースケースにより変わってきます。例えば、ハイパースレッディングを無効にすると、負荷の高いコンピューティング環境で有用です。ハイパースレッディングがオン、オフの両方の状態でローカルのワークロードを使用してパフォーマンスのテストを実施し、各ケースでいずれが適しているか決定するように推奨しています。<indexterm class=\"singular\"><primary>CPU (central processing unit)</primary><secondary>ハイパースレッディングをオンにする</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml88(title)
msgid "Choosing a Hypervisor"
msgstr "ハイパーバイザーの選択"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml129(link)
msgid "LXC"
msgstr "LXC"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml134(link)
msgid "QEMU"
msgstr "QEMU"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml139(link)
msgid "VMware ESX/ESXi"
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml144(link)
msgid "Xen"
msgstr "Xen"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml149(link)
msgid "Hyper-V"
msgstr "Hyper-V"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml154(link)
msgid "Docker"
msgstr "Docker"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml90(para)
msgid ""
"A hypervisor provides software to manage virtual machine access to the "
"underlying hardware. The hypervisor creates, manages, and monitors virtual "
"machines.<indexterm "
"class=\"singular\"><primary>Docker</primary></indexterm><indexterm "
"class=\"singular\"><primary>Hyper-V</primary></indexterm><indexterm "
"class=\"singular\"><primary>ESXi hypervisor</primary></indexterm><indexterm "
"class=\"singular\"><primary>ESX hypervisor</primary></indexterm><indexterm "
"class=\"singular\"><primary>VMware API</primary></indexterm><indexterm "
"class=\"singular\"><primary>Quick EMUlator "
"(QEMU)</primary></indexterm><indexterm class=\"singular\"><primary>Linux "
"containers (LXC)</primary></indexterm><indexterm class=\"singular\"><primary"
">kernel-based VM (KVM) hypervisor</primary></indexterm><indexterm "
"class=\"singular\"><primary>Xen API</primary><secondary>XenServer "
"hypervisor</secondary></indexterm><indexterm "
"class=\"singular\"><primary>hypervisors</primary><secondary>choosing</secondary></indexterm><indexterm"
" class=\"singular\"><primary>compute nodes</primary><secondary>hypervisor "
"choice</secondary></indexterm> OpenStack Compute supports many hypervisors "
"to various degrees, including: <placeholder-1/>"
msgstr "ハイパーバイザーは、仮想マシンの基盤ハードウェアへのアクセスを管理するソフトウェアを提供します。ハイパーバイザーは仮想マシンを作成、管理、監視します。<indexterm class=\"singular\"><primary>Docker</primary></indexterm><indexterm class=\"singular\"><primary>Hyper-V</primary></indexterm><indexterm class=\"singular\"><primary>ESXi ハイパーバイザー</primary></indexterm><indexterm class=\"singular\"><primary>ESX ハイパーバイザー</primary></indexterm><indexterm class=\"singular\"><primary>VMware API</primary></indexterm><indexterm class=\"singular\"><primary>Quick EMUlator (QEMU)</primary></indexterm><indexterm class=\"singular\"><primary>Linux コンテナ (LXC)</primary></indexterm><indexterm class=\"singular\"><primary>kernel-based VM (KVM) ハイパーバイザー</primary></indexterm><indexterm class=\"singular\"><primary>Xen API</primary><secondary>XenServer ハイパーバイザー</secondary></indexterm><indexterm class=\"singular\"><primary>ハイパーバイザー</primary><secondary>選択</secondary></indexterm><indexterm class=\"singular\"><primary>コンピュートノード</primary><secondary>ハイパーバイザーの選択</secondary></indexterm> OpenStack Compute は多くのハイパーバイザーを様々な度合いでサポートしています。<placeholder-1/>"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml158(para)
msgid ""
"Probably the most important factor in your choice of hypervisor is your "
"current usage or experience. Aside from that, there are practical concerns "
"to do with feature parity, documentation, and the level of community "
"experience."
msgstr "おそらく、ハイパーバイザーの選択で最も重要な要素は、現在の使用法やこれまでの経験でしょう。それ以外では、同等の機能の実用上の懸念、ドキュメント、コミュニティでの経験量などあると思います。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml163(para)
msgid ""
"For example, KVM is the most widely adopted hypervisor in the OpenStack "
"community. Besides KVM, more deployments run Xen, LXC, VMware, and Hyper-V "
"than the others listed. However, each of these are lacking some feature "
"support or the documentation on how to use them with OpenStack is out of "
"date."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml169(para)
msgid ""
"The best information available to support your choice is found on the <link "
"href=\"https://wiki.openstack.org/wiki/HypervisorSupportMatrix\" "
"title=\"reference manual\">Hypervisor Support Matrix</link> and in the <link"
" href=\"http://docs.openstack.org/trunk/config-reference/content"
"/section_compute-hypervisors.html\" title=\"configuration "
"reference\">configuration reference</link>."
msgstr ""

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml177(para)
msgid ""
"It is also possible to run multiple hypervisors in a single deployment using"
" host aggregates or cells. However, an individual compute node can run only "
"a single hypervisor at a time.<indexterm "
"class=\"singular\"><primary>hypervisors</primary><secondary>running "
"multiple</secondary></indexterm>"
msgstr "ホストアグリゲートやセルを使用すると、1 つのデプロイメントで複数のハイパーバイザーを実行することも可能です。しかし、個別のコンピュートノードでは 1 度につき 1 つのハイパーバイザーしか実行することができません。<indexterm class=\"singular\"><primary>hypervisors</primary><secondary>複数実行</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml189(title)
msgid "Instance Storage Solutions"
msgstr "インスタンスストレージのソリューション"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml191(para)
msgid ""
"As part of the procurement for a compute cluster, you must specify some "
"storage for the disk on which the instantiated instance runs. There are "
"three main approaches to providing this temporary-style storage, and it is "
"important to understand the implications of the choice.<indexterm "
"class=\"singular\"><primary>storage</primary><secondary>instance storage "
"solutions</secondary></indexterm><indexterm "
"class=\"singular\"><primary>instances</primary><secondary>storage "
"solutions</secondary></indexterm><indexterm "
"class=\"singular\"><primary>compute nodes</primary><secondary>instance "
"storage solutions</secondary></indexterm>"
msgstr "コンピュートクラスターの調達の一部として、インスタンス化されたインスタンスを実行するディスクのストレージを指定する必要があります。一時ストレージ提供のアプローチは主に 3 つあり、それぞれのアプローチの含意を理解することは重要です。<indexterm class=\"singular\"><primary>storage</primary><secondary>インストーラーストレージ・ソリューション</secondary></indexterm><indexterm class=\"singular\"><primary>インスタンス</primary><secondary>ストレージ・ソリューション</secondary></indexterm><indexterm class=\"singular\"><primary>コンピュートノード</primary><secondary>インスタンスストレージソリューション</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml209(para)
msgid "They are:"
msgstr "次の3つの方法があります。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml213(para)
msgid "Off compute node storage—shared file system"
msgstr "コンピュートノード外のストレージ （共有ファイルシステム）"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml217(para)
msgid "On compute node storage—shared file system"
msgstr "コンピュートノード上のストレージ （共有ファイルシステム）"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml221(para)
msgid "On compute node storage—nonshared file system"
msgstr "コンピュートノード上のストレージ （非共有ファイルシステム）"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml225(para)
msgid ""
"In general, the questions you should ask when selecting storage are as "
"follows:"
msgstr "一般的に、ストレージを選択する際に以下の点を考慮する必要があります。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml230(para)
msgid "What is the platter count you can achieve?"
msgstr "実現したいプラッター数（ディスク容量）はどれくらいか？"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml234(para)
msgid "Do more spindles result in better I/O despite network access?"
msgstr "ネットワークアクセスがあったとしても、ディスク数が多い方が良い I/O 性能が得られるか？"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml239(para)
msgid ""
"Which one results in the best cost-performance scenario you're aiming for?"
msgstr "何があなたが目指すコストパフォーマンスのシナリオはどれか？"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml244(para)
msgid "How do you manage the storage operationally?"
msgstr "運用上ストレージをどのように管理したいのか？"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml248(para)
msgid ""
"Many operators use separate compute and storage hosts. Compute services and "
"storage services have different requirements, and compute hosts typically "
"require more CPU and RAM than storage hosts. Therefore, for a fixed budget, "
"it makes sense to have different configurations for your compute nodes and "
"your storage nodes. Compute nodes will be invested in CPU and RAM, and "
"storage nodes will be invested in block storage."
msgstr "多くの運用者はコンピュートホストとストレージホストを分離して使用しています。コンピュートサービスとストレージサービスには異なる要件があり、コンピュートホストでは通常はストレージホストよりも多くの CPU と RAM が必要です。そのため、一定の予算の中では、コンピュートホストとストレージホストの構成が異なることは理にかなっています。コンピュートホストでは、CPU や RAM を、ストレージノードではブロックストレージを多く使用します。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml256(para)
msgid ""
"However, if you are more restricted in the number of physical hosts you have"
" available for creating your cloud and you want to be able to dedicate as "
"many of your hosts as possible to running instances, it makes sense to run "
"compute and storage on the same machines."
msgstr "一方、クラウドの構築に使用できる物理ホスト数に制限があり、できるだけ多くのホストをインスタンスの実行に使えるようにしたい場合は、同じマシンでコンピュートホストとストレージホストを動作させるのは理にかなっています。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml261(para)
msgid ""
"We'll discuss the three main approaches to instance storage in the next few "
"sections."
msgstr "以降の数セクションでは、 3 つの主要アプローチについて説明します。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml267(title)
msgid "Off Compute Node Storage—Shared File System"
msgstr "コンピュートノード外のストレージ （共有ファイルシステム）"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml269(para)
msgid ""
"In this option, the disks storing the running instances are hosted in "
"servers outside of the compute nodes.<indexterm "
"class=\"singular\"><primary>shared storage</primary></indexterm><indexterm "
"class=\"singular\"><primary>file "
"systems</primary><secondary>shared</secondary></indexterm>"
msgstr "このオプションでは、実行中のインスタンスを格納するディスクはコンピュートノード外のサーバーでホストされます。<indexterm class=\"singular\"><primary>共有ストレージ</primary></indexterm><indexterm class=\"singular\"><primary>ファイルシステム</primary><secondary>共有</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml278(para)
msgid ""
"If you use separate compute and storage hosts, you can treat your compute "
"hosts as \"stateless.\" As long as you don't have any instances currently "
"running on a compute host, you can take it offline or wipe it completely "
"without having any effect on the rest of your cloud. This simplifies "
"maintenance for the compute hosts."
msgstr "コンピュートホストとストレージホストを分離して使用すると、コンピュートホストを「ステートレス」として処理できます。コンピュートホストで実行中のインスタンスがなければ、クラウドの他のアイテムに影響を与えることなく、ノードをオフラインにしたり、完全に消去したりすることができます。これにより、コンピュートホストのメンテナンスが簡素化されます。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml284(para)
msgid "There are several advantages to this approach:"
msgstr "このアプローチには複数の利点があります。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml288(para)
msgid "If a compute node fails, instances are usually easily recoverable."
msgstr "コンピュートホストが故障した場合、通常インスタンスは簡単に復旧できます。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml293(para)
msgid "Running a dedicated storage system can be operationally simpler."
msgstr "専用のストレージシステムを動作させることで、運用がシンプルになります。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml298(para)
msgid "You can scale to any number of spindles."
msgstr "スピンドル数を何個にでもスケールすることができます。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml302(para)
msgid "It may be possible to share the external storage for other purposes."
msgstr "外部ストレージを他の用途と共有できる可能性があります。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml307(para)
msgid "The main downsides to this approach are:"
msgstr "この方法の主なマイナス面は以下の点です。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml311(para)
msgid ""
"Depending on design, heavy I/O usage from some instances can affect "
"unrelated instances."
msgstr "設計次第では、一部のインスタンスの I/O が非常に多い場合に、無関係のインスタンスに影響が出る場合があります。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml316(para)
#: ./doc/openstack-ops/ch_arch_compute_nodes.xml350(para)
msgid "Use of the network can decrease performance."
msgstr "ネットワークを使用するため、性能低下が起こる可能性があります。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml322(title)
msgid "On Compute Node Storage—Shared File System"
msgstr "コンピュートノード上のストレージ （共有ファイルシステム）"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml324(para)
msgid ""
"In this option, each compute node is specified with a significant amount of "
"disk space, but a distributed file system ties the disks from each compute "
"node into a single mount."
msgstr "このオプションでは、各コンピュートノードに、多くのディスク容量が指定されていますが、分散ファイルシステムにより、それぞれのコンピュートノードからのディスクが 1 つのマウントとしてまとめられます。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml328(para)
msgid ""
"The main advantage of this option is that it scales to external storage when"
" you require additional storage."
msgstr "このオプションの主な利点は、追加ストレージが必要な場合、外部ストレージにスケールアウトできる点です。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml331(para)
msgid "However, this option has several downsides:"
msgstr "しかし、この方法にはいくつかマイナス点があります。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml335(para)
msgid ""
"Running a distributed file system can make you lose your data locality "
"compared with nonshared storage."
msgstr "分散ファイルシステムを実行すると、非共有ストレージに比べデータの局所性が失われる可能性があります。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml340(para)
msgid "Recovery of instances is complicated by depending on multiple hosts."
msgstr "複数の物理ホストが関係するため、インスタンスの復旧が複雑になります。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml345(para)
#: ./doc/openstack-ops/ch_arch_compute_nodes.xml387(para)
msgid ""
"The chassis size of the compute node can limit the number of spindles able "
"to be used in a compute node."
msgstr "コンピュートノードの筐体サイズによって、コンピュートノードに搭載できるディスク数が制限されます。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml356(title)
msgid "On Compute Node Storage—Nonshared File System"
msgstr "コンピュートノード上のストレージ （非共有ファイルシステム）"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml358(para)
msgid ""
"In this option, each compute node is specified with enough disks to store "
"the instances it hosts.<indexterm class=\"singular\"><primary>file "
"systems</primary><secondary>nonshared</secondary></indexterm>"
msgstr "このオプションでは、ホストするインスタンスを格納するのに十分なディスク容量が各コンピュートノードに指定されます。<indexterm class=\"singular\"><primary>ファイルシステム</primary><secondary>非共有</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml365(para)
msgid "There are two main reasons why this is a good idea:"
msgstr "このアイデアが良いとされる理由は主に 2 点挙げられます。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml369(para)
msgid ""
"Heavy I/O usage on one compute node does not affect instances on other "
"compute nodes."
msgstr "あるコンピュートノード上での I/O が非常に多い場合でも、他のコンピュートノードのインスタンスに影響がありません。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml374(para)
msgid "Direct I/O access can increase performance."
msgstr "I/O アクセスが直接行われるので、性能向上が図れます。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml378(para)
msgid "This has several downsides:"
msgstr "この方法には次のようなマイナス点があります。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml382(para)
msgid "If a compute node fails, the instances running on that node are lost."
msgstr "コンピュートノードが故障すると、そのノードで実行中のインスタンスが失われてしまいます。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml392(para)
msgid ""
"Migrations of instances from one node to another are more complicated and "
"rely on features that may not continue to be developed."
msgstr "ノード間のインスタンスのマイグレーションがより複雑になり、今後開発が継続されない可能性のある機能に依存することになります。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml398(para)
msgid "If additional storage is required, this option does not scale."
msgstr "追加ストレージが必要な場合、このオプションはスケールしません。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml403(para)
msgid ""
"Running a shared file system on a storage system apart from the computes "
"nodes is ideal for clouds where reliability and scalability are the most "
"important factors. Running a shared file system on the compute nodes "
"themselves may be best in a scenario where you have to deploy to preexisting"
" servers for which you have little to no control over their specifications. "
"Running a nonshared file system on the compute nodes themselves is a good "
"option for clouds with high I/O requirements and low concern for "
"reliability.<indexterm "
"class=\"singular\"><primary>scaling</primary><secondary>file system "
"choice</secondary></indexterm>"
msgstr "信頼性と拡張性が最も重要な要因とするクラウドでは、コンピュートノードと分離してストレージシステムで共有ファイルシステムを実行することが理想的です。仕様のコントロールをほぼできない、または全くできない既存のサーバーにデプロイシなければならない場合などは、コンピュートノード自体で共有ファイルシステムを実行するとベストです。また、I/O 要件が高く、信頼性にあまり配慮しなくてもいいクラウドには、コンピュートノード上で非共有ファイルシステムを実行すると良いでしょう。<indexterm class=\"singular\"><primary>スケーリング</primary><secondary>ファイルシステムの選択</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml418(title)
msgid "Issues with Live Migration"
msgstr "ライブマイグレーションに関する問題"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml420(para)
msgid ""
"We consider live migration an integral part of the operations of the cloud. "
"This feature provides the ability to seamlessly move instances from one "
"physical host to another, a necessity for performing upgrades that require "
"reboots of the compute hosts, but only works well with shared "
"storage.<indexterm "
"class=\"singular\"><primary>storage</primary><secondary>live "
"migration</secondary></indexterm><indexterm "
"class=\"singular\"><primary>migration</primary></indexterm><indexterm "
"class=\"singular\"><primary>live migration</primary></indexterm><indexterm "
"class=\"singular\"><primary>compute nodes</primary><secondary>live "
"migration</secondary></indexterm>"
msgstr "ライブマイグレーションは、クラウドの運用に不可欠であると考えられます。この機能により、物理ホストから別の物理ホストに、インスタンスをシームレスに移動し、コンピュートホストの再起動を必要とするアップグレードができるようになります。しかし、ライブマイグレーションは共有ストレージのみで正常に機能します。<indexterm class=\"singular\"><primary>ストレージ</primary><secondary>ライブマイグレーション</secondary></indexterm><indexterm class=\"singular\"><primary>マイグレーション</primary></indexterm><indexterm class=\"singular\"><primary>ライブマイグレーション</primary></indexterm><indexterm class=\"singular\"><primary>コンピュートノード</primary><secondary>ライブマイグレーション</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml438(para)
msgid ""
"Live migration can also be done with nonshared storage, using a feature "
"known as <emphasis>KVM live block migration</emphasis>. While an earlier "
"implementation of block-based migration in KVM and QEMU was considered "
"unreliable, there is a newer, more reliable implementation of block-based "
"live migration as of QEMU 1.4 and libvirt 1.0.2 that is also compatible with"
" OpenStack. However, none of the authors of this guide have first-hand "
"experience using live block migration.<indexterm "
"class=\"singular\"><primary>block migration</primary></indexterm>"
msgstr "ライブマイグレーションは、<emphasis>KVM ライブブロックマイグレーション</emphasis> という機能を使用して、非共有ストレージでも行うことができます。KVM や QEMU でのブロックベースのマイグレーションは当初、信頼できませんでしたが、OpenStack との互換性もある QEMU 1.4 および libvirt 1.0.2 では、より新しく、信頼性の高いブロックベースのライブマイグレーション実装ができるようになっています。ただし、本書の執筆者は、ライブブロックマイグレーションを実際に使用していません。<indexterm class=\"singular\"><primary>ブロックマイグレーション</primary></indexterm>"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml451(title)
msgid "Choice of File System"
msgstr "ファイルシステムの選択"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml453(para)
msgid ""
"If you want to support shared-storage live migration, you need to configure "
"a distributed file system.<indexterm class=\"singular\"><primary>compute "
"nodes</primary><secondary>file system "
"choice</secondary></indexterm><indexterm class=\"singular\"><primary>file "
"systems</primary><secondary>choice of</secondary></indexterm><indexterm "
"class=\"singular\"><primary>storage</primary><secondary>file system "
"choice</secondary></indexterm>"
msgstr "共有ストレージのライブマイグレーションをサポートする場合、分散ファイルシステムを設定する必要があります。<indexterm class=\"singular\"><primary>コンピュートノード</primary><secondary>ファイルシステムの選択</secondary></indexterm><indexterm class=\"singular\"><primary>ファイルシステム</primary><secondary>選択</secondary></indexterm><indexterm class=\"singular\"><primary>ストレージ</primary><secondary>ファイルシステムの選択</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml468(para)
msgid "Possible options include:"
msgstr "次のような選択肢があります。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml472(para)
msgid "NFS (default for Linux)"
msgstr "NFS (Linux でのデフォルト)"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml480(para)
msgid "MooseFS"
msgstr "MooseFS"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml484(para)
msgid "Lustre"
msgstr "Lustre"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml488(para)
msgid ""
"We've seen deployments with all, and recommend that you choose the one you "
"are most familiar with operating. If you are not familiar with any of these,"
" choose NFS, as it is the easiest to set up and there is extensive community"
" knowledge about it."
msgstr "すべてのファイルシステムを使用したデプロイメントに触れ、運用になれているものを選択するように推奨しました。いずれのファイルシステムにも馴染みがない場合は、設定が簡単で、コミュニティのナレッジベースが幅広く存在するため、NFS を選択するようにしてください。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml496(title)
msgid "Overcommitting"
msgstr "オーバーコミット"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml498(para)
msgid ""
"OpenStack allows you to overcommit CPU and RAM on compute nodes. This allows"
" you to increase the number of instances you can have running on your cloud,"
" at the cost of reducing the performance of the instances.<indexterm "
"class=\"singular\"><primary>RAM overcommit</primary></indexterm><indexterm "
"class=\"singular\"><primary>CPUs (central processing "
"units)</primary><secondary>overcommitting</secondary></indexterm><indexterm "
"class=\"singular\"><primary>overcommitting</primary></indexterm><indexterm "
"class=\"singular\"><primary>compute "
"nodes</primary><secondary>overcommitting</secondary></indexterm> OpenStack "
"Compute uses the following ratios by default:"
msgstr "OpenStack は、コンピュートノードで CPU および RAM をオーバーコミットすることができます。これにより、インスタンスのパフォーマンスを落とすことでクラウドで実行可能なインスタンス数を増やすことができます。<indexterm class=\"singular\"><primary>RAM オーバーコミット</primary></indexterm><indexterm class=\"singular\"><primary>CPU (central processing unit)</primary><secondary>overcommitting</secondary></indexterm><indexterm class=\"singular\"><primary>オーバーコミット</primary></indexterm><indexterm class=\"singular\"><primary>コンピュートノード</primary><secondary>オーバーコミット</secondary></indexterm> OpenStack Compute はデフォルトで以下の比率を使用します。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml518(para)
msgid "CPU allocation ratio: 16:1"
msgstr "CPU 割当比: 16:1"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml522(para)
msgid "RAM allocation ratio: 1.5:1"
msgstr "RAM 割当比: 1.5:1"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml526(para)
msgid ""
"The default CPU allocation ratio of 16:1 means that the scheduler allocates "
"up to 16 virtual cores per physical core. For example, if a physical node "
"has 12 cores, the scheduler sees 192 available virtual cores. With typical "
"flavor definitions of 4 virtual cores per instance, this ratio would provide"
" 48 instances on a physical node."
msgstr "デフォルトの CPU 割当比は 16:1 で、これは、物理コア 1 つにつき仮想コアが最大 16 個までスケジューラーにより割り当てることができることを意味します。例えば、物理ノードにコアが 12 個ある場合、スケジューラーには、使用可能な仮想コアが 192 個あることになります。インスタンス 1 個に仮想コア 4 個という通常のフレーバーの定義では、この比率をもとにすると、1 つの物理にインスタンスが 48 個割り当てらることになります。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml532(para)
msgid ""
"The formula for the number of virtual instances on a compute node is "
"<emphasis>(OR*PC)/VC</emphasis>, where:"
msgstr "コンピュートノード上の仮想インスタンス数の公式は、 <emphasis>(OR*PC)/VC</emphasis> です。それぞれ以下を意味します。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml537(emphasis)
msgid "OR"
msgstr "OR"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml540(para)
msgid "CPU overcommit ratio (virtual cores per physical core)"
msgstr "CPU オーバーコミット比率 (物理コアごとの仮想コア)"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml545(emphasis)
msgid "PC"
msgstr "PC"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml548(para)
msgid "Number of physical cores"
msgstr "物理コア数"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml553(emphasis)
msgid "VC"
msgstr "VC"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml556(para)
msgid "Number of virtual cores per instance"
msgstr "インスタンスごとの仮想コア数"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml561(para)
msgid ""
"Similarly, the default RAM allocation ratio of 1.5:1 means that the "
"scheduler allocates instances to a physical node as long as the total amount"
" of RAM associated with the instances is less than 1.5 times the amount of "
"RAM available on the physical node."
msgstr "同様に、RAM 割当比のデフォルト1.5:1 は、インスタンスに関連づけられた RAM の総量が物理ノードで利用できるメモリ量の1.5倍未満であれば、スケジューラーがその物理ノードにインスタンスを割り当てることを意味します。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml566(para)
msgid ""
"For example, if a physical node has 48 GB of RAM, the scheduler allocates "
"instances to that node until the sum of the RAM associated with the "
"instances reaches 72 GB (such as nine instances, in the case where each "
"instance has 8 GB of RAM)."
msgstr "例えば、物理ノードに 48GB の RAM がある場合、そのノード上のインスタンスに割り当てられた RAM の合計が 72GB に達するまでは、スケジューラーはそのノードにインスタンスを割り振ることになります (例えば、各インスタンスのメモリが 8GB であれば、9 インスタンス割り当てられます)。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml571(para)
msgid ""
"You must select the appropriate CPU and RAM allocation ratio for your "
"particular use case."
msgstr "あなた自身のユースケースに合わせて、適切な CPU と RAM の割当比を選択しなければなりません。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml576(title)
msgid "Logging"
msgstr "ロギング"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml578(para)
msgid ""
"Logging is detailed more fully in <xref linkend=\"logging_monitoring\"/>. "
"However, it is an important design consideration to take into account before"
" commencing operations of your cloud.<indexterm "
"class=\"singular\"><primary>logging/monitoring</primary><secondary>compute "
"nodes and</secondary></indexterm><indexterm "
"class=\"singular\"><primary>compute "
"nodes</primary><secondary>logging</secondary></indexterm>"
msgstr "ロギングの詳細は、<xref linkend=\"logging_monitoring\"/> で包括的に記載しています。ただし、クラウドの運用を開始する前に、重要な設計に関する事項について考慮していく必要があります。<indexterm class=\"singular\"><primary>logging/monitoring</primary><secondary>コンピュートノードおよび</secondary></indexterm><indexterm class=\"singular\"><primary>コンピュートノード</primary><secondary>ロギング</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml591(para)
msgid ""
"OpenStack produces a great deal of useful logging information, however; but "
"for the information to be useful for operations purposes, you should "
"consider having a central logging server to send logs to, and a log "
"parsing/analysis system (such as <phrase role=\"keep-"
"together\">logstash</phrase>)."
msgstr "OpenStack は、便利なロギング情報を多く生成しますが、運用目的でその情報を有効活用するには、ログの送信先となる中央ロギングサーバーや、ログの解析/分析システム (<phrase role=\"keep-together\">logstash</phrase> など) の導入を検討する必要があります。"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml601(para)
msgid ""
"Networking in OpenStack is a complex, multifaceted challenge. See <xref "
"linkend=\"network_design\"/>.<indexterm class=\"singular\"><primary>compute "
"nodes</primary><secondary>networking</secondary></indexterm>"
msgstr "OpenStack でのネットワークは複雑で、多くの課題があります。<xref linkend=\"network_design\"/>を参照してください。<indexterm class=\"singular\"><primary>コンピュートノード</primary><secondary>ネットワーキング</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_compute_nodes.xml612(para)
msgid ""
"Compute nodes are the workhorse of your cloud and the place where your "
"users' applications will run. They are likely to be affected by your "
"decisions on what to deploy and how you deploy it. Their requirements should"
" be reflected in the choices you make."
msgstr "コンピュートノードはクラウドの主なアイテムで、ユーザーのアプリケーションが実行される場所です。何をどのようにデプロイするかユーザーの意思決定により、コンピュートノードは影響を受けます。これらの要件は、意思決定していく際に反映させる必要があります。"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml12(title)
msgid "Lay of the Land"
msgstr "環境の把握"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml14(para)
msgid ""
"This chapter helps you set up your working environment and use it to take a "
"look around your cloud."
msgstr "本章の内容は、作業環境を設定し、クラウドの考察に使用するのに役立ちます。"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml18(title)
msgid "Using the OpenStack Dashboard for Administration"
msgstr "管理目的での OpenStack Dashboard の使用"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml20(para)
msgid ""
"As a cloud administrative user, you can use the OpenStack dashboard to "
"create and manage projects, users, images, and flavors. Users are allowed to"
" create and manage images within specified projects and to share images, "
"depending on the Image Service configuration. Typically, the policy "
"configuration allows admin users only to set quotas and create and manage "
"services. The dashboard provides an <guilabel>Admin</guilabel> tab with a "
"<guilabel>System Panel</guilabel> and <guilabel>Identity Panel</guilabel>. "
"These interfaces give you access to system information and usage as well as "
"to settings for configuring what end users can do. Refer to the <link "
"href=\"http://docs.openstack.org/user-guide-"
"admin/content/ch_dashboard.html\">OpenStack Admin User Guide</link> for "
"detailed how-to information about using the dashboard as an admin "
"user.<indexterm class=\"singular\"><primary>working "
"environment</primary><secondary>dashboard</secondary></indexterm><indexterm "
"class=\"singular\"><primary>dashboard</primary></indexterm>"
msgstr "クラウドの管理ユーザーとして OpenStack Dashboard を使用して、プロジェクト、ユーザー、イメージ、フレーバーの作成および管理を行うことができます。ユーザーは Image Service の設定に応じて、指定されたプロジェクト内でイメージを作成/管理したり、共有したりすることができます。通常、ポリシーの設定では、管理ユーザーのみがクォータの設定とサービスの作成/管理を行うことができます。ダッシュボードには <guilabel>管理</guilabel> タブがあり、<guilabel>システムパネル</guilabel> と <guilabel>認証パネル</guilabel> に分かれています。これらのインターフェースにより、システム情報と使用状況のデータにアクセスすることができるのに加えて、エンドユーザーが実行可能な操作を設定することもできます。管理ユーザーとしてダッシュボードを使用する方法についての詳しい説明は  <link href=\"http://docs.openstack.org/user-guide-admin/content/ch_dashboard.html\">OpenStack 管理ユーザーガイド</link> を参照してください。<indexterm class=\"singular\"><primary>作業環境</primary><secondary>ダッシュボード</secondary></indexterm><indexterm class=\"singular\"><primary>ダッシュボード</primary></indexterm>"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml41(title)
msgid "Command-Line Tools"
msgstr "コマンドラインツール"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml43(para)
msgid ""
"We recommend using a combination of the OpenStack command-line interface "
"(CLI) tools and the OpenStack dashboard for administration. Some users with "
"a background in other cloud technologies may be using the EC2 Compatibility "
"API, which uses naming conventions somewhat different from the native API. "
"We highlight those differences.<indexterm "
"class=\"singular\"><primary>working environment</primary><secondary>command-"
"line tools</secondary></indexterm>"
msgstr "管理には、OpenStack コマンドラインインターフェース (CLI) ツールと OpenStack Dashboard を組み合わせて使用することをお勧めします。他のクラウドテクノロジーの使用経験のある一部のユーザーは、EC2 互換 API を使用している可能性があります。この API は、ネイティブの API とは若干異なる命名規則を採用しています。この相違点について以下に説明します。<indexterm class=\"singular\"><primary>作業環境</primary><secondary>コマンドラインツール</secondary></indexterm>"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml53(para)
msgid ""
"We strongly suggest that you install the command-line clients from the <link"
" href=\"https://pypi.python.org/pypi\">Python Package Index</link> (PyPI) "
"instead of from the distribution packages. The clients are under heavy "
"development, and it is very likely at any given time that the version of the"
" packages distributed by your operating-system vendor are out of "
"date.<indexterm class=\"singular\"><primary>command-line "
"tools</primary><secondary>Python Package Index "
"(PyPI)</secondary></indexterm><indexterm class=\"singular\"><primary>pip "
"utility</primary></indexterm><indexterm class=\"singular\"><primary>Python "
"Package Index (PyPI)</primary></indexterm>"
msgstr "コマンドラインクライアントは、ディストリビューションのパッケージからではなく、<link href=\"https://pypi.python.org/pypi\">Python Package Index</link> (PyPI)  からインストールすることを強く推奨します。これは、クライアントの開発が活発に行われており、オペレーティングシステムのベンダーにより配布されたパッケージのバージョンが任意の時点で無効になってしまう可能性が高いためです。<indexterm class=\"singular\"><primary>コマンドラインツール</primary><secondary>Python Package Index (PyPI)</secondary></indexterm><indexterm class=\"singular\"><primary>pip ユーティリティ</primary></indexterm><indexterm class=\"singular\"><primary>Python Package Index (PyPI)</primary></indexterm>"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml68(para)
msgid ""
"The pip utility is used to manage package installation from the PyPI archive"
" and is available in the python-pip package in most Linux distributions. "
"Each OpenStack project has its own client, so depending on which services "
"your site runs, install some or all of the following<indexterm "
"class=\"singular\"><primary>neutron</primary><secondary>python-"
"neutronclient</secondary></indexterm><indexterm "
"class=\"singular\"><primary>swift</primary><secondary>python-"
"swiftclient</secondary></indexterm><indexterm "
"class=\"singular\"><primary>cinder</primary></indexterm><indexterm "
"class=\"singular\"><primary>keystone</primary></indexterm><indexterm "
"class=\"singular\"><primary>glance</primary><secondary>python-"
"glanceclient</secondary></indexterm><indexterm "
"class=\"singular\"><primary>nova</primary><secondary>python-"
"novaclient</secondary></indexterm> packages:"
msgstr "pip ユーティリティは、PyPI  アーカイブからのパッケージインストールの管理に使用するツールで、大半の Linux ディストリビューションの python-pip パッケージに含まれています。各 OpenStack プロジェクトはそれぞれ独自のクライアントがあります。サイトで実行するサービスに応じて、以下のパッケージの一部またはすべてをインストールしてください。<indexterm class=\"singular\"><primary>neutron</primary><secondary>python-neutronclient</secondary></indexterm><indexterm class=\"singular\"><primary>swift</primary><secondary>python-swiftclient</secondary></indexterm><indexterm class=\"singular\"><primary>cinder</primary></indexterm><indexterm class=\"singular\"><primary>keystone</primary></indexterm><indexterm class=\"singular\"><primary>glance</primary><secondary>python-glanceclient</secondary></indexterm><indexterm class=\"singular\"><primary>nova</primary><secondary>python-novaclient</secondary></indexterm>"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml96(para)
msgid "python-novaclient (<glossterm>nova</glossterm> CLI)"
msgstr "python-novaclient (<glossterm>nova</glossterm> CLI)"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml100(para)
msgid "python-glanceclient (<glossterm>glance</glossterm> CLI)"
msgstr "python-glanceclient (<glossterm>glance</glossterm> CLI)"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml104(para)
msgid "python-keystoneclient (<glossterm>keystone</glossterm> CLI)"
msgstr "python-keystoneclient (<glossterm>keystone</glossterm> CLI)"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml109(para)
msgid "python-cinderclient (<glossterm>cinder</glossterm> CLI)"
msgstr "python-cinderclient (<glossterm>cinder</glossterm> CLI)"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml113(para)
msgid "python-swiftclient (<glossterm>swift</glossterm> CLI)"
msgstr "python-swiftclient (<glossterm>swift</glossterm> CLI)"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml117(para)
msgid "python-neutronclient (<glossterm>neutron</glossterm> CLI)"
msgstr "python-neutronclient (<glossterm>neutron</glossterm> CLI)"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml122(title)
msgid "Installing the Tools"
msgstr "ツールの導入"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml124(para)
msgid ""
"To install (or upgrade) a package from the PyPI archive with pip, <indexterm"
" class=\"singular\"><primary>command-line "
"tools</primary><secondary>installing</secondary></indexterm>as root:"
msgstr "pip を使用して PyPI  アーカイブからパッケージをインストール (またはアップグレード) するには、<indexterm class=\"singular\"><primary>コマンドラインツール</primary><secondary>インストール</secondary></indexterm> root として以下のコマンドを実行します。"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml133(para)
msgid "To remove the package:"
msgstr "パッケージを削除するには、"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml137(para)
msgid ""
"If you need even newer versions of the clients, pip can install directly "
"from the upstream git repository using the <code>-e</code> flag. You must "
"specify a name for the Python egg that is installed. For example:"
msgstr "もし新しいバージョンのクライアントが必要な場合、<code>-e</code>フラグを指定することで、アップストリームのgitリポジトリから直接導入できます。その際は、Python egg名を指定しなければいけません。例えば、"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml145(para)
msgid ""
"If you support the EC2 API on your cloud, you should also install the "
"euca2ools package or some other EC2 API tool so that you can get the same "
"view your users have. Using EC2 API-based tools is mostly out of the scope "
"of this guide, though we discuss getting credentials for use with it."
msgstr "クラウド上で EC2 API をサポートする場合には、ユーザーと同じビューを表示できるように、euca2ools パッケージまたはその他の EC2 API ツールもインストールする必要があります。EC2 API ベースのツールの使用に関する内容の大半は本ガイドの適用範囲外となりますが、このツールで使用する認証情報の取得方法についての説明は記載しています。"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml153(title)
msgid "Administrative Command-Line Tools"
msgstr "管理系コマンドラインツール"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml155(para)
msgid ""
"There are also several <literal>*-manage</literal> command-line tools. These"
" are installed with the project's services on the cloud controller and do "
"not need to be installed<indexterm class=\"singular\"><primary>*-manage "
"command-line tools</primary></indexterm><indexterm "
"class=\"singular\"><primary>command-line "
"tools</primary><secondary>administrative</secondary></indexterm> separately:"
msgstr "また、<literal>*-manage</literal> のコマンドラインツールも複数あります。これらは、プロジェクトのサービスとともにクラウドコントローラーにインストールされるので、別途インストールする必要はありません。 <indexterm class=\"singular\"><primary>*-manage コマンドラインツール</primary></indexterm><indexterm class=\"singular\"><primary>コマンドラインツール</primary><secondary>管理系</secondary></indexterm>"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml167(literal)
msgid "nova-manage"
msgstr "nova-manage"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml171(literal)
msgid "glance-manage"
msgstr "glance-manage"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml175(literal)
msgid "keystone-manage"
msgstr "keystone-manage"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml179(literal)
msgid "cinder-manage"
msgstr "cinder-manage"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml183(para)
msgid ""
"Unlike the CLI tools mentioned above, the <code>*-manage</code> tools must "
"be run from the cloud controller, as root, because they need read access to "
"the config files such as <code>/etc/nova/nova.conf</code> and to make "
"queries directly against the database rather than against the OpenStack "
"<glossterm baseform=\"API endpoint\">API endpoints</glossterm>.<indexterm "
"class=\"singular\"><primary>API (application programming "
"interface)</primary><secondary>API "
"endpoint</secondary></indexterm><indexterm "
"class=\"singular\"><primary>endpoints</primary><secondary>API "
"endpoint</secondary></indexterm>"
msgstr "前述の CLI ツールとは異なり、<code>*-manage</code> ツールは、<code>/etc/nova/nova.conf</code> などの設定ファイルへの読み取りアクセスが必要で、かつ OpenStack に対してではなくデータベースに対して直接クエリーを実行しなければならないため、クラウドコントローラーから root として実行する必要があります。<glossterm baseform=\"API endpoint\">API エンドポイント</glossterm>.<indexterm class=\"singular\"><primary>API (Application Programming Interface)</primary><secondary>API エンドポイント</secondary></indexterm><indexterm class=\"singular\"><primary>エンドポイント</primary><secondary>API エンドポイント</secondary></indexterm>"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml199(para)
msgid ""
"The existence of the <code>*-manage</code> tools is a legacy issue. It is a "
"goal of the OpenStack project to eventually migrate all of the remaining "
"functionality in the <code>*-manage</code> tools into the API-based tools. "
"Until that day, you need to SSH into the <glossterm>cloud controller "
"node</glossterm> to perform some maintenance operations that require one of "
"the <phrase role=\"keep-together\"><code role=\"keep-"
"together\">*-manage</code> tools</phrase>.<indexterm "
"class=\"singular\"><primary>cloud controller nodes</primary><secondary"
">command-line tools and</secondary></indexterm>"
msgstr "<code>*-manage</code> ツールが存在するのは、レガシーの問題です。OpenStack プロジェクトでは、最終的には <code>*-manage</code> ツールの残りの機能をすべて API ベースのツールに移行することを目標としています。移行が完了するまで、<phrase role=\"keep-together\"><code role=\"keep-together\">*-manage</code> ツール</phrase> を必要とするメンテナンス操作は、<glossterm>cloud controller node</glossterm> に SSH 接続して実行する必要があります。<indexterm class=\"singular\"><primary>クラウドコントローラーノード</primary><secondary>コマンドラインツール</secondary></indexterm>"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml215(title)
msgid "Getting Credentials"
msgstr "認証情報の取得方法"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml217(para)
msgid ""
"You must have the appropriate credentials if you want to use the command-"
"line tools to make queries against your OpenStack cloud. By far, the easiest"
" way to obtain <glossterm>authentication</glossterm> credentials to use with"
" command-line clients is to use the OpenStack dashboard. From the top-right "
"navigation row, select <guimenuitem>Project</guimenuitem>, then "
"<guimenuitem>Access &amp; Security</guimenuitem>, then <guimenuitem>API "
"Access</guimenuitem> to access the user settings page where you can set your"
" language and timezone preferences for the dashboard view. This action "
"displays two buttons, <guilabel>Download OpenStack RC File</guilabel> and "
"<guilabel>Download EC2 Credentials</guilabel>, which let you generate files "
"that you can source in your shell to populate the environment variables the "
"command-line tools require to know where your service endpoints and your "
"authentication information are. The user you logged in to the dashboard "
"dictates the filename for the openrc file, such as <filename>demo-"
"openrc.sh</filename>. When logged in as admin, the file is named <filename"
">admin-openrc.sh</filename>.<indexterm "
"class=\"singular\"><primary>credentials</primary></indexterm><indexterm "
"class=\"singular\"><primary>authentication</primary></indexterm><indexterm "
"class=\"singular\"><primary>command-line tools</primary><secondary>getting "
"credentials</secondary></indexterm>"
msgstr "コマンドラインツールを使用して OpenStack クラウドに対してクエリーを実行するには、適切な認証情報が必要です。コマンドラインクライアントで使用する<glossterm>認証</glossterm>のクレデンシャルを取得する最も簡単な方法は、OpenStack ダッシュボードを使用する方法です。画面右上のナビレーションバーから <guimenuitem>プロジェクト</guimenuitem> を選択し、<guimenuitem>アクセスとセキュリティ</guimenuitem> をクリックしてから, <guimenuitem>API アクセス</guimenuitem> のタブを開き、ユーザー設定のページにアクセスします。このページでは、ダッシュボードで表示される言語とタイムゾーンを設定することができます。この操作では、<guilabel>OpenStack RC ファイルのダウンロード</guilabel> と <guilabel>EC2 認証情報のダウンロード</guilabel> の 2 つのボタンが表示されます。これらのボタンにより、コマンドラインツールがサービスエンドポイントと認証情報の場所を知るのに必要な環境変数を読み込むために、シェルで元データとして使用することのできるファイルを生成することができます。ダッシュボードにログインしたユーザーによって、openrc ファイルのファイル名が決定します (例: <filename>demo-openrc.sh</filename>)。admin としてログインした場合には、ファイル名は <filename>admin-openrc.sh</filename> となります。<indexterm class=\"singular\"><primary>認証情報</primary></indexterm><indexterm class=\"singular\"><primary>認証</primary></indexterm><indexterm class=\"singular\"><primary>コマンドラインツール</primary><secondary>認証情報の取得</secondary></indexterm>"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml244(para)
msgid "The generated file looks something like this:"
msgstr "出力は以下のようになります。"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml272(para)
msgid ""
"This does not save your password in plain text, which is a good thing. But "
"when you source or run the script, it prompts you for your password and then"
" stores your response in the environment variable <code>OS_PASSWORD</code>. "
"It is important to note that this does require interactivity. It is possible"
" to store a value directly in the script if you require a noninteractive "
"operation, but you then need to be extremely cautious with the security and "
"permissions of this file.<indexterm "
"class=\"singular\"><primary>passwords</primary></indexterm><indexterm "
"class=\"singular\"><primary>security "
"issues</primary><secondary>passwords</secondary></indexterm>"
msgstr "この場合には、パスワードがプレーンテキスト形式で保存されないのがこの方法の利点となりますが、このスクリプトを元データとして使用したり、実行したりする際には、パスワードが要求され、その回答は環境変数 <code>OS_PASSWORD</code> に保存されます。この操作は対話的に実行される必要がある点は、注意すべき重要なポイントです。 操作を非対話的に行う必要がある場合には、値をスクリプトに直接に保存することも可能ですが、その場合にはこのファイルのセキュリティとアクセス権を極めて慎重に管理する必要があります。, <indexterm class=\"singular\"><primary>パスワード</primary></indexterm><indexterm class=\"singular\"><primary>セキュリティ上の問題</primary><secondary>パスワード</secondary></indexterm>"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml288(para)
msgid ""
"EC2 compatibility credentials can be downloaded by selecting "
"<guimenuitem>Project</guimenuitem>, then <guimenuitem>Access &amp; "
"Security</guimenuitem>, then <guimenuitem>API Access</guimenuitem> to "
"display the <guilabel>Download EC2 Credentials</guilabel> button. Click the "
"button to generate a ZIP file with server x509 certificates and a shell "
"script fragment. Create a new directory in a secure location because these "
"are live credentials containing all the authentication information required "
"to access your cloud identity, unlike the default <code>user-openrc</code>. "
"Extract the ZIP file here. You should have <filename>cacert.pem</filename>, "
"<filename>cert.pem</filename>, <filename>ec2rc.sh</filename>, and "
"<filename>pk.pem</filename>. The <filename>ec2rc.sh</filename> is similar to"
" this:<indexterm class=\"singular\"><primary>access "
"key</primary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml324(para)
msgid ""
"To put the EC2 credentials into your environment, source the "
"<code>ec2rc.sh</code> file."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml329(title)
msgid "Inspecting API Calls"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml331(para)
msgid ""
"The command-line tools can be made to show the OpenStack API calls they make"
" by passing the <code>--debug</code> flag to them.<indexterm "
"class=\"singular\"><primary>API (application programming "
"interface)</primary><secondary>API calls, "
"inspecting</secondary></indexterm><indexterm class=\"singular\"><primary"
">command-line tools</primary><secondary>inspecting API "
"calls</secondary></indexterm> For example:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml345(para)
msgid ""
"This example shows the HTTP requests from the client and the responses from "
"the endpoints, which can be helpful in creating custom tools written to the "
"OpenStack API."
msgstr "この例は、クライアントからのHTTPリクエストとエンドポイントからのレスポンスを表示しています。これはOpenStack APIを使ったカスタムツールを作る際に役立ちます。"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml350(para)
msgid ""
"<link href=\"https://wiki.openstack.org/wiki/KeyringSupport\">Keyring "
"Support</link> enables you to securely save your OpenStack password in an "
"encrypted file.<indexterm class=\"singular\"><primary>Keyring "
"Support</primary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml356(para)
msgid ""
"This feature is disabled by default. To enable it, add the <code>--os-"
"cache</code> flag or set the environment variable <code>OS_CACHE=1</code>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml360(para)
msgid ""
"Configuring <literal>OS_CACHE</literal> causes the command-line tool to "
"authenticate on each and every interaction with the cloud. This can assist "
"with working around this scenario. However, it increases the time taken to "
"run commands and also the load on the server."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml368(title)
msgid "Using cURL for further inspection"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml370(para)
msgid ""
"Underlying the use of the command-line tools is the OpenStack API, which is "
"a RESTful API that runs over HTTP. There may be cases where you want to "
"interact with the API directly or need to use it because of a suspected bug "
"in one of the CLI tools. The best way to do this is to use a combination of "
"<link href=\"http://curl.haxx.se/\">cURL</link> and another tool, such as "
"<link href=\"http://stedolan.github.io/jq/\">jq</link>, to parse the JSON "
"from the responses.<indexterm class=\"singular\"><primary>authentication "
"tokens</primary></indexterm><indexterm "
"class=\"singular\"><primary>cURL</primary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml383(para)
msgid ""
"The first thing you must do is authenticate with the cloud using your "
"credentials to get an <glossterm>authentication token</glossterm>."
msgstr "まずはじめに、クラウドの認証が必要です。あなたの認証情報を用いて<glossterm>認証トークン</glossterm>を入手してください。"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml387(para)
msgid ""
"Your credentials are a combination of username, password, and tenant "
"(project). You can extract these values from the <code>openrc.sh</code> "
"discussed above. The token allows you to interact with your other service "
"endpoints without needing to reauthenticate for every request. Tokens are "
"typically good for 24 hours, and when the token expires, you are alerted "
"with a 401 (Unauthorized) response and you can request another <phrase role"
"=\"keep-together\">token</phrase>.<indexterm "
"class=\"singular\"><primary>catalog</primary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml400(para)
msgid "Look at your OpenStack service <glossterm>catalog</glossterm>:"
msgstr "それではOpenStack サービス<glossterm>カタログ</glossterm>を見てみましょう。"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml412(para)
msgid ""
"Read through the JSON response to get a feel for how the catalog is laid "
"out."
msgstr "JSONレスポンスを読むことで、カタログを把握することができます。"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml415(para)
msgid ""
"To make working with subsequent requests easier, store the token in an "
"environment variable:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml425(para)
msgid ""
"Now you can refer to your token on the command line as "
"<literal>$TOKEN</literal>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml430(para)
msgid ""
"Pick a service endpoint from your service catalog, such as compute. Try a "
"request, for example, listing instances (servers):"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml441(para)
msgid ""
"To discover how API requests should be structured, read the <link "
"href=\"http://developer.openstack.org/api-ref.html\">OpenStack API "
"Reference</link>. To chew through the responses using jq, see the <link "
"href=\"http://stedolan.github.io/jq/manual/\">jq Manual</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml446(para)
msgid ""
"The <code>-s flag</code> used in the cURL commands above are used to prevent"
" the progress meter from being shown. If you are having trouble running cURL"
" commands, you'll want to remove it. Likewise, to help you troubleshoot cURL"
" commands, you can include the <code>-v</code> flag to show you the verbose "
"output. There are many more extremely useful features in cURL; refer to the "
"man page for all the options."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml457(title)
msgid "Servers and Services"
msgstr "サーバーとサービス"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml459(para)
msgid ""
"As an administrator, you have a few ways to discover what your OpenStack "
"cloud looks like simply by using the OpenStack tools available. This section"
" gives you an idea of how to get an overview of your cloud, its shape, size,"
" and current state.<indexterm "
"class=\"singular\"><primary>services</primary><secondary>obtaining overview "
"of</secondary></indexterm><indexterm "
"class=\"singular\"><primary>servers</primary><secondary>obtaining overview "
"of</secondary></indexterm><indexterm class=\"singular\"><primary>cloud "
"computing</primary><secondary>cloud "
"overview</secondary></indexterm><indexterm class=\"singular\"><primary"
">command-line tools</primary><secondary>servers and "
"services</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml481(para)
msgid ""
"First, you can discover what servers belong to your OpenStack cloud by "
"running:"
msgstr "まず、あなたのOpenStackクラウドに属し、稼働しているサーバーを把握することができます。"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml486(para)
msgid "The output looks like the following:"
msgstr "出力は以下のようになります。"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml500(para)
msgid ""
"The output shows that there are five compute nodes and one cloud controller."
" You see a smiley face, such as <code>:-)</code>, which indicates that the "
"services are up and running. If a service is no longer available, the "
"<code>:-)</code> symbol changes to <code>XXX</code>. This is an indication "
"that you should troubleshoot why the service is down."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml507(para)
msgid ""
"If you are using cinder, run the following command to see a similar listing:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml520(para)
msgid ""
"With these two tables, you now have a good overview of what servers and "
"services make up your cloud."
msgstr "これら2つの表で、どのサーバーとサービスがあなたのクラウドを構成しているのか、概要を知ることができました。"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml523(para)
msgid ""
"You can also use the Identity Service (keystone) to see what services are "
"available in your cloud as well as what endpoints have been configured for "
"the services.<indexterm class=\"singular\"><primary>Identity "
"Service</primary><secondary>displaying services and endpoints "
"with</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml531(para)
msgid ""
"The following command requires you to have your shell environment configured"
" with the proper administrative variables:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml558(para)
msgid ""
"The preceding output has been truncated to show only two services. You will "
"see one service block for each service that your cloud provides. Note how "
"the endpoint domain can be different depending on the endpoint type. "
"Different endpoint domains per type are not required, but this can be done "
"for different reasons, such as endpoint privacy or network traffic "
"segregation."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml565(para)
msgid ""
"You can find the version of the Compute installation by using the <literal"
">nova-manage</literal><phrase role=\"keep-together\">command</phrase>: "
"<placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml571(title)
msgid "Diagnose Your Compute Nodes"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml573(para)
msgid ""
"You can obtain extra information about virtual machines that are "
"running—their CPU usage, the memory, the disk I/O or network I/O—per "
"instance, by running the <literal>nova diagnostics</literal> command "
"with<indexterm class=\"singular\"><primary>compute "
"nodes</primary><secondary>diagnosing</secondary></indexterm><indexterm "
"class=\"singular\"><primary>command-line tools</primary><secondary>compute "
"node diagnostics</secondary></indexterm> a server ID:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml588(para)
msgid ""
"The output of this command varies depending on the hypervisor because "
"hypervisors support different attributes.<indexterm "
"class=\"singular\"><primary>hypervisors</primary><secondary>compute node "
"diagnosis and</secondary></indexterm> The following demonstrates the "
"difference between the two most popular hypervisors. Here is example output "
"when the hypervisor is Xen: <placeholder-1/>While the command should work "
"with any hypervisor that is controlled through libvirt (e.g., KVM, QEMU, or "
"LXC), it has been tested only with KVM. Here is example output when the "
"hypervisor is KVM:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml638(title)
msgid "Network Inspection"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml640(para)
msgid ""
"To see which fixed IP networks are configured in your cloud, you can use the"
" <literal>nova</literal> command-line client to get the IP ranges:<indexterm"
" class=\"singular\"><primary>networks</primary><secondary>inspection "
"of</secondary></indexterm><indexterm class=\"singular\"><primary>working "
"environment</primary><secondary>network "
"inspection</secondary></indexterm><placeholder-1/>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml658(para)
msgid ""
"The <literal>nova-manage</literal> tool can provide some additional details:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml666(para)
msgid ""
"This output shows that two networks are configured, each network containing "
"255 IPs (a /24 subnet). The first network has been assigned to a certain "
"project, while the second network is still open for assignment. You can "
"assign this network manually; otherwise, it is automatically assigned when a"
" project launches its first instance."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml672(para)
msgid "To find out whether any floating IPs are available in your cloud, run:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml680(para)
msgid ""
"Here, two floating IPs are available. The first has been allocated to a "
"project, while the other is unallocated."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml685(title)
msgid "Users and Projects"
msgstr "ユーザーとプロジェクト"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml687(para)
msgid ""
"To see a list of projects that have been added to the cloud,<indexterm "
"class=\"singular\"><primary>projects</primary><secondary>obtaining list of "
"current</secondary></indexterm><indexterm class=\"singular\"><primary>user "
"management</primary><secondary>listing "
"users</secondary></indexterm><indexterm class=\"singular\"><primary>working "
"environment</primary><secondary>users and projects</secondary></indexterm> "
"run:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml720(para)
msgid "To see a list of users, run:"
msgstr "ユーザーのリストを見るためには、"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml743(para)
msgid ""
"Sometimes a user and a group have a one-to-one mapping. This happens for "
"standard system accounts, such as cinder, glance, nova, and swift, or when "
"only one user is part of a group."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml750(title)
msgid "Running Instances"
msgstr "稼働中のインスタンス"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml752(para)
msgid ""
"To see a list of running instances,<indexterm "
"class=\"singular\"><primary>instances</primary><secondary>list of "
"running</secondary></indexterm><indexterm "
"class=\"singular\"><primary>working environment</primary><secondary>running "
"instances</secondary></indexterm> run:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml776(para)
msgid ""
"Unfortunately, this command does not tell you various details about the "
"running <phrase role=\"keep-together\">instances</phrase>, such as what "
"compute node the instance is running on, what flavor the instance is, and so"
" on. You can use the following command to view details about individual "
"instances:<indexterm class=\"singular\"><primary>config "
"drive</primary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml786(para)
msgid "For example: <placeholder-1/><placeholder-2/>"
msgstr "例えば、<placeholder-1/><placeholder-2/>"

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml816(para)
msgid ""
"This output shows that an instance named <placeholder-1/> was created from "
"an Ubuntu 12.04 image using a flavor of <literal>m1.small</literal> and is "
"hosted on the compute node <literal>c02.example.com</literal>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_lay_of_land.xml825(para)
msgid ""
"We hope you have enjoyed this quick tour of your working environment, "
"including how to interact with your cloud and extract useful information. "
"From here, you can use the <emphasis><link href=\"http://docs.openstack.org"
"/user-guide-admin/content/\">Admin User Guide</link></emphasis> as your "
"reference for all of the command-line functionality in your cloud."
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml12(title)
msgid "Advanced Configuration"
msgstr "高度な設定"

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml14(para)
msgid ""
"OpenStack is intended to work well across a variety of installation flavors,"
" from very small private clouds to large public clouds. To achieve this, the"
" developers add configuration options to their code that allow the behavior "
"of the various components to be tweaked depending on your needs. "
"Unfortunately, it is not possible to cover all possible deployments with the"
" default configuration values.<indexterm "
"class=\"singular\"><primary>advanced "
"configuration</primary><see>configuration "
"options</see></indexterm><indexterm "
"class=\"singular\"><primary>configuration options</primary><secondary>wide "
"availability of</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml29(para)
msgid ""
"At the time of writing, OpenStack has more than 1,500 configuration options."
" You can see them documented at <link href=\"http://docs.openstack.org/trunk"
"/config-reference/content/config_overview.html\">the OpenStack configuration"
" reference guide</link>. This chapter cannot hope to document all of these, "
"but we do try to introduce the important concepts so that you know where to "
"go digging for more information."
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml37(title)
msgid "Differences Between Various Drivers"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml39(para)
msgid ""
"Many OpenStack projects implement a driver layer, and each of these drivers "
"will implement its own configuration options. For example, in OpenStack "
"Compute (nova), there are various hypervisor drivers implemented—libvirt, "
"xenserver, hyper-v, and vmware, for example. Not all of these hypervisor "
"drivers have the same features, and each has different tuning "
"requirements.<indexterm "
"class=\"singular\"><primary>hypervisors</primary><secondary>differences "
"between</secondary></indexterm><indexterm "
"class=\"singular\"><primary>drivers</primary><secondary>differences "
"between</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml55(para)
msgid ""
"The currently implemented hypervisors are listed on <link "
"href=\"http://docs.openstack.org/trunk/config-reference/content"
"/section_compute-hypervisors.html\">the OpenStack documentation "
"website</link>. You can see a matrix of the various features in OpenStack "
"Compute (nova) hypervisor drivers on the OpenStack wiki at <link "
"href=\"https://wiki.openstack.org/wiki/HypervisorSupportMatrix\">the "
"Hypervisor support matrix page</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml63(para)
msgid ""
"The point we are trying to make here is that just because an option exists "
"doesn't mean that option is relevant to your driver choices. Normally, the "
"documentation notes which drivers the configuration applies to."
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml70(title)
msgid "Implementing Periodic Tasks"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml72(para)
msgid ""
"Another common concept across various OpenStack projects is that of periodic"
" tasks. Periodic tasks are much like cron jobs on traditional Unix systems, "
"but they are run inside an OpenStack process. For example, when OpenStack "
"Compute (nova) needs to work out what images it can remove from its local "
"cache, it runs a periodic task to do this.<indexterm "
"class=\"singular\"><primary>periodic tasks</primary></indexterm><indexterm "
"class=\"singular\"><primary>configuration "
"options</primary><secondary>periodic task "
"implementation</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml85(para)
msgid ""
"Periodic tasks are important to understand because of limitations in the "
"threading model that OpenStack uses. OpenStack uses cooperative threading in"
" Python, which means that if something long and complicated is running, it "
"will block other tasks inside that process from running unless it "
"voluntarily yields execution to another cooperative thread.<indexterm "
"class=\"singular\"><primary>cooperative threading</primary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml94(para)
msgid ""
"A tangible example of this is the <literal>nova-compute</literal> process. "
"In order to manage the image cache with libvirt, <literal>nova-"
"compute</literal> has a periodic process that scans the contents of the "
"image cache. Part of this scan is calculating a checksum for each of the "
"images and making sure that checksum matches what <literal>nova-"
"compute</literal> expects it to be. However, images can be very large, and "
"these checksums can take a long time to generate. At one point, before it "
"was reported as a bug and fixed, <literal>nova-compute</literal> would block"
" on this task and stop responding to RPC requests. This was visible to users"
" as failure of operations such as spawning or deleting instances."
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml106(para)
msgid ""
"The take away from this is if you observe an OpenStack process that appears "
"to \"stop\" for a while and then continue to process normally, you should "
"check that periodic tasks aren't the problem. One way to do this is to "
"disable the periodic tasks by setting their interval to zero. Additionally, "
"you can configure how often these periodic tasks run—in some cases, it might"
" make sense to run them at a different frequency from the default."
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml114(para)
msgid ""
"The frequency is defined separately for each periodic task. Therefore, to "
"disable every periodic task in OpenStack Compute (nova), you would need to "
"set a number of configuration options to zero. The current list of "
"configuration options you would need to set to zero are:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml121(literal)
msgid "bandwidth_poll_interval"
msgstr "bandwidth_poll_interval"

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml125(literal)
msgid "sync_power_state_interval"
msgstr "sync_power_state_interval"

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml129(literal)
msgid "heal_instance_info_cache_interval"
msgstr "heal_instance_info_cache_interval"

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml133(literal)
msgid "host_state_interval"
msgstr "host_state_interval"

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml137(literal)
msgid "image_cache_manager_interval"
msgstr "image_cache_manager_interval"

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml141(literal)
msgid "reclaim_instance_interval"
msgstr "reclaim_instance_interval"

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml145(literal)
msgid "volume_usage_poll_interval"
msgstr "volume_usage_poll_interval"

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml149(literal)
msgid "shelved_poll_interval"
msgstr "shelved_poll_interval"

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml153(literal)
msgid "shelved_offload_time"
msgstr "shelved_offload_time"

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml157(literal)
msgid "instance_delete_interval"
msgstr "instance_delete_interval"

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml161(para)
msgid ""
"To set a configuration option to zero, include a line such as "
"<literal>image_cache_manager_interval=0</literal> in your "
"<filename>nova.conf</filename> file."
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml165(para)
msgid ""
"This list will change between releases, so please refer to your "
"configuration guide for up-to-date information."
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml170(title)
msgid "Specific Configuration Topics"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml172(para)
msgid ""
"This section covers specific examples of configuration options you might "
"consider tuning. It is by no means an exhaustive list."
msgstr "この節では、調整を検討した方がよい設定オプションの個別の具体例を扱います。決して完全なリストではありません。"

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml176(title)
msgid "Security Configuration for Compute, Networking, and Storage"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml179(para)
msgid ""
"The <emphasis><link href=\"http://docs.openstack.org/sec/\">OpenStack "
"Security Guide</link></emphasis> provides a deep dive into securing an "
"OpenStack cloud, including SSL/TLS, key management, PKI and certificate "
"management, data transport and privacy concerns, and compliance.<indexterm "
"class=\"singular\"><primary>security "
"issues</primary><secondary>configuration "
"options</secondary></indexterm><indexterm "
"class=\"singular\"><primary>configuration "
"options</primary><secondary>security</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml195(title)
msgid "High Availability"
msgstr "高可用性"

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml197(para)
msgid ""
"The <emphasis><link href=\"http://docs.openstack.org/high-availability-"
"guide/content/\">OpenStack High Availability Guide</link></emphasis> offers "
"suggestions for elimination of a single point of failure that could cause "
"system downtime. While it is not a completely prescriptive document, it "
"offers methods and techniques for avoiding downtime and data loss.<indexterm"
" class=\"singular\"><primary>high "
"availability</primary></indexterm><indexterm "
"class=\"singular\"><primary>configuration options</primary><secondary>high "
"availability</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml212(title)
msgid "Enabling IPv6 Support"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml214(para)
msgid ""
"The Havana release with OpenStack Networking (neutron) does not offer "
"complete support of IPv6. Better support is planned for the Icehouse "
"release. You can follow along the progress being made by watching the <link "
"href=\"https://wiki.openstack.org/wiki/Meetings/Neutron-"
"IPv6-Subteam\">neutron IPv6 Subteam at work</link>.<indexterm "
"class=\"singular\"><primary>Icehouse</primary><secondary>IPv6 "
"support</secondary></indexterm><indexterm class=\"singular\"><primary>IPv6, "
"enabling support for</primary></indexterm><indexterm "
"class=\"singular\"><primary>configuration options</primary><secondary>IPv6 "
"support</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml230(para)
msgid ""
"By modifying your configuration setup, you can set up IPv6 when using "
"<literal>nova-network</literal> for networking, and a tested setup is "
"documented for FlatDHCP and a multi-host configuration. The key is to make "
"<literal>nova-network</literal> think a <literal>radvd</literal> command ran"
" successfully. The entire configuration is detailed in a Cybera blog post, "
"<link href=\"http://www.cybera.ca/news-and-events/tech-radar/an-ipv6"
"-enabled-cloud/\">“An IPv6 enabled cloud”</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml240(title)
msgid "Periodic Task Frequency for Compute"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml242(para)
msgid ""
"Before the Grizzly release, the frequency of periodic tasks was specified in"
" seconds between runs. This meant that if the periodic task took 30 minutes "
"to run and the frequency was set to hourly, then the periodic task actually "
"ran every 90 minutes, because the task would wait an hour after running "
"before running again. This changed in Grizzly, and we now time the frequency"
" of periodic tasks from the start of the work the task does. So, our 30 "
"minute periodic task will run every hour, with a 30 minute wait between the "
"end of the first run and the start of the next.<indexterm "
"class=\"singular\"><primary>configuration "
"options</primary><secondary>periodic task frequency</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml258(title)
msgid "Geographical Considerations for Object Storage"
msgstr ""

#: ./doc/openstack-ops/ch_ops_advanced_configuration.xml260(para)
msgid ""
"Enhanced support for global clustering of object storage servers continues "
"to be added since the Grizzly (1.8.0) release, when regions were introduced."
" You would implement these global clusters to ensure replication across "
"geographic areas in case of a natural disaster and also to ensure that users"
" can write or access their objects more quickly based on the closest data "
"center. You configure a default region with one zone for each cluster, but "
"be sure your network (WAN) can handle the additional request and response "
"load between zones as you add more zones and build a ring that handles more "
"zones. Refer to <link "
"href=\"http://docs.openstack.org/developer/swift/admin_guide.html"
"#geographically-distributed-clusters\">Geographically Distributed "
"Clusters</link> in the documentation for additional information.<indexterm "
"class=\"singular\"><primary>Object Storage</primary><secondary>geographical "
"considerations</secondary></indexterm><indexterm "
"class=\"singular\"><primary>storage</primary><secondary>geographical "
"considerations</secondary></indexterm><indexterm "
"class=\"singular\"><primary>configuration "
"options</primary><secondary>geographical storage "
"considerations</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml12(title)
msgid "Network Design"
msgstr "ネットワーク設計"

#: ./doc/openstack-ops/ch_arch_network_design.xml14(para)
msgid ""
"OpenStack provides a rich networking environment, and this chapter details "
"the requirements and options to deliberate when designing your "
"cloud.<indexterm class=\"singular\"><primary>network "
"design</primary><secondary>first steps</secondary></indexterm><indexterm "
"class=\"singular\"><primary>design "
"considerations</primary><secondary>network design</secondary></indexterm>"
msgstr "OpenStackは様々なネットワーク環境を提供します。この章ではクラウドを設計する際に必要な事項と慎重に決定すべきオプションの詳細を説明します。<indexterm class=\"singular\"><primary>ネットワーク設計</primary><secondary>第1段階</secondary></indexterm><indexterm class=\"singular\"><primary>設計上の考慮事項</primary><secondary>ネットワーク設計</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_network_design.xml27(para)
msgid ""
"If this is the first time you are deploying a cloud infrastructure in your "
"organization, after reading this section, your first conversations should be"
" with your networking team. Network usage in a running cloud is vastly "
"different from traditional network deployments and has the potential to be "
"disruptive at both a connectivity and a policy level.<indexterm "
"class=\"singular\"><primary>cloud computing</primary><secondary>vs. "
"traditional deployments</secondary></indexterm>"
msgstr "これがあなたの組織で初めてのクラウド基盤構築であれば、この章を読んだ後、最初にあなたの（組織の）ネットワーク管理チームと相談すべきです。クラウド運用におけるネットワークの使用は伝統的なネットワーク構築とはかなり異なり、接続性とポリシーレベルの両面で破壊的な結果をもたらす可能性があります。<indexterm class=\"singular\"><primary>クラウドコンピューティング</primary><secondary>VS. 伝統的実装</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_network_design.xml39(para)
msgid ""
"For example, you must plan the number of IP addresses that you need for both"
" your guest instances as well as management infrastructure. Additionally, "
"you must research and discuss cloud network connectivity through proxy "
"servers and firewalls."
msgstr "例えば、管理インフラだけでなくゲストインスタンス用のIPアドレスの数も計画しなければなりません。加えて、プロキシサーバーやファイアウォールを経由してのクラウドネットワークの接続性を調査・議論する必要があります。"

#: ./doc/openstack-ops/ch_arch_network_design.xml44(para)
msgid ""
"In this chapter, we'll give some examples of network implementations to "
"consider and provide information about some of the network layouts that "
"OpenStack uses. Finally, we have some brief notes on the networking services"
" that are essential for stable operation."
msgstr "この章では、いくつかのネットワーク構成の例を挙げながら、OpenStackを使用したネットワークレイアウトについての情報を提供します。最後に、安定稼働のたの重要な音とトワークサービスに関する注意事項を記載します。"

#: ./doc/openstack-ops/ch_arch_network_design.xml50(title)
msgid "Management Network"
msgstr "管理ネットワーク"

#: ./doc/openstack-ops/ch_arch_network_design.xml52(para)
msgid ""
"A <glossterm>management network</glossterm> (a separate network for use by "
"your cloud operators) typically consists of a separate switch and separate "
"NICs (network interface cards), and is a recommended option. This "
"segregation prevents system administration and the monitoring of system "
"access from being disrupted by traffic generated by guests.<indexterm "
"class=\"singular\"><primary>NICs (network interface "
"cards)</primary></indexterm><indexterm "
"class=\"singular\"><primary>management "
"network</primary></indexterm><indexterm class=\"singular\"><primary>network "
"design</primary><secondary>management network</secondary></indexterm>"
msgstr " <glossterm>管理用ネットワーク</glossterm> (クラウド管理者用の別のネットワーク) は一般的には別のスイッチ別のNIC(Network Interface Cards)で構成する事が推奨されます。この構成ではゲストのトラフィックによって監視と管理のためのアクセスが妨げられることを防ぎます。<indexterm class=\"singular\"><primary>NIC (network interface cards)</primary></indexterm><indexterm class=\"singular\"><primary>管理ネットワーク</primary></indexterm><indexterm class=\"singular\"><primary>ネットワークデザイン</primary><secondary>管理ネットワーク</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_network_design.xml67(para)
msgid ""
"Consider creating other private networks for communication between internal "
"components of OpenStack, such as the message queue and OpenStack Compute. "
"Using a virtual local area network (VLAN) works well for these scenarios "
"because it provides a method for creating multiple virtual networks on a "
"physical network."
msgstr "メッセージキューや OpenStack コンピュート といった OpenStack 内部のコンポーネント間の通信用に別のプライベートネットワークの作成を検討して下さい。Virtual Local Area Network(VLAN) は1つの物理ネットワークに複数の仮想ネットワークを作成できるのでこのシナリオに非常に適しています。"

#: ./doc/openstack-ops/ch_arch_network_design.xml75(title)
msgid "Public Addressing Options"
msgstr "パブリックアドレスの選択肢"

#: ./doc/openstack-ops/ch_arch_network_design.xml77(para)
msgid ""
"There are two main types of IP addresses for guest virtual machines: fixed "
"IPs and floating IPs. Fixed IPs are assigned to instances on boot, whereas "
"floating IP addresses can change their association between instances by "
"action of the user. Both types of IP addresses can be either public or "
"private, depending on your use case.<indexterm "
"class=\"singular\"><primary>IP addresses</primary><secondary>public "
"addressing options</secondary></indexterm><indexterm "
"class=\"singular\"><primary>network design</primary><secondary>public "
"addressing options</secondary></indexterm>"
msgstr "ゲストの仮想マシン用に主に2つのタイプのIPアドレス（固定IPアドレスとフローティングIPアドレス）があります。固定IPアドレスはインスタンス起動時に割り当てられ、フローティングIPアドレスは、ユーザ操作によって割当が変更できます。どちらのタイプのIPアドレスも用途に合わせてパブリックまたはプライベートにする事ができます。<indexterm class=\"singular\"><primary>IPアドレス</primary><secondary>パブリックアドレスオプション</secondary></indexterm><indexterm class=\"singular\"><primary>ネットワーク設計</primary><secondary>パブリックアドレスオプション</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_network_design.xml91(para)
msgid ""
"Fixed IP addresses are required, whereas it is possible to run OpenStack "
"without floating IPs. One of the most common use cases for floating IPs is "
"to provide public IP addresses to a private cloud, where there are a limited"
" number of IP addresses available. Another is for a public cloud user to "
"have a \"static\" IP address that can be reassigned when an instance is "
"upgraded or moved.<indexterm class=\"singular\"><primary>IP "
"addresses</primary><secondary>static</secondary></indexterm><indexterm "
"class=\"singular\"><primary>static IP addresses</primary></indexterm>"
msgstr "固定 IP アドレスは必須ですが、フローティング IP アドレスはなくても OpenStack を実行する事が出来ます。フローティング IP の最も一般的な用法の１つは、利用可能なIPアドレス数が限られているプライベートクラウドにパブリックIPアドレスを提供する事です。他にも、インスタンスがアップグレード又は移動した際に割り当て可能な「静的」 IP アドレスを持つパブリック・クラウドユーザ用です。<indexterm class=\"singular\"><primary>IPアドレス</primary><secondary>固定</secondary></indexterm><indexterm class=\"singular\"><primary>固定IPアドレス</primary></indexterm>"

#: ./doc/openstack-ops/ch_arch_network_design.xml104(para)
msgid ""
"Fixed IP addresses can be private for private clouds, or public for public "
"clouds. When an instance terminates, its fixed IP is lost. It is worth "
"noting that newer users of cloud computing may find their ephemeral nature "
"frustrating.<indexterm class=\"singular\"><primary>IP "
"addresses</primary><secondary>fixed</secondary></indexterm><indexterm "
"class=\"singular\"><primary>fixed IP addresses</primary></indexterm>"
msgstr "固定IPアドレスはプライベートクラウドではプライベートに、パブリッククラウドではパブリックにする事が出来ます。インスタンスが削除される際、そのインスタンスの固定IPは割当を解除されます。クラウドコンピューティングの初心者が一時的にストレスを感じる可能性がある事に注意しましょう。<indexterm class=\"singular\"><primary>IPアドレス</primary><secondary>固定</secondary></indexterm><indexterm class=\"singular\"><primary>固定IPアドレス</primary></indexterm>"

#: ./doc/openstack-ops/ch_arch_network_design.xml117(title)
msgid "IP Address Planning"
msgstr "IP アドレス計画"

#: ./doc/openstack-ops/ch_arch_network_design.xml119(para)
msgid ""
"An OpenStack installation can potentially have many subnets (ranges of IP "
"addresses) and different types of services in each. An IP address plan can "
"assist with a shared understanding of network partition purposes and "
"scalability. Control services can have public and private IP addresses, and "
"as noted above, there are a couple of options for an instance's public "
"addresses.<indexterm class=\"singular\"><primary>IP "
"addresses</primary><secondary>address "
"planning</secondary></indexterm><indexterm "
"class=\"singular\"><primary>network design</primary><secondary>IP address "
"planning</secondary></indexterm>"
msgstr "OpenStackのインストールでは潜在的に多くのサブネット(IPアドレスの範囲)　とそれぞれに異なるタイプのサービスを持つ可能性があります。あるIPアドレスプランは、ネットワーク分割の目的とスケーラビリティの共有された理解を手助けします。コントロールサービスはパブリックとプライベートIPアドレスを持つ事ができ、上記の通り、インスタンスのパブリックアドレスとして2種類のオプションが存在します。<indexterm class=\"singular\"><primary>IPアドレス</primary><secondary>アドレス計画</secondary></indexterm><indexterm class=\"singular\"><primary>ネットワーク設計</primary><secondary>IPアドレス計画</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_network_design.xml134(para)
msgid ""
"An IP address plan might be broken down into the following "
"sections:<indexterm class=\"singular\"><primary>IP "
"addresses</primary><secondary>sections of</secondary></indexterm>"
msgstr "IPアドレス計画としては次のような用途で分類されるでしょう：<indexterm class=\"singular\"><primary>IPアドレス</primary><secondary>分類</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_network_design.xml143(term)
msgid "Subnet router"
msgstr "サブネットルーター"

#: ./doc/openstack-ops/ch_arch_network_design.xml146(para)
msgid ""
"Packets leaving the subnet go via this address, which could be a dedicated "
"router or a <literal>nova-network</literal> service."
msgstr "パケットが出て行く際に通るIPアドレスで、これは専用のルータか<literal>nova-network</literal> サービスです。"

#: ./doc/openstack-ops/ch_arch_network_design.xml153(term)
msgid "Control services public interfaces"
msgstr "コントロールサービス用パブリックインターフェース"

#: ./doc/openstack-ops/ch_arch_network_design.xml156(para)
msgid ""
"Public access to <code>swift-proxy</code>, <code>nova-api</code>, <code"
">glance-api</code>, and horizon come to these addresses, which could be on "
"one side of a load balancer or pointing at individual machines."
msgstr "<code>swift-proxy</code>, <code>nova-api</code>, <code>glance-api</code>, horizon へのパブリックアクセスはこれらのアドレス宛にアクセスしてきます。これらのアドレスはロードバランサの片側か、個々の機器を指しています。"

#: ./doc/openstack-ops/ch_arch_network_design.xml164(term)
msgid "Object Storage cluster internal communications"
msgstr "Object Storage クラスタ内の通信"

#: ./doc/openstack-ops/ch_arch_network_design.xml167(para)
msgid ""
"Traffic among object/account/container servers and between these and the "
"proxy server's internal interface uses this private network.<indexterm "
"class=\"singular\"><primary>containers</primary><secondary>container "
"servers</secondary></indexterm><indexterm "
"class=\"singular\"><primary>objects</primary><secondary>object "
"servers</secondary></indexterm><indexterm "
"class=\"singular\"><primary>account server</primary></indexterm>"
msgstr "オブジェクト/アカウント/コンテナサービスの間とこれらとプロクシサーバーのインターフェイス間のトラフィックはこのプライベートネットワークを利用します。<indexterm class=\"singular\"><primary>コンテナ</primary><secondary>コンテナサーバー</secondary></indexterm><indexterm class=\"singular\"><primary>オブジェクト</primary><secondary>オブジェクトサーバー</secondary></indexterm><indexterm class=\"singular\"><primary>アカウントサーバー</primary></indexterm>"

#: ./doc/openstack-ops/ch_arch_network_design.xml184(term)
msgid "Compute and storage communications"
msgstr "コンピュートとストレージの通信"

#: ./doc/openstack-ops/ch_arch_network_design.xml187(para)
msgid ""
"If ephemeral or block storage is external to the compute node, this network "
"is used."
msgstr "一時ディスクまたはブロックストレージがコンピュートノード以外にある場合、このネットワークが使用されます。"

#: ./doc/openstack-ops/ch_arch_network_design.xml193(term)
msgid "Out-of-band remote management"
msgstr "帯域外管理リモート管理"

#: ./doc/openstack-ops/ch_arch_network_design.xml196(para)
msgid ""
"If a dedicated remote access controller chip is included in servers, often "
"these are on a separate network."
msgstr "専用のリモートアクセスコントローラーチップがサーバーに搭載されている場合、多くの場合、これらは独立したネットワーク上に置かれます。"

#: ./doc/openstack-ops/ch_arch_network_design.xml202(term)
msgid "In-band remote management"
msgstr "帯域内リモート管理"

#: ./doc/openstack-ops/ch_arch_network_design.xml205(para)
msgid ""
"Often, an extra (such as 1 GB) interface on compute or storage nodes is used"
" for system administrators or monitoring tools to access the host instead of"
" going through the public interface."
msgstr "システム管理者や監視ツールがパブリックインターフェース経由の代わりにコンピュートノードやストレージノードのアクセスに使用するための追加インターフェース(1GBなど)"

#: ./doc/openstack-ops/ch_arch_network_design.xml213(term)
msgid "Spare space for future growth"
msgstr "将来のための余剰"

#: ./doc/openstack-ops/ch_arch_network_design.xml216(para)
msgid ""
"Adding more public-facing control services or guest instance IPs should "
"always be part of your plan."
msgstr "パブリック側に置かれるコントローラーサービスやゲストインスタンスのIPの追加は、必ずアドレス計画の一部として入れておくべきです。"

#: ./doc/openstack-ops/ch_arch_network_design.xml222(para)
msgid ""
"For example, take a deployment that has both OpenStack Compute and Object "
"Storage, with private ranges 172.22.42.0/24 and 172.22.87.0/26 available. "
"One way to segregate the space might be as follows:"
msgstr "例えば、OpenStack コンピュート と オブジェクトストレージ の両方を使用し、プライベートアドレス範囲として 172.22.42.0/24 と 172.22.87.0/26 が利用できる場面を考えます。一例として、アドレス空間を以下のように分割することができます。"

#: ./doc/openstack-ops/ch_arch_network_design.xml245(para)
msgid ""
"A similar approach can be taken with public IP addresses, taking note that "
"large, flat ranges are preferred for use with guest instance IPs. Take into "
"account that for some OpenStack networking options, a public IP address in "
"the range of a guest instance public IP address is assigned to the <literal"
">nova-compute</literal> host."
msgstr "パブリックIPアドレスの場合でも同様のアプローチが取れます。但し、ゲストインスタンス用のIPとして使用する場合には、大きなフラットなアドレスレンジの方が好まれることに注意した方がよいでしょう。また、OpenStack のネットワーク方式によっては、ゲストインスタンス用のパブリックIPアドレスレンジのうち一つが <literal>nova-compute </literal>ホストに割り当てられることも考慮する必要があります。"

#: ./doc/openstack-ops/ch_arch_network_design.xml253(title)
msgid "Network Topology"
msgstr "ネットワークトポロジー"

#: ./doc/openstack-ops/ch_arch_network_design.xml255(para)
msgid ""
"OpenStack Compute with <literal>nova-network</literal> provides predefined "
"network deployment models, each with its own strengths and weaknesses. The "
"selection of a network manager changes your network topology, so the choice "
"should be made carefully. You also have a choice between the tried-and-true "
"legacy <literal>nova-network</literal> settings or the <phrase role=\"keep-"
"together\">neutron</phrase> project for OpenStack Networking. Both offer "
"networking for launched instances with different implementations and "
"requirements.<indexterm "
"class=\"singular\"><primary>networks</primary><secondary>deployment "
"options</secondary></indexterm><indexterm "
"class=\"singular\"><primary>networks</primary><secondary>network "
"managers</secondary></indexterm><indexterm "
"class=\"singular\"><primary>network design</primary><secondary>network "
"topology</secondary><tertiary>deployment options</tertiary></indexterm>"
msgstr " <literal>nova-network</literal>を使用したOpenStackコンピュートはいくつかのあらかじめ定義されたネットワークの実装モデルを提供しますが、それぞれ強みと弱みがあります。ネットワークマネージャの選択はあなたのネットワークトポロジーを変更するので、慎重に選択するべきです。また、実証済みでレガシーな<literal>nova-network</literal>による設定か、OpenStackネットワーキングのための<phrase role=\"keep-together\">neutron</phrase>プロジェクトを採用するか決定する必要があります。インスタンスのネットワークの実装方法それぞれに異なる実装と要件があります。<indexterm class=\"singular\"><primary>ネットワーク</primary><secondary>開発オプション</secondary></indexterm><indexterm class=\"singular\"><primary>ネットワーク</primary><secondary>絵ネットワークマネージャ</secondary></indexterm><indexterm class=\"singular\"><primary>ネットワークデザイン</primary><secondary>ネットワークトポロジー</secondary><tertiary>deployment options</tertiary></indexterm>"

#: ./doc/openstack-ops/ch_arch_network_design.xml278(para)
msgid ""
"For OpenStack Networking with the neutron project, typical configurations "
"are documented with the idea that any setup you can configure with real "
"hardware you can re-create with a software-defined equivalent. Each tenant "
"can contain typical network elements such as routers, and services such as "
"DHCP."
msgstr "neutronプロジェクトを使用したOpenStackネットワークのための代表的な構成は物理ハードウェアを使った物、ソフトウェア定義の環境を使用して再作成できるものを使ったセットアップ方法を文書化されています。それぞれのテナントはルータやDHCPサービスと言った一般的なネットワーク構成要素を提供する事ができます。"

#: ./doc/openstack-ops/ch_arch_network_design.xml284(para)
msgid ""
"<xref linkend=\"network_deployment_options\"/> discusses the networking "
"deployment options for both legacy <literal>nova-network</literal> options "
"and an equivalent neutron configuration.<indexterm "
"class=\"singular\"><primary>provisioning/deployment</primary><secondary>network"
" deployment options</secondary></indexterm>"
msgstr "<xref linkend=\"network_deployment_options\"/> レガシーな <literal>nova-network</literal>おオプションとそれと同等なneutron構成オプションについて述べます。<indexterm class=\"singular\"><primary>プロビジョニング/デプロイメント</primary><secondary>ネットワークでプロ忌めんとオプション</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_network_design.xml294(caption)
msgid "Networking deployment options"
msgstr "ネットワーク構成オプション"

#: ./doc/openstack-ops/ch_arch_network_design.xml306(th)
msgid "Network deployment model"
msgstr "ネットワーク構成モデル"

#: ./doc/openstack-ops/ch_arch_network_design.xml308(th)
msgid "Strengths"
msgstr "長所"

#: ./doc/openstack-ops/ch_arch_network_design.xml310(th)
msgid "Weaknesses"
msgstr "短所"

#: ./doc/openstack-ops/ch_arch_network_design.xml312(th)
msgid "Neutron equivalent"
msgstr "Neutronでの実装"

#: ./doc/openstack-ops/ch_arch_network_design.xml318(para)
msgid "Flat"
msgstr "Flat"

#: ./doc/openstack-ops/ch_arch_network_design.xml320(para)
msgid "Extremely simple topology."
msgstr "極めて単純なトポロジー。"

#: ./doc/openstack-ops/ch_arch_network_design.xml320(para)
msgid "No DHCP overhead."
msgstr "DHCPによるオーバーヘッドがありません。"

#: ./doc/openstack-ops/ch_arch_network_design.xml323(para)
msgid ""
"Requires file injection into the instance to configure network interfaces."
msgstr "ネットワークインターフェースの設定にはインスタンスへのファイルの注入が必須です。"

#: ./doc/openstack-ops/ch_arch_network_design.xml326(td)
msgid ""
"Configure a single bridge as the integration bridge (br-int) and connect it "
"to a physical network interface with the Modular Layer 2 (ML2) plug-in, "
"which uses Open vSwitch by default."
msgstr "インテグレーションブリッジ(br-int)として1つのブリッジを構成し、Open vSwitchをデフォルトとして使うModuler Layer2(ML2)プラグインでbr-intと物理ネットワークインターフェースを接続します。"

#: ./doc/openstack-ops/ch_arch_network_design.xml334(para)
msgid "Relatively simple to deploy."
msgstr "比較的シンプルな構成"

#: ./doc/openstack-ops/ch_arch_network_design.xml334(para)
msgid "Standard networking."
msgstr "標準的なネットワーク。"

#: ./doc/openstack-ops/ch_arch_network_design.xml335(para)
msgid "Works with all guest operating systems."
msgstr "どんなゲストOSでも動きます。"

#: ./doc/openstack-ops/ch_arch_network_design.xml338(para)
#: ./doc/openstack-ops/ch_arch_network_design.xml350(para)
msgid "Requires its own DHCP broadcast domain."
msgstr "専用の DHCP ブロードキャストドメインが必要。"

#: ./doc/openstack-ops/ch_arch_network_design.xml340(td)
msgid ""
"Configure DHCP agents and routing agents. Network Address Translation (NAT) "
"performed outside of compute nodes, typically on one or more network nodes."
msgstr "DHCPエージェントとルーティングエージェントを構成します。Network Address Translation (NAT) によってコンピュートノードと外部を接続します。一般的に1つ以上のネットワークノードで成り立ちます。"

#: ./doc/openstack-ops/ch_arch_network_design.xml346(para)
msgid "VlanManager"
msgstr "VlanManager"

#: ./doc/openstack-ops/ch_arch_network_design.xml348(para)
msgid "Each tenant is isolated to its own VLANs."
msgstr "それぞれのテナントは自身のVLANによって独立しています。"

#: ./doc/openstack-ops/ch_arch_network_design.xml350(para)
#: ./doc/openstack-ops/ch_arch_network_design.xml372(para)
msgid "More complex to set up."
msgstr "少し複雑な構成。"

#: ./doc/openstack-ops/ch_arch_network_design.xml351(para)
msgid "Requires many VLANs to be trunked onto a single port."
msgstr "一つのポートに多数の VLAN をトランクが必要。"

#: ./doc/openstack-ops/ch_arch_network_design.xml352(para)
msgid "Standard VLAN number limitation."
msgstr "標準的な VLAN 数の上限。"

#: ./doc/openstack-ops/ch_arch_network_design.xml353(para)
msgid "Switches must support 802.1q VLAN tagging."
msgstr "802.1q VLAN タギングに対応したスイッチが必要。"

#: ./doc/openstack-ops/ch_arch_network_design.xml356(para)
msgid ""
"Isolated tenant networks implement some form of isolation of layer 2 traffic"
" between distinct networks. VLAN tagging is key concept, where traffic is "
"“tagged” with an ordinal identifier for the VLAN. Isolated network "
"implementations may or may not include additional services like DHCP, NAT, "
"and routing."
msgstr "独立テナントネットワークは個々のネットワーク間のレイヤー2トラフィックをいくつかの方法で分離する事で実装します。タグVLANはキーコンセプトでトラフィックをどこに流すかを”タグ”で決定します。独立テナントネットワークにはDHCPやNAT、ルーティングと言った追加のサービスが含まれるかもしれませんし、含まれないかもしれません。"

#: ./doc/openstack-ops/ch_arch_network_design.xml364(para)
msgid "FlatDHCP Multi-host with high availability (HA)"
msgstr "高可用性(HA)のためのフラットDHCPマルチホスト構成"

#: ./doc/openstack-ops/ch_arch_network_design.xml367(para)
msgid ""
"Networking failure is isolated to the VMs running on the affected "
"hypervisor."
msgstr "ネットワーク障害は影響を受けるハイパーバイザーのVMに限定されます。"

#: ./doc/openstack-ops/ch_arch_network_design.xml368(para)
msgid "DHCP traffic can be isolated within an individual host."
msgstr "DHCP トラフィックは個々のホスト内に閉じ込めることができる。"

#: ./doc/openstack-ops/ch_arch_network_design.xml369(para)
msgid "Network traffic is distributed to the compute nodes."
msgstr "ネットワークトラフィックをコンピュートノード全体に分散できる。"

#: ./doc/openstack-ops/ch_arch_network_design.xml372(para)
msgid ""
"Compute nodes typically need IP addresses accessible by external networks."
msgstr "コンピュートノードは概して外部ネットワークからアクセス可能なIPアドレスが必要です。"

#: ./doc/openstack-ops/ch_arch_network_design.xml374(para)
msgid ""
"Options must be carefully configured for live migration to work with "
"networking services."
msgstr "ネットワークサービスが正しく動くようにライブマイグレーションを設定するためには注意してオプションを構成する必要があります。"

#: ./doc/openstack-ops/ch_arch_network_design.xml377(para)
msgid ""
"Configure neutron with multiple DHCP and layer-3 agents. Network nodes are "
"not able to failover to each other, so the controller runs networking "
"services, such as DHCP. Compute nodes run the ML2 plug-in with support for "
"agents such as Open vSwitch or Linux Bridge."
msgstr "複数のDHCPおよびレイヤ-3エージェントを持つようなneutronの構成では、ネットワークノードは互いにフェールオーバできませんのでコントローラはDHCPといったネットワークサービスを実行します。コンピュートノードはOpen vSwitchまたはLinux BridgeといったエージェントをサポートするML2プラグインを実行します。"

#: ./doc/openstack-ops/ch_arch_network_design.xml386(para)
msgid ""
"Both <literal>nova-network</literal> and neutron services provide similar "
"capabilities, such as VLAN between VMs. You also can provide multiple NICs "
"on VMs with either service. Further discussion follows."
msgstr "<literal>nova-network</literal>とneutronサービスはVM間でのVLANといった似通った可用性を提供します。また、それぞれのサービスで複数のNICを付与したVMも提供する事ができます。"

#: ./doc/openstack-ops/ch_arch_network_design.xml392(title)
msgid "VLAN Configuration Within OpenStack VMs"
msgstr "OpenStack VM内のVLAN設定"

#: ./doc/openstack-ops/ch_arch_network_design.xml394(para)
msgid ""
"VLAN configuration can be as simple or as complicated as desired. The use of"
" VLANs has the benefit of allowing each project its own subnet and broadcast"
" segregation from other projects. To allow OpenStack to efficiently use "
"VLANs, you must allocate a VLAN range (one for each project) and turn each "
"compute node switch port into a trunk port.<indexterm "
"class=\"singular\"><primary>networks</primary><secondary>VLAN</secondary></indexterm><indexterm"
" class=\"singular\"><primary>VLAN network</primary></indexterm><indexterm "
"class=\"singular\"><primary>network design</primary><secondary>network "
"topology</secondary><tertiary>VLAN with OpenStack VMs</tertiary></indexterm>"
msgstr "VLAN設定は要求によっては複雑であったり単純であったりする事ができます。VLANを使用すると互いのプロジェクトに専用のサブネットを提供でき、ブロードキャストドメインを分割するという利点が得られます。効果的にVLANを使用できるようにするには、VLANの範囲を(それぞれのプロジェクトに1つずつ)割り当て、各コンピュートノードのポートをトランクポートに変更する必要があります。<indexterm class=\"singular\"><primary>ネットワーク</primary><secondary>VLAN</secondary></indexterm><indexterm class=\"singular\"><primary>VLANネットワーク</primary></indexterm><indexterm class=\"singular\"><primary>ネットワーク設計</primary><secondary>ネットワークトポロジー</secondary><tertiary>OpenStack VMとVLAN</tertiary></indexterm>"

#: ./doc/openstack-ops/ch_arch_network_design.xml413(para)
msgid ""
"For example, if you estimate that your cloud must support a maximum of 100 "
"projects, pick a free VLAN range that your network infrastructure is "
"currently not using (such as VLAN 200–299). You must configure OpenStack "
"with this range and also configure your switch ports to allow VLAN traffic "
"from that range."
msgstr "例えば、あなたのクラウドでサポートする必要があるプロジェクト数が最大で100と見込まれる場合、ネットワークインフラで現在使用されていない VLAN の範囲を選んで下さい (例えば VLAN 200 - 299)。この VLAN の範囲を OpenStack に設定するとともに、この範囲の VLAN トラフィックを許可するようにスイッチポートを設定しなければいけません。"

#: ./doc/openstack-ops/ch_arch_network_design.xml421(title)
msgid "Multi-NIC Provisioning"
msgstr "マルチNICプロビジョニング"

#: ./doc/openstack-ops/ch_arch_network_design.xml423(para)
msgid ""
"OpenStack Compute has the ability to assign multiple NICs to instances on a "
"per-project basis. This is generally an advanced feature and not an everyday"
" request. This can easily be done on a per-request basis, though. However, "
"be aware that a second NIC uses up an entire subnet or VLAN. This decrements"
" your total number of supported projects by one.<indexterm "
"class=\"singular\"><primary>MultiNic</primary></indexterm><indexterm "
"class=\"singular\"><primary>network design</primary><secondary>network "
"topology</secondary><tertiary>multi-NIC provisioning</tertiary></indexterm>"
msgstr "OpenStackコンピュートはプロジェクト単位でインスタンスに複数のNICを割り当てる事ができます。これは一般的には追加機能でいつも必要とされる訳ではありませんが、必要とされる度に簡単に設定する事ができます。しかし、2つ目のNIC がサブネット全体あるいはVLANに属してアップしていることを認識しておく必要があります。これは1つのNICでサポートできるプロジェクト数の合計を減らします。<indexterm class=\"singular\"><primary>マルチNIC</primary></indexterm><indexterm class=\"singular\"><primary>ネットワーク設計</primary><secondary>ネットワークトポロジー</secondary><tertiary>マルチNICプロビジョニング</tertiary></indexterm>"

#: ./doc/openstack-ops/ch_arch_network_design.xml440(title)
msgid "Multi-Host and Single-Host Networking"
msgstr "マルチホストあるいはシングルホストネットワーキング"

#: ./doc/openstack-ops/ch_arch_network_design.xml442(para)
msgid ""
"The <literal>nova-network</literal> service has the ability to operate in a "
"multi-host or single-host mode. Multi-host is when each compute node runs a "
"copy of <literal>nova-network</literal> and the instances on that compute "
"node use the compute node as a gateway to the Internet. The compute nodes "
"also host the floating IPs and security groups for instances on that node. "
"Single-host is when a central server—for example, the cloud controller—runs "
"the <code>nova-network</code> service. All compute nodes forward traffic "
"from the instances to the cloud controller. The cloud controller then "
"forwards traffic to the Internet. The cloud controller hosts the floating "
"IPs and security groups for all instances on all compute nodes in the "
"cloud.<indexterm class=\"singular\"><primary>single-host "
"networking</primary></indexterm><indexterm "
"class=\"singular\"><primary>networks</primary><secondary>multi-"
"host</secondary></indexterm><indexterm class=\"singular\"><primary>multi-"
"host networking</primary></indexterm><indexterm "
"class=\"singular\"><primary>network design</primary><secondary>network "
"topology</secondary><tertiary>multi- vs. single-host "
"networking</tertiary></indexterm>"
msgstr "<literal>nova-network</literal>はマルチホストまたはシングルホストモードで運用する事ができます。マルチホスト構成はそれぞれのコンピュートノードで<literal>nova-network</literal> の複製とそのコンピュートノードのインスタンスが稼働している時、コンピュートノードをインターネットへのゲートウェイとして利用します。また、そのコンピュートノードはそこで稼働しているインスタンスのフローティングIPアドレスとセキュリティグループを受け持ちます。シングルホスト構成はクラウドコントローラと言った中央サーバが<code>nova-network</code> サービスを受け持ちます。すべてのコンピュートノードはインターネットへのトラフィックをコントローラに転送します。クラウドコントローラがすべてのコントローラ上のすべてのインスタンスのフローティングIPアドレスとセキュリティグループを受け持ちます。<indexterm class=\"singular\"><primary>シングルホストネットワーク</primary></indexterm><indexterm class=\"singular\"><primary>ネットワーク</primary><secondary>マルチホスト</secondary></indexterm><indexterm class=\"singular\"><primary>マルチホストネットワーク</primary></indexterm><indexterm class=\"singular\"><primary>ネットワークデザイン</primary><secondary>ネットワークトポロジー</secondary><tertiary>マルチvsシングルホストネットワーク</tertiary></indexterm>"

#: ./doc/openstack-ops/ch_arch_network_design.xml469(para)
msgid ""
"There are benefits to both modes. Single-node has the downside of a single "
"point of failure. If the cloud controller is not available, instances cannot"
" communicate on the network. This is not true with multi-host, but multi-"
"host requires that each compute node has a public IP address to communicate "
"on the Internet. If you are not able to obtain a significant block of public"
" IP addresses, multi-host might not be an option."
msgstr "どちらのモードにもメリットがあります。シングルホストモードには、単一障害点というマイナス面があります。クラウドコントローラーが利用できなくなると、インスタンスはネットワークと通信できなくなります。マルチホストモードでは、この状況にはなりませんが、各コンピュートノードはインターネットと通信するためのパブリックIPアドレスが必要となります。十分な大きさのパブリックIPアドレスブロックを取得できない場合には、マルチホストモードは選択肢にならないかもしれません。"

#: ./doc/openstack-ops/ch_arch_network_design.xml480(title)
msgid "Services for Networking"
msgstr "ネットワーク関係のサービス"

#: ./doc/openstack-ops/ch_arch_network_design.xml482(para)
msgid ""
"OpenStack, like any network application, has a number of standard "
"considerations to apply, such as NTP and DNS.<indexterm "
"class=\"singular\"><primary>network design</primary><secondary>services for "
"networking</secondary></indexterm>"
msgstr "多くのネットワークアプリケーションがそうであるようにOpenStackでもNTPやDNS と言った適用するための数多くの検討事項があります。<indexterm class=\"singular\"><primary>ネットワークデザイン</primary><secondary>ネットワークサービス</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_network_design.xml490(title)
msgid "NTP"
msgstr "NTP"

#: ./doc/openstack-ops/ch_arch_network_design.xml492(para)
msgid ""
"Time synchronization is a critical element to ensure continued operation of "
"OpenStack components. Correct time is necessary to avoid errors in instance "
"scheduling, replication of objects in the object store, and even matching "
"log timestamps for debugging.<indexterm "
"class=\"singular\"><primary>networks</primary><secondary>Network Time "
"Protocol (NTP)</secondary></indexterm>"
msgstr "時刻同期はOpenStackコンポーネントを継続運用する上で非常に重要な要素です。正確な時間はインスタンスのスケジューリング、ボブジェクトストア内のオブジェクトのレプリケーションのエラーの回避や、さらにはデバッグのためにログのタイムスタンプの一致という意味合いで必要です。<indexterm class=\"singular\"><primary>ネットワーク</primary><secondary>ネットワークタイムプロトコル (NTP)</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_network_design.xml502(para)
msgid ""
"All servers running OpenStack components should be able to access an "
"appropriate NTP server. You may decide to set up one locally or use the "
"public pools available from the <link href=\"http://www.pool.ntp.org/en/\"> "
"Network Time Protocol project</link>."
msgstr ""

#: ./doc/openstack-ops/ch_arch_network_design.xml510(title)
msgid "DNS"
msgstr "DNS"

#: ./doc/openstack-ops/ch_arch_network_design.xml512(para)
msgid ""
"OpenStack does not currently provide DNS services, aside from the dnsmasq "
"daemon, which resides on <code>nova-network</code> hosts. You could consider"
" providing a dynamic DNS service to allow instances to update a DNS entry "
"with new IP addresses. You can also consider making a generic forward and "
"reverse DNS mapping for instances' IP addresses, such as "
"vm-203-0-113-123.example.com.<indexterm class=\"singular\"><primary>DNS "
"(Domain Name Server, Service or System)</primary><secondary>DNS service "
"choices</secondary></indexterm>"
msgstr "OpenStackは現在のところ <code>nova-network</code>ホストに起動しているdnsmasqデーモンに則したDNSサービスの提供はしていません。インスタンスの新IPアドレスに対するDNSレコードの更新のためにダイナミックDNSの構成を検討する事ができます。また、インスタンスのIPアドレスに対応するvm-203-0-113-123.example.comというような一般的な逆引きDNSサービスの構成も検討する事ができます。<indexterm class=\"singular\"><primary>DNS (Domain Name Serverサービス、システム)</primary><secondary>DNS サービスの選択</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_network_design.xml528(para)
msgid ""
"Armed with your IP address layout and numbers and knowledge about the "
"topologies and services you can use, it's now time to prepare the network "
"for your installation. Be sure to also check out the <link "
"href=\"http://docs.openstack.org/sec/\" title=\"OpenStack Security "
"Guide\"><emphasis>OpenStack Security Guide</emphasis></link> for tips on "
"securing your network. We wish you a good relationship with your networking "
"team!"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml12(title)
msgid "Backup and Recovery"
msgstr "バックアップとリカバリー"

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml14(para)
msgid ""
"Standard backup best practices apply when creating your OpenStack backup "
"policy. For example, how often to back up your data is closely related to "
"how quickly you need to recover from data loss.<indexterm "
"class=\"singular\"><primary>backup/recovery</primary><secondary>considerations</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml24(para)
msgid ""
"If you cannot have any data loss at all, you should also focus on a highly "
"available deployment. The <emphasis><link href=\"http://docs.openstack.org"
"/high-availability-guide/content/\">OpenStack High Availability "
"Guide</link></emphasis> offers suggestions for elimination of a single point"
" of failure that could cause system downtime. While it is not a completely "
"prescriptive document, it offers methods and techniques for avoiding "
"downtime and data loss.<indexterm "
"class=\"singular\"><primary>data</primary><secondary>preventing loss "
"of</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml37(para)
msgid "Other backup considerations include:"
msgstr "さらにバックアップの考慮点として以下があげられます。"

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml41(para)
msgid "How many backups to keep?"
msgstr "いくつのバックアップを持つべきか?"

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml45(para)
msgid "Should backups be kept off-site?"
msgstr "オフサイトにバックアップを置くべきか?"

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml49(para)
msgid "How often should backups be tested?"
msgstr "どの程度の頻度でバックアップをテストすべきか?"

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml53(para)
msgid ""
"Just as important as a backup policy is a recovery policy (or at least "
"recovery testing)."
msgstr "バックアップポリシーと同じくらい大事なことは、リカバリーポリシーです (少なくともリカバリーのテストは必要です)。"

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml57(title)
msgid "What to Back Up"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml59(para)
msgid ""
"While OpenStack is composed of many components and moving parts, backing up "
"the critical data is quite simple.<indexterm "
"class=\"singular\"><primary>backup/recovery</primary><secondary>items "
"included</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml66(para)
msgid ""
"This chapter describes only how to back up configuration files and databases"
" that the various OpenStack components need to run. This chapter does not "
"describe how to back up objects inside Object Storage or data contained "
"inside Block Storage. Generally these areas are left for users to back up on"
" their own."
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml74(title)
msgid "Database Backups"
msgstr "データベースのバックアップ"

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml76(para)
msgid ""
"The example OpenStack architecture designates the cloud controller as the "
"MySQL server. This MySQL server hosts the databases for nova, glance, "
"cinder, and keystone. With all of these databases in one place, it's very "
"easy to create a database backup:<indexterm "
"class=\"singular\"><primary>databases</primary><secondary>backup/recovery "
"of</secondary></indexterm><indexterm "
"class=\"singular\"><primary>backup/recovery</primary><secondary>databases</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml91(para)
msgid "If you only want to backup a single database, you can instead run:"
msgstr "もし、単一のデータベースのみバックアップする場合は次のように実行します。"

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml96(para)
msgid "where <code>nova</code> is the database you want to back up."
msgstr "ここで <code>nova</code> はバックアップ対象のデータベースです。"

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml98(para)
msgid ""
"You can easily automate this process by creating a cron job that runs the "
"following script once per day:"
msgstr "以下のようなcronジョブを一日に一度実行することで、簡単に自動化することも出来ます。"

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml109(para)
msgid ""
"This script dumps the entire MySQL database and deletes any backups older "
"than seven days."
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml114(title)
msgid "File System Backups"
msgstr "ファイルシステムバックアップ"

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml116(para)
msgid ""
"This section discusses which files and directories should be backed up "
"regularly, organized by service.<indexterm class=\"singular\"><primary>file "
"systems</primary><secondary>backup/recovery "
"of</secondary></indexterm><indexterm "
"class=\"singular\"><primary>backup/recovery</primary><secondary>file "
"systems</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml130(para)
msgid ""
"The <filename>/etc/nova</filename> directory on both the cloud controller "
"and compute nodes should be regularly backed up.<indexterm "
"class=\"singular\"><primary>cloud controllers</primary><secondary>file "
"system backups and</secondary></indexterm><indexterm "
"class=\"singular\"><primary>compute "
"nodes</primary><secondary>backup/recovery of</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml142(para)
msgid ""
"<code>/var/log/nova</code> does not need to be backed up if you have all "
"logs going to a central area. It is highly recommended to use a central "
"logging server or back up the log directory."
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml146(para)
msgid ""
"<code>/var/lib/nova</code> is another important directory to back up. The "
"exception to this is the <code>/var/lib/nova/instances</code> subdirectory "
"on compute nodes. This subdirectory contains the KVM images of running "
"instances. You would want to back up this directory only if you need to "
"maintain backup copies of all instances. Under most circumstances, you do "
"not need to do this, but this can vary from cloud to cloud and your service "
"levels. Also be aware that making a backup of a live KVM instance can cause "
"that instance to not boot properly if it is ever restored from a backup."
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml158(title)
msgid "Image Catalog and Delivery"
msgstr "イメージカタログと配布"

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml160(para)
msgid ""
"<code>/etc/glance</code> and <code>/var/log/glance</code> follow the same "
"rules as their nova counterparts.<indexterm "
"class=\"singular\"><primary>Image "
"Service</primary><secondary>backup/recovery of</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml167(para)
msgid ""
"<code>/var/lib/glance</code> should also be backed up. Take special notice "
"of <code>/var/lib/glance/images</code>. If you are using a file-based "
"backend of glance, <code>/var/lib/glance/images</code> is where the images "
"are stored and care should be taken."
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml172(para)
msgid ""
"There are two ways to ensure stability with this directory. The first is to "
"make sure this directory is run on a RAID array. If a disk fails, the "
"directory is available. The second way is to use a tool such as rsync to "
"replicate the images to another server:"
msgstr "このディレクトリの永続性を保証するために二つの方法があります。一つ目はRAIDアレイ上にこのディレクトリを置くことで、ディスク障害時にもこのディレクトリが利用できます。二つ目の方法はrsyncのようなツールを用いてイメージを他のサーバーに複製することです。"

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml182(title)
msgid "Identity"
msgstr "認証"

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml184(para)
msgid ""
"<code>/etc/keystone</code> and <code>/var/log/keystone</code> follow the "
"same rules as other components.<indexterm "
"class=\"singular\"><primary>Identity "
"Service</primary><secondary>backup/recovery</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml191(para)
msgid ""
"<code>/var/lib/keystone</code>, although it should not contain any data "
"being used, can also be backed up just in case."
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml198(para)
msgid ""
"<code>/etc/cinder</code> and <code>/var/log/cinder</code> follow the same "
"rules as other components.<indexterm class=\"singular\"><primary>Block "
"Storage</primary></indexterm><indexterm "
"class=\"singular\"><primary>storage</primary><secondary>block "
"storage</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml207(para)
msgid "<code>/var/lib/cinder</code> should also be backed up."
msgstr "<code>/var/lib/cinder</code>もまたバックアップされるべきです。"

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml213(para)
msgid ""
"<code>/etc/swift</code> is very important to have backed up. This directory "
"contains the swift configuration files as well as the ring files and ring "
"<glossterm>builder file</glossterm>s, which if lost, render the data on your"
" cluster inaccessible. A best practice is to copy the builder files to all "
"storage nodes along with the ring files. Multiple backup copies are spread "
"throughout your storage cluster.<indexterm "
"class=\"singular\"><primary>builder files</primary></indexterm><indexterm "
"class=\"singular\"><primary>rings</primary><secondary>ring "
"builders</secondary></indexterm><indexterm "
"class=\"singular\"><primary>Object "
"Storage</primary><secondary>backup/recovery of</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml234(title)
msgid "Recovering Backups"
msgstr "バックアップのリカバリー"

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml236(para)
msgid ""
"Recovering backups is a fairly simple process. To begin, first ensure that "
"the service you are recovering is not running. For example, to do a full "
"recovery of <literal>nova</literal> on the cloud controller, first stop all "
"<code>nova</code> services:<indexterm "
"class=\"singular\"><primary>recovery</primary><seealso>backup/recovery</seealso></indexterm><indexterm"
" class=\"singular\"><primary>backup/recovery</primary><secondary>recovering "
"backups</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml258(para)
msgid "Now you can import a previously backed-up database:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml262(para)
msgid "You can also restore backed-up nova directories:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml267(para)
msgid "Once the files are restored, start everything back up:"
msgstr "ファイルをリストア後、サービスを起動します。"

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml276(para)
msgid ""
"Other services follow the same process, with their respective directories "
"and <phrase role=\"keep-together\">databases</phrase>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_backup_recovery.xml283(para)
msgid ""
"Backup and subsequent recovery is one of the first tasks system "
"administrators learn. However, each system has different items that need "
"attention. By taking care of your database, image service, and appropriate "
"file system locations, you can be assured that you can handle any event "
"requiring recovery."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml12(title)
msgid "Maintenance, Failures, and Debugging"
msgstr "メンテナンス、故障およびデバッグ"

#: ./doc/openstack-ops/ch_ops_maintenance.xml14(para)
msgid ""
"Downtime, whether planned or unscheduled, is a certainty when running a "
"cloud. This chapter aims to provide useful information for dealing "
"proactively, or reactively, with these occurrences.<indexterm "
"class=\"startofrange\" "
"xml:id=\"maindebug\"><primary>maintenance/debugging</primary><seealso>troubleshooting</seealso></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml26(title)
msgid "Cloud Controller and Storage Proxy Failures and Maintenance"
msgstr "クラウドコントローラーとストレージプロキシの故障とメンテナンス"

#: ./doc/openstack-ops/ch_ops_maintenance.xml28(para)
msgid ""
"The cloud controller and storage proxy are very similar to each other when "
"it comes to expected and unexpected downtime. One of each server type "
"typically runs in the cloud, which makes them very noticeable when they are "
"not running."
msgstr "想定内の場合も想定外の場合も停止時間が発生した場合の挙動が、クラウドコントローラーとストレージプロキシは互いに似ています。クラウドコントローラーとストレージプロキシはそれぞれクラウドで一つ実行されるので、動作していない場合、非常に目立ちます。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml33(para)
msgid ""
"For the cloud controller, the good news is if your cloud is using the "
"FlatDHCP multi-host HA network mode, existing instances and volumes continue"
" to operate while the cloud controller is offline. For the storage proxy, "
"however, no storage traffic is possible until it is back up and running."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml42(title)
#: ./doc/openstack-ops/ch_ops_maintenance.xml174(title)
msgid "Planned Maintenance"
msgstr "計画メンテナンス"

#: ./doc/openstack-ops/ch_ops_maintenance.xml44(para)
msgid ""
"One way to plan for cloud controller or storage proxy maintenance is to "
"simply do it off-hours, such as at 1 a.m. or 2 a.m. This strategy affects "
"fewer users. If your cloud controller or storage proxy is too important to "
"have unavailable at any point in time, you must look into high-availability "
"options.<indexterm class=\"singular\"><primary>cloud "
"controllers</primary><secondary>planned maintenance "
"of</secondary></indexterm><indexterm "
"class=\"singular\"><primary>maintenance/debugging</primary><secondary>cloud "
"controller planned maintenance</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml62(title)
msgid "Rebooting a Cloud Controller or Storage Proxy"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml64(para)
msgid ""
"All in all, just issue the \"reboot\" command. The operating system cleanly "
"shuts down services and then automatically reboots. If you want to be very "
"thorough, run your backup jobs just before you reboot.<indexterm "
"class=\"singular\"><primary>maintenance/debugging</primary><secondary>rebooting"
" following</secondary></indexterm><indexterm "
"class=\"singular\"><primary>storage</primary><secondary>storage proxy "
"maintenance</secondary></indexterm><indexterm "
"class=\"singular\"><primary>reboot</primary><secondary>cloud controller or "
"storage proxy</secondary></indexterm><indexterm "
"class=\"singular\"><primary>cloud "
"controllers</primary><secondary>rebooting</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml89(title)
msgid "After a Cloud Controller or Storage Proxy Reboots"
msgstr "クラウドコントローラーまたはストレージプロキシの再起動後"

#: ./doc/openstack-ops/ch_ops_maintenance.xml91(para)
msgid ""
"After a cloud controller reboots, ensure that all required services were "
"successfully started. The following commands use <code>ps</code> and "
"<code>grep</code> to determine if nova, glance, and keystone are currently "
"running:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml101(para)
msgid ""
"Also check that all services are functioning. The following set of commands "
"sources the <code>openrc</code> file, then runs some basic glance, nova, and"
" keystone commands. If the commands work as expected, you can be confident "
"that those services are in working condition:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml112(para)
msgid ""
"For the storage proxy, ensure that the Object Storage service has resumed:"
msgstr "ストレージプロキシの場合、Object Storage サービスが再開していることを確認します。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml117(para)
msgid "Also check that it is functioning:"
msgstr "また、正しく機能していることを確認します。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml125(title)
msgid "Total Cloud Controller Failure"
msgstr "全体的なクラウドコントローラーの故障"

#: ./doc/openstack-ops/ch_ops_maintenance.xml127(para)
msgid ""
"The cloud controller could completely fail if, for example, its motherboard "
"goes bad. Users will immediately notice the loss of a cloud controller since"
" it provides core functionality to your cloud environment. If your "
"infrastructure monitoring does not alert you that your cloud controller has "
"failed, your users definitely will. Unfortunately, this is a rough "
"situation. The cloud controller is an integral part of your cloud. If you "
"have only one controller, you will have many missing services if it goes "
"down.<indexterm class=\"singular\"><primary>cloud "
"controllers</primary><secondary>total failure "
"of</secondary></indexterm><indexterm "
"class=\"singular\"><primary>maintenance/debugging</primary><secondary>cloud "
"controller total failure</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml144(para)
msgid ""
"To avoid this situation, create a highly available cloud controller cluster."
" This is outside the scope of this document, but you can read more in the "
"draft <link href=\"http://docs.openstack.org/high-availability-guide/content"
"/ch-intro.html\">OpenStack High Availability Guide</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml150(para)
msgid ""
"The next best approach is to use a configuration-management tool, such as "
"Puppet, to automatically build a cloud controller. This should not take more"
" than 15 minutes if you have a spare server available. After the controller "
"rebuilds, restore any backups taken (see <xref "
"linkend=\"backup_and_recovery\"/>)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml156(para)
msgid ""
"Also, in practice, the <literal>nova-compute</literal> services on the "
"compute nodes do not always reconnect cleanly to rabbitmq hosted on the "
"controller when it comes back up after a long reboot; a restart on the nova "
"services on the compute nodes is required."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml166(title)
msgid "Compute Node Failures and Maintenance"
msgstr "コンピュートノードの故障とメンテナンス"

#: ./doc/openstack-ops/ch_ops_maintenance.xml168(para)
msgid ""
"Sometimes a compute node either crashes unexpectedly or requires a reboot "
"for maintenance reasons."
msgstr "コンピュートノードは、予期せずクラッシュしたり、メンテナンスのために再起動が必要になったりすることがときどきあります。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml176(para)
msgid ""
"If you need to reboot a compute node due to planned maintenance (such as a "
"software or hardware upgrade), first ensure that all hosted instances have "
"been moved off the node. If your cloud is utilizing shared storage, use the "
"<code>nova live-migration</code> command. First, get a list of instances "
"that need to be moved:<indexterm class=\"singular\"><primary>compute "
"nodes</primary><secondary>maintenance</secondary></indexterm><indexterm "
"class=\"singular\"><primary>maintenance/debugging</primary><secondary>compute"
" node planned maintenance</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml193(para)
msgid "Next, migrate them one by one:"
msgstr "次に、それらを一つずつマイグレーションします。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml197(para)
msgid ""
"If you are not using shared storage, you can use the <code>--block-"
"migrate</code> option:"
msgstr "共有ストレージを使用していない場合、<code>--block-migrate</code> オプションを使用できます。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml202(para)
msgid ""
"After you have migrated all instances, ensure that the <code>nova-"
"compute</code> service has <phrase role=\"keep-together\">stopped</phrase>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml208(para)
msgid ""
"If you use a configuration-management system, such as Puppet, that ensures "
"the <code>nova-compute</code> service is always running, you can temporarily"
" move the <literal>init</literal> files:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml216(para)
msgid ""
"Next, shut down your compute node, perform your maintenance, and turn the "
"node back on. You can reenable the <code>nova-compute</code> service by "
"undoing the previous commands:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml223(para)
msgid "Then start the <code>nova-compute</code> service:"
msgstr "そして <code>nova-compute</code> サービスを起動します。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml227(para)
msgid ""
"You can now optionally migrate the instances back to their original compute "
"node."
msgstr "インスタンスを元のコンピュートノードにマイグレーションすることもできます。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml234(title)
msgid "After a Compute Node Reboots"
msgstr "コンピュートノードの再起動後"

#: ./doc/openstack-ops/ch_ops_maintenance.xml236(para)
msgid ""
"When you reboot a compute node, first verify that it booted successfully. "
"This includes ensuring that the <code>nova-compute</code> service is "
"running:<indexterm "
"class=\"singular\"><primary>reboot</primary><secondary>compute "
"node</secondary></indexterm><indexterm "
"class=\"singular\"><primary>maintenance/debugging</primary><secondary>compute"
" node reboot</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml251(para)
msgid "Also ensure that it has successfully connected to the AMQP server:"
msgstr "AMQP サーバーに正常に接続できることも確認します。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml257(para)
msgid ""
"After the compute node is successfully running, you must deal with the "
"instances that are hosted on that compute node because none of them are "
"running. Depending on your SLA with your users or customers, you might have "
"to start each instance and ensure that they start correctly."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml269(para)
msgid ""
"You can create a list of instances that are hosted on the compute node by "
"performing the following command:<indexterm "
"class=\"singular\"><primary>instances</primary><secondary>maintenance/debugging</secondary></indexterm><indexterm"
" "
"class=\"singular\"><primary>maintenance/debugging</primary><secondary>instances</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml282(para)
msgid ""
"After you have the list, you can use the nova command to start each "
"instance:"
msgstr "一覧を取得した後、各インスタンスを起動するために nova コマンドを使用できます。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml288(para)
msgid ""
"Any time an instance shuts down unexpectedly, it might have problems on "
"boot. For example, the instance might require an <code>fsck</code> on the "
"root partition. If this happens, the user can use the dashboard VNC console "
"to fix this."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml294(para)
msgid ""
"If an instance does not boot, meaning <code>virsh list</code> never shows "
"the instance as even attempting to boot, do the following on the compute "
"node:"
msgstr "インスタンスがブートしなければ、つまりブートしようとしても <code>virsh list</code> がインスタンスを表示しなければ、コンピュートノードにおいて以下のとおり実行します。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml300(para)
msgid ""
"Try executing the <code>nova reboot</code> command again. You should see an "
"error message about why the instance was not able to boot"
msgstr "再び <code>nova reboot</code> コマンドを実行してみてください。インスタンスがなぜブートできないかについて、エラーメッセージを確認すべきです。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml304(para)
msgid ""
"In most cases, the error is the result of something in libvirt's XML file "
"(<code>/etc/libvirt/qemu/instance-xxxxxxxx.xml</code>) that no longer "
"exists. You can enforce re-creation of the XML file as well as rebooting the"
" instance by running the following command:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml315(title)
msgid "Inspecting and Recovering Data from Failed Instances"
msgstr "故障したインスタンスからの検査とデータ復旧"

#: ./doc/openstack-ops/ch_ops_maintenance.xml317(para)
msgid ""
"In some scenarios, instances are running but are inaccessible through SSH "
"and do not respond to any command. The VNC console could be displaying a "
"boot failure or kernel panic error messages. This could be an indication of "
"file system corruption on the VM itself. If you need to recover files or "
"inspect the content of the instance, qemu-nbd can be used to mount the "
"disk.<indexterm "
"class=\"singular\"><primary>data</primary><secondary>inspecting/recovering "
"failed instances</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml329(para)
msgid ""
"If you access or view the user's content and data, get approval "
"first!<indexterm class=\"singular\"><primary>security "
"issues</primary><secondary>failed instance data "
"inspection</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml337(para)
msgid ""
"To access the instance's disk "
"(<literal>/var/lib/nova/instances/instance-<replaceable>xxxxxx</replaceable>/disk</literal>),"
" use the following steps:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml343(para)
msgid "Suspend the instance using the <literal>virsh</literal> command."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml348(para)
msgid "Connect the qemu-nbd device to the disk."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml352(para)
#: ./doc/openstack-ops/ch_ops_maintenance.xml412(para)
msgid "Mount the qemu-nbd device."
msgstr "qemu-nbd デバイスをマウントします。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml356(para)
msgid "Unmount the device after inspecting."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml360(para)
msgid "Disconnect the qemu-nbd device."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml364(para)
msgid "Resume the instance."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml368(para)
msgid ""
"If you do not follow steps 4 through 6, OpenStack Compute cannot manage the "
"instance any longer. It fails to respond to any command issued by OpenStack "
"Compute, and it is marked as shut down."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml372(para)
msgid ""
"Once you mount the disk file, you should be able to access it and treat it "
"as a collection of normal directories with files and a directory structure. "
"However, we do not recommend that you edit or touch any files because this "
"could change the access control lists (ACLs) that are used to determine "
"which accounts can perform what operations on files and directories. "
"Changing ACLs can make the instance unbootable if it is not "
"already.<indexterm class=\"singular\"><primary>access control list "
"(ACL)</primary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml384(para)
msgid ""
"Suspend the instance using the <literal>virsh</literal> command, taking note"
" of the internal ID:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml399(para)
msgid "Connect the qemu-nbd device to the disk:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml414(para)
msgid ""
"The qemu-nbd device tries to export the instance disk's different partitions"
" as separate devices. For example, if vda is the disk and vda1 is the root "
"partition, qemu-nbd exports the device as <literal>/dev/nbd0</literal> and "
"<literal>/dev/nbd0p1</literal>, respectively:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml422(para)
msgid ""
"You can now access the contents of <code>/mnt</code>, which correspond to "
"the first partition of the instance's disk."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml425(para)
msgid ""
"To examine the secondary or ephemeral disk, use an alternate mount point if "
"you want both primary and secondary drives mounted at the same time:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml458(para)
msgid ""
"Once you have completed the inspection, unmount the mount point and release "
"the qemu-nbd device:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml467(para)
msgid "Resume the instance using <literal>virsh</literal>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml485(title)
msgid "Volumes"
msgstr "ボリューム"

#: ./doc/openstack-ops/ch_ops_maintenance.xml487(para)
msgid ""
"If the affected instances also had attached volumes, first generate a list "
"of instance and volume UUIDs:<indexterm "
"class=\"singular\"><primary>volume</primary><secondary>maintenance/debugging</secondary></indexterm><indexterm"
" "
"class=\"singular\"><primary>maintenance/debugging</primary><secondary>volumes</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml505(para)
msgid "You should see a result similar to the following:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml515(para)
msgid ""
"Next, manually detach and reattach the volumes, where X is the proper mount "
"point:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml521(para)
msgid ""
"Be sure that the instance has successfully booted and is at a login screen "
"before doing the above."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml528(title)
msgid "Total Compute Node Failure"
msgstr "コンピュートノード全体の故障"

#: ./doc/openstack-ops/ch_ops_maintenance.xml530(para)
msgid ""
"Compute nodes can fail the same way a cloud controller can fail. A "
"motherboard failure or some other type of hardware failure can cause an "
"entire compute node to go offline. When this happens, all instances running "
"on that compute node will not be available. Just like with a cloud "
"controller failure, if your infrastructure monitoring does not detect a "
"failed compute node, your users will notify you because of their lost "
"instances.<indexterm class=\"singular\"><primary>compute "
"nodes</primary><secondary>failures</secondary></indexterm><indexterm "
"class=\"singular\"><primary>maintenance/debugging</primary><secondary>compute"
" node total failures</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml546(para)
msgid ""
"If a compute node fails and won't be fixed for a few hours (or at all), you "
"can relaunch all instances that are hosted on the failed node if you use "
"shared storage for <code>/var/lib/nova/instances</code>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml551(para)
msgid ""
"To do this, generate a list of instance UUIDs that are hosted on the failed "
"node by running the following query on the nova database:"
msgstr "これを実行するために、nova データベースにおいて以下のクエリーを実行することにより、故障したノードにおいてホストされているインスタンスの UUID の一覧を生成します。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml558(para)
msgid ""
"Next, update the nova database to indicate that all instances that used to "
"be hosted on c01.example.com are now hosted on c02.example.com:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml565(para)
msgid ""
"After that, use the <literal>nova</literal> command to reboot all instances "
"that were on c01.example.com while regenerating their XML files at the same "
"time:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml571(para)
msgid ""
"Finally, reattach volumes using the same method described in the section "
"<link linkend=\"volumes\">Volumes</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml578(title)
msgid "/var/lib/nova/instances"
msgstr "/var/lib/nova/instances"

#: ./doc/openstack-ops/ch_ops_maintenance.xml580(para)
msgid ""
"It's worth mentioning this directory in the context of failed compute nodes."
" This directory contains the libvirt KVM file-based disk images for the "
"instances that are hosted on that compute node. If you are not running your "
"cloud in a shared storage environment, this directory is unique across all "
"compute nodes.<indexterm class=\"singular\"><primary>/var/lib/nova/instances"
" directory</primary></indexterm><indexterm "
"class=\"singular\"><primary>maintenance/debugging</primary><secondary>/var/lib/nova/instances</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml592(para)
msgid ""
"<code>/var/lib/nova/instances</code> contains two types of directories."
msgstr "<code>/var/lib/nova/instances</code> には 2 種類のディレクトリがあります。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml595(para)
msgid ""
"The first is the <code>_base</code> directory. This contains all the cached "
"base images from glance for each unique image that has been launched on that"
" compute node. Files ending in <code>_20</code> (or a different number) are "
"the ephemeral base images."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml600(para)
msgid ""
"The other directories are titled <code>instance-xxxxxxxx</code>. These "
"directories correspond to instances running on that compute node. The files "
"inside are related to one of the files in the <code>_base</code> directory. "
"They're essentially differential-based files containing only the changes "
"made from the original <code>_base</code> directory."
msgstr "もう一つのディレクトリは <code>instance-xxxxxxxx</code> という名前です。これらのディレクトリはコンピュートノードにおいて実行中のインスタンスと対応します。中にあるファイルは <code>_base</code> ディレクトリにあるファイルのどれかと関連があります。これらは基本的に、元々の <code>_base</code> ディレクトリからの変更点のみ含む、差分ベースのファイルです。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml607(para)
msgid ""
"All files and directories in <code>/var/lib/nova/instances</code> are "
"uniquely named. The files in _base are uniquely titled for the glance image "
"that they are based on, and the directory names <code>instance-"
"xxxxxxxx</code> are uniquely titled for that particular instance. For "
"example, if you copy all data from <code>/var/lib/nova/instances</code> on "
"one compute node to another, you do not overwrite any files or cause any "
"damage to images that have the same unique name, because they are "
"essentially the same file."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml616(para)
msgid ""
"Although this method is not documented or supported, you can use it when "
"your compute node is permanently offline but you have instances locally "
"stored on it."
msgstr "この方法はドキュメントに書かれておらず、サポートされていない方法ですが、コンピュートノードが完全にオフラインになってしまったが、インスタンスがローカルに保存されているときに、この方法を使用できます。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml625(title)
msgid "Storage Node Failures and Maintenance"
msgstr "ストレージノードの故障とメンテナンス"

#: ./doc/openstack-ops/ch_ops_maintenance.xml627(para)
msgid ""
"Because of the high redundancy of Object Storage, dealing with object "
"storage node issues is a lot easier than dealing with compute node issues."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml634(title)
msgid "Rebooting a Storage Node"
msgstr "ストレージノードの再起動"

#: ./doc/openstack-ops/ch_ops_maintenance.xml636(para)
msgid ""
"If a storage node requires a reboot, simply reboot it. Requests for data "
"hosted on that node are redirected to other copies while the server is "
"rebooting.<indexterm class=\"singular\"><primary>storage "
"node</primary></indexterm><indexterm "
"class=\"singular\"><primary>nodes</primary><secondary>storage "
"nodes</secondary></indexterm><indexterm "
"class=\"singular\"><primary>maintenance/debugging</primary><secondary>storage"
" node reboot</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml654(title)
msgid "Shutting Down a Storage Node"
msgstr "ストレージノードのシャットダウン"

#: ./doc/openstack-ops/ch_ops_maintenance.xml656(para)
msgid ""
"If you need to shut down a storage node for an extended period of time (one "
"or more days), consider removing the node from the storage ring. For "
"example:<indexterm "
"class=\"singular\"><primary>maintenance/debugging</primary><secondary>storage"
" node shut down</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml671(para)
msgid "Next, redistribute the ring files to the other nodes:"
msgstr "次に、ring ファイルを他のノードに再配布します。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml678(para)
msgid ""
"These actions effectively take the storage node out of the storage cluster."
msgstr "これらの操作はストレージノードをストレージクラスターから効率的に外せます。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml681(para)
msgid ""
"When the node is able to rejoin the cluster, just add it back to the ring. "
"The exact syntax you use to add a node to your swift cluster with <code"
">swift-ring-builder</code> heavily depends on the original options used when"
" you originally created your cluster. Please refer back to those commands."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml691(title)
msgid "Replacing a Swift Disk"
msgstr "Swift ディスクの交換"

#: ./doc/openstack-ops/ch_ops_maintenance.xml693(para)
msgid ""
"If a hard drive fails in an Object Storage node, replacing it is relatively "
"easy. This assumes that your Object Storage environment is configured "
"correctly, where the data that is stored on the failed drive is also "
"replicated to other drives in the Object Storage environment.<indexterm "
"class=\"singular\"><primary>hard drives, "
"replacing</primary></indexterm><indexterm "
"class=\"singular\"><primary>maintenance/debugging</primary><secondary>swift "
"disk replacement</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml705(para)
msgid "This example assumes that <code>/dev/sdb</code> has failed."
msgstr "この例では、<code>/dev/sdb</code> が故障したと仮定します。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml707(para)
msgid "First, unmount the disk:"
msgstr "まず、ディスクをアンマウントします。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml711(para)
msgid ""
"Next, physically remove the disk from the server and replace it with a "
"working disk."
msgstr "次に、ディスクを物理的にサーバーから取り外し、正常なディスクと入れ替えます。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml714(para)
msgid "Ensure that the operating system has recognized the new disk:"
msgstr "オペレーティングシステムが新しいディスクを認識していることを確認します。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml719(para)
msgid "You should see a message about <code>/dev/sdb</code>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml721(para)
msgid ""
"Because it is recommended to not use partitions on a swift disk, simply "
"format the disk as a whole:"
msgstr "Swift ディスクではパーティションを使用しないことが推奨されるので、単にディスク全体をフォーマットします。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml726(para)
msgid "Finally, mount the disk:"
msgstr "最後に、ディスクをマウントします。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml730(para)
msgid ""
"Swift should notice the new disk and that no data exists. It then begins "
"replicating the data to the disk from the other existing replicas."
msgstr "Swift は新しいディスクを認識します。また、データが存在しないことを認識します。そうすると、他の既存の複製からディスクにデータを複製しはじめます。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml739(title)
msgid "Handling a Complete Failure"
msgstr "完全な故障の対処"

#: ./doc/openstack-ops/ch_ops_maintenance.xml741(para)
msgid ""
"A common way of dealing with the recovery from a full system failure, such "
"as a power outage of a data center, is to assign each service a priority, "
"and restore in order. <xref linkend=\"restor-prior-table\"/> shows an "
"example.<indexterm class=\"singular\"><primary>service "
"restoration</primary></indexterm><indexterm "
"class=\"singular\"><primary>maintenance/debugging</primary><secondary>complete"
" failures</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml754(caption)
msgid "Example service restoration priority list"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml758(th)
msgid "Priority"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml760(th)
msgid "Services"
msgstr "サービス"

#: ./doc/openstack-ops/ch_ops_maintenance.xml768(para)
msgid "Internal network connectivity"
msgstr "内部ネットワーク接続性"

#: ./doc/openstack-ops/ch_ops_maintenance.xml774(para)
msgid "Backing storage services"
msgstr "バックエンドのストレージサービス"

#: ./doc/openstack-ops/ch_ops_maintenance.xml778(para)
msgid "3"
msgstr "3"

#: ./doc/openstack-ops/ch_ops_maintenance.xml780(para)
msgid "Public network connectivity for user virtual machines"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml787(para)
msgid ""
"<literal>nova-compute</literal>, <literal>nova-network</literal>, cinder "
"hosts"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml792(para)
msgid "5"
msgstr "5"

#: ./doc/openstack-ops/ch_ops_maintenance.xml794(para)
msgid "User virtual machines"
msgstr "ユーザーの仮想マシン"

#: ./doc/openstack-ops/ch_ops_maintenance.xml798(para)
msgid "10"
msgstr "10"

#: ./doc/openstack-ops/ch_ops_maintenance.xml800(para)
msgid "Message queue and database services"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml804(para)
msgid "15"
msgstr "15"

#: ./doc/openstack-ops/ch_ops_maintenance.xml806(para)
msgid "Keystone services"
msgstr "Keystone サービス"

#: ./doc/openstack-ops/ch_ops_maintenance.xml810(para)
msgid "20"
msgstr "20"

#: ./doc/openstack-ops/ch_ops_maintenance.xml812(literal)
msgid "cinder-scheduler"
msgstr "cinder-scheduler"

#: ./doc/openstack-ops/ch_ops_maintenance.xml816(para)
msgid "21"
msgstr "21"

#: ./doc/openstack-ops/ch_ops_maintenance.xml818(para)
msgid "Image Catalog and Delivery services"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml822(para)
msgid "22"
msgstr "22"

#: ./doc/openstack-ops/ch_ops_maintenance.xml824(para)
msgid "<literal>nova-scheduler</literal> services"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml828(para)
msgid "98"
msgstr "98"

#: ./doc/openstack-ops/ch_ops_maintenance.xml830(literal)
msgid "cinder-api"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml834(para)
msgid "99"
msgstr "99"

#: ./doc/openstack-ops/ch_ops_maintenance.xml836(para)
msgid "<literal>nova-api</literal> services"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml840(para)
msgid "100"
msgstr "100"

#: ./doc/openstack-ops/ch_ops_maintenance.xml842(para)
msgid "Dashboard node"
msgstr "ダッシュボードサービス"

#: ./doc/openstack-ops/ch_ops_maintenance.xml847(para)
msgid ""
"Use this example priority list to ensure that user-affected services are "
"restored as soon as possible, but not before a stable environment is in "
"place. Of course, despite being listed as a single-line item, each step "
"requires significant work. For example, just after starting the database, "
"you should check its integrity, or, after starting the nova services, you "
"should verify that the hypervisor matches the database and fix any <phrase "
"role=\"keep-together\">mismatches</phrase>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml861(para)
msgid ""
"Maintaining an OpenStack cloud requires that you manage multiple physical "
"servers, and this number might grow over time. Because managing nodes "
"manually is error prone, we strongly recommend that you use a configuration-"
"management tool. These tools automate the process of ensuring that all your "
"nodes are configured properly and encourage you to maintain your "
"configuration information (such as packages and configuration options) in a "
"version-controlled repository.<indexterm "
"class=\"singular\"><primary>configuration "
"management</primary></indexterm><indexterm "
"class=\"singular\"><primary>networks</primary><secondary>configuration "
"management</secondary></indexterm><indexterm "
"class=\"singular\"><primary>maintenance/debugging</primary><secondary>configuration"
" management</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml881(para)
msgid ""
"Several configuration-management tools are available, and this guide does "
"not recommend a specific one. The two most popular ones in the OpenStack "
"community are <link href=\"https://puppetlabs.com/\">Puppet</link>, with "
"available <link href=\"https://github.com/puppetlabs/puppetlabs-"
"openstack\">OpenStack Puppet modules</link>; and <link "
"href=\"http://www.getchef.com/chef/\">Chef</link>, with available <link "
"href=\"https://github.com/opscode/openstack-chef-repo\">OpenStack Chef "
"recipes</link>. Other newer configuration tools include <link "
"href=\"https://juju.ubuntu.com/\">Juju</link>, <link "
"href=\"http://www.ansible.com/home\">Ansible</link>, and <link "
"href=\"http://www.saltstack.com/\">Salt</link>; and more mature "
"configuration management tools include <link "
"href=\"http://cfengine.com/\">CFEngine</link> and <link "
"href=\"http://bcfg2.org/\">Bcfg2</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml902(title)
msgid "Working with Hardware"
msgstr "ハードウェアの取り扱い"

#: ./doc/openstack-ops/ch_ops_maintenance.xml904(para)
msgid ""
"As for your initial deployment, you should ensure that all hardware is "
"appropriately burned in before adding it to production. Run software that "
"uses the hardware to its limits—maxing out RAM, CPU, disk, and network. Many"
" options are available, and normally double as benchmark software, so you "
"also get a good idea of the performance of your system.<indexterm "
"class=\"singular\"><primary>hardware</primary><secondary>maintenance/debugging</secondary></indexterm><indexterm"
" "
"class=\"singular\"><primary>maintenance/debugging</primary><secondary>hardware</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml922(title)
msgid "Adding a Compute Node"
msgstr "コンピュートノードの追加"

#: ./doc/openstack-ops/ch_ops_maintenance.xml924(para)
msgid ""
"If you find that you have reached or are reaching the capacity limit of your"
" computing resources, you should plan to add additional compute nodes. "
"Adding more nodes is quite easy. The process for adding compute nodes is the"
" same as when the initial compute nodes were deployed to your cloud: use an "
"automated deployment system to bootstrap the bare-metal server with the "
"operating system and then have a configuration-management system install and"
" configure OpenStack Compute. Once the Compute Service has been installed "
"and configured in the same way as the other compute nodes, it automatically "
"attaches itself to the cloud. The cloud controller notices the new node(s) "
"and begins scheduling instances to launch there.<indexterm "
"class=\"singular\"><primary>cloud controllers</primary><secondary>new "
"compute nodes and</secondary></indexterm><indexterm "
"class=\"singular\"><primary>nodes</primary><secondary>adding</secondary></indexterm><indexterm"
" class=\"singular\"><primary>compute "
"nodes</primary><secondary>adding</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml948(para)
msgid ""
"If your OpenStack Block Storage nodes are separate from your compute nodes, "
"the same procedure still applies because the same queuing and polling system"
" is used in both services."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml952(para)
msgid ""
"We recommend that you use the same hardware for new compute and block "
"storage nodes. At the very least, ensure that the CPUs are similar in the "
"compute nodes to not break live migration."
msgstr "新しいコンピュートノードとブロックストレージノードには、同じハードウェアを使用することを推奨します。最低限、ライブマイグレーションが失敗しないように、コンピュートノードでは CPU は同様のものにしてください。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml960(title)
msgid "Adding an Object Storage Node"
msgstr "オブジェクトストレージノードの追加"

#: ./doc/openstack-ops/ch_ops_maintenance.xml962(para)
msgid ""
"Adding a new object storage node is different from adding compute or block "
"storage nodes. You still want to initially configure the server by using "
"your automated deployment and configuration-management systems. After that "
"is done, you need to add the local disks of the object storage node into the"
" object storage ring. The exact command to do this is the same command that "
"was used to add the initial disks to the ring. Simply rerun this command on "
"the object storage proxy server for all disks on the new object storage "
"node. Once this has been done, rebalance the ring and copy the resulting "
"ring files to the other storage nodes.<indexterm "
"class=\"singular\"><primary>Object Storage</primary><secondary>adding "
"nodes</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml978(para)
msgid ""
"If your new object storage node has a different number of disks than the "
"original nodes have, the command to add the new node is different from the "
"original commands. These parameters vary from environment to environment."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml988(title)
msgid "Replacing Components"
msgstr "コンポーネントの交換"

#: ./doc/openstack-ops/ch_ops_maintenance.xml990(para)
msgid ""
"Failures of hardware are common in large-scale deployments such as an "
"infrastructure cloud. Consider your processes and balance time saving "
"against availability. For example, an Object Storage cluster can easily live"
" with dead disks in it for some period of time if it has sufficient "
"capacity. Or, if your compute installation is not full, you could consider "
"live migrating instances off a host with a RAM failure until you have time "
"to deal with the problem."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml1003(title)
#: ./doc/openstack-ops/ch_arch_cloud_controller.xml51(term)
msgid "Databases"
msgstr "データベース"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1005(para)
msgid ""
"Almost all OpenStack components have an underlying database to store "
"persistent information. Usually this database is MySQL. Normal MySQL "
"administration is applicable to these databases. OpenStack does not "
"configure the databases out of the ordinary. Basic administration includes "
"performance tweaking, high availability, backup, recovery, and repairing. "
"For more information, see a standard MySQL administration guide.<indexterm "
"class=\"singular\"><primary>databases</primary><secondary>maintenance/debugging</secondary></indexterm><indexterm"
" "
"class=\"singular\"><primary>maintenance/debugging</primary><secondary>databases</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml1021(para)
msgid ""
"You can perform a couple of tricks with the database to either more quickly "
"retrieve information or fix a data inconsistency error—for example, an "
"instance was terminated, but the status was not updated in the database. "
"These tricks are discussed throughout this book."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml1029(title)
msgid "Database Connectivity"
msgstr "データベース接続性"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1031(para)
msgid ""
"Review the component's configuration file to see how each OpenStack "
"component accesses its corresponding database. Look for either "
"<code>sql_connection</code> or simply <code>connection</code>. The following"
" command uses <code>grep</code> to display the SQL connection string for "
"nova, glance, cinder, and keystone:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml1037(emphasis)
msgid ""
"grep -hE \"connection ?=\" /etc/nova/nova.conf /etc/glance/glance-*.conf "
"/etc/cinder/cinder.conf /etc/keystone/keystone.conf"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml1045(para)
msgid "The connection strings take this format:"
msgstr "connection 文字列は以下の形式をとります。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1053(title)
msgid "Performance and Optimizing"
msgstr "パフォーマンスと最適化"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1055(para)
msgid ""
"As your cloud grows, MySQL is utilized more and more. If you suspect that "
"MySQL might be becoming a bottleneck, you should start researching MySQL "
"optimization. The MySQL manual has an entire section dedicated to this "
"topic: <link href=\"http://dev.mysql.com/doc/refman/5.5/en/optimize-"
"overview.html\">Optimization Overview</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml1067(title)
msgid "HDWMY"
msgstr "HDWMY"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1069(para)
msgid ""
"Here's a quick list of various to-do items for each hour, day, week, month, "
"and year. Please note that these tasks are neither required nor definitive "
"but helpful ideas:<indexterm "
"class=\"singular\"><primary>maintenance/debugging</primary><secondary>schedule"
" of tasks</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml1080(title)
msgid "Hourly"
msgstr "毎時"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1084(para)
msgid "Check your monitoring system for alerts and act on them."
msgstr "監視システムのアラートを確認し、それらに対処します。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1089(para)
msgid "Check your ticket queue for new tickets."
msgstr "チケットキューの新しいチケットを確認します。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1097(title)
msgid "Daily"
msgstr "日次"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1101(para)
msgid "Check for instances in a failed or weird state and investigate why."
msgstr "故障または異常になっているインスタンスを確認し、理由を調査します。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1106(para)
msgid "Check for security patches and apply them as needed."
msgstr "セキュリティパッチを確認し、必要に応じて適用します。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1114(title)
msgid "Weekly"
msgstr "週次"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1120(para)
msgid "User quotas"
msgstr "ユーザークォータ"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1124(para)
msgid "Disk space"
msgstr "ディスク領域"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1128(para)
msgid "Image usage"
msgstr "イメージ使用量"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1132(para)
msgid "Large instances"
msgstr "大きなインスタンス"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1136(para)
msgid "Network usage (bandwidth and IP usage)"
msgstr "ネットワーク使用量 (帯域および IP 使用量)"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1118(para)
msgid "Check cloud usage: <placeholder-1/>"
msgstr "クラウドの使用量を確認します: <placeholder-1/>"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1142(para)
msgid "Verify your alert mechanisms are still working."
msgstr "アラート機能が動作していることを確認します。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1150(title)
msgid "Monthly"
msgstr "月次"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1154(para)
msgid "Check usage and trends over the past month."
msgstr "この 1 か月における使用量および傾向を確認します。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1158(para)
msgid "Check for user accounts that should be removed."
msgstr "削除すべきユーザーアカウントを確認します。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1162(para)
msgid "Check for operator accounts that should be removed."
msgstr "削除すべきオペレーターアカウントを確認します。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1170(title)
msgid "Quarterly"
msgstr "四半期ごと"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1174(para)
msgid "Review usage and trends over the past quarter."
msgstr "この四半期における使用量および傾向を確認します。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1178(para)
msgid "Prepare any quarterly reports on usage and statistics."
msgstr "使用量と統計に関する四半期レポートを準備します。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1182(para)
msgid "Review and plan any necessary cloud additions."
msgstr "クラウドの追加の必要性を検討し、計画を立てます。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1186(para)
msgid "Review and plan any major OpenStack upgrades."
msgstr "OpenStack のメジャーアップグレードの内容を確認し、その計画を立てます。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1194(title)
msgid "Semiannually"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml1198(para)
msgid "Upgrade OpenStack."
msgstr "OpenStack をアップグレードします。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1202(para)
msgid ""
"Clean up after an OpenStack upgrade (any unused or new services to be aware "
"of?)."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml1212(title)
msgid "Determining Which Component Is Broken"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml1214(para)
msgid ""
"OpenStack's collection of different components interact with each other "
"strongly. For example, uploading an image requires interaction from <code"
">nova-api</code>, <code>glance-api</code>, <code>glance-registry</code>, "
"keystone, and potentially <code>swift-proxy</code>. As a result, it is "
"sometimes difficult to determine exactly where problems lie. Assisting in "
"this is the purpose of this section.<indexterm "
"class=\"singular\"><primary>logging/monitoring</primary><secondary>tailing "
"logs</secondary></indexterm><indexterm "
"class=\"singular\"><primary>maintenance/debugging</primary><secondary>determining"
" component affected</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml1233(title)
msgid "Tailing Logs"
msgstr "最新ログの確認"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1235(para)
msgid ""
"The first place to look is the log file related to the command you are "
"trying to run. For example, if <code>nova list</code> is failing, try "
"tailing a nova log file and running the command again:<indexterm "
"class=\"singular\"><primary>tailing logs</primary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml1242(para)
#: ./doc/openstack-ops/ch_ops_maintenance.xml1257(para)
msgid "Terminal 1:"
msgstr "端末 1:"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1246(para)
#: ./doc/openstack-ops/ch_ops_maintenance.xml1261(para)
msgid "Terminal 2:"
msgstr "端末 2:"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1250(para)
msgid ""
"Look for any errors or traces in the log file. For more information, see "
"<xref linkend=\"logging_monitoring\"/>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml1253(para)
msgid ""
"If the error indicates that the problem is with another component, switch to"
" tailing that component's log file. For example, if nova cannot access "
"glance, look at the <literal>glance-api</literal> log:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml1265(para)
msgid "Wash, rinse, and repeat until you find the core cause of the problem."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml1272(title)
msgid "Running Daemons on the CLI"
msgstr "コマンドラインでのデーモンの実行"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1274(para)
msgid ""
"Unfortunately, sometimes the error is not apparent from the log files. In "
"this case, switch tactics and use a different command; maybe run the service"
" directly on the command line. For example, if the <code>glance-api</code> "
"service refuses to start and stay running, try launching the daemon from the"
" command line:<indexterm "
"class=\"singular\"><primary>daemons</primary><secondary>running on "
"CLI</secondary></indexterm><indexterm class=\"singular\"><primary>Command-"
"line interface (CLI)</primary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml1289(para)
msgid ""
"The <literal>-H</literal> flag is required when running the daemons with "
"sudo because some daemons will write files relative to the user's home "
"directory, and this write may fail if <literal>-H</literal> is left off."
msgstr "sudo を用いてデーモンを実行するとき、<literal>-H</literal> フラグが必要です。いくつかのデーモンは、ユーザーのホームディレクトリーからの相対パスのファイルに書き込みを行うため、<literal>-H</literal> がないと、この書き込みが失敗してしまいます。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1288(para)
msgid "This might print the error and cause of the problem.<placeholder-1/>"
msgstr "これにより、エラーと問題の原因が表示されるかもしれません。 <placeholder-1/>"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1296(title)
msgid "Example of Complexity"
msgstr "複雑な例"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1298(para)
msgid ""
"One morning, a compute node failed to run any instances. The log files were "
"a bit vague, claiming that a certain instance was unable to be started. This"
" ended up being a red herring because the instance was simply the first "
"instance in alphabetical order, so it was the first instance that <literal"
">nova-compute</literal> would touch."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml1304(para)
msgid ""
"Further troubleshooting showed that libvirt was not running at all. This "
"made more sense. If libvirt wasn't running, then no instance could be "
"virtualized through KVM. Upon trying to start libvirt, it would silently die"
" immediately. The libvirt logs did not explain why."
msgstr "さらなるトラブルシューティングにより、libvirt がまったく動作していないことがわかりました。これは大きな手がかりです。libvirt が動作していないと、KVM によるインスタンスの仮想化ができません。libvirt を開始させようとしても、libvirt は何も表示せずすぐに停止しました。libvirt のログでは理由がわかりませんでした。"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1310(para)
msgid ""
"Next, the <code>libvirtd</code> daemon was run on the command line. Finally "
"a helpful error message: it could not connect to d-bus. As ridiculous as it "
"sounds, libvirt, and thus <code>nova-compute</code>, relies on d-bus and "
"somehow d-bus crashed. Simply starting d-bus set the entire chain back on "
"track, and soon everything was back up and running."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml1325(title)
msgid "Uninstalling"
msgstr "アンインストール"

#: ./doc/openstack-ops/ch_ops_maintenance.xml1327(para)
msgid ""
"While we'd always recommend using your automated deployment system to "
"reinstall systems from scratch, sometimes you do need to remove OpenStack "
"from a system the hard way. Here's how:<indexterm "
"class=\"singular\"><primary>uninstall "
"operation</primary></indexterm><indexterm "
"class=\"singular\"><primary>maintenance/debugging</primary><secondary>uninstalling</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml1340(para)
msgid "Remove all packages."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml1344(para)
msgid "Remove remaining files."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml1348(para)
msgid "Remove databases."
msgstr ""

#: ./doc/openstack-ops/ch_ops_maintenance.xml1352(para)
msgid ""
"These steps depend on your underlying distribution, but in general you "
"should be looking for \"purge\" commands in your package manager, like "
"<literal>aptitude purge ~c $package</literal>. Following this, you can look "
"for orphaned files in the directories referenced throughout this guide. To "
"uninstall the database properly, refer to the manual appropriate for the "
"product in use.<indexterm class=\"endofrange\" startref=\"maindebug\"/>"
msgstr ""

#: ./doc/openstack-ops/acknowledgements.xml19(title)
msgid "Acknowledgments"
msgstr "謝辞"

#: ./doc/openstack-ops/acknowledgements.xml20(para)
msgid ""
"The OpenStack Foundation supported the creation of this book with plane "
"tickets to Austin, lodging (including one adventurous evening without power "
"after a windstorm), and delicious food. For about USD $10,000, we could "
"collaborate intensively for a week in the same room at the Rackspace Austin "
"office. The authors are all members of the OpenStack Foundation, which you "
"can join. Go to the <link href=\"https://www.openstack.org/join\">Foundation"
" web site</link> at <uri>http://openstack.org/join</uri>."
msgstr ""

#: ./doc/openstack-ops/acknowledgements.xml28(para)
msgid ""
"We want to acknowledge our excellent host Rackers at Rackspace in Austin:"
msgstr "私たちは、オースチンの Rackspace での素晴らしいホスト Rackersに感謝したい:"

#: ./doc/openstack-ops/acknowledgements.xml32(para)
msgid ""
"Emma Richards of Rackspace Guest Relations took excellent care of our lunch "
"orders and even set aside a pile of sticky notes that had fallen off the "
"walls."
msgstr "Rackspace ゲストリレーションズの Emma Richards は、私たちのランチの注文を素晴らしく面倒を見てくれて、更に壁から剥がれ落ちた付箋紙の山を脇においてくれました。"

#: ./doc/openstack-ops/acknowledgements.xml37(para)
msgid ""
"Betsy Hagemeier, a Fanatical Executive Assistant, took care of a room "
"reshuffle and helped us settle in for the week."
msgstr "熱狂的なエグゼクティブアシスタントの Betsy Hagemeier は、部屋の改造の面倒を見てくれて、1週間で解決する手助けをしてくれました。"

#: ./doc/openstack-ops/acknowledgements.xml41(para)
msgid ""
"The Real Estate team at Rackspace in Austin, also known as \"The Victors,\" "
"were super responsive."
msgstr "「The Victors」としても知られている、オースチンの Rackspace の不動産チームは、素晴らしい応答をしてくれました。"

#: ./doc/openstack-ops/acknowledgements.xml45(para)
msgid ""
"Adam Powell in Racker IT supplied us with bandwidth each day and second "
"monitors for those of us needing more screens."
msgstr "Rackspace IT部門 の Adam Powell は、私たちに毎日のネットワーク帯域を提供してくれました。また、より多くのスクリーンが必要となったため、セカンドモニタを提供してくれました。"

#: ./doc/openstack-ops/acknowledgements.xml49(para)
msgid ""
"On Wednesday night we had a fun happy hour with the Austin OpenStack Meetup "
"group and Racker Katie Schmidt took great care of our group."
msgstr "水曜日の夜、オースチン OpenStack ミートアップグループと楽しく幸せな時間を過ごし、Racker Katie Schmidt は私たちのグループを素晴らしい世話をしてくれました。"

#: ./doc/openstack-ops/acknowledgements.xml54(para)
msgid "We also had some excellent input from outside of the room:"
msgstr "私たちは部屋の外から、いくつかの素晴らしいインプットを得ました。"

#: ./doc/openstack-ops/acknowledgements.xml57(para)
msgid ""
"Tim Bell from CERN gave us feedback on the outline before we started and "
"reviewed it mid-week."
msgstr "CERNの Tim Bell は、私たちが作業を開始する前に、その概要についてフィードバックを与えてくれて、週の半ばにはレビューをしてくれました。"

#: ./doc/openstack-ops/acknowledgements.xml61(para)
msgid ""
"Sébastien Han has written excellent blogs and generously gave his permission"
" for re-use."
msgstr "Sébastien Han は素晴らしいブログを書いてくれて、寛大にも再利用の許可を与えてくれました。"

#: ./doc/openstack-ops/acknowledgements.xml65(para)
msgid ""
"Oisin Feeley read it, made some edits, and provided emailed feedback right "
"when we asked."
msgstr "Oisin Feeley は、このマニュアルを読んで、いくつかの編集をし、私たちが問い合わせをした際には、E-mailでのフィードバックをくれました。"

#: ./doc/openstack-ops/acknowledgements.xml69(para)
msgid ""
"Inside the book sprint room with us each day was our book sprint facilitator"
" Adam Hyde. Without his tireless support and encouragement, we would have "
"thought a book of this scope was impossible in five days. Adam has proven "
"the book sprint method effectively again and again. He creates both tools "
"and faith in collaborative authoring at <link "
"href=\"http://www.booksprints.net/\">www.booksprints.net</link>."
msgstr ""

#: ./doc/openstack-ops/acknowledgements.xml77(para)
msgid ""
"We couldn't have pulled it off without so much supportive help and "
"encouragement."
msgstr "私たちは、これらの多大な協力的な援助と励まし無しには、これを成し遂げることはできなかったでしょう。"

#. When image changes, this message will be marked fuzzy or untranslated for
#. you.
#. It doesn't matter what you translate it to: it's not used at all.
#: ./doc/openstack-ops/ch_arch_provision.xml156(None)
msgid ""
"@@image: 'http://git.openstack.org/cgit/openstack/operations-guide/plain/doc"
"/openstack-ops/figures/osog_0201.png'; md5=THIS FILE DOESN'T EXIST"
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml12(title)
msgid "Provisioning and Deployment"
msgstr "プロビジョニングとデプロイメント"

#: ./doc/openstack-ops/ch_arch_provision.xml14(para)
msgid ""
"A critical part of a cloud's scalability is the amount of effort that it "
"takes to run your cloud. To minimize the operational cost of running your "
"cloud, set up and use an automated deployment and configuration "
"infrastructure with a configuration management system, such as Puppet or "
"Chef. Combined, these systems greatly reduce manual effort and the chance "
"for operator error.<indexterm class=\"singular\"><primary>cloud "
"computing</primary><secondary>minimizing costs of</secondary></indexterm>"
msgstr "クラウドのスケーラビリティにおける重要な部分の一つは、クラウドを運用するのに必要な労力にあります。クラウドの運用コストを最小化するために、Puppet や Chef などの設定管理システムを使用して、自動化されたデプロイメントおよび設定インフラストラクチャーを設定、使用してください。これらのシステムを統合すると、工数やオペレーターのミスを大幅に減らすことができます。<indexterm class=\"singular\"><primary>クラウドコンピューティング</primary><secondary>コストの最小化</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_provision.xml25(para)
msgid ""
"This infrastructure includes systems to automatically install the operating "
"system's initial configuration and later coordinate the configuration of all"
" services automatically and centrally, which reduces both manual effort and "
"the chance for error. Examples include Ansible, Chef, Puppet, and Salt. You "
"can even use OpenStack to deploy OpenStack, fondly named TripleO, for "
"OpenStack On OpenStack.<indexterm "
"class=\"singular\"><primary>Puppet</primary></indexterm><indexterm "
"class=\"singular\"><primary>Chef</primary></indexterm>"
msgstr "このインフラストラクチャーには、オペレーティングシステムの初期設定を自動にインストールするシステムや、全サーバーを自動的かつ一元的に連携、設定するシステムが含まれており、手作業やエラーの発生する可能性を減らします。例えば、Ansible、Chef、Puppet、Salt などのシステムです。OpenStack を使用して、OpenStack をデプロイすることも可能です。これは、TripleO (OpenStack 上の OpenStack) という愛称で呼ばれています。<indexterm class=\"singular\"><primary>Puppet</primary></indexterm><indexterm class=\"singular\"><primary>Chef</primary></indexterm>"

#: ./doc/openstack-ops/ch_arch_provision.xml37(title)
msgid "Automated Deployment"
msgstr "自動デプロイメント"

#: ./doc/openstack-ops/ch_arch_provision.xml39(para)
msgid ""
"An automated deployment system installs and configures operating systems on "
"new servers, without intervention, after the absolute minimum amount of "
"manual work, including physical racking, MAC-to-IP assignment, and power "
"configuration. Typically, solutions rely on wrappers around PXE boot and "
"TFTP servers for the basic operating system install and then hand off to an "
"automated configuration management system.<indexterm "
"class=\"singular\"><primary>deployment</primary><see>provisioning/deployment</see></indexterm><indexterm"
" "
"class=\"singular\"><primary>provisioning/deployment</primary><secondary>automated"
" deployment</secondary></indexterm>"
msgstr "自動のデプロイメントシステムは、物理ラッキング、MAC から IP アドレスの割当、電源設定など、必要最小限の手作業のみで、介入なしに新規サーバー上にオペレーティングシステムのインストールと設定を行います。ソリューションは通常、PXE ブートや TFTP サーバー関連のラッパーに依存して基本のオペレーティングシステムをインストールして、次に自動設定管理システムに委譲されます。<indexterm class=\"singular\"><primary>デプロイメント</primary><see>プロビジョニング/デプロイメント</see></indexterm><indexterm class=\"singular\"><primary>プロビジョニング/デプロイメント</primary><secondary>自動デプロイメント</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_provision.xml55(para)
msgid ""
"Both Ubuntu and Red Hat Enterprise Linux include mechanisms for configuring "
"the operating system, including preseed and kickstart, that you can use "
"after a network boot. Typically, these are used to bootstrap an automated "
"configuration system. Alternatively, you can use an image-based approach for"
" deploying the operating system, such as systemimager. You can use both "
"approaches with a virtualized infrastructure, such as when you run VMs to "
"separate your control services and physical infrastructure."
msgstr "Ubuntu と Red Hat Enterprise Linux にはいずれも、ネットワークブート後に使用可能なpreseed や kickstart といった、オペレーティングシステムを設定するための仕組みがあります。これらは、典型的には自動環境設定システムのブートストラップに使用されます。他の方法としては、systemimager のようなイメージベースのオペレーティングシステムのデプロイメント手法を使うこともできます。これらの手法はどちらも、物理インフラストラクチャーと制御サービスを分離するために仮想マシンを実行する場合など、仮想化基盤と合わせて使用できます。"

#: ./doc/openstack-ops/ch_arch_provision.xml64(para)
msgid ""
"When you create a deployment plan, focus on a few vital areas because they "
"are very hard to modify post deployment. The next two sections talk about "
"configurations for:"
msgstr "デプロイメントプランを作成する場合、デプロイメント後の修正は困難であるため、いくつかの重要な分野にフォーカスを当ててください。次の 2 章で以下の設定内容について説明していきます。"

#: ./doc/openstack-ops/ch_arch_provision.xml70(para)
msgid "Disk partioning and disk array setup for scalability"
msgstr "スケーラビリティ確保に向けたディスクのパーティショニングおよびディスク配列設定"

#: ./doc/openstack-ops/ch_arch_provision.xml74(para)
msgid "Networking configuration just for PXE booting"
msgstr "PXE ブート用のネットワーク設定"

#: ./doc/openstack-ops/ch_arch_provision.xml79(title)
msgid "Disk Partitioning and RAID"
msgstr "ディスクのパーティショニングと RAID"

#: ./doc/openstack-ops/ch_arch_provision.xml81(para)
msgid ""
"At the very base of any operating system are the hard drives on which the "
"operating system (OS) is installed.<indexterm "
"class=\"singular\"><primary>RAID (redundant array of independent "
"disks)</primary></indexterm><indexterm "
"class=\"singular\"><primary>partitions</primary><secondary>disk "
"partitioning</secondary></indexterm><indexterm "
"class=\"singular\"><primary>disk partitioning</primary></indexterm>"
msgstr "オペレーティングシステムの基盤は、オペレーティングシステムがインストールされるハードドライブです。<indexterm class=\"singular\"><primary>RAID (Redundant Array of Independent Disks)</primary></indexterm><indexterm class=\"singular\"><primary>パーティション</primary><secondary>ディスクパーティショニング</secondary></indexterm><indexterm class=\"singular\"><primary>ディスクパーティショニング</primary></indexterm>"

#: ./doc/openstack-ops/ch_arch_provision.xml92(para)
msgid ""
"You must complete the following configurations on the server's hard drives:"
msgstr "サーバーのハードディスクに対して、以下の環境設定を完了させなければなりません。"

#: ./doc/openstack-ops/ch_arch_provision.xml97(para)
msgid ""
"Partitioning, which provides greater flexibility for layout of operating "
"system and swap space, as described below."
msgstr "パーティショニング。以下に説明されている通り、オペレーティングシステムと Swap 領域のレイアウトにおける柔軟性がはるかに高くになります。"

#: ./doc/openstack-ops/ch_arch_provision.xml102(para)
msgid ""
"Adding to a RAID array (RAID stands for redundant array of independent "
"disks), based on the number of disks you have available, so that you can add"
" capacity as your cloud grows. Some options are described in more detail "
"below."
msgstr "使用可能なディスクの数をもとに、RAID 配列 (RAID は Redundant Array of Independent Disks の略) に追加します。 こうすることで、クラウドが大きくなった場合も容量を追加できます。オプションは、以下で詳しく説明しています。"

#: ./doc/openstack-ops/ch_arch_provision.xml109(para)
msgid ""
"The simplest option to get started is to use one hard drive with two "
"partitions:"
msgstr "最もシンプルに使用を開始できるオプションは、１台のハードディスクを２つのパーティションに分割することです。"

#: ./doc/openstack-ops/ch_arch_provision.xml114(para)
msgid ""
"File system to store files and directories, where all the data lives, "
"including the root partition that starts and runs the system"
msgstr "ファイルやディレクトリを格納するファイルシステム。システムを起動、実行する root パーティションなど、全データが設置される場所。"

#: ./doc/openstack-ops/ch_arch_provision.xml120(para)
msgid ""
"Swap space to free up memory for processes, as an independent area of the "
"physical disk used only for swapping and nothing else"
msgstr "プロセス用にメモリーを空ける Swap 領域。物理ディスクから独立した、スワップのみに使用される領域。"

#: ./doc/openstack-ops/ch_arch_provision.xml126(para)
msgid ""
"RAID is not used in this simplistic one-drive setup because generally for "
"production clouds, you want to ensure that if one disk fails, another can "
"take its place. Instead, for production, use more than one disk. The number "
"of disks determine what types of RAID arrays to build."
msgstr "通常、本番環境のクラウドでは、1 つのディスクに問題が発生した場合、別のディスクが必ず稼働するようにするため、RAID は、このシンプルな、ドライブ 1 つの設定では使用されません。本番環境では、ディスクを 1 つ以上使用します。ディスク数により、どのようなタイプの RAID 配列を構築するか決定します。"

#: ./doc/openstack-ops/ch_arch_provision.xml132(para)
msgid ""
"We recommend that you choose one of the following multiple disk options:"
msgstr "以下に挙げる複数のディスクの選択肢から選ぶことを推奨します。"

#: ./doc/openstack-ops/ch_arch_provision.xml137(term)
msgid "Option 1"
msgstr "オプション 1"

#: ./doc/openstack-ops/ch_arch_provision.xml140(para)
msgid ""
"Partition all drives in the same way in a horizontal fashion, as shown in "
"<xref linkend=\"disk_partition_figure\"/>."
msgstr "<xref linkend=\"disk_partition_figure\"/> にあるように、すべてのドライブを同じように並列してパーティショニングにします。"

#: ./doc/openstack-ops/ch_arch_provision.xml144(para)
msgid ""
"With this option, you can assign different partitions to different RAID "
"arrays. You can allocate partition 1 of disk one and two to the "
"<code>/boot</code> partition mirror. You can make partition 2 of all disks "
"the root partition mirror. You can use partition 3 of all disks for a <code"
">cinder-volumes</code> LVM partition running on a RAID 10 array."
msgstr "このオプションでは、パーティションごとに異なる RAID アレイにおくことができます。例えば、ディスク 1 とディスク 2 のパーティション 1 を <code>/boot</code> パーティションのミラーとして、すべてのディスクのパーティション 2 をルートパーティションのミラーとして、すべてのディスクのパーティション 3 を RAID10 アレイの上の <code>cinder-volumes</code> の LVM パーティションとして割り当てることができます。"

#: ./doc/openstack-ops/ch_arch_provision.xml152(title)
msgid "Partition setup of drives"
msgstr "ドライブのパーティション設定"

#: ./doc/openstack-ops/ch_arch_provision.xml161(para)
msgid ""
"While you might end up with unused partitions, such as partition 1 in disk "
"three and four of this example, this option allows for maximum utilization "
"of disk space. I/O performance might be an issue as a result of all disks "
"being used for all tasks."
msgstr "この例では、ディスク 3 と 4 のパーティション 1 のように未使用のパーティションが残る可能性もありますが、このオプションにより、ディスク領域の使用状況を最大化することができます。すべてのディスクがすべてのタスクで利用されるため、I/O のパフォーマンスが問題になる可能性があります。"

#: ./doc/openstack-ops/ch_arch_provision.xml170(term)
msgid "Option 2"
msgstr "オプション 2"

#: ./doc/openstack-ops/ch_arch_provision.xml173(para)
msgid ""
"Add all raw disks to one large RAID array, either hardware or software "
"based. You can partition this large array with the boot, root, swap, and LVM"
" areas. This option is simple to implement and uses all partitions. However,"
" disk I/O might suffer."
msgstr "すべてのローディスクを 1 つの大きな RAID 配列に追加します。ここでは、ソフトウェアベースでもハードウェアベースでも構いません。この大きなRAID 配列を boot、root、swap、LVM 領域に分割します。この選択肢はシンプルですべてのパーティションを利用することができますが、I/O性能に悪影響がでる可能性があります。"

#: ./doc/openstack-ops/ch_arch_provision.xml182(term)
msgid "Option 3"
msgstr "オプション 3"

#: ./doc/openstack-ops/ch_arch_provision.xml185(para)
msgid ""
"Dedicate entire disks to certain partitions. For example, you could allocate"
" disk one and two entirely to the boot, root, and swap partitions under a "
"RAID 1 mirror. Then, allocate disk three and four entirely to the LVM "
"partition, also under a RAID 1 mirror. Disk I/O should be better because I/O"
" is focused on dedicated tasks. However, the LVM partition is much smaller."
msgstr "全ディスク領域を特定のパーティションに割り当てます。例えば、ディスク 1 と 2 すべてを RAID 1 ミラーとして boot、root、swapパーティションに割り当てます。そして、ディスク 3 と 4 すべてを、同様に RAID 1 ミラーとしてLVMパーティションに割り当てます。I/O は専用タスクにフォーカスするため、ディスクの I/O は良くなるはずです。しかし、LVM パーティションははるかに小さくなります。"

#: ./doc/openstack-ops/ch_arch_provision.xml197(para)
msgid ""
"You may find that you can automate the partitioning itself. For example, MIT"
" uses <link href=\"http://fai-project.org/\">Fully Automatic Installation "
"(FAI)</link> to do the initial PXE-based partition and then install using a "
"combination of min/max and percentage-based partitioning.<indexterm "
"class=\"singular\"><primary>Fully Automatic Installation "
"(FAI)</primary></indexterm>"
msgstr "パーティショニング自体を自動化可能であることが分かります。例えば、MIT は <link href=\"http://fai-project.org/\">Fully Automatic Installation (FAI)</link> を使用して、初期の PXE ベースのパーティション分割を行い、min/max およびパーセントベースのパーティショニングを組み合わせてインストールしていきます。<indexterm class=\"singular\"><primary>Fully Automatic Installation (FAI)</primary></indexterm>"

#: ./doc/openstack-ops/ch_arch_provision.xml206(para)
msgid ""
"As with most architecture choices, the right answer depends on your "
"environment. If you are using existing hardware, you know the disk density "
"of your servers and can determine some decisions based on the options above."
" If you are going through a procurement process, your user's requirements "
"also help you determine hardware purchases. Here are some examples from a "
"private cloud providing web developers custom environments at AT&amp;T. This"
" example is from a specific deployment, so your existing hardware or "
"procurement opportunity may vary from this. AT&amp;T uses three types of "
"hardware in its deployment:"
msgstr "多くのアーキテクチャの選択肢と同様に、環境により適切なソリューションは変わって来ます。既存のハードウェアを使用する場合、サーバーのディスク密度を把握し、上記のオプションをもとに意思決定していきます。調達プロセスを行っている場合、ユーザー要件などもハードウェア購入決定の一助となります。ここでは AT&amp;T の Web 開発者にカスタムの環境を提供するプライベートクラウドの例をあげています。この例は、特定のデプロイメントであるため、既存のハードウェアや調達機会はこれと異なる可能性があります。AT&amp;T は、デプロイメントに 3 種類のハードウェアを使用しています。"

#: ./doc/openstack-ops/ch_arch_provision.xml218(para)
msgid ""
"Hardware for controller nodes, used for all stateless OpenStack API "
"services. About 32–64 GB memory, small attached disk, one processor, varied "
"number of cores, such as 6–12."
msgstr "コントローラーノードのハードウェア。ステートレスの OpenStack API サービスすべてに使用します。メモリー約 32-64GB、接続された容量の小さいディスク、プロセッサー 1 つ、6-12 個程度のコア。"

#: ./doc/openstack-ops/ch_arch_provision.xml224(para)
msgid ""
"Hardware for compute nodes. Typically 256 or 144 GB memory, two processors, "
"24 cores. 4–6 TB direct attached storage, typically in a RAID 5 "
"configuration."
msgstr "コンピュートノードのハードウェア。通常、メモリー 256 GB または 144 GB、プロセッサー 2 個、コア 24 個、通常 RAID 5 設定のダイレクトアタッチストレージ (DAS)。"

#: ./doc/openstack-ops/ch_arch_provision.xml230(para)
msgid ""
"Hardware for storage nodes. Typically for these, the disk space is optimized"
" for the lowest cost per GB of storage while maintaining rack-space "
"efficiency."
msgstr "ストレージノードのハードウェア。通常、ラックスペース効率を確保しつつも、ディスク容量のコストが GB ベースで最も低く最適化されています。"

#: ./doc/openstack-ops/ch_arch_provision.xml236(para)
msgid ""
"Again, the right answer depends on your environment. You have to make your "
"decision based on the trade-offs between space utilization, simplicity, and "
"I/O performance."
msgstr "ここでも、環境によって適したソリューションが変わります。スペース使用状況、シンプルさ、I/O パフォーマンスの長所、短所をベースに意思決定していく必要があります。"

#: ./doc/openstack-ops/ch_arch_provision.xml242(title)
msgid "Network Configuration"
msgstr "ネットワーク設定"

#: ./doc/openstack-ops/ch_arch_provision.xml244(para)
msgid ""
"Network configuration is a very large topic that spans multiple areas of "
"this book. For now, make sure that your servers can PXE boot and "
"successfully communicate with the deployment server.<indexterm "
"class=\"singular\"><primary>networks</primary><secondary>configuration "
"of</secondary></indexterm>"
msgstr "ネットワーク設定は、本書でも複数の箇所で取り上げられている大きいトピックです。ここでは、お使いのサーバが PXEブートでき、デプロイメントサーバと正常に通信できることを確認しておいてください。.<indexterm class=\"singular\"><primary>ネットワーク</primary><secondary>設定</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_provision.xml253(para)
msgid ""
"For example, you usually cannot configure NICs for VLANs when PXE booting. "
"Additionally, you usually cannot PXE boot with bonded NICs. If you run into "
"this scenario, consider using a simple 1 GB switch in a private network on "
"which only your cloud communicates."
msgstr "例えば、PXE ブートの際には、通常は VLAN の設定は行えません。さらに、通常は bonding された NIC から PXE ブートを行うこともできません。このような状況の場合、クラウド内でのみ通信できるネットワークで、シンプルな 1Gbps のスイッチを使うことを検討してください。"

#: ./doc/openstack-ops/ch_arch_provision.xml261(title)
msgid "Automated Configuration"
msgstr "自動環境設定"

#: ./doc/openstack-ops/ch_arch_provision.xml263(para)
msgid ""
"The purpose of automatic configuration management is to establish and "
"maintain the consistency of a system without using human intervention. You "
"want to maintain consistency in your deployments so that you can have the "
"same cloud every time, repeatably. Proper use of automatic configuration-"
"management tools ensures that components of the cloud systems are in "
"particular states, in addition to simplifying deployment, and configuration "
"change propagation.<indexterm class=\"singular\"><primary>automated "
"configuration</primary></indexterm><indexterm "
"class=\"singular\"><primary>provisioning/deployment</primary><secondary>automated"
" configuration</secondary></indexterm>"
msgstr "自動環境設定管理の目的は、人間の介在なしにシステムの一貫性を確保、維持することにあります。毎回、同じクラウド環境を繰り返し作るために、デプロイメントにおける一貫性を確保します。自動環境設定管理ツールを正しく利用することによって、デプロイメントと環境設定の変更を伝搬する作業を簡素化するだけでなく、クラウドシステムのコンポーネントが必ず特定の状態にあるようにすることができます。<indexterm class=\"singular\"><primary>自動設定</primary></indexterm><indexterm class=\"singular\"><primary>プロビジョニング/デプロイメント</primary><secondary>自動設定</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_provision.xml277(para)
msgid ""
"These tools also make it possible to test and roll back changes, as they are"
" fully repeatable. Conveniently, a large body of work has been done by the "
"OpenStack community in this space. Puppet, a configuration management tool, "
"even provides official modules for OpenStack in an OpenStack infrastructure "
"system known as <link href=\"https://github.com/stackforge/puppet-"
"openstack\">Stackforge</link>. Chef configuration management is provided "
"within <link role=\"orm:hideurl:ital\" href=\"https://github.com/stackforge"
"/openstack-chef-repo\"/>. Additional configuration management systems "
"include Juju, Ansible, and Salt. Also, PackStack is a command-line utility "
"for Red Hat Enterprise Linux and derivatives that uses Puppet modules to "
"support rapid deployment of OpenStack on existing servers over an SSH "
"connection.<indexterm "
"class=\"singular\"><primary>Stackforge</primary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml293(para)
msgid ""
"An integral part of a configuration-management system is the items that it "
"controls. You should carefully consider all of the items that you want, or "
"do not want, to be automatically managed. For example, you may not want to "
"automatically format hard drives with user data."
msgstr "設定管理システムの不可欠な部分は、このシステムが制御する項目です。自動管理をする項目、しない項目をすべて慎重に検討していく必要があります。例えば、ユーザーデータが含まれるハードドライブは自動フォーマットは必要ありません。"

#: ./doc/openstack-ops/ch_arch_provision.xml300(title)
msgid "Remote Management"
msgstr "リモート管理"

#: ./doc/openstack-ops/ch_arch_provision.xml302(para)
msgid ""
"In our experience, most operators don't sit right next to the servers "
"running the cloud, and many don't necessarily enjoy visiting the data "
"center. OpenStack should be entirely remotely configurable, but sometimes "
"not everything goes according to plan.<indexterm "
"class=\"singular\"><primary>provisioning/deployment</primary><secondary>remote"
" management</secondary></indexterm>"
msgstr "経験上、多くのオペレーターはクラウドを動かすサーバのそばにいるわけではありませんし、多くの人が必ずしも楽しんでデータセンターに訪問してるわけではありません。OpenStackは、完全にリモート設定できるはずですが、計画通りにいかないこともあります。<indexterm class=\"singular\"><primary>プロビジョニング/デプロイメント</primary><secondary>遠隔管理</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_provision.xml312(para)
msgid ""
"In this instance, having an out-of-band access into nodes running OpenStack "
"components is a boon. The IPMI protocol is the de facto standard here, and "
"acquiring hardware that supports it is highly recommended to achieve that "
"lights-out data center aim."
msgstr "この場合、OpenStack が動くノードに対して外側からアクセスできるようにすることが重要です。ここでは、IPMIプロトコルが事実上標準となっています。完全自動のデータセンタを実現するために、IPMIをサポートしたハードウェアを入手することを強く推奨します。"

#: ./doc/openstack-ops/ch_arch_provision.xml317(para)
msgid ""
"In addition, consider remote power control as well. While IPMI usually "
"controls the server's power state, having remote access to the PDU that the "
"server is plugged into can really be useful for situations when everything "
"seems wedged."
msgstr "さらに、リモート電源管理装置も検討してください。通常、IPMI はサーバーの電源状態を制御しますが、サーバーが接続されている PDU にリモートアクセスできれば、すべてが手詰まりに見えるような状況で非常に役に立ちます。"

#: ./doc/openstack-ops/ch_arch_provision.xml324(title)
msgid "Parting Thoughts for Provisioning and Deploying OpenStack"
msgstr "OpenStack のプロビジョニングおよびデプロイメントの概念"

#: ./doc/openstack-ops/ch_arch_provision.xml326(para)
msgid ""
"You can save time by understanding the use cases for the cloud you want to "
"create. Use cases for OpenStack are varied. Some include object storage "
"only; others require preconfigured compute resources to speed development-"
"environment set up; and others need fast provisioning of compute resources "
"that are already secured per tenant with private networks. Your users may "
"have need for highly redundant servers to make sure their legacy "
"applications continue to run. Perhaps a goal would be to architect these "
"legacy applications so that they run on multiple instances in a cloudy, "
"fault-tolerant way, but not make it a goal to add to those clusters over "
"time. Your users may indicate that they need scaling considerations because "
"of heavy Windows server use.<indexterm "
"class=\"singular\"><primary>provisioning/deployment</primary><secondary>tips"
" for</secondary></indexterm>"
msgstr "作成するクラウドのユースケースを理解することで時間を節約することあできます。OpenStack のユースケースはさまざまで、オブジェクトストレージのみのもの、開発環境設定を加速するために事前設定されたコンピュートリソースが必要なもの、プライベートネットワークでテナントごとにセキュリティが確保されたコンピュートリソースの迅速にプロビジョニングするものもあります。ユーザーは、レガシーアプリケーションが継続して実行されるように、非常に冗長化されたサーバーが必要な場合もあります。おそらく、時間をかけてこれらのクラスターを追加するのが目的ではなく、クラウドの耐障害性を確保したかたちで、複数のインスタンス上で実行するために、レガシーのアプリケーションを構築するのが目的の場合もあります。ユーザーによっては、負荷の高い Windows サーバーを使用するため、スケーリングを考慮する必要があると指定する場合もあるでしょう。<indexterm class=\"singular\"><primary>プロビジョニング/デプロイメント</primary><secondary>tips for</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_provision.xml343(para)
msgid ""
"You can save resources by looking at the best fit for the hardware you have "
"in place already. You might have some high-density storage hardware "
"available. You could format and repurpose those servers for OpenStack Object"
" Storage. All of these considerations and input from users help you build "
"your use case and your deployment plan."
msgstr "すでに設置済みのハードウェアに最適な方法で使用されていることをチェックすることで、リソースを節約することができます。高濃度のストレージハードウェアがあるとします。このハードウェアをフォーマットして、OpenStack Object Storage 用にサーバーの用途を変更することができます。ユーザーからのこのような検討やインプットすべてをベースにすることで、ユースケースやデプロイメントプランの作成が容易になります。"

#: ./doc/openstack-ops/ch_arch_provision.xml350(para)
msgid ""
"For further research about OpenStack deployment, investigate the supported "
"and documented preconfigured, prepackaged installers for OpenStack from "
"companies such as <link href=\"http://www.ubuntu.com/cloud/ubuntu-"
"openstack\">Canonical</link>, <link "
"href=\"http://www.cisco.com/web/solutions/openstack/index.html\">Cisco</link>,"
" <link href=\"http://www.cloudscaling.com/\">Cloudscaling</link>, <link "
"href=\"http://www-03.ibm.com/software/products/en/smartcloud-"
"orchestrator/\">IBM</link>, <link "
"href=\"http://www.metacloud.com/\">Metacloud</link>, <link "
"href=\"http://www.mirantis.com/\">Mirantis</link>, <link "
"href=\"http://www.pistoncloud.com/\">Piston</link>, <link "
"href=\"http://www.rackspace.com/cloud/private/\">Rackspace</link>, <link "
"href=\"http://www.redhat.com/openstack/\">Red Hat</link>, <link "
"href=\"https://www.suse.com/products/suse-cloud/\">SUSE</link>, and <link "
"href=\"https://www.swiftstack.com/\">SwiftStack</link>."
msgstr ""

#: ./doc/openstack-ops/ch_arch_provision.xml370(para)
msgid ""
"The decisions you make with respect to provisioning and deployment will "
"affect your day-to-day, week-to-week, and month-to-month maintenance of the "
"cloud. Your configuration management will be able to evolve over time. "
"However, more thought and design need to be done for upfront choices about "
"deployment, disk partitioning, and network configuration."
msgstr "プロビジョニングやデプロイメントでの意思決定は、クラウドの日次、週次、月次のメンテナンスに影響を与えます。設定管理は時が経つにつれ進化することができます。しかし、デプロイメント、ディスクのパーティショニング、ネットワーク設定を事前に選択するには、さらに検討、設計が必要になります。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml12(title)
msgid ""
"Designing for Cloud Controllers and <phrase role=\"keep-together\">Cloud "
"Management</phrase>"
msgstr "クラウドコントローラーのデザインと<phrase role=\"keep-together\">クラウド管理</phrase>"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml15(para)
msgid ""
"OpenStack is designed to be massively horizontally scalable, which allows "
"all services to be distributed widely. However, to simplify this guide, we "
"have decided to discuss services of a more central nature, using the concept"
" of a <emphasis>cloud controller</emphasis>. A cloud controller is just a "
"conceptual simplification. In the real world, you design an architecture for"
" your cloud controller that enables high availability so that if any node "
"fails, another can take over the required tasks. In reality, cloud "
"controller tasks are spread out across more than a single node.<indexterm "
"class=\"singular\"><primary>design considerations</primary><secondary>cloud "
"controller services</secondary></indexterm><indexterm "
"class=\"singular\"><primary>cloud controllers</primary><secondary>concept "
"of</secondary></indexterm>"
msgstr "OpenStackはすべてのサービスが広く分散できるよう水平方向に大規模にスケーリングできるように設計されています。しかし、このガイドではシンプルに<emphasis>クラウドコントローラー</emphasis>の利用についてより中心的な性質を持つサービスについて議論する事にしました。クラウドコントローラーという言葉はその概念をシンプルに表現した物に過ぎません。実際にはあなたはクラウドコントローラーは冗長構成としてどのノードが障害となっても他のノードで運用ができるような設計にデザインします。実際にはクラウドコントローラーのタスクは1つ以上のノードにまたがって展開されます。<indexterm class=\"singular\"><primary>設計上の考慮点</primary><secondary>クラウドコントローラーサービス</secondary></indexterm><indexterm class=\"singular\"><primary>クラウドコントローラー</primary><secondary>コンセプト</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml33(para)
msgid ""
"The cloud controller provides the central management system for OpenStack "
"deployments. Typically, the cloud controller manages authentication and "
"sends messaging to all the systems through a message queue."
msgstr "クラウドコントローラは、複数ノードで構成されるOpenStack構成に対する集中管理機能を提供します。典型的には、クラウドコントローラは認証および、メッセージキューを通じたメッセージのやりとりを管理します。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml38(para)
msgid ""
"For many deployments, the cloud controller is a single node. However, to "
"have high availability, you have to take a few considerations into account, "
"which we'll cover in this chapter."
msgstr "多くの構成では、クラウドコントローラーはシングルノードで構成されています。しかし、高可用性のためには、この章で取り上げるいくつかの事項を考慮する必要があります。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml42(para)
msgid ""
"The cloud controller manages the following services for the cloud:<indexterm"
" class=\"singular\"><primary>cloud controllers</primary><secondary>services "
"managed by</secondary></indexterm>"
msgstr "クラウドコントローラーはクラウドの次のサービスを管理します:<indexterm class=\"singular\"><primary>クラウドコントローラー</primary><secondary>管理対象サービス</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml54(para)
msgid ""
"Tracks current information about users and instances, for example, in a "
"database, typically one database instance managed per service"
msgstr "ユーザとインスタンスの現在の状態をトラッキングします。例えば、一般的なデータベースでは1つのデータベースインスタンスはサービス毎に管理されます。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml61(term)
msgid "Message queue services"
msgstr "メッセージキューサービス"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml64(para)
msgid ""
"All AMQP—Advanced Message Queue Protocol—messages for services are received "
"and sent according to the queue broker<indexterm "
"class=\"singular\"><primary>Advanced Message Queuing Protocol "
"(AMQP)</primary></indexterm>"
msgstr "サービスのためのすべてのAMQP（Advavnced Message Queue Protocol）メッセージはキューブローカーによって送受信されます。<indexterm class=\"singular\"><primary>Advanced Message Queuing Protocol (AMQP)</primary></indexterm>"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml73(term)
msgid "Conductor services"
msgstr "コンダクターサービス"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml76(para)
msgid "Proxy requests to a database"
msgstr "データベースリクエストのプロクシ"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml81(term)
msgid "Authentication and authorization for identity management"
msgstr "アイデンティティ管理のための認証と認可"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml84(para)
msgid ""
"Indicates which users can do what actions on certain cloud resources; quota "
"management is spread out among services, however<indexterm "
"class=\"singular\"><primary>authentication</primary></indexterm>"
msgstr "ある特定のクラウドリソースで誰が何をしようとしているか示します。しかし、クオータ管理は全体のサービスに展開されます。<indexterm class=\"singular\"><primary>認証</primary></indexterm>"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml93(term)
msgid "Image-management services"
msgstr "イメージ管理サービス"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml96(para)
msgid ""
"Stores and serves images with metadata on each, for launching in the cloud"
msgstr "クラウド内で起動するための各メタデータが付属したイメージデータを蓄え、提供します"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml102(term)
msgid "Scheduling services"
msgstr "スケジュールサービス"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml105(para)
msgid ""
"Indicates which resources to use first; for example, spreading out where "
"instances are launched based on an algorithm"
msgstr "どのリソースを最初に使用するかを示します。例えば、インスタンスをどこで起動するかをアルゴリズムに乗っ取って展開します。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml111(term)
msgid "User dashboard"
msgstr "ユーザーダッシュボード"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml114(para)
msgid ""
"Provides a web-based frontend for users to consume OpenStack cloud services"
msgstr "利用ユーザ用のOpenStackクラウドサービスのウェブインターフェースを提供します。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml120(term)
msgid "API endpoints"
msgstr "APIエンドポイント"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml123(para)
msgid ""
"Offers each service's REST API access, where the API endpoint catalog is "
"managed by the Identity Service"
msgstr "それぞれのサービス用のAPIアクセスを提供します。APIエンドポイントカタログの場所はIIdentity サービスが管理しています。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml129(para)
msgid ""
"For our example, the cloud controller has a collection of "
"<code>nova-*</code> components that represent the global state of the cloud;"
" talks to services such as authentication; maintains information about the "
"cloud in a database; communicates to all compute nodes and storage "
"<glossterm>worker</glossterm>s through a queue; and provides API access. "
"Each service running on a designated cloud controller may be broken out into"
" separate nodes for scalability or availability.<indexterm "
"class=\"singular\"><primary>storage</primary><secondary>storage "
"workers</secondary></indexterm><indexterm "
"class=\"singular\"><primary>workers</primary></indexterm>"
msgstr "我々の例では、クラウドコントローラは<code>nova-*</code> コンポーネントの集まりで、それらは認証のようなサービスとのやり取りや、データベース内の情報の管理、キューを通したストレージ <glossterm>ワーカー</glossterm>コンピュートノードとのコミュニケーション、APIアクセス、などといったクラウド全体の状態管理を受け持っています。それぞれのサービスは可用性やスケーラビリティを考慮して別々のノードへ分離する事ができます。<indexterm class=\"singular\"><primary>storage</primary><secondary>ストレージワーカー</secondary></indexterm><indexterm class=\"singular\"><primary>ワーカー</primary></indexterm>"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml143(para)
msgid ""
"As another example, you could use pairs of servers for a collective cloud "
"controller—one active, one standby—for redundant nodes providing a given set"
" of related services, such as:"
msgstr "他の例として、コントローラーをクラスタとして構成し1つはアクティブ、もう一つはスタンバイとして冗長ノードが以下のような機能を提供できるように複数のサーバを使用する事ができます。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml149(para)
msgid ""
"Frontend web for API requests, the scheduler for choosing which compute node"
" to boot an instance on, Identity services, and the dashboard"
msgstr "APIリクエスト用のフロントエンドウェブ、インスタンスをどのノードで起動するかを決定するスケジューラ、Identity サービス、ダッシュボード"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml155(para)
msgid "Database and message queue server (such as MySQL, RabbitMQ)"
msgstr "データベースとメッセージキューサーバ（例:MySQL、RabbitMQ）"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml159(para)
msgid "Image Service for the image management"
msgstr "イメージ管理のためのイメージサービス"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml163(para)
msgid ""
"Now that you see the myriad designs for controlling your cloud, read more "
"about the further considerations to help with your design decisions."
msgstr "クラウドコントローラの設計は無数にあります、クラウドコントローラの設計の助けとして更なる考慮事項をお読みください。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml168(title)
msgid "Hardware Considerations"
msgstr "ハードウェアの考慮事項"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml170(para)
msgid ""
"A cloud controller's hardware can be the same as a compute node, though you "
"may want to further specify based on the size and type of cloud that you "
"run.<indexterm "
"class=\"singular\"><primary>hardware</primary><secondary>design "
"considerations</secondary></indexterm><indexterm "
"class=\"singular\"><primary>design "
"considerations</primary><secondary>hardware "
"considerations</secondary></indexterm>"
msgstr "クラウドの大きさやタイプによってハードウェアを指定したいかもしれませんが、クラウドコントローラーのハードウェアはコンピュートノードと同じ物を利用する事ができます。<indexterm class=\"singular\"><primary>ハードウェア</primary><secondary>設計上の考慮事項</secondary></indexterm><indexterm class=\"singular\"><primary>設計上の考慮事項</primary><secondary>ハードウェアの考慮点</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml182(para)
msgid ""
"It's also possible to use virtual machines for all or some of the services "
"that the cloud controller manages, such as the message queuing. In this "
"guide, we assume that all services are running directly on the cloud "
"controller."
msgstr "クラウドコントローラーが管理するすべての、または一部のサービス、たとえばメッセージキューに対して仮想マシンを使うことも可能です。このガイドでは、すべてのサービスが直接クラウドコントローラー上で実行されるものと仮定します。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml187(para)
msgid ""
"<xref linkend=\"controller-hardware-sizing\"/> contains common "
"considerations to review when sizing hardware for the cloud controller "
"design.<indexterm class=\"singular\"><primary>cloud "
"controllers</primary><secondary>hardware sizing "
"considerations</secondary></indexterm><indexterm "
"class=\"singular\"><primary>Active Directory</primary></indexterm><indexterm"
" class=\"singular\"><primary>dashboard</primary></indexterm>"
msgstr "<xref linkend=\"controller-hardware-sizing\"/> クラウドコントローラー設計のハードウェアサイジングにおける一般的な考慮事項<indexterm class=\"singular\"><primary>クラウドコントローラー</primary><secondary>ハードウェアサイジングに関する考慮事項</secondary></indexterm><indexterm class=\"singular\"><primary>Active Directory</primary></indexterm><indexterm class=\"singular\"><primary>ダッシュボード</primary></indexterm>"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml200(caption)
msgid "Cloud controller hardware sizing considerations"
msgstr "クラウドコントローラーのハードウェアサイジングに関する考慮事項"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml208(th)
msgid "Consideration"
msgstr "考慮事項"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml210(th)
msgid "Ramification"
msgstr "派生問題"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml216(para)
msgid "How many instances will run at once?"
msgstr "同時に何インスタンス実行されますか？"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml218(para)
msgid ""
"Size your database server accordingly, and scale out beyond one cloud "
"controller if many instances will report status at the same time and "
"scheduling where a new instance starts up needs computing power."
msgstr "データベースサーバーを負荷に応じてサイジングしてください。もし、多数のインスタンスが同時に状態を報告したり、CPU能力が必要な新規インスタンス起動のスケジューリングを行う場合は、１台のクラウドコントローラーを超えてスケールアウトしてください。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml225(para)
msgid "How many compute nodes will run at once?"
msgstr "同時にコンピュートノードが何ノード実行されますか？"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml227(para)
msgid ""
"Ensure that your messaging queue handles requests successfully and size "
"accordingly."
msgstr "メッセージキューが正しくリクエストを処理することを保証し、適切にサイジングしてください。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml232(para)
msgid "How many users will access the API?"
msgstr "どのくらいの数のユーザがAPIにアクセスしますか？"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml234(para)
msgid ""
"If many users will make multiple requests, make sure that the CPU load for "
"the cloud controller can handle it."
msgstr "もし多数のユーザが複数のリクエストを発行するのであれば、クラウドコントローラーがそれらを扱えるよう、CPU負荷を確認してください。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml239(para)
msgid ""
"How many users will access the <glossterm>dashboard</glossterm> versus the "
"REST API directly?"
msgstr "REST APIに直接アクセスに対してどのくらい多くのユーザが <glossterm>ダッシュボード</glossterm>にアクセスしますか？"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml243(para)
msgid ""
"The dashboard makes many requests, even more than the API access, so add "
"even more CPU if your dashboard is the main interface for your users."
msgstr "ダッシュボードは、APIアクセスよりもさらに多くのリクエストを発行します。そのため、もしユーザに対するインタフェースがダッシュボードなのであれば、より多くのCPUを追加してください。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml249(para)
msgid ""
"How many <code>nova-api</code> services do you run at once for your cloud?"
msgstr "あなたのクラウドで、何個の<code>nova-api</code>サービスを同時に実行しますか？"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml252(para)
msgid "You need to size the controller with a core per service."
msgstr "サービスごとに１コア割り当ててコントローラーをサイジングする必要があります。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml257(para)
msgid "How long does a single instance run?"
msgstr "１つのインスタンスがどのくらい実行され続けますか？"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml259(para)
msgid ""
"Starting instances and deleting instances is demanding on the compute node "
"but also demanding on the controller node because of all the API queries and"
" scheduling needs."
msgstr "インスタンスの起動と停止は  コンピュートノードに負荷をかけますが、それだけでなく、すべてのAPI処理とスケジューリングの必要性のために、コントローラーノードにも負荷をかけます。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml265(para)
msgid "Does your authentication system also verify externally?"
msgstr "認証システムは外部に確認を行いますか？"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml268(para)
msgid ""
"External systems such as LDAP or <glossterm>Active Directory</glossterm> "
"require network connectivity between the cloud controller and an external "
"authentication system. Also ensure that the cloud controller has the CPU "
"power to keep up with requests."
msgstr "LDAPや<glossterm>Active Directory</glossterm>のような外部認証システムを利用する場合クラウドコントローラと外部認証システムとの間のネットワーク接続性が良好である必要があります。また、クラウドコントローラがそれらのリクエストを処理するための十分のCPUパワーが必要です。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml279(title)
msgid "Separation of Services"
msgstr "サービスの分離"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml281(para)
msgid ""
"While our example contains all central services in a single location, it is "
"possible and indeed often a good idea to separate services onto different "
"physical servers. <xref linkend=\"sep-services-table\"/> is a list of "
"deployment scenarios we've seen and their justifications.<indexterm "
"class=\"singular\"><primary>provisioning/deployment</primary><secondary>deployment"
" scenarios</secondary></indexterm><indexterm "
"class=\"singular\"><primary>services</primary><secondary>separation "
"of</secondary></indexterm><indexterm class=\"singular\"><primary>separation "
"of services</primary></indexterm><indexterm "
"class=\"singular\"><primary>design "
"considerations</primary><secondary>separation of "
"services</secondary></indexterm>"
msgstr "この例ではすべての中心的なサービスが1つの場所にありますが、サービスを分割してそれぞれ別の物理サーバに配置する事は可能であり、本当に良いアイデアです。<xref linkend=\"sep-services-table\"/> は構築のシナリオと設計の理由です。<indexterm class=\"singular\"><primary>プロビジョニング/構築</primary><secondary>構築シナリオ</secondary></indexterm><indexterm class=\"singular\"><primary>サービス</primary><secondary>分離</secondary></indexterm><indexterm class=\"singular\"><primary>サービスの分離</primary></indexterm><indexterm class=\"singular\"><primary>設計上の考慮事項</primary><secondary>サービスの分離</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml302(caption)
msgid "Deployment scenarios"
msgstr "構成シナリオ"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml310(th)
msgid "Scenario"
msgstr "シナリオ"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml312(th)
msgid "Justification"
msgstr "理由"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml318(para)
msgid ""
"Run <code>glance-*</code> servers on the <code>swift-proxy</code> server."
msgstr "<code>swift-proxy</code> サーバで<code>glance-*</code>サーバを稼働する"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml321(para)
msgid ""
"This deployment felt that the spare I/O on the Object Storage proxy server "
"was sufficient and that the Image Delivery portion of glance benefited from "
"being on physical hardware and having good connectivity to the Object "
"Storage backend it was using."
msgstr "この構成ではオブジェクトストレージプロクシサーバのI/Oの空きが十分にあり、glance　のイメージ配信部分は物理ハードウェアとオブジェクトストレージのバックエンドに使用している良好なネットワーク接続性の恩恵を十分に受ける事ができると感じた。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml329(para)
msgid "Run a central dedicated database server."
msgstr "中央データベースサーバを構成する"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml331(para)
msgid ""
"This deployment used a central dedicated server to provide the databases for"
" all services. This approach simplified operations by isolating database "
"server updates and allowed for the simple creation of slave database servers"
" for failover."
msgstr "この構成では、すべてのサービスに対するデータベースサービスを提供する専用サーバを設置しました。これにより、データベースサーバーのアップデートを分離でき、運用がシンプルになりました。また、フェイルオーバーのためのスレーブデータベースサーバーの設置が単純になりました。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml338(para)
msgid "Run one VM per service."
msgstr "1サービスにつき1つのVMを稼働させる"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml340(para)
msgid ""
"This deployment ran central services on a set of servers running KVM. A "
"dedicated VM was created for each service (<literal>nova-"
"scheduler</literal>, rabbitmq, database, etc). This assisted the deployment "
"with scaling because administrators could tune the resources given to each "
"virtual machine based on the load it received (something that was not well "
"understood during installation)."
msgstr "この構成では中央サーバをKVM上のサーバで実行しました。専用のVMをそれぞれのサービスで用意しました(<literal>nova-scheduler</literal>, RabbitMQ, データベースなど)。この構成はクラウド管理者が(インストール時によく推測できないので)それぞれのサービスへの負荷のかかり具合によって各バーチャルマシンへのリソース割当を変更する事ができる構成でした。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml350(para)
msgid "Use an external load balancer."
msgstr "外部ロードバランサーの使用"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml352(para)
msgid ""
"This deployment had an expensive hardware load balancer in its organization."
" It ran multiple <code>nova-api</code> and <code>swift-proxy</code> servers "
"on different physical servers and used the load balancer to switch between "
"them."
msgstr "この構成は、組織内に高価なハードウェアロードバランサーを持っていました。彼らは複数の <code>nova-api</code> と<code>swift-proxy</code> サーバーを異なる物理サーバーで動作させ、その振り分けにロードバランサーを利用し増した。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml360(para)
msgid ""
"One choice that always comes up is whether to virtualize. Some services, "
"such as <code>nova-compute</code>, <code>swift-proxy</code> and <code>swift-"
"object</code> servers, should not be virtualized. However, control servers "
"can often be happily virtualized—the performance penalty can usually be "
"offset by simply running more of the service."
msgstr "仮想化するかどうかについてはいつも問題になります。 <code>nova-compute</code>、<code>swift-proxy</code> 、 <code>swift-object</code> といったいくつかのサーバーは仮想化にすべきではありません。しかし、制御系のサーバについては仮想化にすると幸せになります。それによる性能のペナルティは単純により多くのサービスを動かす事で相殺する事ができます。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml370(para)
msgid ""
"OpenStack Compute uses a SQL database to store and retrieve stateful "
"information. MySQL is the popular database choice in the OpenStack "
"community.<indexterm "
"class=\"singular\"><primary>databases</primary><secondary>design "
"considerations</secondary></indexterm><indexterm "
"class=\"singular\"><primary>design "
"considerations</primary><secondary>database choice</secondary></indexterm>"
msgstr "OpenStackコンピュートはステートフルな情報を保存、取得するためにSQLデータベースを使用します。MySQLはOpenStackコミュニティでポピュラーな選択です。<indexterm class=\"singular\"><primary>データベース</primary><secondary>設計上の考慮事項</secondary></indexterm><indexterm class=\"singular\"><primary>設計上の考慮事項</primary><secondary>データベースの選択</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml382(para)
msgid ""
"Loss of the database leads to errors. As a result, we recommend that you "
"cluster your database to make it failure tolerant. Configuring and "
"maintaining a database cluster is done outside OpenStack and is determined "
"by the database software you choose to use in your cloud environment. "
"MySQL/Galera is a popular option for MySQL-based databases."
msgstr "データベースの消失はエラーにつながります。結論としては、データベースを冗長化するためにクラスター構成とする事を推奨します。使クラウド環境で使用するデータベースをクラスタ化しをOpenStack外に配置します。MySQLベースのデータベースではMySQL/Galeraが人気です。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml390(title)
msgid "Message Queue"
msgstr "メッセージキュー"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml392(para)
msgid ""
"Most OpenStack services communicate with each other using the "
"<emphasis>message queue</emphasis>.<indexterm "
"class=\"singular\"><primary>messages</primary><secondary>design "
"considerations</secondary></indexterm><indexterm "
"class=\"singular\"><primary>design "
"considerations</primary><secondary>message queues</secondary></indexterm> "
"For example, Compute communicates to block storage services and networking "
"services through the message queue. Also, you can optionally enable "
"notifications for any service. RabbitMQ, Qpid, and 0mq are all popular "
"choices for a message-queue service. In general, if the message queue fails "
"or becomes inaccessible, the cluster grinds to a halt and ends up in a read-"
"only state, with information stuck at the point where the last message was "
"sent. Accordingly, we recommend that you cluster the message queue. Be aware"
" that clustered message queues can be a pain point for many OpenStack "
"deployments. While RabbitMQ has native clustering support, there have been "
"reports of issues when running it at a large scale. While other queuing "
"solutions are available, such as 0mq and Qpid, 0mq does not offer stateful "
"queues. Qpid is the <phrase role=\"keep-together\">messaging</phrase> system"
" of choice for Red Hat and its derivatives. Qpid does not have native "
"clustering capabilities and requires a supplemental service, such as "
"Pacemaker or Corsync. For your message queue, you need to determine what "
"level of data loss you are comfortable with and whether to use an OpenStack "
"project's ability to retry multiple MQ hosts in the event of a failure, such"
" as using Compute's ability to do so.<indexterm "
"class=\"singular\"><primary>0mq</primary></indexterm><indexterm "
"class=\"singular\"><primary>Qpid</primary></indexterm><indexterm "
"class=\"singular\"><primary>RabbitMQ</primary></indexterm><indexterm "
"class=\"singular\"><primary>message queue</primary></indexterm>"
msgstr "多くのOpenStackサービスは<emphasis>メッセージキュー</emphasis>を使用してお互いと通信をしています。<indexterm class=\"singular\"><primary>メッセージ</primary><secondary>設計上の考慮事項</secondary></indexterm><indexterm class=\"singular\"><primary>設計上の考慮事項</primary><secondary>メッセージキュー</secondary></indexterm>例えば、コンピュートはメッセージキューを通じてブロックストレージサービスとネットワークサービスと通信をしています。また、どのようなサービスでも通知を有効にする事ができます。メッセージキューサービスの選択としてRabbitMQ、Qpid、0mqがポピュラーです。一般的には、メッセージキューが障害あるいはアクセス不能となった場合、クラスターはメッセージを最後に送信した状態のままスタックした状態で停止しリードオンリーの状態となります。ですので、メッセージキューはクラスター公正にする事をお勧めします。クラスタ化されたメッセージキューは多くのOpenStack構成で弱点になることを覚えておく必要があります。RabbitMQは標準でクラスタ対応していますが大規模になった場合にいくつかの問題が報告されています。0mqやQPIDといった他のメッセージングソリューションも存在していますが、0mqはステートフルなキューを提供していません。QpidはRed Hat系ディストリビューションでの<phrase role=\"keep-together\">メッセージング</phrase>システムの選択となります。Qpidは標準でクラスタをサポートしておらず、PacemakerやCorosyncといった補助的なサービスが必要になります。メッセージキューに関しては、コンピュータの機能を利用する際にするように許容範囲なデータ損失のレベルとイベント失敗時に複数のMQホストを試行するOpenStackの機能を利用するかどうかを決める必要があります。<indexterm class=\"singular\"><primary>0mq</primary></indexterm><indexterm class=\"singular\"><primary>Qpid</primary></indexterm><indexterm class=\"singular\"><primary>RabbitMQ</primary></indexterm><indexterm class=\"singular\"><primary>メッセージキュー</primary></indexterm>"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml431(title)
msgid "Conductor Services"
msgstr "コンダクターサービス"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml433(para)
msgid ""
"In the previous version of OpenStack, all <literal>nova-compute</literal> "
"services required direct access to the database hosted on the cloud "
"controller. This was problematic for two reasons: security and performance. "
"With regard to security, if a compute node is compromised, the attacker "
"inherently has access to the database. With regard to performance, <literal"
">nova-compute</literal> calls to the database are single-threaded and "
"blocking. This creates a performance bottleneck because database requests "
"are fulfilled serially rather than in parallel.<indexterm "
"class=\"singular\"><primary>conductors</primary></indexterm><indexterm "
"class=\"singular\"><primary>design "
"considerations</primary><secondary>conductor "
"services</secondary></indexterm>"
msgstr "以前のバージョンのOpenStackではすべての<literal>nova-compute</literal>サービスはクラウドコントローラーに搭載されたデータベースに直接アクセスする必要がありました。これはセキュリティとパフォーマンスという2つの問題を抱えていました。セキュリティに関してはもしコンピュートノードに侵入された場合、アタッカーはデータベースにアクセスできてしまいます。パフォーマンスに関しては、<literal>nova-compute</literal>はデータベースの呼び出しをシングルスレッドで行い、他の呼び出しをブロックする点です。データベースリクエストはシリアルリクエストよりパラレルリクエストの方が効率がいいのでこの点はパフォーマンスのボトルネックになります。<indexterm class=\"singular\"><primary>コンダクター</primary></indexterm><indexterm class=\"singular\"><primary>設計上の考慮事項</primary><secondary>コンダクターサービス</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml449(para)
msgid ""
"The conductor service resolves both of these issues by acting as a proxy for"
" the <literal>nova-compute</literal> service. Now, instead of <literal>nova-"
"compute</literal> directly accessing the database, it contacts the <literal"
">nova-conductor</literal> service, and <literal>nova-conductor</literal> "
"accesses the database on <literal>nova-compute</literal>'s behalf. Since "
"<literal>nova-compute</literal> no longer has direct access to the database,"
" the security issue is resolved. Additionally, <literal>nova-"
"conductor</literal> is a nonblocking service, so requests from all compute "
"nodes are fulfilled in parallel."
msgstr "コンダクターサービスは<literal>nova-compute</literal>サービスのプロクシとして次の両方の問題を解決します。現在は、 <literal>nova-compute</literal>が直接データベースにアクセスするのに変わって<literal>nova-conductor</literal>サービスにアクセスし<literal>nova-conductor</literal>サービスが<literal>nova-compute</literal>サービスの代理でデータベースにアクセスをします。これにより<literal>nova-compute</literal>はもう直接データベースにアクセスする必要はなくセキュリティ問題は解消されます。加えて <literal>nova-conductor</literal> はノンブロッキングサービスなのですべてのコンピュートからのリクエストが並列で処理できます。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml461(para)
msgid ""
"If you are using <literal>nova-network</literal> and multi-host networking "
"in your cloud environment, <literal>nova-compute</literal> still requires "
"direct access to the database.<indexterm class=\"singular\"><primary>multi-"
"host networking</primary></indexterm>"
msgstr "あなたのクラウド環境で、<literal>nova-network</literal>とマルチホストネットワークを使用している場合、 <literal>nova-compute</literal>は現在もデータベースへの直接アクセスを必要とします。<indexterm class=\"singular\"><primary>マルチホストネットワーク</primary></indexterm>"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml468(para)
msgid ""
"The <literal>nova-conductor</literal> service is horizontally scalable. To "
"make <literal>nova-conductor</literal> highly available and fault tolerant, "
"just launch more instances of the <code>nova-conductor</code> process, "
"either on the same server or across multiple servers."
msgstr "<literal>nova-conductor</literal>サービスは水平方向にスケーラブルです。<literal>nova-conductor</literal>を冗長構成になるためには、<code>nova-conductor</code> プロセスを同一サーバまたは複数のサーバに渡って複数起動するだけです。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml476(title)
msgid "Application Programming Interface (API)"
msgstr "Application Programming Interface (API)"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml478(para)
msgid ""
"All public access, whether direct, through a command-line client, or through"
" the web-based dashboard, uses the API service. Find the API reference at "
"<link href=\"http://api.openstack.org/\"/>.<indexterm "
"class=\"singular\"><primary>API (application programming "
"interface)</primary><secondary>design "
"considerations</secondary></indexterm><indexterm "
"class=\"singular\"><primary>design considerations</primary><secondary>API "
"support</secondary></indexterm>"
msgstr "すべてのパブリックアクセス（直接アクセス、コマンドライン、ウェブベースダッシュボード）はすべてAPIサービスを使用します。APIリファレンスは<link href=\"http://api.openstack.org/\"/>です。<indexterm class=\"singular\"><primary>API (application programming interface)</primary><secondary>設計上の考慮事項</secondary></indexterm><indexterm class=\"singular\"><primary>設計上の考慮事項</primary><secondary>API サポート</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml491(para)
msgid ""
"You must choose whether you want to support the Amazon EC2 compatibility "
"APIs, or just the OpenStack APIs. One issue you might encounter when running"
" both APIs is an inconsistent experience when referring to images and "
"instances."
msgstr "Amazon EC2 互換 API をサポートしたいか、OpenStack API だけなのか、選択しなければなりません。両方の API を運用する場合、イメージとインスタンスを参照する際の見え方が違うことが一つの論点になります。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml496(para)
msgid ""
"For example, the EC2 API refers to instances using IDs that contain "
"hexadecimal, whereas the OpenStack API uses names and digits. Similarly, the"
" EC2 API tends to rely on DNS aliases for contacting virtual machines, as "
"opposed to OpenStack, which typically lists IP addresses.<indexterm "
"class=\"singular\"><primary>DNS (Domain Name Server, Service or "
"System)</primary><secondary>DNS aliases</secondary></indexterm><indexterm "
"class=\"singular\"><primary>troubleshooting</primary><secondary>DNS "
"issues</secondary></indexterm>"
msgstr "例えば、EC2 API では、16 進数を含む ID を使ってインスタンスを参照するのに対して、OpenStack API では名前と数値を使います。同様に、EC2 API は仮想マシンに接続するのに DNS エイリアスに頼る傾向がありますが、OpenStack では典型的には IP アドレスを使います。<indexterm class=\"singular\"><primary>DNS (Domain Name Server, Service or System)</primary><secondary>DNS エイリアス</secondary></indexterm><indexterm class=\"singular\"><primary>トラブルシューティング</primary><secondary>DNS 問題</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml510(para)
msgid ""
"If OpenStack is not set up in the right way, it is simple to have scenarios "
"in which users are unable to contact their instances due to having only an "
"incorrect DNS alias. Despite this, EC2 compatibility can assist users "
"migrating to your cloud."
msgstr "もしOpenStakcが正しく構成されていない場合、正しくないDNSエイリアスしな無いため、ユーザはインスタンスへアクセスできないというシンプルな事態が生じます。それにもかかわらず、EC2互換はユーザをあなたのクラウドへ移行することをアシストします。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml515(para)
msgid ""
"As with databases and message queues, having more than one <glossterm>API "
"server</glossterm> is a good thing. Traditional HTTP load-balancing "
"techniques can be used to achieve a highly available <code>nova-api</code> "
"service.<indexterm class=\"singular\"><primary>API (application programming "
"interface)</primary><secondary>API server</secondary></indexterm>"
msgstr "データベースやメッセージキューのように、１台以上の<glossterm>API サーバー</glossterm> を設置する事は良い案です。<code>nova-api</code>　サービスを高可用にするために、伝統的な HTTP 負荷分散技術を利用することができます。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml526(title)
msgid "Extensions"
msgstr "API 拡張"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml528(para)
msgid ""
"The <link href=\"http://docs.openstack.org/api/api-specs.html\" title=\"API "
"Specifications\">API Specifications</link> define the core actions, "
"capabilities, and mediatypes of the OpenStack API. A client can always "
"depend on the availability of this core API, and implementers are always "
"required to support it in its <phrase role=\"keep-"
"together\">entirety</phrase>. Requiring strict adherence to the core API "
"allows clients to rely upon a minimal level of functionality when "
"interacting with multiple implementations of the same API.<indexterm "
"class=\"singular\"><primary>extensions</primary><secondary>design "
"considerations</secondary></indexterm><indexterm "
"class=\"singular\"><primary>design "
"considerations</primary><secondary>extensions</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml546(para)
msgid ""
"The OpenStack Compute API is extensible. An extension adds capabilities to "
"an API beyond those defined in the core. The introduction of new features, "
"MIME types, actions, states, headers, parameters, and resources can all be "
"accomplished by means of extensions to the core API. This allows the "
"introduction of new features in the API without requiring a version change "
"and allows the introduction of vendor-specific niche functionality."
msgstr "OpenStack Compute API は拡張可能です。ある拡張は、ある API にコア定義を超えたケイパビリティを追加します。新機能、新しい MIME タイプ、アクション、状態、ヘッダ、パラメータ、そしてリソースの導入は、コア API の拡張によって達成することができます。これにより、API に対してバージョンを変更することなく新機能を導入することができ、ベンダー固有の特定の機能を導入することもできます。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml556(title)
msgid "Scheduling"
msgstr "スケジューリング"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml558(para)
msgid ""
"The scheduling services are responsible for determining the compute or "
"storage node where a virtual machine or block storage volume should be "
"created. The scheduling services receive creation requests for these "
"resources from the message queue and then begin the process of determining "
"the appropriate node where the resource should reside. This process is done "
"by applying a series of user-configurable filters against the available "
"collection of nodes.<indexterm "
"class=\"singular\"><primary>schedulers</primary><secondary>design "
"considerations</secondary></indexterm><indexterm "
"class=\"singular\"><primary>design "
"considerations</primary><secondary>scheduling</secondary></indexterm>"
msgstr "スケジューリングサービスは仮想マシンやブロックストレージのボリュームがどのコンピュートあるはストレージノードで生成されるかを決定する事に責任を持ちます。スケジューリングサービスはメッセージキューからそれらのリソースの生成リクエストを受け、どのリソースが適切かを決定するプロセスを起動します。このプロセスは利用可能なノード郡からユーザが設定したフィルタを適用する事で実行されます。<indexterm class=\"singular\"><primary>スケジューラー</primary><secondary>設計上の考慮事項</secondary></indexterm><indexterm class=\"singular\"><primary>設計上の考慮事項</primary><secondary>スケジューリング</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml574(para)
msgid ""
"There are currently two schedulers: <literal>nova-scheduler</literal> for "
"virtual machines and <literal>cinder-scheduler</literal> for block storage "
"volumes. Both schedulers are able to scale horizontally, so for high-"
"availability purposes, or for very large or high-schedule-frequency "
"installations, you should consider running multiple instances of each "
"scheduler. The schedulers all listen to the shared message queue, so no "
"special load balancing is required."
msgstr "現在のところ2つのスケジューラがあります：仮想サーバを受け持つ<literal>nova-scheduler</literal> とブロックストレージボリュームを受け持つ<literal>cinder-scheduler</literal> です。それぞれのスケジューラは高可用性目的や、高負荷環境での実装のために水平方向にスケーリングが可能で、それぞれのスケジューラに対して複数のインスタンスを起動すべきです。スケジューラはすべて共有されたメッセージキューをリスンするので特別な負荷分散は必要ありません。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml587(para)
msgid ""
"The OpenStack Image Service consists of two parts: <code>glance-api</code> "
"and <code>glance-registry</code>. The former is responsible for the delivery"
" of images; the compute node uses it to download images from the backend. "
"The latter maintains the metadata information associated with virtual "
"machine images and requires a database.<indexterm "
"class=\"singular\"><primary>glance</primary><secondary>glance "
"registry</secondary></indexterm><indexterm "
"class=\"singular\"><primary>glance</primary><secondary>glance API "
"server</secondary></indexterm><indexterm "
"class=\"singular\"><primary>metadata</primary><secondary>OpenStack Image "
"Service and</secondary></indexterm><indexterm "
"class=\"singular\"><primary>Image Service</primary><secondary>design "
"considerations</secondary></indexterm><indexterm "
"class=\"singular\"><primary>design "
"considerations</primary><secondary>images</secondary></indexterm>"
msgstr "OpenStackイメージサービスは<code>glance-api</code> と<code>glance-registry</code>の2つのパートから成り立っています。前者はコンピュートノードがバックエンドからイメージをダウンロードする際の、イメージの配信に責任を持ちます。後者は仮想マシンに属し、データベースを必要とするメタデータの情報をメンテナンスします。<indexterm class=\"singular\"><primary>glance</primary><secondary>glance registry</secondary></indexterm><indexterm class=\"singular\"><primary>glance</primary><secondary>glance API サーバ</secondary></indexterm><indexterm class=\"singular\"><primary>メタデータ</primary><secondary>OpenStack イメージサービスと</secondary></indexterm><indexterm class=\"singular\"><primary>イメージサービス</primary><secondary>設計上の考慮事項</secondary></indexterm><indexterm class=\"singular\"><primary>設計上の考慮事項</primary><secondary>イメージ</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml614(para)
msgid ""
"The <code>glance-api</code> part is an abstraction layer that allows a "
"choice of backend. Currently, it supports:"
msgstr "<code>glance-api</code>部はバックエンドを選択する事ができる抽象的なレイヤーです。現在、以下をサポートしています："

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml619(term)
msgid "OpenStack Object Storage"
msgstr "OpenStack オブジェクトストレージ"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml622(para)
msgid "Allows you to store images as objects."
msgstr "イメージをオブジェクトとして格納する事を許可します"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml627(term)
msgid "File system"
msgstr "ファイルシステム"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml630(para)
msgid "Uses any traditional file system to store the images as files."
msgstr "イメージをファイルとして格納するために一般的なファイルシステムを使用します。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml636(term)
msgid "S3"
msgstr "S3"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml639(para)
msgid "Allows you to fetch images from Amazon S3."
msgstr "Amazon S3からイメージを取得する事を許可します。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml644(term)
msgid "HTTP"
msgstr "HTTP"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml647(para)
msgid ""
"Allows you to fetch images from a web server. You cannot write images by "
"using this mode."
msgstr "イメージをウェブサーバから取得する事を許可します。このモードではイメージの書き込みはできません。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml653(para)
msgid ""
"If you have an OpenStack Object Storage service, we recommend using this as "
"a scalable place to store your images. You can also use a file system with "
"sufficient performance or Amazon S3—unless you do not need the ability to "
"upload new images through OpenStack."
msgstr "OpenStack Storageサービスがある場合は、イメージを保存するためにスケーラブルな場所を利用する事を推奨します。また、OpenStackをとおして新しいイメージをアップロードする必要がない場合を除いて、十分な性能を備えたファイルシステムかAmazon S3を使用する事もできます。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml660(title)
msgid "Dashboard"
msgstr "ダッシュボード"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml662(para)
msgid ""
"The OpenStack dashboard (horizon) provides a web-based user interface to the"
" various OpenStack components. The dashboard includes an end-user area for "
"users to manage their virtual infrastructure and an admin area for cloud "
"operators to manage the OpenStack environment as a whole.<indexterm "
"class=\"singular\"><primary>dashboard</primary></indexterm><indexterm "
"class=\"singular\"><primary>design "
"considerations</primary><secondary>dashboard</secondary></indexterm>"
msgstr "OpenStackダッシュボード(horizon)は様々なOpenStackコンポーネントのウェブベースユーザーインターフェースを提供します。ダッシュボードにはエンドユーザの仮想インフラを管理するための領域と、OpenStack環境全体を管理するためのクラウド管理者のための管理者領域が含まれます。<indexterm class=\"singular\"><primary>ダッシュボード</primary></indexterm><indexterm class=\"singular\"><primary>設計上の考慮事項</primary><secondary>ダッシュボード</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml674(para)
msgid ""
"The dashboard is implemented as a Python web application that normally runs "
"in <glossterm>Apache</glossterm><code>httpd</code>. Therefore, you may treat"
" it the same as any other web application, provided it can reach the API "
"servers (including their admin endpoints) over the <phrase role=\"keep-"
"together\">network</phrase>.<indexterm "
"class=\"singular\"><primary>Apache</primary></indexterm>"
msgstr "ダッシュボードはPythonのウェブアプリケーションとして実装され、通常は<glossterm>Apache</glossterm><code>httpd</code>サーバ上で稼働します。したがって、そこから <phrase role=\"keep-together\">ネットワーク</phrase>経由で (管理者 エンドポイントを含む) API サーバーにアクセスできるという条件の下、他の任意の Web アプリケーションと同じように取り扱うことができます。<indexterm class=\"singular\"><primary>Apache</primary></indexterm>"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml685(title)
msgid "Authentication and Authorization"
msgstr "認証と認可"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml687(para)
msgid ""
"The concepts supporting OpenStack's authentication and authorization are "
"derived from well-understood and widely used systems of a similar nature. "
"Users have credentials they can use to authenticate, and they can be a "
"member of one or more groups (known as projects or tenants, "
"interchangeably).<indexterm "
"class=\"singular\"><primary>credentials</primary></indexterm><indexterm "
"class=\"singular\"><primary>authorization</primary></indexterm><indexterm "
"class=\"singular\"><primary>authentication</primary></indexterm><indexterm "
"class=\"singular\"><primary>design "
"considerations</primary><secondary>authentication/authorization</secondary></indexterm>"
msgstr "OpenStackの認証と承認は良く知られ、幅広いシステムで良く利用されている物から来ています。ユーザは認証のためにクレデンシャルを持ち、1つ以上のグループ(プロジェクトまたはテナントと呼ばれます)のメンバーとなる事ができます。<indexterm class=\"singular\"><primary>クレデンシャル</primary></indexterm><indexterm class=\"singular\"><primary>認証</primary></indexterm><indexterm class=\"singular\"><primary>承認</primary></indexterm><indexterm class=\"singular\"><primary>設計上の考慮事項</primary><secondary>認証/承認</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml703(para)
msgid ""
"For example, a cloud administrator might be able to list all instances in "
"the cloud, whereas a user can see only those in his current group. Resources"
" quotas, such as the number of cores that can be used, disk space, and so "
"on, are associated with a project."
msgstr "例えば、クラウドのユーザは自分の現在のグループに属するインスタンスのみが見えるのに対して、クラウドの管理者はそのクラウドのすべてのインスタンスの一覧をとることができるでしょう。利用可能なコア数、ディスク容量等のリソースのクォータはプロジェクトに対して関連づけられています。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml708(para)
msgid ""
"The OpenStack Identity Service (keystone) is the point that provides the "
"authentication decisions and user attribute information, which is then used "
"by the other OpenStack services to perform authorization. Policy is set in "
"the <filename>policy.json</filename> file. For <phrase role=\"keep-"
"together\">information</phrase> on how to configure these, see <xref "
"linkend=\"projects_users\"/>.<indexterm class=\"singular\"><primary>Identity"
" Service</primary><secondary>authentication "
"decisions</secondary></indexterm><indexterm "
"class=\"singular\"><primary>Identity Service</primary><secondary>plug-in "
"support</secondary></indexterm>"
msgstr "OpenStack Identity Service (Keystone) は、認証の判定とユーザの属性情報を提供する場となり、他の OpenStack サービスから認証のために使用されます。ポリシーは <filename>policy.json</filename> で記述されます。これらを設定するための<phrase role=\"keep-together\">情報</phrase>については、<xref linkend=\"projects_users\"/> を参照してください。<indexterm class=\"singular\"><primary>Identity サービス</primary><secondary>認証の判定</secondary></indexterm><indexterm class=\"singular\"><primary>Identity サービス</primary><secondary>プラグインサポート</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml723(para)
msgid ""
"The Identity Service supports different plug-ins for authentication "
"decisions and identity storage. Examples of these plug-ins include:"
msgstr "Identity サービスは、バックエンド認証と情報保持のために種々のプラグインをサポートしています。これらの選択肢は、現在は以下の物が含まれています。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml728(para)
msgid "In-memory key-value Store (a simplified internal storage structure)"
msgstr "メモリ内のキーバリュー型ストア（シンプルな内部ストレージ構造）"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml733(para)
msgid "SQL database (such as MySQL or PostgreSQL)"
msgstr "SQL データベース (MySQL や PostgreSQL など)"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml737(para)
msgid "PAM (Pluggable Authentication Module)"
msgstr "PAM (Pluggable Authentication Module)"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml741(para)
msgid "LDAP (such as OpenLDAP or Microsoft's Active Directory)"
msgstr "LDAP (OpenLDAP や Microsoft の Active Directory)"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml745(para)
msgid ""
"Many deployments use the SQL database; however, LDAP is also a popular "
"choice for those with existing authentication infrastructure that needs to "
"be integrated."
msgstr "多くのデプロイメントで SQL データベースが使われていますが、既存の認証インフラとインテグレーションする必要のある環境では、LDAP もポピュラーな選択肢です。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml751(title)
msgid "Network Considerations"
msgstr "ネットワークの考慮事項"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml753(para)
msgid ""
"Because the cloud controller handles so many different services, it must be "
"able to handle the amount of traffic that hits it. For example, if you "
"choose to host the OpenStack Imaging Service on the cloud controller, the "
"cloud controller should be able to support the transferring of the images at"
" an acceptable speed.<indexterm class=\"singular\"><primary>cloud "
"controllers</primary><secondary>network traffic "
"and</secondary></indexterm><indexterm "
"class=\"singular\"><primary>networks</primary><secondary>design "
"considerations</secondary></indexterm><indexterm "
"class=\"singular\"><primary>design "
"considerations</primary><secondary>networks</secondary></indexterm>"
msgstr "クラウドコントローラーは非常に多くのサービスを取り扱うため、それらすべてのトラフィックを処理できなければなりません。例えば、クラウドコントローラー上に OpenStack イメージ サービスを乗せることにした場合、そのクラウドコントローラーは許容可能な速度でイメージの転送できなければなりません。<indexterm class=\"singular\"><primary>クラウドコントローラー</primary><secondary>ネットワークトラフィック</secondary></indexterm><indexterm class=\"singular\"><primary>ネットワーク</primary><secondary>設計上の考慮事項</secondary></indexterm><indexterm class=\"singular\"><primary>設計上の考慮事項</primary><secondary>ネットワーク</secondary></indexterm>"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml771(para)
msgid ""
"As another example, if you choose to use single-host networking where the "
"cloud controller is the network gateway for all instances, then the cloud "
"controller must support the total amount of traffic that travels between "
"your cloud and the public Internet."
msgstr "他の例としては、クラウドコントローラーがすべてのインスタンスのゲートウェイとなるような単一ホスト・ネットワークモデルを使うことにした場合、クラウドコントローラーは外部インターネットとあなたのクラウドの間でやりとりされるすべてのトラフィックを支えられなければなりません。"

#: ./doc/openstack-ops/ch_arch_cloud_controller.xml776(para)
msgid ""
"We recommend that you use a fast NIC, such as 10 GB. You can also choose to "
"use two 10 GB NICs and bond them together. While you might not be able to "
"get a full bonded 20 GB speed, different transmission streams use different "
"NICs. For example, if the cloud controller transfers two images, each image "
"uses a different NIC and gets a full 10 GB of bandwidth.<indexterm "
"class=\"singular\"><primary>bandwidth</primary><secondary>design "
"considerations for</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml12(title)
msgid "Logging and Monitoring"
msgstr "ロギングと監視"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml14(para)
msgid ""
"As an OpenStack cloud is composed of so many different services, there are a"
" large number of log files. This chapter aims to assist you in locating and "
"working with them and describes other ways to track the status of your "
"deployment.<indexterm "
"class=\"singular\"><primary>debugging</primary><see>logging/monitoring; "
"maintenance/debugging</see></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml24(title)
msgid "Where Are the Logs?"
msgstr "ログはどこにあるのか？"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml26(para)
msgid ""
"Most services use the convention of writing their log files to "
"subdirectories of the <code>/var/log directory</code>, as listed in <xref "
"linkend=\"openstack-log-locations\"/>.<indexterm "
"class=\"singular\"><primary>cloud controllers</primary><secondary>log "
"information</secondary></indexterm><indexterm "
"class=\"singular\"><primary>logging/monitoring</primary><secondary>log "
"location</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml39(caption)
msgid "OpenStack log locations"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml43(th)
msgid "Node type"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml45(th)
msgid "Service"
msgstr "サービス"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml47(th)
msgid "Log location"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml53(para)
#: ./doc/openstack-ops/ch_ops_log_monitor.xml61(para)
#: ./doc/openstack-ops/ch_ops_log_monitor.xml69(para)
#: ./doc/openstack-ops/ch_ops_log_monitor.xml77(para)
#: ./doc/openstack-ops/ch_ops_log_monitor.xml85(para)
#: ./doc/openstack-ops/ch_ops_log_monitor.xml93(para)
msgid "Cloud controller"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml55(code)
msgid "nova-*"
msgstr "nova-*"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml57(code)
msgid "/var/log/nova"
msgstr "/var/log/nova"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml63(code)
msgid "glance-*"
msgstr "glance-*"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml65(code)
msgid "/var/log/glance"
msgstr "/var/log/glance"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml71(code)
msgid "cinder-*"
msgstr "cinder-*"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml73(code)
msgid "/var/log/cinder"
msgstr "/var/log/cinder"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml79(code)
msgid "keystone-*"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml81(code)
msgid "/var/log/keystone"
msgstr "/var/log/keystone"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml87(code)
msgid "neutron-*"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml89(code)
msgid "/var/log/neutron"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml97(code)
msgid "/var/log/apache2/"
msgstr "/var/log/apache2/"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml101(para)
msgid "All nodes"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml103(para)
msgid "misc (swift, dnsmasq)"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml105(code)
msgid "/var/log/syslog"
msgstr "/var/log/syslog"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml109(para)
#: ./doc/openstack-ops/ch_ops_log_monitor.xml117(para)
msgid "Compute nodes"
msgstr "コンピュートノード"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml111(para)
msgid "libvirt"
msgstr "libvirt"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml113(code)
msgid "/var/log/libvirt/libvirtd.log"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml119(para)
msgid "Console (boot up messages) for VM instances:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml121(code)
msgid "/var/lib/nova/instances/instance-"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml122(code)
msgid "&lt;instance id&gt;/console.log"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml127(para)
msgid "Block Storage nodes"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml129(para)
msgid "cinder-volume"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml131(code)
msgid "/var/log/cinder/cinder-volume.log"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml139(title)
msgid "Reading the Logs"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml141(para)
msgid ""
"OpenStack services use the standard logging levels, at increasing severity: "
"DEBUG, INFO, AUDIT, WARNING, ERROR, CRITICAL, and TRACE. That is, messages "
"only appear in the logs if they are more \"severe\" than the particular log "
"level, with DEBUG allowing all log statements through. For example, TRACE is"
" logged only if the software has a stack trace, while INFO is logged for "
"every message including those that are only for information.<indexterm "
"class=\"singular\"><primary>logging/monitoring</primary><secondary>logging "
"levels</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml153(para)
msgid ""
"To disable DEBUG-level logging, edit "
"<filename>/etc/nova/nova.conf</filename> as follows:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml158(para)
msgid ""
"Keystone is handled a little differently. To modify the logging level, edit "
"the <filename>/etc/keystone/logging.conf</filename> file and look at the "
"<code>logger_root</code> and <code>handler_file</code> sections."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml163(para)
msgid ""
"<phrase role=\"keep-together\">Logging for horizon is configured in "
"<filename>/etc/openstack_dashboard/local_</filename></phrase><filename>settings.py</filename>."
" Because horizon is a Django web application, it follows the <link "
"href=\"https://docs.djangoproject.com/en/dev/topics/logging/\" "
"title=\"Django Logging\">Django Logging framework conventions</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml169(para)
msgid ""
"The first step in finding the source of an error is typically to search for "
"a CRITICAL, TRACE, or ERROR message in the log starting at the bottom of the"
" log file.<indexterm "
"class=\"singular\"><primary>logging/monitoring</primary><secondary>reading "
"log messages</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml177(para)
msgid ""
"Here is an example of a CRITICAL log message, with the corresponding TRACE "
"(Python traceback) immediately following:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml211(para)
msgid ""
"In this example, <literal>cinder-volumes</literal> failed to start and has "
"provided a stack trace, since its volume backend has been unable to set up "
"the storage volume—probably because the LVM volume that is expected from the"
" configuration does not exist."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml216(para)
msgid "Here is an example error log:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml221(para)
msgid ""
"In this error, a nova service has failed to connect to the RabbitMQ server "
"because it got a connection refused error."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml226(title)
msgid "Tracing Instance Requests"
msgstr "インスタンスリクエストの追跡"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml228(para)
msgid ""
"When an instance fails to behave properly, you will often have to trace "
"activity associated with that instance across the log files of various "
"<code>nova-*</code> services and across both the cloud controller and "
"compute nodes.<indexterm "
"class=\"singular\"><primary>instances</primary><secondary>tracing instance "
"requests</secondary></indexterm><indexterm "
"class=\"singular\"><primary>logging/monitoring</primary><secondary>tracing "
"instance requests</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml241(para)
msgid ""
"The typical way is to trace the UUID associated with an instance across the "
"service logs."
msgstr "一般的な方法はインスタンスのUUIDをキーにして、各サービスのログを追跡することです。"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml244(para)
msgid "Consider the following example:"
msgstr "次のような例を考えてみましょう。"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml253(para)
msgid ""
"Here, the ID associated with the instance is "
"<code>faf7ded8-4a46-413b-b113-f19590746ffe</code>. If you search for this "
"string on the cloud controller in the "
"<filename>/var/log/nova-*.log</filename> files, it appears in <filename"
">nova-api.log</filename> and <filename>nova-scheduler.log</filename>. If you"
" search for this on the compute nodes in "
"<filename>/var/log/nova-*.log</filename>, it appears in <filename>nova-"
"network.log</filename> and <filename>nova-compute.log</filename>. If no "
"ERROR or CRITICAL messages appear, the most recent log entry that reports "
"this may provide a hint about what has gone wrong."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml267(title)
msgid "Adding Custom Logging Statements"
msgstr "カスタムログの追加"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml269(para)
msgid ""
"If there is not enough information in the existing logs, you may need to add"
" your own custom logging statements to the <code>nova-*</code> "
"services.<indexterm "
"class=\"singular\"><primary>customization</primary><secondary>custom log "
"statements</secondary></indexterm><indexterm "
"class=\"singular\"><primary>logging/monitoring</primary><secondary>adding "
"custom log statements</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml281(para)
msgid ""
"The source files are located in <filename>/usr/lib/python2.7/dist-"
"packages/nova</filename>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml284(para)
msgid ""
"To add logging statements, the following line should be near the top of the "
"file. For most files, these should already be there:"
msgstr "ログステートメントを追加するには、次の行をファイルの先頭に置きます。ほとんどのファイルでは、これらは既に存在します。"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml290(para)
msgid "To add a DEBUG logging statement, you would do:"
msgstr "DEBUGログステートメントを追加するには次のようにします。"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml294(para)
msgid ""
"You may notice that all the existing logging messages are preceded by an "
"underscore and surrounded by parentheses, for example:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml299(para)
msgid ""
"This formatting is used to support translation of logging messages into "
"different languages using the <link "
"href=\"https://docs.python.org/2/library/gettext.html\">gettext</link> "
"internationalization library. You don't need to do this for your own custom "
"log messages. However, if you want to contribute the code back to the "
"OpenStack project that includes logging statements, you must surround your "
"log messages with underscores and parentheses."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml309(title)
msgid "RabbitMQ Web Management Interface or rabbitmqctl"
msgstr "RabbitMQ Web管理インターフェイス および rabbitmqctl"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml311(para)
msgid ""
"Aside from connection failures, RabbitMQ log files are generally not useful "
"for debugging OpenStack related issues. Instead, we recommend you use the "
"RabbitMQ web management interface.<indexterm "
"class=\"singular\"><primary>RabbitMQ</primary></indexterm><indexterm "
"class=\"singular\"><primary>logging/monitoring</primary><secondary>RabbitMQ "
"web management interface</secondary></indexterm> Enable it on your cloud "
"controller:<indexterm class=\"singular\"><primary>cloud "
"controllers</primary><secondary>enabling RabbitMQ</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml330(para)
msgid ""
"The RabbitMQ web management interface is accessible on your cloud controller"
" at <emphasis>http://localhost:55672</emphasis>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml334(para)
msgid ""
"Ubuntu 12.04 installs RabbitMQ version 2.7.1, which uses port 55672. "
"RabbitMQ versions 3.0 and above use port 15672 instead. You can check which "
"version of RabbitMQ you have running on your local Ubuntu machine by doing:"
msgstr "Ubuntu 12.04はRabiitMQのバージョン2.7.1を55672番ポートを使うようにインストールします。RabbitMQバージョン3.0以降では15672が利用されます。Ubuntuマシン上でどのバージョンのRabbitMQが実行されているかは次のように確認できます。"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml343(para)
msgid ""
"An alternative to enabling the RabbitMQ web management interface is to use "
"the <phrase role=\"keep-together\"><literal>rabbitmqctl</literal></phrase> "
"commands. For example, <literal>rabbitmqctl list_queues| grep "
"cinder</literal> displays any messages left in the queue. If there are "
"messages, it's a possible sign that cinder services didn't connect properly "
"to rabbitmq and might have to be restarted."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml350(para)
msgid ""
"Items to monitor for RabbitMQ include the number of items in each of the "
"queues and the processing time statistics for the server."
msgstr "RabbitMQで監視すべき項目としては、各キューでのアイテムの数と、サーバーでの処理時間の統計情報があります。"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml355(title)
msgid "Centrally Managing Logs"
msgstr "ログの集中管理"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml357(para)
msgid ""
"Because your cloud is most likely composed of many servers, you must check "
"logs on each of those servers to properly piece an event together. A better "
"solution is to send the logs of all servers to a central location so that "
"they can all be accessed from the same area.<indexterm "
"class=\"singular\"><primary>logging/monitoring</primary><secondary>central "
"log management</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml367(para)
msgid ""
"Ubuntu uses rsyslog as the default logging service. Since it is natively "
"able to send logs to a remote location, you don't have to install anything "
"extra to enable this feature, just modify the configuration file. In doing "
"this, consider running your logging over a management network or using an "
"encrypted VPN to avoid interception."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml374(title)
msgid "rsyslog Client Configuration"
msgstr "rsyslog クライアント設定"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml376(para)
msgid ""
"To begin, configure all OpenStack components to log to syslog in addition to"
" their standard log file location. Also configure each component to log to a"
" different syslog facility. This makes it easier to split the logs into "
"individual components on the central server:<indexterm "
"class=\"singular\"><primary>rsyslog</primary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml384(para)
msgid "<filename>nova.conf</filename>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml389(para)
msgid ""
"<filename>glance-api.conf</filename> and <filename>glance-"
"registry.conf</filename>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml395(para)
msgid "<filename>cinder.conf</filename>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml400(para)
msgid "<filename>keystone.conf</filename>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml405(para)
msgid "By default, Object Storage logs to syslog."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml407(para)
msgid ""
"Next, create <filename>/etc/rsyslog.d/client.conf</filename> with the "
"following line:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml412(para)
msgid ""
"This instructs rsyslog to send all logs to the IP listed. In this example, "
"the IP points to the cloud controller."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml417(title)
msgid "rsyslog Server Configuration"
msgstr "rsyslog サーバー設定"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml419(para)
msgid ""
"Designate a server as the central logging server. The best practice is to "
"choose a server that is solely dedicated to this purpose. Create a file "
"called <filename>/etc/rsyslog.d/server.conf</filename> with the following "
"contents:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml444(para)
msgid ""
"This example configuration handles the nova service only. It first "
"configures rsyslog to act as a server that runs on port 514. Next, it "
"creates a series of logging templates. Logging templates control where "
"received logs are stored. Using the last example, a nova log from "
"c01.example.com goes to the following locations:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml452(filename)
msgid "/var/log/rsyslog/c01.example.com/nova.log"
msgstr "/var/log/rsyslog/c01.example.com/nova.log"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml456(filename)
#: ./doc/openstack-ops/ch_ops_log_monitor.xml468(filename)
msgid "/var/log/rsyslog/nova.log"
msgstr "/var/log/rsyslog/nova.log"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml460(para)
msgid "This is useful, as logs from c02.example.com go to:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml464(filename)
msgid "/var/log/rsyslog/c02.example.com/nova.log"
msgstr "/var/log/rsyslog/c02.example.com/nova.log"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml472(para)
msgid ""
"You have an individual log file for each compute node as well as an "
"aggregated log that contains nova logs from all nodes."
msgstr ""

#. FIXME This section needs updating, especially with the advent of
#.          ceilometer
#: ./doc/openstack-ops/ch_ops_log_monitor.xml481(title)
msgid "StackTach"
msgstr "StackTach"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml483(para)
msgid ""
"StackTach is a tool created by Rackspace to collect and report the "
"notifications sent by <code>nova</code>. Notifications are essentially the "
"same as logs but can be much more detailed. A good overview of notifications"
" can be found at <link "
"href=\"https://wiki.openstack.org/wiki/SystemUsageData\" title=\"StackTach "
"GitHub repo\">System Usage Data</link>.<indexterm "
"class=\"singular\"><primary>StackTach</primary></indexterm><indexterm "
"class=\"singular\"><primary>logging/monitoring</primary><secondary>StackTack"
" tool</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml496(para)
msgid ""
"To enable <code>nova</code> to send notifications, add the following to "
"<filename>nova.conf</filename>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml502(para)
msgid ""
"Once <code>nova</code> is sending notifications, install and configure "
"StackTach. Since StackTach is relatively new and constantly changing, "
"installation instructions would quickly become outdated. Please refer to the"
" <link href=\"https://github.com/rackerlabs/stacktach\">StackTach GitHub "
"repo</link> for instructions as well as a demo video."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml510(title)
msgid "Monitoring"
msgstr "監視"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml512(para)
msgid ""
"There are two types of monitoring: watching for problems and watching usage "
"trends. The former ensures that all services are up and running, creating a "
"functional cloud. The latter involves monitoring resource usage over time in"
" order to make informed decisions about potential bottlenecks and "
"upgrades.<indexterm class=\"singular\"><primary>cloud "
"controllers</primary><secondary>process monitoring "
"and</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml525(title)
msgid "Nagios"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml527(para)
msgid ""
"Nagios is an open source monitoring service. It's capable of executing "
"arbitrary commands to check the status of server and network services, "
"remotely executing arbitrary commands directly on servers, and allowing "
"servers to push notifications back in the form of passive monitoring. Nagios"
" has been around since 1999. Although newer monitoring services are "
"available, Nagios is a tried-and-true systems administration "
"staple.<indexterm class=\"singular\"><primary>Nagios</primary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml539(title)
msgid "Process Monitoring"
msgstr "プロセス監視"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml541(para)
msgid ""
"A basic type of alert monitoring is to simply check and see whether a "
"required process is running.<indexterm "
"class=\"singular\"><primary>monitoring</primary><secondary>process "
"monitoring</secondary></indexterm><indexterm "
"class=\"singular\"><primary>process "
"monitoring</primary></indexterm><indexterm "
"class=\"singular\"><primary>logging/monitoring</primary><secondary>process "
"monitoring</secondary></indexterm> For example, ensure that the <code>nova-"
"api</code> service is running on the cloud controller:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml568(para)
msgid ""
"You can create automated alerts for critical processes by using Nagios and "
"NRPE. For example, to ensure that the <code>nova-compute</code> process is "
"running on compute nodes, create an alert on your Nagios server that looks "
"like this:"
msgstr "NagiosとNRPEを使って、クリティカルなプロセスの自動化されたアラートを作成することが可能です。<code>nova-compute</code> プロセスがコンピュートノードで動作していることを保証するために、Nagiosサーバー上で次のようなアラートを作成します。"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml582(para)
msgid ""
"Then on the actual compute node, create the following NRPE configuration:"
msgstr "そして、対象のコンピュートノードにおいて、次のようなNRPE設定を作成します。"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml588(para)
msgid ""
"Nagios checks that at least one <literal>nova-compute</literal> service is "
"running at all times."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml593(title)
msgid "Resource Alerting"
msgstr "リソースのアラート"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml595(para)
msgid ""
"Resource alerting provides notifications when one or more resources are "
"critically low. While the monitoring thresholds should be tuned to your "
"specific OpenStack environment, monitoring resource usage is not specific to"
" OpenStack at all—any generic type of alert will work fine.<indexterm "
"class=\"singular\"><primary>monitoring</primary><secondary>resource "
"alerting</secondary></indexterm><indexterm "
"class=\"singular\"><primary>alerts</primary><secondary>resource</secondary></indexterm><indexterm"
" class=\"singular\"><primary>resources</primary><secondary>resource "
"alerting</secondary></indexterm><indexterm "
"class=\"singular\"><primary>logging/monitoring</primary><secondary>resource "
"alerting</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml617(para)
msgid "Some of the resources that you want to monitor include:"
msgstr "監視項目に含む幾つかのリソースをあげます。"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml621(para)
msgid "Disk usage"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml625(para)
msgid "Server load"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml629(para)
msgid "Memory usage"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml633(para)
msgid "Network I/O"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml637(para)
msgid "Available vCPUs"
msgstr "利用可能な vCPU 数"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml641(para)
msgid ""
"For example, to monitor disk capacity on a compute node with Nagios, add the"
" following to your Nagios configuration:"
msgstr "例として、コンピュートノード上のディスク容量をNagiosを使って監視する場合、次のようなNagios設定を追加します。"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml652(para)
msgid "On the compute node, add the following to your NRPE configuration:"
msgstr "コンピュートノード上では、次のようなNRPE設定を追加します。"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml658(para)
msgid ""
"Nagios alerts you with a WARNING when any disk on the compute node is 80 "
"percent full and CRITICAL when 90 percent is full."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml663(title)
msgid "Metering and Telemetry with Ceilometer"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml665(para)
msgid ""
"An integrated OpenStack project (code-named ceilometer) collects metering "
"data and provides alerts for Compute, Storage, and Networking. Data "
"collected by the metering system could be used for billing. Depending on "
"deployment configuration, metered data may be accessible to users based on "
"the deployment configuration. The Telemetry service provides a REST API "
"documented at <link href=\"http://developer.openstack.org/api-ref-"
"telemetry-v2.html\"/>. You can read more about the project at <link "
"href=\"http://docs.openstack.org/developer/ceilometer\"/>.<indexterm "
"class=\"singular\"><primary>monitoring</primary><secondary>metering and "
"telemetry</secondary></indexterm><indexterm "
"class=\"singular\"><primary>telemetry/metering</primary></indexterm><indexterm"
" "
"class=\"singular\"><primary>metering/telemetry</primary></indexterm><indexterm"
" class=\"singular\"><primary>ceilometer</primary></indexterm><indexterm "
"class=\"singular\"><primary>logging/monitoring</primary><secondary>ceilometer"
" project</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml692(title)
msgid "OpenStack-Specific Resources"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml694(para)
msgid ""
"Resources such as memory, disk, and CPU are generic resources that all "
"servers (even non-OpenStack servers) have and are important to the overall "
"health of the server. When dealing with OpenStack specifically, these "
"resources are important for a second reason: ensuring that enough are "
"available to launch instances. There are a few ways you can see OpenStack "
"resource usage.<indexterm "
"class=\"singular\"><primary>monitoring</primary><secondary>OpenStack-"
"specific resources</secondary></indexterm><indexterm "
"class=\"singular\"><primary>resources</primary><secondary>generic vs. "
"OpenStack-specific</secondary></indexterm><indexterm "
"class=\"singular\"><primary>logging/monitoring</primary><secondary"
">OpenStack-specific resources</secondary></indexterm> The first is through "
"the <code>nova</code> command:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml716(para)
msgid ""
"This command displays a list of how many instances a tenant has running and "
"some light usage statistics about the combined instances. This command is "
"useful for a quick overview of your cloud, but it doesn't really get into a "
"lot of details."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml721(para)
msgid ""
"Next, the <code>nova</code> database contains three tables that store usage "
"information."
msgstr "次に <code>nova</code> データベースは 利用情報に関して3つのテーブルを持っています。"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml724(para)
msgid ""
"The <code>nova.quotas</code> and <code>nova.quota_usages</code> tables store"
" quota information. If a tenant's quota is different from the default quota "
"settings, its quota is stored in the <phrase role=\"keep-"
"together\"><code>nova.quotas</code></phrase> table. For example:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml745(para)
msgid ""
"The <code>nova.quota_usages</code> table keeps track of how many resources "
"the tenant currently has in use:"
msgstr "<code>nova.quota_usages</code>テーブルはどのくらいリソースをテナントが利用しているかを記録しています。"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml761(para)
msgid ""
"By comparing a tenant's hard limit with their current resource usage, you "
"can see their usage percentage. For example, if this tenant is using 1 "
"floating IP out of 10, then they are using 10 percent of their floating IP "
"quota. Rather than doing the calculation manually, you can use SQL or the "
"scripting language of your choice and create a formatted report:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml790(para)
msgid ""
"The preceding information was generated by using a custom script that can be"
" found on <link href=\"https://github.com/cybera/novac/blob/dev/libexec"
"/novac-quota-report\">GitHub</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml795(para)
msgid ""
"This script is specific to a certain OpenStack installation and must be "
"modified to fit your environment. However, the logic should easily be "
"transferable."
msgstr "このスクリプトは特定のOpenStackインストール環境向けなので、自身の環境に適用する際には変更しなくてはいけませんが、ロジックは簡単に変更できるでしょう。"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml802(title)
msgid "Intelligent Alerting"
msgstr "インテリジェントなアラート"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml804(para)
msgid ""
"Intelligent alerting can be thought of as a form of continuous integration "
"for operations. For example, you can easily check to see whether the Image "
"Service is up and running by ensuring that the <code>glance-api</code> and "
"<code>glance-registry</code> processes are running or by seeing whether "
"<code>glace-api</code> is responding on port 9292.<indexterm "
"class=\"singular\"><primary>monitoring</primary><secondary>intelligent "
"alerting</secondary></indexterm><indexterm "
"class=\"singular\"><primary>alerts</primary><secondary>intelligent</secondary><seealso>logging/monitoring</seealso></indexterm><indexterm"
" class=\"singular\"><primary>intelligent "
"alerting</primary></indexterm><indexterm "
"class=\"singular\"><primary>logging/monitoring</primary><secondary>intelligent"
" alerting</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml827(para)
msgid ""
"But how can you tell whether images are being successfully uploaded to the "
"Image Service? Maybe the disk that Image Service is storing the images on is"
" full or the S3 backend is down. You could naturally check this by doing a "
"quick image upload:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml847(para)
msgid ""
"By taking this script and rolling it into an alert for your monitoring "
"system (such as Nagios), you now have an automated way of ensuring that "
"image uploads to the Image Catalog are working."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml852(para)
msgid ""
"You must remove the image after each test. Even better, test whether you can"
" successfully delete an image from the Image Service."
msgstr "毎回テスト後にイメージを削除する必要があります。イメージサービスからイメージが削除できるかのテストにしてしまえば、さらによいです。"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml857(para)
msgid ""
"Intelligent alerting takes considerably more time to plan and implement than"
" the other alerts described in this chapter. A good outline to implement "
"intelligent alerting is:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml863(para)
msgid "Review common actions in your cloud."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml867(para)
msgid "Create ways to automatically test these actions."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml871(para)
msgid "Roll these tests into an alerting system."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml875(para)
msgid "Some other examples for Intelligent Alerting include:"
msgstr "インテリジェントなアラートのその他の例としては以下があります。"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml879(para)
msgid "Can instances launch and be destroyed?"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml883(para)
msgid "Can users be created?"
msgstr "ユーザの作成は可能か?"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml887(para)
msgid "Can objects be stored and deleted?"
msgstr "オブジェクトの保存と削除は可能か?"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml891(para)
msgid "Can volumes be created and destroyed?"
msgstr "ボリュームの作成と削除は可能か?"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml897(title)
msgid "Trending"
msgstr "トレンド"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml899(para)
msgid ""
"Trending can give you great insight into how your cloud is performing day to"
" day. You can learn, for example, if a busy day was simply a rare occurrence"
" or if you should start adding new compute nodes.<indexterm "
"class=\"singular\"><primary>monitoring</primary><secondary>trending</secondary><seealso>logging/monitoring</seealso></indexterm><indexterm"
" class=\"singular\"><primary>trending</primary><secondary>monitoring cloud "
"performance with</secondary></indexterm><indexterm "
"class=\"singular\"><primary>logging/monitoring</primary><secondary>trending</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml918(para)
msgid ""
"Trending takes a slightly different approach than alerting. While alerting "
"is interested in a binary result (whether a check succeeds or fails), "
"trending records the current state of something at a certain point in time. "
"Once enough points in time have been recorded, you can see how the value has"
" changed over time.<indexterm "
"class=\"singular\"><primary>trending</primary><secondary>vs. "
"alerts</secondary></indexterm><indexterm "
"class=\"singular\"><primary>binary</primary><secondary>binary results in "
"trending</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml932(para)
msgid ""
"All of the alert types mentioned earlier can also be used for trend "
"reporting. Some other trend examples include:<indexterm "
"class=\"singular\"><primary>trending</primary><secondary>report "
"examples</secondary></indexterm>"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml942(para)
msgid "The number of instances on each compute node"
msgstr "各コンピュートノード上のインスタンス数"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml946(para)
msgid "The types of flavors in use"
msgstr "使用中のフレーバー"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml950(para)
msgid "The number of volumes in use"
msgstr "使用中のボリューム数"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml954(para)
msgid "The number of Object Storage requests each hour"
msgstr "1時間あたりの Object Storage リクエスト数"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml958(para)
msgid "The number of <literal>nova-api</literal> requests each hour"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml963(para)
msgid "The I/O statistics of your storage services"
msgstr "ストレージサービスの I/O の統計"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml967(para)
msgid ""
"As an example, recording <code>nova-api</code> usage can allow you to track "
"the need to scale your cloud controller. By keeping an eye on <code>nova-"
"api</code> requests, you can determine whether you need to spawn more "
"<literal>nova-api</literal> processes or go as far as introducing an "
"entirely new server to run <code>nova-api</code>. To get an approximate "
"count of the requests, look for standard INFO messages in "
"<code>/var/log/nova/nova-api.log</code>:"
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml977(para)
msgid ""
"You can obtain further statistics by looking for the number of successful "
"requests:"
msgstr "成功したリクエストを検索することで、更なる情報を取得できます。"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml982(para)
msgid ""
"By running this command periodically and keeping a record of the result, you"
" can create a trending report over time that shows whether your <code>nova-"
"api</code> usage is increasing, decreasing, or keeping steady."
msgstr "このコマンドを定期的に実行し結果を記録することで、トレンドレポートを作ることができます。これにより<code>/var/log/nova/nova-api.log</code>の使用量が増えているのか、減っているのか、安定しているのか、を知ることができます。"

#: ./doc/openstack-ops/ch_ops_log_monitor.xml987(para)
msgid ""
"A tool such as collectd can be used to store this information. While "
"collectd is out of the scope of this book, a good starting point would be to"
" use collectd to store the result as a COUNTER data type. More information "
"can be found in <link "
"href=\"https://collectd.org/wiki/index.php/Data_source\">collectd's "
"documentation</link>."
msgstr ""

#: ./doc/openstack-ops/ch_ops_log_monitor.xml999(para)
msgid ""
"For stable operations, you want to detect failure promptly and determine "
"causes efficiently. With a distributed system, it's even more important to "
"track the right items to meet a service-level target. Learning where these "
"logs are located in the file system or API gives you an advantage. This "
"chapter also showed how to read, interpret, and manipulate information from "
"OpenStack services so that you can monitor effectively."
msgstr ""

#. Put one translator per line, in the form of NAME <EMAIL>, YEAR1, YEAR2
#: ./doc/openstack-ops/ch_ops_log_monitor.xml0(None)
msgid "translator-credits"
msgstr "Akihiro MOTOKI <amotoki@gmail.com>, 2013\nAkira Yoshiyama <akirayoshiyama@gmail.com>, 2013\nMasanori Itoh <masanori.itoh@gmail.com>, 2013\nmasayukig <masayuki.igawa@gmail.com>, 2013\n*はたらくpokotan* <>, 2013\nTsutomu TAKEKAWA <takekawa@gmail.com>, 2013\ndoki701 <tokidokidokidoki@gmail.com>, 2013\nTomoyuki KATO <tomo@dream.daynight.jp>, 2012-2013\ntmak <t.makabe@gmail.com>, 2013"
